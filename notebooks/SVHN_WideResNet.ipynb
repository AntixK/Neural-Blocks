{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm_notebook\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "PATH = '/home/antixk/Anand/' #'/home/robot/Anand/'\n",
    "sys.path.append(PATH)\n",
    "\n",
    "from NeuralBlocks.models.wresnet import WideResNet\n",
    "# from NeuralBlocks.models.densenet import DenseNet\n",
    "\n",
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# net1 = DenseNet(3, 10, norm='BN')\n",
    "# net2 = WideResNet(depth=22, num_classes=10, widen_factor=5,dropout_rate=0.3,norm='BN')\n",
    "\n",
    "# print(count_parameters(net1), count_parameters(net2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2456)\n",
    "# cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "np.random.seed(2456)\n",
    "\n",
    "NUM_EPOCH = 200\n",
    "BATCH_SIZE = 128\n",
    "CHECKPOINT_INTERVAL = 100\n",
    "LRS = [0.0001, 0.001, 0.01]\n",
    "NORMS =[None,'BN', 'SN', 'WN', 'MWN', 'MSN', 'MSNTReLU', 'MWNTReLU']\n",
    "DATA_PATH = PATH+\"NeuralBlocks/data_utils/datasets/SVHN/\"\n",
    "SAVE_PATH = PATH+\"NeuralBlocks/experiments/SVHN/\"\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/robot-i9/Anand/NeuralBlocks/data_utils/datasets/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /home/robot-i9/Anand/NeuralBlocks/data_utils/datasets/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "trainset = torchvision.datasets.SVHN(root=DATA_PATH, download=True, transform=transform, split='train')\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.SVHN(root=DATA_PATH, download=True, transform=transform, split='test')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        train_loss_log.append(train_loss/(batch_idx+1))\n",
    "        train_acc_log.append( 100.*correct/total)\n",
    "        \n",
    "        if(batch_idx%CHECKPOINT_INTERVAL==0):\n",
    "             print(\"Train Epoch [{:3d}/{:3d}]Batch [{:3d}/{:3d}] Loss: {:.3f} Acc {:.3f}%\".format(epoch, NUM_EPOCH,batch_idx, len(trainloader),\n",
    "                train_loss/(batch_idx+1), 100.*correct/total))\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            test_loss_log.append(test_loss/(batch_idx+1))\n",
    "            test_acc_log.append( 100.*correct/total)\n",
    "        \n",
    "            if(batch_idx%CHECKPOINT_INTERVAL==0):\n",
    "                print(\"Test Epoch [{:3d}/{:3d}]Batch [{:3d}/{:3d}] Loss: {:.3f} Acc {:.3f}%\".format(epoch, NUM_EPOCH,batch_idx, len(testloader),\n",
    "                test_loss/(batch_idx+1), 100.*correct/total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(SAVE_PATH+'checkpoint'):\n",
    "            os.mkdir(SAVE_PATH+'checkpoint')\n",
    "        torch.save(state, SAVE_PATH+'checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e667392f59584e1089d7db22b3990b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2e4dc1fc9042fba664f8a127202f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9ce565b0c94430bb7913a692321138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.317 Acc 4.688%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.242 Acc 18.464%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.242 Acc 18.676%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.240 Acc 18.732%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.240 Acc 18.742%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.239 Acc 18.777%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Saving..\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.253 Acc 12.500%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.233 Acc 19.013%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.234 Acc 18.921%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.226 Acc 19.651%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.195 Acc 21.160%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.139 Acc 23.408%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.670 Acc 36.719%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.589 Acc 45.591%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.589 Acc 45.725%\n",
      "Saving..\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.674 Acc 43.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.609 Acc 45.042%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.553 Acc 47.054%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.513 Acc 48.572%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.467 Acc 50.251%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.429 Acc 51.608%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 1.143 Acc 61.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 1.065 Acc 64.635%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 1.062 Acc 64.681%\n",
      "Saving..\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.229 Acc 61.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 1.174 Acc 60.721%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 1.143 Acc 61.762%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 1.124 Acc 62.593%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 1.101 Acc 63.558%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 1.082 Acc 64.236%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.901 Acc 67.969%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.846 Acc 72.502%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.841 Acc 72.466%\n",
      "Saving..\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.988 Acc 67.188%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.929 Acc 69.802%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.909 Acc 70.557%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.892 Acc 71.229%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.879 Acc 71.735%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.868 Acc 72.165%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.812 Acc 75.781%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.739 Acc 76.145%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.731 Acc 76.073%\n",
      "Saving..\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.838 Acc 71.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.757 Acc 75.665%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.759 Acc 75.618%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.751 Acc 75.968%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.740 Acc 76.368%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.729 Acc 76.870%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.597 Acc 83.594%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.578 Acc 81.521%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.569 Acc 81.825%\n",
      "Saving..\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.667 Acc 80.469%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.661 Acc 79.069%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.659 Acc 79.275%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.654 Acc 79.376%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.648 Acc 79.584%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.643 Acc 79.753%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.547 Acc 82.812%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.516 Acc 83.888%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.509 Acc 84.021%\n",
      "Saving..\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.490 Acc 88.281%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.588 Acc 81.706%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.579 Acc 81.751%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.574 Acc 82.021%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.572 Acc 82.097%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.568 Acc 82.250%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.532 Acc 86.719%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.483 Acc 84.800%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.476 Acc 85.075%\n",
      "Saving..\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.719 Acc 78.906%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.543 Acc 83.060%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.540 Acc 83.069%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.536 Acc 83.303%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.527 Acc 83.607%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.523 Acc 83.795%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.437 Acc 88.281%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.417 Acc 87.167%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.411 Acc 87.212%\n",
      "Saving..\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.402 Acc 86.719%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.489 Acc 84.901%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.499 Acc 84.523%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.492 Acc 84.699%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.488 Acc 84.860%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.485 Acc 84.968%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.478 Acc 86.719%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.407 Acc 87.399%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.399 Acc 87.601%\n",
      "Saving..\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.558 Acc 83.594%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.464 Acc 85.504%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.455 Acc 85.961%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.455 Acc 85.932%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.452 Acc 85.941%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.451 Acc 86.036%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.399 Acc 89.062%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.367 Acc 88.800%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.360 Acc 88.899%\n",
      "Saving..\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.588 Acc 81.250%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.417 Acc 87.260%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.429 Acc 86.804%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.426 Acc 86.996%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.429 Acc 86.849%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.426 Acc 86.903%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.425 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.359 Acc 89.271%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.352 Acc 89.230%\n",
      "Saving..\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.292 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.428 Acc 86.649%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.419 Acc 86.952%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.419 Acc 87.041%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.413 Acc 87.188%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.409 Acc 87.330%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.410 Acc 89.062%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.345 Acc 89.681%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.337 Acc 89.817%\n",
      "Saving..\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.385 Acc 87.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.400 Acc 87.848%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.398 Acc 87.935%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.397 Acc 87.788%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.398 Acc 87.734%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.393 Acc 87.901%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.366 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.318 Acc 90.849%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.310 Acc 90.889%\n",
      "Saving..\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.540 Acc 85.938%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.384 Acc 88.513%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.382 Acc 88.398%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.381 Acc 88.416%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.377 Acc 88.517%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.376 Acc 88.464%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.389 Acc 92.188%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.318 Acc 90.803%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.311 Acc 90.711%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.339 Acc 90.625%\n",
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.364 Acc 88.869%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.364 Acc 88.740%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.366 Acc 88.777%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.363 Acc 88.862%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.363 Acc 88.882%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.415 Acc 89.062%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.316 Acc 91.027%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.308 Acc 91.107%\n",
      "Saving..\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.384 Acc 85.156%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.356 Acc 89.310%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.354 Acc 89.171%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.349 Acc 89.314%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.344 Acc 89.524%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.346 Acc 89.457%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.378 Acc 89.844%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.310 Acc 90.927%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.303 Acc 90.959%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.335 Acc 89.844%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.334 Acc 89.681%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.338 Acc 89.688%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.337 Acc 89.634%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.335 Acc 89.707%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.338 Acc 89.650%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.374 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.295 Acc 91.406%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.288 Acc 91.515%\n",
      "Saving..\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.370 Acc 86.719%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.334 Acc 89.790%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.327 Acc 90.042%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.328 Acc 90.028%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.332 Acc 89.877%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.329 Acc 89.972%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.339 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.276 Acc 92.087%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.268 Acc 92.230%\n",
      "Saving..\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.334 Acc 91.406%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.338 Acc 90.138%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.318 Acc 90.427%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.318 Acc 90.472%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.320 Acc 90.354%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.320 Acc 90.333%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.268 Acc 92.141%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.260 Acc 92.463%\n",
      "Saving..\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.409 Acc 88.281%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.310 Acc 90.370%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.309 Acc 90.505%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.312 Acc 90.503%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.308 Acc 90.607%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.313 Acc 90.461%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.321 Acc 92.188%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.271 Acc 92.443%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.262 Acc 92.522%\n",
      "Saving..\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.315 Acc 91.406%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.304 Acc 90.726%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.313 Acc 90.528%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.308 Acc 90.692%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.305 Acc 90.771%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.304 Acc 90.818%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.294 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.262 Acc 92.830%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.253 Acc 92.903%\n",
      "Saving..\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.311 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.283 Acc 91.213%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.290 Acc 91.282%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.294 Acc 91.149%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.297 Acc 91.007%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.298 Acc 91.001%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.341 Acc 90.625%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.257 Acc 92.675%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.251 Acc 92.763%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.303 Acc 89.844%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.284 Acc 91.615%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.292 Acc 91.262%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.291 Acc 91.310%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.288 Acc 91.381%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.291 Acc 91.349%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.305 Acc 92.188%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.252 Acc 93.000%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.242 Acc 93.206%\n",
      "Saving..\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.302 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.294 Acc 91.329%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.288 Acc 91.449%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.286 Acc 91.450%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.287 Acc 91.500%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.284 Acc 91.517%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.260 Acc 92.698%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.252 Acc 92.821%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.393 Acc 89.062%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.280 Acc 91.522%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.282 Acc 91.453%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.284 Acc 91.476%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.278 Acc 91.619%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.280 Acc 91.603%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.253 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.238 Acc 93.502%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.230 Acc 93.641%\n",
      "Saving..\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.277 Acc 91.638%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.282 Acc 91.651%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.277 Acc 91.772%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.276 Acc 91.833%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.274 Acc 91.893%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.249 Acc 92.915%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.243 Acc 93.050%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.369 Acc 89.844%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.272 Acc 92.102%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.268 Acc 92.199%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.270 Acc 92.060%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.270 Acc 92.018%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.271 Acc 91.949%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.311 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.239 Acc 93.379%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.234 Acc 93.560%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.265 Acc 90.625%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.268 Acc 91.754%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.269 Acc 91.869%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.269 Acc 91.962%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.269 Acc 91.924%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.268 Acc 91.991%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.303 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.242 Acc 93.680%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.234 Acc 93.692%\n",
      "Saving..\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.351 Acc 88.281%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.264 Acc 92.126%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.258 Acc 92.265%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.258 Acc 92.286%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.259 Acc 92.273%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.237 Acc 93.502%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.231 Acc 93.567%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.190 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.257 Acc 92.713%\n",
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.255 Acc 92.568%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.258 Acc 92.382%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.257 Acc 92.443%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.258 Acc 92.403%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.300 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.231 Acc 93.827%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.224 Acc 93.886%\n",
      "Saving..\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.285 Acc 91.406%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.262 Acc 92.396%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.253 Acc 92.483%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.255 Acc 92.416%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.256 Acc 92.441%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.256 Acc 92.398%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.230 Acc 92.188%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.217 Acc 94.199%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.210 Acc 94.209%\n",
      "Saving..\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.235 Acc 92.969%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.247 Acc 92.667%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.247 Acc 92.580%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.252 Acc 92.553%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.251 Acc 92.571%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.253 Acc 92.526%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.311 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.243 Acc 93.433%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.237 Acc 93.408%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.254 Acc 92.188%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.236 Acc 92.567%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.242 Acc 92.615%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.243 Acc 92.574%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.246 Acc 92.593%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.249 Acc 92.560%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.225 Acc 94.044%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.217 Acc 94.045%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.268 Acc 89.844%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.262 Acc 92.118%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.250 Acc 92.510%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.246 Acc 92.678%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.245 Acc 92.754%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.245 Acc 92.705%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.224 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.221 Acc 94.214%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.216 Acc 94.205%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.195 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.243 Acc 92.860%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.243 Acc 92.918%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.243 Acc 92.888%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.243 Acc 92.885%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.244 Acc 92.883%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.215 Acc 94.261%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.208 Acc 94.325%\n",
      "Saving..\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.238 Acc 93.100%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.241 Acc 92.895%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.239 Acc 92.979%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.238 Acc 92.957%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.238 Acc 92.997%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.235 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.224 Acc 93.851%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.219 Acc 93.812%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.227 Acc 93.154%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.240 Acc 92.868%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.240 Acc 92.886%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.237 Acc 93.006%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.237 Acc 93.000%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.212 Acc 94.570%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.205 Acc 94.547%\n",
      "Saving..\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.218 Acc 93.301%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.224 Acc 93.225%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.236%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.230 Acc 93.216%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.231 Acc 93.167%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.215 Acc 94.384%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.208 Acc 94.380%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.359 Acc 86.719%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.223 Acc 93.216%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.230 Acc 93.116%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.228 Acc 93.221%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.230 Acc 93.150%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.230 Acc 93.162%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.231 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.225 Acc 94.013%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.219 Acc 94.045%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.217 Acc 93.541%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.223 Acc 93.311%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.223 Acc 93.407%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.225 Acc 93.366%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.228 Acc 93.329%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.237 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.216 Acc 94.338%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.209 Acc 94.306%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.389 Acc 93.750%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.237 Acc 93.340%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.235 Acc 93.315%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.229 Acc 93.428%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.229 Acc 93.337%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.228 Acc 93.309%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.206 Acc 94.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.201 Acc 94.535%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.177 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.226 Acc 93.626%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.224 Acc 93.513%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.224 Acc 93.610%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.222 Acc 93.643%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.223 Acc 93.521%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.218 Acc 92.969%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.212 Acc 94.392%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.205 Acc 94.547%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.203 Acc 94.199%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.211 Acc 93.979%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.214 Acc 93.794%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.216 Acc 93.719%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.219 Acc 93.633%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.234 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.202 Acc 94.879%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.197 Acc 94.741%\n",
      "Saving..\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.278 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.220 Acc 93.209%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.219 Acc 93.373%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.219 Acc 93.511%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.222 Acc 93.534%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.220 Acc 93.536%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.195 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.208 Acc 94.609%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.203 Acc 94.632%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.292 Acc 90.625%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.222 Acc 93.464%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.219 Acc 93.711%\n",
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.216 Acc 93.758%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.214 Acc 93.748%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.216 Acc 93.703%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.266 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.208 Acc 94.616%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.203 Acc 94.590%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.205 Acc 94.144%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.212 Acc 93.902%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.210 Acc 93.908%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.212 Acc 93.869%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.214 Acc 93.873%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.198 Acc 94.732%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.194 Acc 94.796%\n",
      "Saving..\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.207 Acc 93.858%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.204 Acc 94.014%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.211 Acc 93.911%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.212 Acc 93.816%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.211 Acc 93.840%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.215 Acc 94.438%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.210 Acc 94.454%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.207 Acc 93.851%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.210 Acc 93.808%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.210 Acc 93.781%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.212 Acc 93.762%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.212 Acc 93.725%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.200 Acc 94.748%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.193 Acc 94.885%\n",
      "Saving..\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.203 Acc 94.090%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.206 Acc 93.917%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.208 Acc 93.926%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.208 Acc 93.859%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.199 Acc 94.887%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.193 Acc 94.939%\n",
      "Saving..\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.219 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.208 Acc 93.982%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.207 Acc 94.007%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.210 Acc 93.849%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.208 Acc 93.947%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.207 Acc 93.959%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.197 Acc 95.065%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.191 Acc 94.998%\n",
      "Saving..\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.285 Acc 91.406%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.207 Acc 93.967%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.208 Acc 93.863%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.208 Acc 93.836%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.207 Acc 93.857%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.206 Acc 93.948%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.195 Acc 94.879%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.189 Acc 94.873%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.194 Acc 94.230%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.198 Acc 94.139%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.200 Acc 94.121%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.202 Acc 94.130%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.202 Acc 94.074%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.200 Acc 94.833%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.195 Acc 94.885%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.197 Acc 94.431%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.210 Acc 94.061%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.204 Acc 94.126%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.205 Acc 94.145%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.205 Acc 94.134%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.240 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.206 Acc 94.957%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.200 Acc 95.064%\n",
      "Saving..\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.200 Acc 94.322%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.195 Acc 94.485%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.196 Acc 94.363%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.200 Acc 94.227%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.200 Acc 94.224%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.197 Acc 94.879%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.191 Acc 94.862%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.189 Acc 94.268%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.194 Acc 94.181%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.197 Acc 94.321%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.196 Acc 94.286%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.196 Acc 94.286%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.193 Acc 95.204%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.185 Acc 95.235%\n",
      "Saving..\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.191 Acc 94.601%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.195 Acc 94.376%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.198 Acc 94.326%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.197 Acc 94.344%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.196 Acc 94.360%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.199 Acc 95.011%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.191 Acc 95.095%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.169 Acc 91.406%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.189 Acc 94.570%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.192 Acc 94.562%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.192 Acc 94.529%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.194 Acc 94.479%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.195 Acc 94.405%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.237 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.206 Acc 95.011%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.200 Acc 95.017%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.192 Acc 94.493%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.191 Acc 94.625%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.191 Acc 94.612%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.193 Acc 94.535%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.194 Acc 94.455%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.241 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.191 Acc 95.220%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.185 Acc 95.235%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.300 Acc 90.625%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.192 Acc 94.431%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.191 Acc 94.438%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.191 Acc 94.498%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.191 Acc 94.442%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.191 Acc 94.453%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.195 Acc 95.119%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.190 Acc 95.211%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.280 Acc 89.844%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.180 Acc 94.856%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.180 Acc 94.920%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.184 Acc 94.767%\n",
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.188 Acc 94.631%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.189 Acc 94.592%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.211 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.186 Acc 95.289%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.179 Acc 95.386%\n",
      "Saving..\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.185 Acc 94.655%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.189 Acc 94.617%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.193 Acc 94.534%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.193 Acc 94.484%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.192 Acc 94.500%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.185 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.181 Acc 95.382%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.175 Acc 95.491%\n",
      "Saving..\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.182 Acc 94.678%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.178 Acc 94.893%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.184 Acc 94.801%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.185 Acc 94.761%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.186 Acc 94.712%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.225 Acc 93.750%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.195 Acc 95.019%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.189 Acc 95.099%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.269 Acc 91.406%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.191 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.189 Acc 94.605%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.187 Acc 94.651%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.188 Acc 94.598%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.191 Acc 95.243%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.320%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.191 Acc 94.593%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.186 Acc 94.718%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.633%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.185 Acc 94.658%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.229 Acc 93.750%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.181 Acc 95.464%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.176 Acc 96.094%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.185 Acc 94.779%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.185 Acc 94.803%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.186 Acc 94.684%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.184 Acc 94.771%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.184 Acc 94.753%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.193 Acc 95.104%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.187 Acc 95.219%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.266 Acc 92.969%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.178 Acc 94.933%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.176 Acc 94.951%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.181 Acc 94.778%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.184 Acc 94.734%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.182 Acc 94.803%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.259 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.211 Acc 94.879%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.202 Acc 94.939%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.175 Acc 95.026%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.176 Acc 94.951%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.179 Acc 94.879%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.179 Acc 94.851%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.181 Acc 94.771%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.183 Acc 95.394%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.175 Acc 94.632%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.180 Acc 94.710%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.181 Acc 94.773%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.181 Acc 94.812%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.181 Acc 94.813%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.227 Acc 92.969%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.200 Acc 95.042%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.193 Acc 95.095%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.179 Acc 94.957%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.178 Acc 94.916%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.173 Acc 95.027%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.174 Acc 95.016%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.177 Acc 94.940%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.186 Acc 95.266%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.180 Acc 95.355%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.212 Acc 93.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.176 Acc 94.578%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.173 Acc 94.819%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.172 Acc 94.980%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.172 Acc 94.960%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.173 Acc 94.971%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.182 Acc 95.475%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.176 Acc 95.534%\n",
      "Saving..\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.165 Acc 95.220%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.167 Acc 95.254%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.172 Acc 95.089%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.173 Acc 95.038%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.174 Acc 95.016%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.191 Acc 95.227%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.182 Acc 95.351%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.174 Acc 95.026%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.173 Acc 95.052%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.174 Acc 95.037%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.175 Acc 95.016%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.175 Acc 94.990%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.193 Acc 95.328%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.185 Acc 95.328%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.215 Acc 94.531%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.166 Acc 95.235%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.177 Acc 94.858%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.174 Acc 95.024%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.176 Acc 94.966%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.196 Acc 95.328%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.188 Acc 95.425%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.167 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.166 Acc 95.212%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.170 Acc 95.099%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 95.030%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.173 Acc 95.083%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.173 Acc 95.015%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.192 Acc 95.343%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.183 Acc 95.534%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.164 Acc 95.212%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.162 Acc 95.219%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.164 Acc 95.229%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.167 Acc 95.170%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.170 Acc 95.114%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.183 Acc 95.405%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.491%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.162 Acc 97.656%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.176 Acc 94.817%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.171 Acc 94.943%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.172 Acc 94.954%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.171 Acc 95.036%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.171 Acc 95.074%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.191 Acc 95.212%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.185 Acc 95.250%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.163 Acc 95.537%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.169 Acc 95.320%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.167 Acc 95.271%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.169 Acc 95.164%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.170 Acc 95.143%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.195 Acc 95.189%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 95.169%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.170 Acc 95.212%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.169 Acc 95.159%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.167 Acc 95.217%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.169 Acc 95.157%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.189 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.188 Acc 95.305%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.182 Acc 95.437%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.095 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.168 Acc 95.266%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.173%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.168 Acc 95.183%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.167 Acc 95.198%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.167 Acc 95.211%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.208 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.289%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.178 Acc 95.460%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.158 Acc 95.475%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.161 Acc 95.382%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.164 Acc 95.255%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.165 Acc 95.281%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.676%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Saving..\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.130 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.165 Acc 95.196%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.164 Acc 95.239%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.165 Acc 95.310%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.164 Acc 95.285%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.166 Acc 95.231%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.181 Acc 95.746%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.173 Acc 95.884%\n",
      "Saving..\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.171 Acc 95.282%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.164 Acc 95.301%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.164 Acc 95.341%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.163 Acc 95.299%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.163 Acc 95.317%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.231 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.193 Acc 95.382%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.185 Acc 95.437%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.111 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.164 Acc 95.065%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.161 Acc 95.254%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.164 Acc 95.165%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.165 Acc 95.198%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.165 Acc 95.241%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.222 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.188 Acc 95.398%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.180 Acc 95.546%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.179 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.153 Acc 95.561%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.157 Acc 95.414%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.159 Acc 95.412%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.161 Acc 95.327%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.177 Acc 95.421%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.171 Acc 95.546%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.169 Acc 95.297%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.167 Acc 95.223%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.161 Acc 95.333%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.159 Acc 95.390%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.158 Acc 95.423%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.189 Acc 95.444%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.181 Acc 95.561%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.183 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.163 Acc 95.297%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.160 Acc 95.464%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.157 Acc 95.531%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.159 Acc 95.482%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.161 Acc 95.425%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.187 Acc 95.599%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.181 Acc 95.600%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.154 Acc 95.514%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.156 Acc 95.565%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.156 Acc 95.569%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.157 Acc 95.568%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.157 Acc 95.512%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.174 Acc 95.746%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.167 Acc 95.814%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.154 Acc 95.552%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.156 Acc 95.577%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.156 Acc 95.458%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.157 Acc 95.420%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.158 Acc 95.394%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.197 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.183 Acc 95.568%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.175 Acc 95.627%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.196 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.152 Acc 95.738%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.152 Acc 95.627%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.157 Acc 95.536%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.155 Acc 95.591%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.157 Acc 95.511%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.186 Acc 95.568%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.179 Acc 95.534%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.115 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.152 Acc 95.676%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.155 Acc 95.487%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.156 Acc 95.531%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.154 Acc 95.560%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.156 Acc 95.482%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.174 Acc 95.653%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.168 Acc 95.705%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.147 Acc 95.606%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.150 Acc 95.620%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.154 Acc 95.546%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.155 Acc 95.538%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.155 Acc 95.560%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.189 Acc 95.645%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.181 Acc 95.756%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.200 Acc 92.188%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.152 Acc 95.583%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.153 Acc 95.604%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.155 Acc 95.528%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.155 Acc 95.540%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.154 Acc 95.579%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.193 Acc 95.529%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.186 Acc 95.515%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.184 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.153 Acc 95.568%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.151 Acc 95.569%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.152 Acc 95.554%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.154 Acc 95.581%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.154 Acc 95.579%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.177 Acc 95.717%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.154 Acc 95.552%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.147 Acc 95.690%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.150 Acc 95.684%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.149 Acc 95.690%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.151 Acc 95.620%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.183 Acc 95.506%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.177 Acc 95.662%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.144 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.157 Acc 95.444%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.635%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.149 Acc 95.686%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.150 Acc 95.706%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.151 Acc 95.679%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.187 Acc 95.684%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.179 Acc 95.767%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.157 Acc 95.429%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.152 Acc 95.655%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.156 Acc 95.567%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.155 Acc 95.607%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.153 Acc 95.610%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.191 Acc 95.645%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.183 Acc 95.725%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.160 Acc 95.475%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.153 Acc 95.697%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.153 Acc 95.629%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.153 Acc 95.589%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.150 Acc 95.681%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.180 Acc 95.838%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.171 Acc 95.899%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.123 Acc 93.750%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.140 Acc 95.915%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.148 Acc 95.702%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.149 Acc 95.699%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.185 Acc 95.606%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.176 Acc 95.728%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.143 Acc 95.823%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.150 Acc 95.647%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.148 Acc 95.621%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.149 Acc 95.650%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.149 Acc 95.648%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.199 Acc 95.367%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.191 Acc 95.511%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.140 Acc 96.032%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.148 Acc 95.794%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.148 Acc 95.767%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.147 Acc 95.768%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.148 Acc 95.740%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.178 Acc 95.483%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.170 Acc 95.686%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.141 Acc 96.001%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.140 Acc 95.981%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.141 Acc 95.943%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.142 Acc 95.915%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.146 Acc 95.821%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.190 Acc 95.653%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.181 Acc 95.826%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.194 Acc 97.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.143 Acc 95.846%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.151 Acc 95.709%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.148 Acc 95.738%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.148 Acc 95.749%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.146 Acc 95.765%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.183 Acc 95.668%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.175 Acc 95.841%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.218 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.139 Acc 95.885%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.137 Acc 95.977%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.142 Acc 95.894%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.144 Acc 95.844%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.146 Acc 95.796%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.179 Acc 95.808%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.172 Acc 95.907%\n",
      "Saving..\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.136 Acc 95.939%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.137 Acc 95.981%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.138 Acc 95.954%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.141 Acc 95.897%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.143 Acc 95.857%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.164 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.198 Acc 95.204%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.189 Acc 95.278%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.190 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.142 Acc 95.753%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.142 Acc 95.857%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.144 Acc 95.816%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.142 Acc 95.805%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.143 Acc 95.808%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.180 Acc 95.784%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.171 Acc 95.864%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.139 Acc 95.707%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.141 Acc 95.759%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.140 Acc 95.787%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.141 Acc 95.813%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.143 Acc 95.841%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.178 Acc 95.775%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.136 Acc 96.063%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.134 Acc 96.008%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.141 Acc 95.946%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.140 Acc 95.872%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.142 Acc 95.850%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.184 Acc 95.577%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.143 Acc 95.738%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.144 Acc 95.767%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.139 Acc 95.902%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.141 Acc 95.922%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.140 Acc 95.960%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.189 Acc 95.568%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.181 Acc 95.697%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.134 Acc 96.140%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.141 Acc 95.993%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.141 Acc 95.977%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.142 Acc 95.959%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.142 Acc 95.942%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.185 Acc 95.521%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.177 Acc 95.616%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.132 Acc 95.869%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.130 Acc 96.082%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.137 Acc 95.964%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.139 Acc 95.924%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.141 Acc 95.866%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.192 Acc 95.668%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.183 Acc 95.798%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.139 Acc 96.040%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.139 Acc 95.958%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.140 Acc 95.920%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.141 Acc 95.934%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.141 Acc 95.985%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.179 Acc 95.639%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.138 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.136 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.137 Acc 96.055%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.137 Acc 96.014%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.137 Acc 95.994%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.187 Acc 95.560%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.179 Acc 95.713%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.136 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.128 Acc 96.403%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.134 Acc 96.218%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.137 Acc 96.028%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.189 Acc 95.645%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.183 Acc 95.666%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.128 Acc 96.310%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.130 Acc 96.234%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.133 Acc 96.125%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.136 Acc 96.086%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.181 Acc 95.568%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.174 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.139 Acc 95.955%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.135 Acc 96.140%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.134 Acc 96.125%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.136 Acc 96.016%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.138 Acc 95.961%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.173 Acc 95.919%\n",
      "Saving..\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.137 Acc 96.047%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.134 Acc 95.969%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.133 Acc 96.127%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.134 Acc 96.084%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.134 Acc 96.097%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.188 Acc 95.722%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.181 Acc 95.787%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.130 Acc 96.349%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.134 Acc 96.195%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.134 Acc 96.120%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.138 Acc 96.043%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.137 Acc 96.091%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.179 Acc 95.947%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 96.012%\n",
      "Saving..\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.140 Acc 95.838%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.132 Acc 96.150%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.133 Acc 96.133%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.193 Acc 95.653%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.184 Acc 95.740%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.128 Acc 96.140%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.131 Acc 96.160%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.133 Acc 96.159%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.133 Acc 96.152%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.133 Acc 96.145%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.179 Acc 95.769%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.169 Acc 95.829%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.126 Acc 96.411%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.128 Acc 96.319%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.131 Acc 96.262%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.131 Acc 96.242%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.132 Acc 96.172%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.184 Acc 95.777%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.174 Acc 95.829%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.125 Acc 96.381%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.129 Acc 96.288%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.129 Acc 96.341%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.130 Acc 96.286%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.186 Acc 95.599%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.179 Acc 95.705%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.125 Acc 96.256%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.135 Acc 96.068%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.133 Acc 96.129%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.132 Acc 96.136%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.195 Acc 95.429%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.186 Acc 95.639%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.130 Acc 96.225%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.131 Acc 96.226%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.130 Acc 96.172%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.128 Acc 96.228%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.130 Acc 96.203%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.178 Acc 95.784%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.170 Acc 95.829%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.058 Acc 100.000%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.122 Acc 96.357%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.124 Acc 96.343%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.126 Acc 96.283%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.128 Acc 96.214%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.189 Acc 95.591%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.182 Acc 95.701%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.124 Acc 96.331%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.128 Acc 96.229%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.129 Acc 96.228%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.131 Acc 96.192%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.179 Acc 95.651%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.127 Acc 96.291%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.130 Acc 96.226%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.129 Acc 96.247%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.200 Acc 95.537%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.190 Acc 95.643%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.125 Acc 96.287%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.129 Acc 96.199%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.129 Acc 96.229%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.129 Acc 96.209%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.129 Acc 96.209%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.192 Acc 95.583%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.183 Acc 95.701%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.121 Acc 96.612%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.124 Acc 96.405%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.124 Acc 96.330%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.125 Acc 96.363%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.127 Acc 96.262%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.182 Acc 95.599%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.173 Acc 95.705%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.247 Acc 92.188%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.127 Acc 96.148%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.123 Acc 96.265%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.124 Acc 96.255%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.127 Acc 96.181%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.128 Acc 96.183%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.193 Acc 95.838%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.184 Acc 95.884%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.212 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.117 Acc 96.697%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.122 Acc 96.576%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.126 Acc 96.379%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.127 Acc 96.329%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.128 Acc 96.304%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.190 Acc 95.645%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.182 Acc 95.783%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.124 Acc 96.372%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.125 Acc 96.323%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.127 Acc 96.338%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.126 Acc 96.333%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.127 Acc 96.290%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.120 Acc 97.656%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.196 Acc 95.715%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.187 Acc 95.880%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.123 Acc 96.403%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.125 Acc 96.401%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.123 Acc 96.387%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.126 Acc 96.394%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.125 Acc 96.365%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.192 Acc 95.521%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.183 Acc 95.616%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.146 Acc 94.531%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.129 Acc 96.117%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.129 Acc 96.137%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.128 Acc 96.159%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.126 Acc 96.259%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.125 Acc 96.287%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.188 Acc 95.684%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.179 Acc 95.783%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.178 Acc 94.531%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.124 Acc 96.210%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.126 Acc 96.280%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.125 Acc 96.371%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.123 Acc 96.406%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [134/200]Batch [100/204] Loss: 0.194 Acc 95.537%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.186 Acc 95.627%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.119 Acc 96.457%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.121 Acc 96.354%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.120 Acc 96.408%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.121 Acc 96.396%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.123 Acc 96.325%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.189 Acc 95.514%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.178 Acc 95.690%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.123 Acc 96.419%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.123 Acc 96.331%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.122 Acc 96.333%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.123 Acc 96.287%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.123 Acc 96.304%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.203 Acc 95.622%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.193 Acc 95.725%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.072 Acc 96.094%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.128 Acc 96.234%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.124 Acc 96.325%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.122 Acc 96.363%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.122 Acc 96.395%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.201 Acc 95.568%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.193 Acc 95.643%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.119 Acc 96.364%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.122 Acc 96.276%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.123 Acc 96.270%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.121 Acc 96.351%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.121 Acc 96.384%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.185 Acc 95.815%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.177 Acc 95.892%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.094 Acc 95.312%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.114 Acc 96.481%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.124 Acc 96.405%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.122 Acc 96.506%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.121 Acc 96.509%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.120 Acc 96.533%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.190 Acc 95.800%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.182 Acc 95.798%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.113 Acc 96.651%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.116 Acc 96.533%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.119 Acc 96.447%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.118 Acc 96.458%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.120 Acc 96.452%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.186 Acc 95.637%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.177 Acc 95.864%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.065 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.118 Acc 96.504%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.119 Acc 96.501%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.120 Acc 96.493%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.121 Acc 96.445%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.175 Acc 95.312%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.195 Acc 95.614%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.186 Acc 95.631%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.241 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.118 Acc 96.635%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.120 Acc 96.638%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.119 Acc 96.636%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.117 Acc 96.672%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.119 Acc 96.563%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.189 Acc 95.684%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.177 Acc 95.837%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.116 Acc 96.650%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.119 Acc 96.553%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.119 Acc 96.521%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.186 Acc 95.722%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.118 Acc 96.511%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.116 Acc 96.514%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.116 Acc 96.558%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.184 Acc 95.529%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.174 Acc 95.736%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.110 Acc 96.705%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.112 Acc 96.692%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.112 Acc 96.597%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.114 Acc 96.571%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.116 Acc 96.529%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.194 Acc 95.722%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.185 Acc 95.810%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.115 Acc 96.634%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.113 Acc 96.657%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.114 Acc 96.621%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.190 Acc 95.808%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.180 Acc 95.977%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.115 Acc 96.388%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.116 Acc 96.482%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.115 Acc 96.512%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.114 Acc 96.598%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.115 Acc 96.568%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.191 Acc 95.328%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.184 Acc 95.491%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.106 Acc 96.720%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.112 Acc 96.642%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.113 Acc 96.654%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.117 Acc 96.562%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.194 Acc 95.746%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.185 Acc 95.876%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.061 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.117 Acc 96.720%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.116 Acc 96.599%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.117 Acc 96.587%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.116 Acc 96.622%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.115 Acc 96.574%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.203 Acc 95.622%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [149/200]Batch [200/204] Loss: 0.191 Acc 95.725%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.111 Acc 96.615%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.110 Acc 96.670%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.110 Acc 96.698%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.112 Acc 96.655%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.186 Acc 95.699%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.154 Acc 96.875%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.112 Acc 96.674%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.108 Acc 96.833%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.111 Acc 96.752%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.115 Acc 96.604%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.199 Acc 95.514%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.189 Acc 95.658%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.110 Acc 96.805%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.112 Acc 96.688%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.114 Acc 96.671%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.183 Acc 95.815%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.174 Acc 95.903%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.109 Acc 96.589%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.109 Acc 96.657%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.111 Acc 96.667%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.112 Acc 96.645%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.111 Acc 96.643%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.182 Acc 95.661%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.174 Acc 95.798%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.127 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.111 Acc 96.635%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.116 Acc 96.552%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.112 Acc 96.631%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.112 Acc 96.649%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.111 Acc 96.710%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.192 Acc 95.730%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.946%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.110 Acc 96.751%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.109 Acc 96.723%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.112 Acc 96.657%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.113 Acc 96.631%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.112 Acc 96.685%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 95.862%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.181 Acc 95.934%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.103 Acc 97.068%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.107 Acc 96.856%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.108 Acc 96.779%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.109 Acc 96.783%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.108 Acc 96.778%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.189 Acc 95.792%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.179 Acc 95.876%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.099 Acc 97.092%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.105 Acc 96.949%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.110 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.110 Acc 96.749%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.186 Acc 95.653%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.176 Acc 95.806%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.102 Acc 96.890%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.109 Acc 96.821%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.109 Acc 96.750%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.109 Acc 96.741%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.110 Acc 96.711%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.188 Acc 95.900%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.178 Acc 95.942%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.140 Acc 93.750%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.107 Acc 96.759%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.108 Acc 96.766%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.109 Acc 96.753%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.112 Acc 96.668%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.110 Acc 96.708%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.185 Acc 95.730%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.176 Acc 95.884%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.101 Acc 96.960%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.107 Acc 96.859%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.109 Acc 96.714%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.111 Acc 96.688%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.110 Acc 96.758%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.202 Acc 95.529%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.192 Acc 95.612%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.109 Acc 96.712%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.112 Acc 96.623%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.113 Acc 96.625%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.110 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.195 Acc 95.722%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.184 Acc 95.872%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.111 Acc 96.612%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.107 Acc 96.743%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.106 Acc 96.771%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.108 Acc 96.756%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.108 Acc 96.738%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.189 Acc 95.753%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.180 Acc 95.899%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.063 Acc 96.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.105 Acc 96.937%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.106 Acc 96.859%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.108 Acc 96.793%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.108 Acc 96.755%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.197 Acc 95.869%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.188 Acc 95.950%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.104 Acc 97.177%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.108 Acc 96.964%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.108 Acc 96.904%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.107 Acc 96.877%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.195 Acc 95.815%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.183 Acc 95.981%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.101 Acc 97.084%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.106 Acc 96.922%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.103 Acc 96.901%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.104 Acc 96.838%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.115 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.194 Acc 95.838%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.185 Acc 95.884%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.157 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.108 Acc 96.883%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.101 Acc 96.937%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.103 Acc 96.909%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.104 Acc 96.920%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.191 Acc 95.699%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.183 Acc 95.748%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.097 Acc 97.084%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.106 Acc 96.871%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.106 Acc 96.846%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.105 Acc 96.877%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.105 Acc 96.887%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.201 Acc 95.900%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.192 Acc 95.977%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.103 Acc 96.832%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.104 Acc 96.779%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.104 Acc 96.846%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.103 Acc 96.867%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.777%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.186 Acc 95.767%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.106 Acc 96.674%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.102 Acc 96.883%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.104 Acc 96.849%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.103 Acc 96.908%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.105 Acc 96.813%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.195 Acc 95.838%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.186 Acc 95.872%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.105 Acc 96.879%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.106 Acc 96.865%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.107 Acc 96.797%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.106 Acc 96.816%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.194 Acc 95.908%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.183 Acc 96.012%\n",
      "Saving..\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.102 Acc 97.022%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.104 Acc 96.953%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.105 Acc 96.803%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.105 Acc 96.769%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.211 Acc 95.514%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.201 Acc 95.674%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.097 Acc 97.014%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.103 Acc 96.836%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.102 Acc 96.880%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.103 Acc 96.893%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.104 Acc 96.883%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.205 Acc 95.761%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.195 Acc 95.763%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.102 Acc 97.022%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.102 Acc 96.953%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.102 Acc 96.935%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.103 Acc 96.898%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.191 Acc 95.676%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.181 Acc 95.853%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.175 Acc 93.750%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.102 Acc 96.991%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.102 Acc 96.871%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.103 Acc 96.820%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.104 Acc 96.826%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.104 Acc 96.839%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.202 Acc 95.614%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.191 Acc 95.678%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.097 Acc 97.068%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.101 Acc 97.007%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.099 Acc 97.058%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.100 Acc 97.045%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.183 Acc 95.896%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.094 Acc 97.045%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.096 Acc 97.042%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.097 Acc 97.000%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.102 Acc 96.877%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.102 Acc 96.900%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.208 Acc 95.583%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.198 Acc 95.705%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.091 Acc 97.362%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.094 Acc 97.221%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.095 Acc 97.186%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.096 Acc 97.159%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.098 Acc 97.075%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.201 Acc 95.722%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.189 Acc 95.818%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.039 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.103 Acc 96.790%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.095 Acc 96.937%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.097 Acc 96.987%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.099 Acc 96.912%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.100 Acc 96.914%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.190 Acc 95.761%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.180 Acc 95.880%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.099 Acc 96.926%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.100 Acc 96.939%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.100 Acc 96.953%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.203 Acc 95.537%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.190 Acc 95.655%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.095 Acc 97.030%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.100 Acc 96.896%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.100 Acc 96.887%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.101 Acc 96.905%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.203 Acc 95.854%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.193 Acc 95.899%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.098 Acc 97.107%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.099 Acc 97.046%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.100 Acc 96.994%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.101 Acc 96.949%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.100 Acc 96.955%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.216 Acc 95.606%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.203 Acc 95.775%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.092 Acc 97.409%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.100 Acc 97.081%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.099 Acc 97.057%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.099 Acc 97.027%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.100 Acc 97.020%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.212 Acc 95.583%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.201 Acc 95.701%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.218 Acc 92.188%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.092 Acc 97.107%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.095 Acc 97.059%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.096 Acc 97.039%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.097 Acc 97.059%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.197 Acc 95.583%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.187 Acc 95.721%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.093 Acc 97.153%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.097 Acc 97.077%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.097 Acc 97.072%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.096 Acc 97.066%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.096 Acc 97.075%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.206 Acc 95.645%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.194 Acc 95.833%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.095 Acc 97.208%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.092 Acc 97.256%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.094 Acc 97.129%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.097 Acc 97.070%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.099 Acc 97.020%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.196 Acc 95.746%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.186 Acc 95.868%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.101 Acc 97.053%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.099 Acc 97.093%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.098 Acc 97.101%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.096 Acc 97.109%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.201 Acc 95.661%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.814%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.178 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.092 Acc 97.161%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.096 Acc 97.108%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.096 Acc 97.096%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.096 Acc 97.064%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.201 Acc 95.784%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.192 Acc 95.849%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.188 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.096 Acc 97.208%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.096 Acc 97.128%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.095 Acc 97.155%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.098 Acc 97.032%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.203 Acc 95.769%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.190 Acc 95.907%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.095 Acc 97.132%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.095 Acc 97.111%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.096 Acc 97.086%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.198 Acc 95.661%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.187 Acc 95.787%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.095 Acc 97.184%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.092 Acc 97.209%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.094 Acc 97.179%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.095 Acc 97.113%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.095 Acc 97.109%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.222 Acc 95.537%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.209 Acc 95.647%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.099 Acc 97.107%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.093 Acc 97.264%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.092 Acc 97.249%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.094 Acc 97.237%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.096 Acc 97.135%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.203 Acc 95.684%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.191 Acc 95.756%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.093 Acc 97.221%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.094 Acc 97.155%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.095 Acc 97.083%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.096 Acc 97.087%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.661%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.186 Acc 95.822%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.092 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.098 Acc 97.053%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.096 Acc 97.132%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.096 Acc 97.083%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.096 Acc 97.089%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.207 Acc 95.838%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.195 Acc 95.954%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.097 Acc 97.050%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.096 Acc 97.106%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.096 Acc 97.083%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.096 Acc 97.064%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.208 Acc 95.637%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.196 Acc 95.763%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [195/200]Batch [100/573] Loss: 0.097 Acc 97.037%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.094 Acc 97.104%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.095 Acc 97.088%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.095 Acc 97.056%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.096 Acc 97.076%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.215 Acc 95.738%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.202 Acc 95.888%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.141 Acc 93.750%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.092 Acc 96.929%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.091 Acc 97.108%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.091 Acc 97.173%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.091 Acc 97.173%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.202 Acc 95.676%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.192 Acc 95.728%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.089 Acc 97.268%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.092 Acc 97.236%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.094 Acc 97.113%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.095 Acc 97.053%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.195 Acc 95.653%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.184 Acc 95.736%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.173 Acc 91.406%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.085 Acc 97.393%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.089 Acc 97.299%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.091 Acc 97.218%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.092 Acc 97.167%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.093 Acc 97.148%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.202 Acc 95.653%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.190 Acc 95.775%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.090 Acc 97.030%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.091 Acc 97.120%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.093 Acc 97.083%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.093 Acc 97.101%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.094 Acc 97.117%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.214 Acc 95.668%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.202 Acc 95.728%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c21fffee2d744ddb5bee0a3bfae6e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.337 Acc 9.375%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.309 Acc 8.988%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.266 Acc 15.683%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.215 Acc 19.721%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.164 Acc 22.695%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.117 Acc 24.975%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.655 Acc 41.406%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.703 Acc 39.550%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.704 Acc 39.657%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.838 Acc 35.156%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.781 Acc 38.459%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.732 Acc 40.668%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.683 Acc 42.951%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.635 Acc 45.355%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.592 Acc 47.452%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.155 Acc 57.812%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.172 Acc 61.912%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.169 Acc 61.870%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.294 Acc 61.719%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.276 Acc 61.100%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.243 Acc 62.345%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.216 Acc 63.442%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.187 Acc 64.596%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.158 Acc 65.703%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.833 Acc 71.094%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.847 Acc 73.940%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.847 Acc 73.993%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.051 Acc 73.438%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.956 Acc 74.095%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.931 Acc 75.101%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.912 Acc 75.867%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.886 Acc 76.757%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.863 Acc 77.660%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.547 Acc 84.375%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.567 Acc 84.777%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.569 Acc 84.608%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.738 Acc 84.375%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.695 Acc 83.470%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.685 Acc 83.633%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.668 Acc 84.105%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.651 Acc 84.467%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.637 Acc 84.685%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.424 Acc 88.281%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.429 Acc 87.771%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.430 Acc 87.675%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.466 Acc 89.062%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.543 Acc 86.595%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.528 Acc 86.851%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.522 Acc 87.033%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.509 Acc 87.276%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.500 Acc 87.422%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.327 Acc 89.844%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.358 Acc 89.952%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.359 Acc 89.785%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.412 Acc 90.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.443 Acc 88.274%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.445 Acc 88.235%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.435 Acc 88.603%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.429 Acc 88.762%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.424 Acc 88.838%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.299 Acc 90.625%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.307 Acc 91.066%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.308 Acc 90.905%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.409 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.398 Acc 89.016%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.388 Acc 89.424%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.382 Acc 89.610%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.378 Acc 89.668%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.375 Acc 89.710%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.271 Acc 90.625%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.279 Acc 91.785%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.277 Acc 91.877%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.425 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.342 Acc 90.586%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.340 Acc 90.501%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.344 Acc 90.389%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.344 Acc 90.329%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.342 Acc 90.332%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.230 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.256 Acc 92.420%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.258 Acc 92.246%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.349 Acc 90.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.315 Acc 91.143%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.321 Acc 90.948%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.322 Acc 90.929%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.321 Acc 91.009%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.320 Acc 90.965%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.253 Acc 88.281%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.244 Acc 93.023%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.243 Acc 92.922%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.271 Acc 92.188%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.304 Acc 91.190%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.306 Acc 91.212%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.308 Acc 91.154%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.306 Acc 91.241%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.304 Acc 91.286%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.232 Acc 90.625%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.244 Acc 92.891%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.243 Acc 92.728%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.243 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.288 Acc 91.723%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.291 Acc 91.554%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.286 Acc 91.715%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.286 Acc 91.689%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.287 Acc 91.668%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.275 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.238 Acc 93.108%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.237 Acc 92.988%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.452 Acc 85.938%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.277 Acc 92.157%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.274 Acc 92.188%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.277 Acc 92.040%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.276 Acc 91.963%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.275 Acc 91.950%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.239 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.237 Acc 93.309%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.236 Acc 93.210%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.394 Acc 89.844%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.279 Acc 91.847%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.273 Acc 92.071%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.268 Acc 92.245%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.269 Acc 92.168%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.266 Acc 92.242%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.229 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.229 Acc 93.317%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.229 Acc 93.350%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.257 Acc 92.683%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.259 Acc 92.526%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.257 Acc 92.525%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.259 Acc 92.451%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.259 Acc 92.462%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.210 Acc 92.188%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.216 Acc 93.796%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.215 Acc 93.723%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.240 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.247 Acc 93.054%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.254 Acc 92.782%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.249 Acc 92.893%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.250 Acc 92.803%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.251 Acc 92.730%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.282 Acc 89.844%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.223 Acc 93.626%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.221 Acc 93.544%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.379 Acc 91.406%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.247 Acc 92.845%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.249 Acc 92.763%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.248 Acc 92.761%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.248 Acc 92.768%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.246 Acc 92.827%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.185 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.209 Acc 94.067%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.208 Acc 94.014%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.302 Acc 89.062%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.248 Acc 92.744%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.234 Acc 93.148%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.237 Acc 93.073%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.240 Acc 92.971%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.241 Acc 92.920%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.185 Acc 91.406%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.204 Acc 94.369%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.201 Acc 94.232%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.306 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.236 Acc 93.139%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.233 Acc 93.280%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.233 Acc 93.223%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.235 Acc 93.156%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.236 Acc 93.101%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.232 Acc 89.844%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.204 Acc 94.322%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.203 Acc 94.263%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.281 Acc 89.062%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.234 Acc 93.185%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.230 Acc 93.276%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.233 Acc 93.184%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.231 Acc 93.265%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.232 Acc 93.207%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.237 Acc 91.406%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.201 Acc 94.384%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.199 Acc 94.434%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.101 Acc 98.438%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.230 Acc 93.216%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.223 Acc 93.513%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.226 Acc 93.501%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.227 Acc 93.423%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.228 Acc 93.398%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.199 Acc 94.454%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.199 Acc 94.298%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.215 Acc 92.188%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.215 Acc 93.665%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.220 Acc 93.544%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.224 Acc 93.457%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.224 Acc 93.442%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.228 Acc 93.318%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.138 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.203 Acc 94.462%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.201 Acc 94.446%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.291 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.214 Acc 93.533%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.217 Acc 93.614%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.217 Acc 93.633%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.217 Acc 93.635%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.220 Acc 93.588%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.194 Acc 94.701%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.191 Acc 94.601%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.152 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.215 Acc 93.758%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.217 Acc 93.653%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.214 Acc 93.758%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.214 Acc 93.771%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.215 Acc 93.744%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.191 Acc 94.686%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.188 Acc 94.694%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.206 Acc 93.858%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.208 Acc 93.925%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.210 Acc 93.919%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.211 Acc 93.886%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.211 Acc 93.881%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.193 Acc 91.406%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.193 Acc 94.524%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.191 Acc 94.652%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.299 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.207 Acc 93.874%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.204 Acc 94.115%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.207 Acc 94.010%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.208 Acc 93.945%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.208 Acc 93.950%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.187 Acc 94.895%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.185 Acc 94.943%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.207 Acc 93.998%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.207 Acc 94.022%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.206 Acc 94.038%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.207 Acc 93.968%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.207 Acc 93.957%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.187 Acc 95.011%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.186 Acc 95.005%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.169 Acc 92.969%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.192 Acc 94.330%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.196 Acc 94.279%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.196 Acc 94.233%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.201 Acc 94.130%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.203 Acc 94.095%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.194 Acc 94.593%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.195 Acc 94.543%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.199 Acc 93.959%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.201 Acc 94.042%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.202 Acc 94.059%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.203 Acc 94.031%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.202 Acc 94.059%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.192 Acc 94.640%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.191 Acc 94.675%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.291 Acc 90.625%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.194 Acc 94.454%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.199 Acc 94.263%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.198 Acc 94.251%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.201 Acc 94.177%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.202 Acc 94.163%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.221 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.181 Acc 95.158%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.179 Acc 95.126%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.191 Acc 94.578%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.196 Acc 94.286%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.196 Acc 94.295%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.197 Acc 94.221%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.196 Acc 94.261%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.183 Acc 95.227%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.181 Acc 95.122%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.248 Acc 93.750%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.201 Acc 94.183%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.194 Acc 94.380%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.197 Acc 94.347%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.197 Acc 94.362%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.196 Acc 94.343%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.185 Acc 94.926%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.185 Acc 94.908%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.142 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.191 Acc 94.462%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.197 Acc 94.395%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.193 Acc 94.381%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.194 Acc 94.319%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.195 Acc 94.288%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.178 Acc 95.212%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.176 Acc 95.231%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.300 Acc 90.625%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.182 Acc 94.779%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.187 Acc 94.621%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.188 Acc 94.625%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.189 Acc 94.601%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.191 Acc 94.495%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.179 Acc 95.282%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.189 Acc 94.640%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.191 Acc 94.500%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.186 Acc 94.609%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.186 Acc 94.629%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.199 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.189 Acc 95.050%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.186 Acc 95.040%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.280 Acc 93.750%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.189 Acc 94.601%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.187 Acc 94.656%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.184 Acc 94.658%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.187 Acc 94.558%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.173 Acc 95.459%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.171 Acc 95.530%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.180 Acc 94.941%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.186 Acc 94.745%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.186 Acc 94.682%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.187 Acc 94.621%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.186 Acc 94.581%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.174 Acc 95.367%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.172 Acc 95.359%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.207 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.179 Acc 94.856%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.182 Acc 94.788%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.181 Acc 94.884%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.183 Acc 94.765%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.184 Acc 94.717%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.177 Acc 95.328%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.172 Acc 95.433%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.204 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.179 Acc 94.879%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.178 Acc 94.842%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.179 Acc 94.825%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.180 Acc 94.779%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.180 Acc 94.782%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.178 Acc 95.243%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.174 Acc 95.278%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.181 Acc 92.969%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.185 Acc 94.701%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.179 Acc 94.819%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.178 Acc 94.858%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.179 Acc 94.818%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.179 Acc 94.812%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.107 Acc 96.875%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.168 Acc 95.537%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.165 Acc 95.658%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.182 Acc 94.841%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.181 Acc 94.842%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.179 Acc 94.845%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.179 Acc 94.865%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.172 Acc 95.599%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.169 Acc 95.721%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.148 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.166 Acc 95.189%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.168 Acc 95.025%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.168 Acc 95.087%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.173 Acc 94.983%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.175 Acc 94.899%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.175 Acc 95.529%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.172 Acc 95.449%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.192 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.168 Acc 95.042%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.173 Acc 95.130%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.174 Acc 95.017%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.176 Acc 94.907%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.176 Acc 94.918%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.189 Acc 94.957%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.187 Acc 94.920%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.213 Acc 92.188%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.168 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.170 Acc 95.122%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.173 Acc 94.980%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.172 Acc 95.022%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.171 Acc 95.091%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.177 Acc 95.436%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.175 Acc 95.441%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.189 Acc 92.969%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.173 Acc 95.220%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.170 Acc 95.165%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.169 Acc 95.123%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.172 Acc 95.085%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.172 Acc 95.091%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.169 Acc 95.645%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.168 Acc 95.643%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.198 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.167 Acc 95.196%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.167 Acc 95.138%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.171 Acc 95.061%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.171 Acc 95.028%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.174 Acc 94.976%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.162 Acc 95.684%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.162 Acc 95.674%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.165 Acc 95.142%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.166 Acc 95.103%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.164 Acc 95.167%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.166 Acc 95.092%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.169 Acc 95.079%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.163 Acc 95.653%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.160 Acc 95.686%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.163 Acc 95.088%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.171 Acc 95.126%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.168 Acc 95.185%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.167 Acc 95.155%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.170 Acc 95.072%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.176 Acc 95.498%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.174 Acc 95.487%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.169 Acc 95.243%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.161 Acc 95.355%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.166 Acc 95.264%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.167 Acc 95.233%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.182 Acc 95.258%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.180 Acc 95.347%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.168 Acc 95.243%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.168 Acc 95.165%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.164 Acc 95.300%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.165 Acc 95.258%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.165 Acc 95.292%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.178 Acc 95.382%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.174 Acc 95.429%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.150 Acc 95.692%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.157 Acc 95.511%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.160 Acc 95.419%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.162 Acc 95.346%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.165 Acc 95.258%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.163 Acc 95.777%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.161 Acc 95.888%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.162 Acc 95.227%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.163 Acc 95.118%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.163 Acc 95.167%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.162 Acc 95.258%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.164 Acc 95.253%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.176 Acc 95.429%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.174 Acc 95.476%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.165 Acc 95.270%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.166 Acc 95.300%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.165 Acc 95.299%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.164 Acc 95.345%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.166 Acc 95.676%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.163 Acc 95.728%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.147 Acc 95.738%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.152 Acc 95.713%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.154 Acc 95.621%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.158 Acc 95.552%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.160 Acc 95.515%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.170 Acc 95.552%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.168 Acc 95.569%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.214 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.152 Acc 95.674%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.152 Acc 95.691%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.155 Acc 95.599%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.160 Acc 95.472%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.167 Acc 95.699%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.162 Acc 95.752%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.320 Acc 92.188%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.154 Acc 95.498%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.156 Acc 95.410%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.159 Acc 95.331%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.159 Acc 95.375%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.159 Acc 95.362%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.169 Acc 95.583%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.165 Acc 95.573%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.157 Acc 95.575%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.157 Acc 95.612%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.157 Acc 95.528%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.157 Acc 95.488%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.156 Acc 95.506%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.173 Acc 95.568%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.171 Acc 95.542%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.149 Acc 95.436%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.155 Acc 95.340%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.155 Acc 95.450%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.155 Acc 95.451%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.157 Acc 95.439%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.170 Acc 95.599%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.166 Acc 95.713%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.161 Acc 95.452%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.155 Acc 95.581%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.157 Acc 95.541%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.157 Acc 95.560%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.159 Acc 95.501%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.169 Acc 95.498%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.149 Acc 95.645%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.150 Acc 95.666%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.153 Acc 95.653%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.154 Acc 95.566%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.156 Acc 95.545%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.168 Acc 95.738%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.164 Acc 95.814%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.155 Acc 95.484%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.152 Acc 95.608%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.153 Acc 95.642%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.154 Acc 95.590%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.168 Acc 95.599%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.162 Acc 95.791%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.152 Acc 95.800%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.155 Acc 95.655%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.152 Acc 95.629%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.152 Acc 95.611%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.152 Acc 95.589%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.192 Acc 95.166%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.187 Acc 95.114%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.145 Acc 95.877%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.145 Acc 95.837%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.148 Acc 95.738%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.150 Acc 95.667%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.151 Acc 95.613%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.164 Acc 95.769%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.158 Acc 95.923%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.174 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.142 Acc 95.800%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.147 Acc 95.748%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.150 Acc 95.689%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.150 Acc 95.675%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.149 Acc 95.724%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.164 Acc 95.877%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.160 Acc 95.896%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.143 Acc 95.924%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.145 Acc 95.767%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.147 Acc 95.736%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.149 Acc 95.749%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.150 Acc 95.721%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.163 Acc 95.777%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.161 Acc 95.826%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.135 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.146 Acc 95.947%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.145 Acc 95.911%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.148 Acc 95.787%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.148 Acc 95.784%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.149 Acc 95.768%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.161 Acc 96.024%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.158 Acc 95.997%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.137 Acc 95.970%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.144 Acc 95.860%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.146 Acc 95.799%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.194 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.177 Acc 95.511%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.141 Acc 96.194%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.143 Acc 95.896%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.141 Acc 95.907%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.141 Acc 95.899%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.144 Acc 95.802%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.174 Acc 95.568%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.168 Acc 95.670%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.141 Acc 95.962%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.142 Acc 95.885%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.144 Acc 95.874%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.180 Acc 95.521%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.569%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.129 Acc 96.334%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.137 Acc 96.024%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.139 Acc 95.982%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.141 Acc 95.913%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.142 Acc 95.888%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.171 Acc 95.620%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.148 Acc 95.862%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.142 Acc 95.973%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.144 Acc 95.922%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.142 Acc 95.952%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.140 Acc 95.989%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.134 Acc 96.071%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.139 Acc 96.039%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.142 Acc 95.918%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.144 Acc 95.833%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.163 Acc 95.869%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.161 Acc 95.880%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.141 Acc 96.016%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.142 Acc 95.893%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.142 Acc 95.880%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.171 Acc 95.722%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.787%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.136 Acc 95.947%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.134 Acc 96.140%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.135 Acc 96.044%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.137 Acc 96.107%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.139 Acc 96.045%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.169 Acc 95.560%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 95.592%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.143 Acc 95.777%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.139 Acc 96.051%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.140 Acc 96.003%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.138 Acc 96.078%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.140 Acc 96.002%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.170 Acc 95.709%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.136 Acc 96.035%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.139 Acc 95.967%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.137 Acc 96.045%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.140 Acc 95.966%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.169 Acc 95.684%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.165 Acc 95.775%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.131 Acc 96.101%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.132 Acc 96.140%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.135 Acc 96.057%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.138 Acc 96.049%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.159 Acc 95.931%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.155 Acc 95.977%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.128 Acc 96.272%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.133 Acc 96.257%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.137 Acc 96.138%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.137 Acc 96.129%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.137 Acc 96.130%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.158 Acc 95.893%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.158 Acc 95.962%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.127 Acc 96.504%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.133 Acc 96.137%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.138 Acc 95.926%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.138 Acc 95.966%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.168 Acc 95.838%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.131 Acc 96.195%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.132 Acc 96.166%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.133 Acc 96.154%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.134 Acc 96.095%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.178 Acc 96.094%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.171 Acc 95.692%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.806%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.203 Acc 93.750%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.136 Acc 95.934%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.136 Acc 95.977%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.135 Acc 96.033%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.136 Acc 96.010%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.171 Acc 95.738%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.133 Acc 96.442%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.133 Acc 96.261%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.134 Acc 96.190%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.136 Acc 96.166%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.135 Acc 96.145%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.146 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.175 Acc 95.831%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.171 Acc 95.787%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.133 Acc 96.194%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.137 Acc 96.105%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.136 Acc 96.107%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.135 Acc 96.148%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.133 Acc 96.128%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.158 Acc 95.993%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.157 Acc 96.004%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.125 Acc 96.380%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.126 Acc 96.314%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.129 Acc 96.244%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.132 Acc 96.114%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.168 Acc 95.947%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.164 Acc 95.950%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.203 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.128 Acc 96.304%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.130 Acc 96.265%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.135 Acc 96.125%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.134 Acc 96.117%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.166 Acc 95.885%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.161 Acc 95.989%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.121 Acc 98.438%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.129 Acc 96.132%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.125 Acc 96.296%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.125 Acc 96.395%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.126 Acc 96.349%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.129 Acc 96.273%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.166 Acc 95.738%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.163 Acc 95.853%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.128 Acc 96.241%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.128 Acc 96.253%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.131 Acc 96.234%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.131 Acc 96.211%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.091 Acc 95.312%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.155 Acc 96.148%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.153 Acc 96.175%\n",
      "Saving..\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.127 Acc 96.465%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.129 Acc 96.265%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.126 Acc 96.353%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.126 Acc 96.363%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.129 Acc 96.314%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.163 Acc 95.893%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.158 Acc 96.024%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.124 Acc 96.875%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.124 Acc 96.388%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.125 Acc 96.315%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.125 Acc 96.377%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.126 Acc 96.367%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.127 Acc 96.321%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.170 Acc 95.869%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.165 Acc 95.919%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.124 Acc 96.511%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.126 Acc 96.358%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.128 Acc 96.353%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.128 Acc 96.386%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.128 Acc 96.396%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.167 Acc 96.055%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.162 Acc 96.137%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.119 Acc 96.519%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.121 Acc 96.498%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.125 Acc 96.390%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.128 Acc 96.259%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.128 Acc 96.268%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.169 Acc 95.763%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.122 Acc 96.467%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.124 Acc 96.353%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.125 Acc 96.359%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.127 Acc 96.334%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.164 Acc 95.962%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.158 Acc 96.035%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.124 Acc 96.504%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.126 Acc 96.405%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.127 Acc 96.353%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.128 Acc 96.324%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.128 Acc 96.292%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.173 Acc 95.645%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.171 Acc 95.705%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.124 Acc 96.473%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.121 Acc 96.506%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.122 Acc 96.468%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.124 Acc 96.464%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.126 Acc 96.376%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.176 Acc 95.575%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.171 Acc 95.767%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.121 Acc 96.511%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.124 Acc 96.447%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.124 Acc 96.387%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.124 Acc 96.409%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.127 Acc 96.339%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.168 Acc 95.792%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.165 Acc 95.872%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.110 Acc 96.651%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.114 Acc 96.634%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.119 Acc 96.480%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.123 Acc 96.370%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.167 Acc 95.900%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.165 Acc 95.954%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.119 Acc 96.612%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.119 Acc 96.556%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.123 Acc 96.403%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.123 Acc 96.406%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.169 Acc 95.771%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.129 Acc 99.219%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.114 Acc 96.682%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.118 Acc 96.552%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.122 Acc 96.418%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.124 Acc 96.367%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.160 Acc 96.156%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.159 Acc 96.195%\n",
      "Saving..\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.119 Acc 96.542%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.121 Acc 96.556%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.124 Acc 96.468%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.123 Acc 96.478%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.123 Acc 96.457%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.166 Acc 95.916%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.162 Acc 96.016%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.111 Acc 96.790%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.114 Acc 96.813%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.120 Acc 96.548%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.119 Acc 96.596%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.120 Acc 96.498%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.171 Acc 95.692%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.166 Acc 95.775%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.117 Acc 96.705%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.115 Acc 96.770%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.115 Acc 96.724%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.117 Acc 96.655%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.120 Acc 96.537%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.162 Acc 95.993%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.158 Acc 96.070%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.171 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.121 Acc 96.364%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.125 Acc 96.234%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.125 Acc 96.317%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.124 Acc 96.367%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.124 Acc 96.342%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.167 Acc 95.970%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.166 Acc 95.962%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.118 Acc 96.720%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.120 Acc 96.661%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.119 Acc 96.602%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.122 Acc 96.548%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.122 Acc 96.507%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.163 Acc 96.063%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.159 Acc 96.156%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.182 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.115 Acc 96.604%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.116 Acc 96.580%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.117 Acc 96.566%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.120 Acc 96.462%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.121 Acc 96.431%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.166 Acc 95.939%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.163 Acc 96.012%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.114 Acc 96.767%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.112 Acc 96.758%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.115 Acc 96.605%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.119 Acc 96.509%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.121 Acc 96.456%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.163 Acc 96.035%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.120 Acc 96.457%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.119 Acc 96.471%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.120 Acc 96.499%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.120 Acc 96.470%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [105/200]Batch [500/573] Loss: 0.119 Acc 96.510%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.166 Acc 95.985%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.163 Acc 96.008%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.120 Acc 96.517%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.121 Acc 96.525%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.119 Acc 96.546%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.119 Acc 96.538%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.167 Acc 95.823%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.162 Acc 95.946%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.121 Acc 95.312%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.119 Acc 96.566%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.119 Acc 96.673%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.117 Acc 96.704%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.117 Acc 96.647%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.119 Acc 96.569%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.170 Acc 95.854%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.165 Acc 95.973%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.118 Acc 96.627%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.119 Acc 96.549%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.118 Acc 96.493%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.117 Acc 96.517%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.118 Acc 96.502%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.172 Acc 95.699%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.168 Acc 95.787%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.113 Acc 96.697%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.113 Acc 96.708%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.112 Acc 96.735%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.111 Acc 96.766%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.114 Acc 96.668%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.173 Acc 95.746%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.169 Acc 95.833%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.112 Acc 96.751%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.114 Acc 96.745%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.115 Acc 96.696%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.117 Acc 96.635%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.166 Acc 95.884%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.118 Acc 96.560%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.119 Acc 96.548%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.117 Acc 96.589%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.117 Acc 96.548%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.176 Acc 95.514%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.173 Acc 95.713%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.113 Acc 94.531%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.121 Acc 96.442%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.116 Acc 96.603%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.115 Acc 96.608%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.115 Acc 96.602%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.115 Acc 96.593%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.169 Acc 96.009%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.109 Acc 96.798%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.112 Acc 96.667%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.113 Acc 96.672%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.113 Acc 96.686%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.172 Acc 95.862%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.106 Acc 96.798%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.109 Acc 96.828%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.109 Acc 96.803%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.111 Acc 96.730%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.164 Acc 95.908%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.163 Acc 95.997%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.115 Acc 96.635%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.114 Acc 96.595%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.115 Acc 96.643%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.114 Acc 96.668%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 95.893%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.169 Acc 95.934%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.110 Acc 96.759%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.110 Acc 96.782%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.109 Acc 96.867%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.110 Acc 96.834%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.111 Acc 96.761%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.175 Acc 95.730%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.171 Acc 95.853%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.107 Acc 96.786%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.108 Acc 96.826%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.112 Acc 96.705%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.169 Acc 95.792%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.167 Acc 95.880%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.121 Acc 96.395%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.116 Acc 96.704%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.113 Acc 96.771%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.111 Acc 96.762%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.112 Acc 96.756%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.169 Acc 95.854%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.165 Acc 95.962%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.104 Acc 96.860%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.109 Acc 96.782%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.110 Acc 96.766%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.110 Acc 96.776%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.109 Acc 96.767%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.166 Acc 95.955%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.163 Acc 96.059%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.108 Acc 99.219%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.108 Acc 96.983%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.112 Acc 96.727%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.114 Acc 96.696%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.112 Acc 96.709%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.113 Acc 96.680%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.175 Acc 95.854%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.170 Acc 95.958%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.102 Acc 96.852%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.106 Acc 96.909%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.106 Acc 96.879%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.166 Acc 95.924%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.162 Acc 95.989%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.102 Acc 97.192%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.105 Acc 96.941%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.108 Acc 96.805%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.108 Acc 96.815%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.108 Acc 96.814%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.176 Acc 95.606%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.110 Acc 96.712%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.110 Acc 96.649%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.110 Acc 96.668%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.111 Acc 96.668%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.175 Acc 95.769%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.170 Acc 95.853%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.105 Acc 96.824%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.108 Acc 96.737%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.109 Acc 96.696%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.108 Acc 96.752%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.172 Acc 95.838%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.168 Acc 95.868%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.107 Acc 96.999%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.106 Acc 97.023%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.106 Acc 97.015%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.106 Acc 96.941%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.107 Acc 96.880%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.168 Acc 96.024%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.164 Acc 96.109%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.107 Acc 96.782%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.105 Acc 96.854%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.107 Acc 96.811%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.108 Acc 96.746%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.924%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.169 Acc 96.032%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.103 Acc 97.037%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.104 Acc 96.914%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.106 Acc 96.852%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.107 Acc 96.830%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.107 Acc 96.783%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.168 Acc 96.140%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.162 Acc 96.171%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.099 Acc 96.929%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.105 Acc 96.755%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.104 Acc 96.800%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.105 Acc 96.811%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.106 Acc 96.811%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.168 Acc 95.993%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.104 Acc 97.022%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.103 Acc 96.894%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.104 Acc 96.898%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.104 Acc 96.918%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.106 Acc 96.834%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.144 Acc 93.750%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.164 Acc 96.024%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.181 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.100 Acc 97.123%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.101 Acc 97.015%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.101 Acc 97.031%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.104 Acc 96.992%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.106 Acc 96.894%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.167 Acc 95.978%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.163 Acc 96.035%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.105 Acc 96.829%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.103 Acc 96.863%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.106 Acc 96.848%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.106 Acc 96.814%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.171 Acc 95.862%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.169 Acc 95.876%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.110 Acc 96.929%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.109 Acc 96.898%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.108 Acc 96.917%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.106 Acc 96.965%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.106 Acc 96.972%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.181 Acc 95.838%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.175 Acc 95.798%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.108 Acc 96.914%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.102 Acc 97.062%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.102 Acc 97.096%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.103 Acc 97.043%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.103 Acc 97.032%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.171 Acc 96.032%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.950%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.101 Acc 96.921%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.102 Acc 96.940%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.101 Acc 97.013%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.102 Acc 96.965%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.168 Acc 96.086%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.166 Acc 96.098%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.093 Acc 97.130%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.097 Acc 97.163%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.097 Acc 97.194%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.099 Acc 97.066%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.101 Acc 97.029%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.838%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.173 Acc 95.791%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.105 Acc 96.857%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.104 Acc 96.906%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.142 Acc 96.875%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.175 Acc 95.978%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.168 Acc 96.117%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.191 Acc 92.969%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.096 Acc 97.246%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.097 Acc 97.151%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.100 Acc 97.015%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.103 Acc 96.918%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.103 Acc 96.906%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.165 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.175 Acc 95.900%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.171 Acc 95.946%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.137 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.096 Acc 97.022%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.097 Acc 97.062%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.100 Acc 97.000%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.102 Acc 96.956%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.168 Acc 95.934%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.091 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.105 Acc 96.941%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.105 Acc 96.948%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.103 Acc 96.957%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.103 Acc 96.920%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.108 Acc 96.875%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.931%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 96.078%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.096 Acc 97.208%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.098 Acc 97.065%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.100 Acc 97.031%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.101 Acc 97.058%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.101 Acc 97.028%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.177 Acc 95.800%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.169 Acc 96.016%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.090 Acc 97.262%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.099 Acc 97.050%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.100 Acc 97.059%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.100 Acc 97.050%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.101 Acc 97.000%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.167 Acc 96.040%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.162 Acc 96.168%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.096 Acc 97.053%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.097 Acc 97.101%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.099 Acc 97.066%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.101 Acc 97.026%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.174 Acc 95.985%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.167 Acc 96.129%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.099 Acc 97.006%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.096 Acc 97.058%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.097 Acc 97.044%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.100 Acc 96.961%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.100 Acc 96.967%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.182 Acc 95.591%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.176 Acc 95.767%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.089 Acc 97.393%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.096 Acc 97.030%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.099 Acc 97.029%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.169 Acc 95.993%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.163 Acc 96.133%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.099 Acc 96.960%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.093 Acc 97.225%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.095 Acc 97.186%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.095 Acc 97.152%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.097 Acc 97.101%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.177 Acc 95.823%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.171 Acc 95.962%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.097 Acc 97.169%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.101 Acc 96.957%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.100 Acc 97.009%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.182 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.181 Acc 95.808%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.176 Acc 95.826%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.096 Acc 97.184%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.093 Acc 97.229%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.096 Acc 97.148%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.097 Acc 97.037%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.173 Acc 95.939%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.169 Acc 95.981%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.168 Acc 95.312%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.097 Acc 97.153%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.098 Acc 97.100%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.099 Acc 97.116%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.099 Acc 97.099%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.099 Acc 97.110%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.175 Acc 95.684%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.172 Acc 95.779%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.103 Acc 96.728%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.098 Acc 97.011%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.096 Acc 97.114%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.097 Acc 97.089%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.098 Acc 97.078%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.939%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 96.000%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.097 Acc 96.883%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.097 Acc 96.999%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.096 Acc 97.023%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.097 Acc 97.029%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.097 Acc 97.062%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.182 Acc 95.777%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.178 Acc 95.861%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.098 Acc 96.867%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.096 Acc 97.028%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.098 Acc 97.037%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.169 Acc 96.032%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.165 Acc 96.039%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.094 Acc 97.099%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.094 Acc 97.167%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.096 Acc 97.101%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.097 Acc 97.052%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.099 Acc 97.045%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.198 Acc 95.475%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.190 Acc 95.588%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.034 Acc 100.000%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.099 Acc 96.852%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.100 Acc 96.929%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.100 Acc 96.909%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.100 Acc 96.984%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.099 Acc 97.004%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.171 Acc 95.993%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.168 Acc 96.012%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.087 Acc 97.285%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.091 Acc 97.167%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.093 Acc 97.163%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.093 Acc 97.136%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.094 Acc 97.148%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.180 Acc 95.792%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.176 Acc 95.756%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.087 Acc 97.285%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.093 Acc 97.240%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.093 Acc 97.197%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.094 Acc 97.157%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.096 Acc 97.135%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.173 Acc 95.955%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.169 Acc 96.008%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.091 Acc 97.300%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.094 Acc 97.209%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.094 Acc 97.181%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.096 Acc 97.156%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.095 Acc 97.167%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.188 Acc 95.753%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.183 Acc 95.802%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.092 Acc 97.153%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.096 Acc 97.111%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.096 Acc 97.048%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.095 Acc 97.065%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.188 Acc 95.627%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.089 Acc 97.262%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.091 Acc 97.170%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.092 Acc 97.212%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.095 Acc 97.161%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.095 Acc 97.170%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.171 Acc 95.939%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.168 Acc 95.997%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.088 Acc 97.362%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.090 Acc 97.329%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.091 Acc 97.265%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.094 Acc 97.192%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.174 Acc 95.934%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.092 Acc 97.324%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.094 Acc 97.163%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.095 Acc 97.134%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.094 Acc 97.163%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.177 Acc 96.024%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.171 Acc 96.102%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.094 Acc 97.061%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.095 Acc 97.120%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.094 Acc 97.127%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.093 Acc 97.140%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.182 Acc 95.707%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.178 Acc 95.818%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.096 Acc 97.068%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.092 Acc 97.213%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.091 Acc 97.244%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.090 Acc 97.222%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.092 Acc 97.163%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.177 Acc 95.869%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.173 Acc 95.954%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.093 Acc 97.123%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.092 Acc 97.217%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.094 Acc 97.145%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.094 Acc 97.124%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.095 Acc 97.100%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.185 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.182 Acc 95.864%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.088 Acc 97.269%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.089 Acc 97.317%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.090 Acc 97.243%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.180 Acc 95.746%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.176 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.087 Acc 97.370%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.090 Acc 97.277%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.091 Acc 97.247%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.091 Acc 97.240%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.178 Acc 95.730%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.174 Acc 95.783%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.090 Acc 97.153%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.087 Acc 97.252%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.092 Acc 97.171%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.092 Acc 97.181%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.092 Acc 97.188%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.181 Acc 95.800%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.175 Acc 95.884%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.185 Acc 96.875%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.089 Acc 97.163%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.088 Acc 97.228%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.088 Acc 97.232%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.091 Acc 97.185%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.179 Acc 95.985%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.173 Acc 96.059%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.089 Acc 97.361%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.088 Acc 97.368%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.088 Acc 97.350%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.090 Acc 97.274%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.661%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.090 Acc 97.347%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.088 Acc 97.407%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.088 Acc 97.364%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.089 Acc 97.349%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.173 Acc 95.924%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.169 Acc 96.074%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.082 Acc 97.409%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.087 Acc 97.264%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.089 Acc 97.199%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.089 Acc 97.233%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.089 Acc 97.252%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.172 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.185 Acc 95.955%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.182 Acc 95.958%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.200 Acc 95.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.084 Acc 97.509%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.086 Acc 97.376%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.089 Acc 97.237%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.090 Acc 97.235%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.182 Acc 95.808%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.175 Acc 95.861%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.080 Acc 97.579%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.083 Acc 97.454%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.086 Acc 97.415%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.088 Acc 97.331%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.088 Acc 97.326%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.179 Acc 96.001%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.175 Acc 96.148%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.091 Acc 97.231%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.091 Acc 97.128%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.091 Acc 97.186%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.090 Acc 97.249%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.090 Acc 97.280%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.182 Acc 95.893%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.175 Acc 96.028%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.084 Acc 97.502%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.091 Acc 97.209%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.091 Acc 97.166%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.089 Acc 97.210%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.090 Acc 97.204%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.178 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.183 Acc 95.722%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.177 Acc 95.903%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.093 Acc 97.223%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.086 Acc 97.396%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.088 Acc 97.293%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.088 Acc 97.288%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.089 Acc 97.285%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.184 Acc 95.753%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.179 Acc 95.907%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.084 Acc 97.416%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.085 Acc 97.345%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.087 Acc 97.298%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.088 Acc 97.301%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.184 Acc 95.869%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.178 Acc 95.888%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.087 Acc 97.471%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.089 Acc 97.338%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.088 Acc 97.334%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.089 Acc 97.329%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.091 Acc 97.259%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.885%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.172 Acc 95.942%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.141 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.091 Acc 97.293%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.090 Acc 97.223%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.089 Acc 97.237%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.089 Acc 97.227%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.195 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.188 Acc 95.668%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.185 Acc 95.748%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.083 Acc 97.466%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.084 Acc 97.451%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.085 Acc 97.401%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.182 Acc 95.823%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.177 Acc 95.938%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.087 Acc 97.316%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.088 Acc 97.303%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.088 Acc 97.273%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.189 Acc 95.707%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.186 Acc 95.709%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.086 Acc 97.347%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.086 Acc 97.322%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.085 Acc 97.392%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.086 Acc 97.345%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.086 Acc 97.349%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.179 Acc 95.931%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.176 Acc 95.977%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.087 Acc 97.231%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.086 Acc 97.358%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.086 Acc 97.346%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.087 Acc 97.309%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.185 Acc 95.784%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.180 Acc 95.857%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.082 Acc 97.455%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.085 Acc 97.404%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.086 Acc 97.397%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.087 Acc 97.368%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.205 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.184 Acc 95.800%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.178 Acc 95.915%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.085 Acc 97.447%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.083 Acc 97.516%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.085 Acc 97.446%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.085 Acc 97.422%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.085 Acc 97.424%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.187 Acc 95.645%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.182 Acc 95.845%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.083 Acc 97.454%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.084 Acc 97.449%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.085 Acc 97.442%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.084 Acc 97.478%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.185 Acc 95.753%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.182 Acc 95.857%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.082 Acc 97.579%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.080 Acc 97.590%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.083 Acc 97.485%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.084 Acc 97.401%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.084 Acc 97.379%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.186 Acc 95.800%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.181 Acc 95.927%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.078 Acc 97.579%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.081 Acc 97.547%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.083 Acc 97.463%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.208 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.196 Acc 95.614%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.187 Acc 95.775%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.079 Acc 97.486%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.083 Acc 97.388%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.082 Acc 97.420%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.082 Acc 97.446%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.084 Acc 97.371%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.185 Acc 95.808%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.184 Acc 95.896%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.077 Acc 97.679%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.077 Acc 97.695%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.083 Acc 97.479%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.083 Acc 97.464%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.181 Acc 95.978%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.179 Acc 96.074%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.082 Acc 97.447%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.083 Acc 97.516%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.085 Acc 97.423%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.085 Acc 97.368%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.084 Acc 97.382%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.185 Acc 95.862%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.179 Acc 95.985%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.076 Acc 97.540%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.077 Acc 97.551%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.081 Acc 97.451%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.082 Acc 97.446%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.084 Acc 97.354%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.165 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.191 Acc 95.591%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.185 Acc 95.775%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.177 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.079 Acc 97.679%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.082 Acc 97.485%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.083 Acc 97.436%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.082 Acc 97.481%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.083 Acc 97.463%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.183 Acc 95.900%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.179 Acc 95.934%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.106 Acc 94.531%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.077 Acc 97.509%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.082 Acc 97.514%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.083 Acc 97.474%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.174 Acc 96.101%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.170 Acc 96.109%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.085 Acc 97.324%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.085 Acc 97.322%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.084 Acc 97.290%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.085 Acc 97.304%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.084 Acc 97.337%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.188 Acc 96.016%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.180 Acc 96.067%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.077 Acc 97.795%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.082 Acc 97.532%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.081 Acc 97.501%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.082 Acc 97.461%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.082 Acc 97.482%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.191 Acc 95.808%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.185 Acc 95.931%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.075 Acc 97.718%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [200/573] Loss: 0.076 Acc 97.606%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.079 Acc 97.612%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.082 Acc 97.553%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.083 Acc 97.486%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.182 Acc 95.730%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.132 Acc 94.531%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.076 Acc 97.401%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.081 Acc 97.361%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.081 Acc 97.417%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.082 Acc 97.419%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.083 Acc 97.405%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.185 Acc 95.792%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.182 Acc 95.853%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.079 Acc 97.587%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.082 Acc 97.435%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.082 Acc 97.425%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.081 Acc 97.469%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.083 Acc 97.404%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.190 Acc 95.753%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.185 Acc 95.919%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.083 Acc 97.625%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.080 Acc 97.629%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.082 Acc 97.558%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.082 Acc 97.553%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.081 Acc 97.567%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.174 Acc 96.117%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074af0a5984948e88e674dac2b2c88a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.310 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.240 Acc 18.975%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.898%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.240 Acc 18.816%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.239 Acc 18.840%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.220 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.221 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.277 Acc 17.188%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.231 Acc 18.696%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.226 Acc 19.026%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.194 Acc 20.416%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.137 Acc 22.765%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.069 Acc 25.787%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.452 Acc 54.688%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.411 Acc 54.100%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.412 Acc 54.023%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.561 Acc 45.312%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.437 Acc 52.081%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.369 Acc 54.019%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.306 Acc 56.240%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.257 Acc 58.031%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.218 Acc 59.433%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.977 Acc 67.969%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.926 Acc 69.980%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.922 Acc 69.963%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.128 Acc 62.500%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.948 Acc 69.237%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.936 Acc 69.706%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.912 Acc 70.606%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.898 Acc 71.080%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.883 Acc 71.526%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.764 Acc 76.562%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.681 Acc 78.473%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.675 Acc 78.455%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.635 Acc 82.812%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.754 Acc 76.075%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.745 Acc 76.345%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.735 Acc 76.630%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.722 Acc 76.991%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.713 Acc 77.320%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.644 Acc 81.250%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.574 Acc 81.946%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.566 Acc 82.012%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.714 Acc 77.344%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.643 Acc 79.672%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.628 Acc 80.096%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.626 Acc 80.238%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.618 Acc 80.510%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.612 Acc 80.757%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.516 Acc 85.938%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.467 Acc 85.659%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.462 Acc 85.599%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.509 Acc 82.812%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.577 Acc 81.784%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.568 Acc 82.008%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.564 Acc 82.267%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.555 Acc 82.501%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.547 Acc 82.753%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.409 Acc 88.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.418 Acc 87.593%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.414 Acc 87.547%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.497 Acc 83.594%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.512 Acc 84.120%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.507 Acc 84.107%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.506 Acc 84.160%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.502 Acc 84.320%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.498 Acc 84.381%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.364 Acc 89.844%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.381 Acc 88.521%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.377 Acc 88.569%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.388 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.475 Acc 85.087%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.476 Acc 85.211%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.475 Acc 85.263%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.471 Acc 85.359%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.468 Acc 85.481%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.356 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.352 Acc 89.542%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.349 Acc 89.498%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.363 Acc 88.281%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.444 Acc 86.270%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.437 Acc 86.451%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.435 Acc 86.584%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.437 Acc 86.491%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.437 Acc 86.446%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.370 Acc 89.062%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.344 Acc 89.627%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.339 Acc 89.646%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.413 Acc 85.938%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.429 Acc 86.719%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.421 Acc 86.960%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.419 Acc 87.007%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.422 Acc 87.044%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.420 Acc 87.096%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.317 Acc 89.062%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.335 Acc 90.231%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.330 Acc 90.314%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.530 Acc 87.500%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.407 Acc 87.446%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.397 Acc 87.799%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.400 Acc 87.653%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.397 Acc 87.708%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.397 Acc 87.765%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.365 Acc 89.062%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.320 Acc 90.463%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.316 Acc 90.547%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.320 Acc 90.625%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.388 Acc 88.041%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.385 Acc 88.106%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.381 Acc 88.214%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.379 Acc 88.324%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.379 Acc 88.275%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.326 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.311 Acc 90.903%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.306 Acc 90.975%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.249 Acc 92.188%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.387 Acc 88.088%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.379 Acc 88.301%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.376 Acc 88.367%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.373 Acc 88.490%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.370 Acc 88.601%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.268 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.291 Acc 91.538%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.286 Acc 91.752%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.358 Acc 87.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.353 Acc 89.101%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.349 Acc 89.199%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.353 Acc 89.133%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.350 Acc 89.197%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.354 Acc 89.098%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.274 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.281 Acc 91.677%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.276 Acc 91.818%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.400 Acc 87.500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.344 Acc 89.697%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.341 Acc 89.649%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.341 Acc 89.558%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.341 Acc 89.518%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.342 Acc 89.469%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.276 Acc 89.844%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.294 Acc 91.638%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.287 Acc 91.667%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.251 Acc 93.750%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.331 Acc 89.975%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.334 Acc 89.910%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.333 Acc 89.870%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.337 Acc 89.768%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.336 Acc 89.780%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.270 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.261 Acc 92.551%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.258 Acc 92.561%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.316 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.327 Acc 90.207%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.331 Acc 90.019%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.330 Acc 89.857%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.328 Acc 89.992%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.323 Acc 90.078%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.255 Acc 93.038%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.252 Acc 92.973%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.314 Acc 94.531%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.305 Acc 90.401%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.307 Acc 90.431%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.307 Acc 90.602%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.307 Acc 90.629%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.311 Acc 90.564%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.246 Acc 90.625%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.258 Acc 92.744%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.252 Acc 92.817%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.386 Acc 84.375%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.310 Acc 90.563%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.311 Acc 90.574%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.312 Acc 90.532%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.310 Acc 90.551%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.310 Acc 90.597%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.234 Acc 90.625%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.252 Acc 92.783%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.247 Acc 92.910%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.243 Acc 92.969%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.306 Acc 90.896%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.303 Acc 90.998%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.302 Acc 91.020%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.299 Acc 91.104%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.298 Acc 91.085%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.249 Acc 93.015%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.246 Acc 92.942%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.192 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.290 Acc 91.012%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.292 Acc 91.056%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.294 Acc 91.121%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.291 Acc 91.188%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.294 Acc 91.152%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.233 Acc 90.625%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.228 Acc 93.711%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.227 Acc 93.556%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.277 Acc 91.399%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.284 Acc 91.115%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.287 Acc 91.219%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.289 Acc 91.200%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.287 Acc 91.250%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.232 Acc 93.518%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.229 Acc 93.435%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.240 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.282 Acc 91.662%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.281 Acc 91.546%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.285 Acc 91.440%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.283 Acc 91.424%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.283 Acc 91.447%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.236 Acc 93.572%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.233 Acc 93.435%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.260 Acc 90.625%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.270 Acc 91.948%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.273 Acc 91.810%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.275 Acc 91.816%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.277 Acc 91.761%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.277 Acc 91.734%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.199 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.219 Acc 94.121%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.216 Acc 94.045%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.282 Acc 91.855%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.277 Acc 91.888%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.274 Acc 91.951%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.273 Acc 91.956%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.272 Acc 91.957%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.216 Acc 91.406%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.229 Acc 93.874%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.227 Acc 93.664%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.275 Acc 91.878%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.271 Acc 92.153%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.273 Acc 91.988%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.270 Acc 91.993%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.267 Acc 92.086%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.219 Acc 90.625%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.221 Acc 93.974%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.218 Acc 93.874%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.167 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.257 Acc 92.412%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.257 Acc 92.460%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.259 Acc 92.330%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.263 Acc 92.254%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.261 Acc 92.292%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.216 Acc 94.338%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.211 Acc 94.267%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.230 Acc 92.969%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.252 Acc 92.474%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.257 Acc 92.277%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.252 Acc 92.429%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.254 Acc 92.441%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.257 Acc 92.315%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.224 Acc 93.781%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.222 Acc 93.812%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.260 Acc 92.242%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.254 Acc 92.374%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.255 Acc 92.494%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.256 Acc 92.462%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.255 Acc 92.498%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.213 Acc 94.253%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.210 Acc 94.189%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.234 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.260 Acc 92.195%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.256 Acc 92.374%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.252 Acc 92.465%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.253 Acc 92.449%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.253 Acc 92.473%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.211 Acc 94.330%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.209 Acc 94.267%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.248 Acc 92.698%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.248 Acc 92.654%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.246 Acc 92.681%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.251 Acc 92.628%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.250 Acc 92.652%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.173 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.205 Acc 94.562%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.202 Acc 94.504%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.330 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.244 Acc 92.752%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.241 Acc 92.774%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.245 Acc 92.701%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.246 Acc 92.741%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.249 Acc 92.702%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.210 Acc 94.400%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.211 Acc 94.248%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.184 Acc 91.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.231 Acc 92.938%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.239 Acc 92.949%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.240 Acc 92.844%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.240 Acc 92.786%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.241 Acc 92.791%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.547%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.201 Acc 94.578%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.312 Acc 92.188%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.243 Acc 92.984%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.244 Acc 92.771%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.239 Acc 92.943%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.238 Acc 92.994%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.239 Acc 92.970%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.933%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.192 Acc 94.951%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.279 Acc 92.188%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.231 Acc 93.394%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.232 Acc 93.136%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.234 Acc 93.119%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.233 Acc 93.169%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.234 Acc 93.154%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.205 Acc 94.585%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.203 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.221 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.226 Acc 93.626%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.232 Acc 93.412%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.232 Acc 93.335%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.233 Acc 93.238%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.232 Acc 93.254%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.189 Acc 95.011%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.187 Acc 94.935%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.223 Acc 93.572%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.225 Acc 93.330%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.230 Acc 93.241%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.231 Acc 93.216%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.232 Acc 93.200%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.197 Acc 94.864%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.196 Acc 94.726%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.227 Acc 93.294%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.227 Acc 93.315%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.298%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.227 Acc 93.288%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.228 Acc 93.239%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.200 Acc 94.756%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.198 Acc 94.656%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.356 Acc 90.625%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.233 Acc 93.170%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.225 Acc 93.509%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.228 Acc 93.392%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.226 Acc 93.405%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.224 Acc 93.437%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.208 Acc 92.188%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.200 Acc 94.817%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.198 Acc 94.675%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.243 Acc 89.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.226 Acc 93.332%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.219 Acc 93.474%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.222 Acc 93.477%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.221 Acc 93.458%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.220 Acc 93.532%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.206 Acc 94.500%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.206 Acc 94.415%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.266 Acc 91.406%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.223 Acc 93.425%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.223 Acc 93.521%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.225 Acc 93.457%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.224 Acc 93.456%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.224 Acc 93.497%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.202 Acc 94.756%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.201 Acc 94.652%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.292 Acc 92.188%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.215 Acc 93.611%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.222 Acc 93.493%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.218 Acc 93.623%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.218 Acc 93.674%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.219 Acc 93.574%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.201 Acc 94.640%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.199 Acc 94.617%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.228 Acc 91.406%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.209 Acc 93.858%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.206 Acc 93.882%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.210 Acc 93.882%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.211 Acc 93.914%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.213 Acc 93.847%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.195 Acc 94.856%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.192 Acc 94.897%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.210 Acc 93.634%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.215 Acc 93.575%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.211 Acc 93.776%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.211 Acc 93.826%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.213 Acc 93.759%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.202 Acc 94.632%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.201 Acc 94.535%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.083 Acc 99.219%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.210 Acc 93.827%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.212 Acc 93.781%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.214 Acc 93.706%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.214 Acc 93.713%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.213 Acc 93.789%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.182 Acc 95.405%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.279 Acc 93.750%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.200 Acc 94.121%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.202 Acc 94.201%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.207 Acc 94.087%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.211 Acc 93.999%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.211 Acc 93.943%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.189 Acc 94.995%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.187 Acc 95.005%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.305 Acc 90.625%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.200 Acc 93.881%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.202 Acc 94.135%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.208 Acc 94.015%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.210 Acc 93.982%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.210 Acc 93.959%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.186 Acc 95.150%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.185 Acc 94.951%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.191 Acc 94.477%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.205 Acc 94.073%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.206 Acc 94.108%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.209 Acc 94.048%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.207 Acc 94.098%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.188 Acc 95.166%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.186 Acc 95.173%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.320 Acc 89.844%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.197 Acc 94.291%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.207 Acc 93.975%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.205 Acc 94.010%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.205 Acc 94.027%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.208 Acc 93.962%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.183 Acc 95.142%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.182 Acc 95.079%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.269 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.196 Acc 94.276%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.198 Acc 94.352%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.201 Acc 94.282%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.202 Acc 94.249%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.204 Acc 94.140%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.194 Acc 94.926%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.195 Acc 94.850%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.295 Acc 94.531%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.208 Acc 94.129%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.207 Acc 94.042%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.207 Acc 94.002%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.205 Acc 94.046%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.202 Acc 94.127%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.176 Acc 95.429%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.201 Acc 94.199%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.197 Acc 94.263%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.194 Acc 94.329%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.197 Acc 94.214%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.198 Acc 94.151%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.178 Acc 95.297%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.177 Acc 95.208%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.298 Acc 90.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.193 Acc 94.253%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.195 Acc 94.193%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.199 Acc 94.145%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.197 Acc 94.192%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.199 Acc 94.196%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.413%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.177 Acc 95.386%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.197 Acc 94.338%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.194 Acc 94.438%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.193 Acc 94.440%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.196 Acc 94.397%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.198 Acc 94.341%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.142 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.182 Acc 95.181%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.227%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.196 Acc 92.188%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.195 Acc 94.384%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.201 Acc 94.306%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.197 Acc 94.383%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.197 Acc 94.346%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.198 Acc 94.347%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.195 Acc 95.104%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.194 Acc 95.025%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.192 Acc 94.462%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.194 Acc 94.345%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.195 Acc 94.303%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.196 Acc 94.305%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.196 Acc 94.346%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.180 Acc 95.266%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.179 Acc 95.231%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.167 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.190 Acc 94.454%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.191 Acc 94.492%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.191 Acc 94.443%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.189 Acc 94.527%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.192 Acc 94.435%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.173 Acc 95.552%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.171 Acc 95.441%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.231 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.185 Acc 94.694%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.184 Acc 94.764%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.188 Acc 94.581%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.191 Acc 94.528%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.190 Acc 95.003%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.189 Acc 94.963%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.179 Acc 94.779%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.186 Acc 94.500%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.191 Acc 94.559%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.192 Acc 94.536%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.183 Acc 95.351%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.181 Acc 95.258%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.256 Acc 90.625%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.190 Acc 94.438%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.192 Acc 94.415%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.188 Acc 94.492%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.191 Acc 94.438%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.191 Acc 94.453%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.112 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.374%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.171 Acc 95.476%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.126 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.177 Acc 94.670%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.189 Acc 94.609%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.191 Acc 94.555%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.191 Acc 94.553%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.177 Acc 95.459%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.176 Acc 95.336%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.214 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.177 Acc 94.787%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.186 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.185 Acc 94.578%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.187 Acc 94.574%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.188 Acc 94.556%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.182 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.190 Acc 94.451%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.189 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.188 Acc 94.578%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.179 Acc 95.552%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.177 Acc 95.515%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.185 Acc 94.856%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.187 Acc 94.726%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.191 Acc 94.583%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.190 Acc 94.629%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.188 Acc 94.726%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.183 Acc 95.390%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.185 Acc 95.316%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.164 Acc 93.750%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.180 Acc 94.825%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.179 Acc 94.908%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.179 Acc 94.908%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.180 Acc 94.882%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.182 Acc 94.824%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.181 Acc 95.552%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.507%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.177 Acc 94.810%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.186 Acc 94.582%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.183 Acc 94.625%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.180 Acc 94.744%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.183 Acc 94.656%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.178 Acc 95.355%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.174 Acc 95.073%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.182 Acc 94.862%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.180 Acc 94.850%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.181 Acc 94.798%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.183 Acc 94.756%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.177 Acc 95.568%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.588%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.184 Acc 94.678%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.180 Acc 94.733%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.183 Acc 94.658%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.184 Acc 94.689%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.183 Acc 94.665%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.180 Acc 95.336%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.179 Acc 95.371%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.277 Acc 91.406%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.183 Acc 94.701%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.186 Acc 94.663%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.186 Acc 94.708%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.183 Acc 94.761%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.181 Acc 94.760%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.107 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.274%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.175 Acc 95.340%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.169 Acc 94.949%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.175 Acc 94.842%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.178 Acc 94.848%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.178 Acc 94.804%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.178 Acc 94.818%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.179 Acc 95.251%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.177 Acc 95.305%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.235 Acc 93.750%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.178 Acc 95.011%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.175 Acc 95.009%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.176 Acc 94.928%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.177 Acc 94.907%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.096 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.176 Acc 95.568%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.173 Acc 95.585%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.168 Acc 95.119%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.171 Acc 94.974%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.173 Acc 94.978%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.174 Acc 94.950%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.176 Acc 94.863%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.175 Acc 95.445%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.188 Acc 92.969%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.174 Acc 94.779%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.173 Acc 94.881%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.175 Acc 94.960%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.175 Acc 94.942%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.175 Acc 94.935%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.105 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.178 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.171 Acc 95.142%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 95.001%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.174 Acc 95.030%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.173 Acc 95.015%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.178 Acc 95.289%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.174 Acc 95.472%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.171 Acc 95.042%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.171 Acc 95.037%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.171 Acc 95.076%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.169 Acc 95.063%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.172 Acc 95.058%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.185 Acc 95.251%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.186 Acc 95.192%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.185 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.162 Acc 95.227%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.167 Acc 95.095%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.167 Acc 95.175%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.169 Acc 95.162%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.171 Acc 95.094%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.506%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.176 Acc 95.460%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.172 Acc 95.042%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.170 Acc 94.967%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.170 Acc 95.040%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.172 Acc 95.042%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.174 Acc 94.966%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.171 Acc 95.701%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.161 Acc 95.142%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.166 Acc 95.200%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.168 Acc 95.170%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.169 Acc 95.122%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.171 Acc 95.088%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.168 Acc 95.661%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.167 Acc 95.612%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.184 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.167 Acc 95.243%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.176%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.171 Acc 95.092%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.172 Acc 95.108%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.169 Acc 95.141%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.179 Acc 95.483%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.179 Acc 95.468%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.167 Acc 95.297%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.168 Acc 95.131%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.170 Acc 95.055%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.170 Acc 95.061%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.114 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.176 Acc 95.630%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.167 Acc 95.320%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.165 Acc 95.394%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.168 Acc 95.315%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.168 Acc 95.235%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.169 Acc 95.163%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.193 Acc 95.235%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.191 Acc 95.200%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.165 Acc 95.034%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.166 Acc 95.095%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.166 Acc 95.136%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.166 Acc 95.153%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.166 Acc 95.227%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.119 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.175 Acc 95.653%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.172 Acc 95.690%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.166 Acc 95.359%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.169 Acc 95.223%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.166 Acc 95.328%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.166 Acc 95.332%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.168 Acc 95.189%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.188 Acc 95.057%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.187 Acc 95.211%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.127 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.157 Acc 95.452%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.161 Acc 95.281%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.166 Acc 95.224%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.167 Acc 95.149%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.166 Acc 95.214%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.180 Acc 95.568%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.179 Acc 95.495%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.242 Acc 91.406%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.164 Acc 95.305%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.166 Acc 95.274%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.166 Acc 95.331%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.165 Acc 95.303%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.166 Acc 95.213%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.185 Acc 95.374%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.183 Acc 95.433%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.166 Acc 95.274%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.163 Acc 95.417%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.165 Acc 95.341%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.164 Acc 95.316%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.165 Acc 95.300%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.172 Acc 95.661%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.170 Acc 95.693%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.281 Acc 93.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.164 Acc 95.537%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.165 Acc 95.390%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.164 Acc 95.362%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.165 Acc 95.305%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.164 Acc 95.337%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.171 Acc 95.637%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.167 Acc 95.736%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.159 Acc 95.545%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.162 Acc 95.519%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.162 Acc 95.536%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.165 Acc 95.406%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.164 Acc 95.375%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.178 Acc 95.599%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.175 Acc 95.701%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.168 Acc 92.969%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.104%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.159 Acc 95.188%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.161 Acc 95.261%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.162 Acc 95.274%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.162 Acc 95.295%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.119 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.178 Acc 95.490%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.177 Acc 95.565%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.127 Acc 95.312%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.156 Acc 95.483%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.159 Acc 95.355%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.161 Acc 95.357%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.162 Acc 95.350%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.162 Acc 95.361%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.174 Acc 95.862%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.155 Acc 95.514%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.156 Acc 95.600%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.158 Acc 95.559%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.160 Acc 95.488%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.160 Acc 95.412%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.179 Acc 95.336%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.169 Acc 95.305%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.162 Acc 95.398%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.160 Acc 95.471%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.160 Acc 95.431%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.160 Acc 95.408%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.168 Acc 95.815%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.168 Acc 95.814%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.150 Acc 95.498%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.154 Acc 95.530%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.155 Acc 95.551%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.154 Acc 95.558%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.159 Acc 95.490%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.170 Acc 95.794%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.232 Acc 92.188%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.153 Acc 95.521%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.155 Acc 95.612%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.158 Acc 95.588%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.158 Acc 95.511%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.159 Acc 95.479%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.087 Acc 96.875%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.181 Acc 95.537%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.177 Acc 95.620%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.082 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.152 Acc 95.722%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.666%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.155 Acc 95.601%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.156 Acc 95.620%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.156 Acc 95.568%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.173 Acc 95.699%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.169 Acc 95.779%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.150 Acc 95.490%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.152 Acc 95.441%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.158 Acc 95.341%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.156 Acc 95.394%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.157 Acc 95.403%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.171 Acc 95.831%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.168 Acc 95.752%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.153 Acc 95.429%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.152 Acc 95.674%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.154 Acc 95.673%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.156 Acc 95.579%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.157 Acc 95.537%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.178 Acc 95.722%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.175 Acc 95.728%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.150 Acc 95.699%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.156 Acc 95.550%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.153 Acc 95.556%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.156 Acc 95.544%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.157 Acc 95.498%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.179 Acc 95.784%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.176 Acc 95.775%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.161 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.161 Acc 95.452%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.157 Acc 95.550%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.157 Acc 95.531%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.153 Acc 95.560%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.153 Acc 95.610%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.181 Acc 95.374%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.179 Acc 95.456%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.132 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.575%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.153 Acc 95.425%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.154 Acc 95.447%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.154 Acc 95.496%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.155 Acc 95.543%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.186 Acc 95.459%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.184 Acc 95.534%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.151 Acc 95.630%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.150 Acc 95.643%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.151 Acc 95.663%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.149 Acc 95.712%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.150 Acc 95.684%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.175 Acc 95.568%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.173 Acc 95.600%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.149 Acc 95.506%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.146 Acc 95.658%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.150 Acc 95.595%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.153 Acc 95.564%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.153 Acc 95.581%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.104 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.575%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.173 Acc 95.662%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.309 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.158 Acc 95.475%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.152 Acc 95.693%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.152 Acc 95.621%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.152 Acc 95.611%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.152 Acc 95.657%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.170 Acc 95.792%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.167 Acc 95.791%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.150 Acc 95.599%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.147 Acc 95.635%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.150 Acc 95.614%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.150 Acc 95.689%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.151 Acc 95.668%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.166 Acc 95.931%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.163 Acc 95.896%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.147 Acc 95.846%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.150 Acc 95.651%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.150 Acc 95.629%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.152 Acc 95.609%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.152 Acc 95.634%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.166 Acc 95.838%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.163 Acc 95.923%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.138 Acc 96.055%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.143 Acc 95.969%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.146 Acc 95.847%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.148 Acc 95.798%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.151 Acc 95.685%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.413%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.180 Acc 95.433%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.146 Acc 95.521%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.145 Acc 95.791%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.146 Acc 95.811%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.146 Acc 95.827%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.147 Acc 95.766%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.171 Acc 95.614%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.169 Acc 95.732%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.147 Acc 95.893%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.149 Acc 95.682%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.150 Acc 95.630%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.149 Acc 95.640%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.118 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.164 Acc 95.761%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.162 Acc 95.853%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.112 Acc 93.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.142 Acc 95.746%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.146 Acc 95.810%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.149 Acc 95.684%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.150 Acc 95.687%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.147 Acc 95.734%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.162 Acc 95.854%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.161 Acc 95.868%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.153 Acc 95.831%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.148 Acc 95.833%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.149 Acc 95.780%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.149 Acc 95.772%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.149 Acc 95.769%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.176 Acc 95.699%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.173 Acc 95.752%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.139 Acc 95.939%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.147 Acc 95.693%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.144 Acc 95.733%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.146 Acc 95.704%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.147 Acc 95.723%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.099 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.165 Acc 95.893%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.163 Acc 95.845%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.151 Acc 95.622%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.154 Acc 95.515%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.149 Acc 95.642%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.147 Acc 95.755%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.147 Acc 95.760%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.086 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 95.970%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.168 Acc 95.981%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.225 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.138 Acc 95.784%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.138 Acc 95.791%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.140 Acc 95.829%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.142 Acc 95.780%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.143 Acc 95.774%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.173 Acc 95.730%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.170 Acc 95.752%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.134 Acc 96.202%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.143 Acc 95.931%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.146 Acc 95.839%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.146 Acc 95.874%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.146 Acc 95.843%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.082 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.176 Acc 95.614%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.172 Acc 95.798%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.138 Acc 96.028%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.144 Acc 95.865%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.145 Acc 95.842%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.144 Acc 95.877%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.179 Acc 95.676%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.176 Acc 95.643%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.143 Acc 95.692%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.144 Acc 95.725%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.146 Acc 95.772%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.145 Acc 95.780%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.144 Acc 95.810%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.171 Acc 95.885%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.168 Acc 95.864%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.138 Acc 96.032%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.136 Acc 96.043%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.139 Acc 95.967%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.143 Acc 95.825%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.145 Acc 95.769%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.173 Acc 95.924%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.141 Acc 95.831%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.144 Acc 96.000%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.143 Acc 95.998%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.142 Acc 95.967%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.076 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.174 Acc 95.784%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.172 Acc 95.705%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.131 Acc 95.978%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.141 Acc 95.943%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.142 Acc 95.885%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.142 Acc 95.900%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.142 Acc 95.978%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.139 Acc 96.021%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.141 Acc 95.989%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.142 Acc 95.966%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.181 Acc 95.560%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.178 Acc 95.620%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.132 Acc 95.962%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.137 Acc 95.954%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.136 Acc 95.967%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.139 Acc 95.895%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.141 Acc 95.885%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.172 Acc 95.715%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.167 Acc 95.725%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.140 Acc 95.862%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.141 Acc 95.933%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.143 Acc 95.866%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.142 Acc 95.874%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.168 Acc 95.818%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.139 Acc 96.241%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.137 Acc 96.028%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.137 Acc 96.008%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.136 Acc 96.066%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.138 Acc 96.017%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.183 Acc 95.498%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.179 Acc 95.631%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.137 Acc 96.032%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.131 Acc 96.218%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.133 Acc 96.169%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.137 Acc 96.057%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.138 Acc 96.038%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.178 Acc 95.591%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.173 Acc 95.697%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.171 Acc 94.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.141 Acc 96.071%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.140 Acc 96.028%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.142 Acc 95.881%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.141 Acc 95.918%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.140 Acc 95.933%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.183 Acc 95.692%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.180 Acc 95.752%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.162 Acc 93.750%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.136 Acc 95.924%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.142 Acc 95.888%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.142 Acc 95.954%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.141 Acc 95.959%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.140 Acc 96.002%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.114 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.885%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.168 Acc 95.888%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.128 Acc 96.194%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.137 Acc 95.977%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.135 Acc 95.930%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.138 Acc 95.891%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.138 Acc 95.910%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.166 Acc 95.854%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.162 Acc 95.911%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.207 Acc 92.188%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.133 Acc 96.129%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.135 Acc 96.070%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.138 Acc 95.952%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.138 Acc 95.953%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.171 Acc 95.800%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.135 Acc 96.202%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.134 Acc 96.143%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.133 Acc 96.150%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.135 Acc 96.103%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.080 Acc 96.875%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.181 Acc 95.661%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.713%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.332 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.140 Acc 96.028%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.139 Acc 96.081%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.137 Acc 96.098%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.136 Acc 96.092%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.172 Acc 95.872%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.137 Acc 96.179%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.138 Acc 96.144%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.137 Acc 96.104%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.135 Acc 96.139%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.134 Acc 96.181%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.167 Acc 96.109%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.166 Acc 95.981%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.120 Acc 96.581%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.129 Acc 96.385%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.130 Acc 96.278%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.134 Acc 96.166%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.136 Acc 96.106%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.184 Acc 95.606%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.181 Acc 95.588%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.221 Acc 91.406%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.135 Acc 96.183%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.133 Acc 96.270%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.132 Acc 96.254%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.134 Acc 96.192%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.173 Acc 95.769%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.946%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.134 Acc 96.047%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.133 Acc 96.168%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.131 Acc 96.166%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.133 Acc 96.150%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.135 Acc 96.056%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.089 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.169 Acc 95.630%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.167 Acc 95.783%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.132 Acc 96.310%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.128 Acc 96.327%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.133 Acc 96.161%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.134 Acc 96.207%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.132 Acc 96.243%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.177 Acc 95.753%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.174 Acc 95.736%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.126 Acc 96.310%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.130 Acc 96.280%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.129 Acc 96.273%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.133 Acc 96.162%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.133 Acc 96.126%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.099 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.186 Acc 95.568%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.185 Acc 95.635%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.127 Acc 96.241%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.130 Acc 96.117%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.133 Acc 96.078%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.133 Acc 96.053%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.184 Acc 95.885%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.183 Acc 95.853%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.127 Acc 96.349%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.125 Acc 96.428%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.127 Acc 96.403%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.129 Acc 96.337%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.131 Acc 96.303%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.177 Acc 95.715%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.173 Acc 95.849%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.135 Acc 96.140%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.132 Acc 96.164%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.132 Acc 96.168%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.131 Acc 96.189%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.169 Acc 95.970%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 95.989%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.123 Acc 96.218%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.127 Acc 96.156%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.129 Acc 96.107%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.130 Acc 96.053%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.131 Acc 96.047%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.178 Acc 95.668%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.175 Acc 95.759%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.123 Acc 96.233%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.126 Acc 96.051%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.131 Acc 96.031%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.131 Acc 96.053%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.132 Acc 96.047%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.083 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.171 Acc 95.829%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.118 Acc 96.519%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.121 Acc 96.409%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.125 Acc 96.317%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.129 Acc 96.207%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.128 Acc 96.237%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.168 Acc 95.784%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.165 Acc 95.880%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.126 Acc 96.300%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.126 Acc 96.213%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.128 Acc 96.199%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.129 Acc 96.225%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.110 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.174 Acc 95.529%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.171 Acc 95.690%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.125 Acc 96.253%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.128 Acc 96.275%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.129 Acc 96.211%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.130 Acc 96.189%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.186 Acc 95.459%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.183 Acc 95.655%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.274 Acc 94.531%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.131 Acc 96.101%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.132 Acc 96.063%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.130 Acc 96.117%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.129 Acc 96.189%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.129 Acc 96.153%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.107 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.175 Acc 95.792%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.171 Acc 95.919%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.128 Acc 96.303%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.127 Acc 96.276%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.129 Acc 96.198%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.130 Acc 96.226%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.180 Acc 95.622%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.176 Acc 95.678%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.033 Acc 100.000%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.126 Acc 96.327%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.126 Acc 96.299%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.128 Acc 96.255%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.130 Acc 96.220%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.177 Acc 95.676%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.172 Acc 95.849%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.117 Acc 96.403%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.123 Acc 96.315%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.127 Acc 96.226%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.128 Acc 96.218%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.129 Acc 96.219%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.107 Acc 96.875%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.182 Acc 95.993%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.179 Acc 96.012%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.119 Acc 96.419%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.125 Acc 96.265%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.125 Acc 96.260%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.127 Acc 96.261%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.127 Acc 96.276%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.715%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 95.826%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.127 Acc 96.481%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.126 Acc 96.405%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.125 Acc 96.413%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.128 Acc 96.341%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.129 Acc 96.289%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.176 Acc 95.862%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.171 Acc 95.993%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.123 Acc 96.349%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.123 Acc 96.304%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.129 Acc 96.224%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.125 Acc 96.359%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.085 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.184 Acc 95.560%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.177 Acc 95.717%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.182 Acc 96.094%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.124 Acc 96.457%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.123 Acc 96.436%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.123 Acc 96.369%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.124 Acc 96.376%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.126 Acc 96.315%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.175 Acc 95.931%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.172 Acc 95.896%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.125 Acc 96.334%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.122 Acc 96.409%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.123 Acc 96.387%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.126 Acc 96.271%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.127 Acc 96.278%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.099 Acc 94.531%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.176 Acc 95.784%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.172 Acc 95.853%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.180 Acc 92.188%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.124 Acc 96.256%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.122 Acc 96.284%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.126 Acc 96.262%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.124 Acc 96.298%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.126 Acc 96.286%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.068 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.170 Acc 95.661%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.165 Acc 95.853%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.116 Acc 96.566%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.117 Acc 96.475%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.122 Acc 96.426%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.124 Acc 96.368%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.181 Acc 95.777%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.179 Acc 95.818%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.118 Acc 96.465%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.121 Acc 96.401%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.124 Acc 96.327%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.124 Acc 96.294%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.124 Acc 96.287%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.176 Acc 95.730%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.173 Acc 95.833%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.111 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.116 Acc 96.519%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.119 Acc 96.490%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.125 Acc 96.322%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.130 Acc 96.267%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.129 Acc 96.237%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.178 Acc 95.761%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.176 Acc 95.829%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.123 Acc 96.442%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.124 Acc 96.385%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.122 Acc 96.501%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.122 Acc 96.442%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.122 Acc 96.423%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.093 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.171 Acc 95.924%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.167 Acc 96.000%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.110 Acc 96.836%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.112 Acc 96.685%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.117 Acc 96.574%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.119 Acc 96.526%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.121 Acc 96.449%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.074 Acc 98.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.178 Acc 95.916%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.174 Acc 95.919%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.117 Acc 96.504%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.117 Acc 96.393%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.120 Acc 96.460%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.122 Acc 96.413%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.122 Acc 96.401%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.176 Acc 95.962%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.186 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.119 Acc 96.589%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.120 Acc 96.482%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.123 Acc 96.374%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.121 Acc 96.441%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.121 Acc 96.417%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.177 Acc 95.908%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.173 Acc 95.868%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.119 Acc 96.459%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.120 Acc 96.382%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.120 Acc 96.404%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.120 Acc 96.412%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.185 Acc 95.777%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.182 Acc 95.818%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.145 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.115 Acc 96.488%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.122 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.123 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.122 Acc 96.372%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.122 Acc 96.401%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.176 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.171 Acc 95.892%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.206 Acc 94.531%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.122 Acc 96.473%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.120 Acc 96.545%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.121 Acc 96.460%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.121 Acc 96.466%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.120 Acc 96.504%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.170 Acc 95.831%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.166 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.111 Acc 96.666%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.120 Acc 96.482%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.119 Acc 96.491%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.117 Acc 96.563%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.120 Acc 96.459%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.081 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.171 Acc 95.900%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.040 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.115 Acc 96.666%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.116 Acc 96.537%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.118 Acc 96.488%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.119 Acc 96.482%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.176 Acc 96.109%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.171 Acc 96.113%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.113 Acc 96.615%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.117 Acc 96.564%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.119 Acc 96.509%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.119 Acc 96.515%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.172 Acc 95.800%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.168 Acc 95.837%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.111 Acc 96.720%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.116 Acc 96.587%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.118 Acc 96.555%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.119 Acc 96.527%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.170 Acc 95.838%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.165 Acc 95.911%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.123 Acc 96.426%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.117 Acc 96.549%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.120 Acc 96.491%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.121 Acc 96.493%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.120 Acc 96.499%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.075 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.172 Acc 95.808%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.170 Acc 95.849%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.117 Acc 96.465%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.117 Acc 96.553%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.119 Acc 96.501%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.117 Acc 96.523%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.082 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.173 Acc 95.854%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.169 Acc 95.942%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.113 Acc 96.689%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.115 Acc 96.739%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.118 Acc 96.644%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.117 Acc 96.655%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.116 Acc 96.610%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.182 Acc 95.831%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.179 Acc 95.977%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.132 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.108 Acc 96.689%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.108 Acc 96.793%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.114 Acc 96.631%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.114 Acc 96.629%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.085 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.171 Acc 95.761%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.220 Acc 94.531%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.122 Acc 96.457%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.118 Acc 96.572%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.121 Acc 96.486%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.118 Acc 96.540%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.117 Acc 96.546%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.182 Acc 95.722%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.176 Acc 95.791%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.104 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.117 Acc 96.473%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.115 Acc 96.549%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.117 Acc 96.429%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.115 Acc 96.462%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.116 Acc 96.473%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.103 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.185 Acc 95.815%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.178 Acc 95.907%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.111 Acc 96.473%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.118 Acc 96.381%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.118 Acc 96.465%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.117 Acc 96.530%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.118 Acc 96.523%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.181 Acc 95.808%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.178 Acc 95.876%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.109 Acc 96.573%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.106 Acc 96.704%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.111 Acc 96.618%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.114 Acc 96.529%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.085 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.187 Acc 95.692%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.185 Acc 95.728%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.153 Acc 93.750%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.109 Acc 96.504%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.113 Acc 96.498%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.117 Acc 96.520%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.117 Acc 96.484%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.177 Acc 95.715%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.173 Acc 95.872%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.119 Acc 96.697%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.117 Acc 96.642%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.117 Acc 96.579%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.115 Acc 96.598%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.114 Acc 96.624%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.187 Acc 95.761%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.183 Acc 95.857%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.107 Acc 96.774%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.114 Acc 96.537%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.114 Acc 96.517%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.114 Acc 96.567%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.114 Acc 96.601%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.091 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.173 Acc 95.862%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.169 Acc 96.024%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.113 Acc 96.798%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.113 Acc 96.696%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.111 Acc 96.694%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.113 Acc 96.680%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.171 Acc 95.893%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.117 Acc 96.529%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.115 Acc 96.592%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.115 Acc 96.622%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.182 Acc 95.792%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.178 Acc 95.884%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.169 Acc 93.750%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.112 Acc 96.635%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.114 Acc 96.615%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.112 Acc 96.654%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.114 Acc 96.625%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.179 Acc 95.854%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.175 Acc 95.997%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.116 Acc 96.658%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.113 Acc 96.580%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.115 Acc 96.566%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.115 Acc 96.608%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.115 Acc 96.572%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.177 Acc 95.978%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.175 Acc 95.981%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.105 Acc 96.744%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.109 Acc 96.720%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.110 Acc 96.673%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.112 Acc 96.644%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.178 Acc 95.637%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.172 Acc 95.721%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.134 Acc 95.312%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.113 Acc 96.767%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.111 Acc 96.735%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.112 Acc 96.702%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.114 Acc 96.650%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.170 Acc 95.885%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.165 Acc 96.008%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.108 Acc 96.651%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.109 Acc 96.774%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.110 Acc 96.737%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.110 Acc 96.709%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.113 Acc 96.640%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.180 Acc 95.676%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.176 Acc 95.798%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.109 Acc 96.700%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.111 Acc 96.701%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.111 Acc 96.707%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.112 Acc 96.682%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.185 Acc 95.560%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.179 Acc 95.635%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.110 Acc 96.798%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.111 Acc 96.817%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.110 Acc 96.784%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.112 Acc 96.744%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.112 Acc 96.763%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.184 Acc 95.815%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.179 Acc 95.958%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.094 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.109 Acc 96.774%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.112 Acc 96.622%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.116 Acc 96.527%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.115 Acc 96.580%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.095 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.188 Acc 95.661%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.184 Acc 95.872%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.110 Acc 96.960%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.111 Acc 96.797%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.109 Acc 96.787%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.110 Acc 96.744%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.193 Acc 95.637%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.189 Acc 95.783%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.107 Acc 96.682%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.111 Acc 96.688%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.110 Acc 96.660%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.112 Acc 96.593%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.112 Acc 96.636%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.084 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.177 Acc 95.916%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.173 Acc 95.872%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.111 Acc 96.960%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.108 Acc 96.902%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.111 Acc 96.771%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.111 Acc 96.682%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.074 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.187 Acc 95.475%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.182 Acc 95.546%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.109 Acc 96.635%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.115 Acc 96.482%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.112 Acc 96.605%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.113 Acc 96.618%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.111 Acc 96.672%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.067 Acc 98.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.192 Acc 95.715%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.185 Acc 95.833%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.104 Acc 96.728%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.108 Acc 96.576%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.110 Acc 96.644%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.108 Acc 96.721%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.108 Acc 96.716%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.183 Acc 95.459%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.177 Acc 95.623%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.111 Acc 96.604%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.111 Acc 96.642%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.113 Acc 96.605%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.108 Acc 96.750%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.108 Acc 96.763%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.179 Acc 95.748%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.108 Acc 96.840%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.108 Acc 96.805%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.109 Acc 96.803%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.110 Acc 96.733%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.195 Acc 95.591%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.190 Acc 95.713%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.115 Acc 96.646%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.112 Acc 96.719%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.110 Acc 96.721%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.108 Acc 96.780%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.179 Acc 95.900%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.174 Acc 95.942%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.108 Acc 96.774%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.109 Acc 96.618%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.107 Acc 96.709%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.108 Acc 96.715%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.109 Acc 96.707%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.177 Acc 95.845%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.105 Acc 96.898%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.107 Acc 96.769%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.107 Acc 96.764%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.107 Acc 96.785%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.184 Acc 95.684%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.177 Acc 95.841%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbce4f4a26e45ad9884465c97009d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.331 Acc 5.469%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.271 Acc 14.875%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.254 Acc 16.857%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.249 Acc 17.385%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.242 Acc 17.745%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.225 Acc 18.755%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.992 Acc 32.031%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.036 Acc 30.794%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.039 Acc 30.803%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.003 Acc 32.031%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.887 Acc 34.677%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.819 Acc 37.310%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.748 Acc 40.111%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.673 Acc 42.994%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.600 Acc 45.613%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.994 Acc 67.969%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.020 Acc 67.188%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.016 Acc 67.137%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.092 Acc 65.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.128 Acc 63.281%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.097 Acc 64.179%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.060 Acc 65.441%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.030 Acc 66.398%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.004 Acc 67.237%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.713 Acc 79.688%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.734 Acc 76.679%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.725 Acc 76.889%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.996 Acc 69.531%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.847 Acc 72.409%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.830 Acc 72.998%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.815 Acc 73.656%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.796 Acc 74.295%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.783 Acc 74.772%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.624 Acc 82.812%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.631 Acc 79.943%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.624 Acc 80.049%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.822 Acc 74.219%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.722 Acc 77.313%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.702 Acc 77.880%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.691 Acc 78.159%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.680 Acc 78.497%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.668 Acc 78.842%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.512 Acc 82.031%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.525 Acc 83.725%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.517 Acc 84.033%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.566 Acc 79.688%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.606 Acc 80.933%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.601 Acc 80.927%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.593 Acc 81.206%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.592 Acc 81.289%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.586 Acc 81.528%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.441 Acc 85.156%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.462 Acc 85.837%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.454 Acc 86.124%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.540 Acc 85.156%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.532 Acc 83.470%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.530 Acc 83.586%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.533 Acc 83.308%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.531 Acc 83.457%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.530 Acc 83.416%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.401 Acc 87.500%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.410 Acc 87.454%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.403 Acc 87.815%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.548 Acc 82.812%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.509 Acc 83.880%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.506 Acc 83.947%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.498 Acc 84.141%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.497 Acc 84.299%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.495 Acc 84.430%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.370 Acc 85.938%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.370 Acc 89.124%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.363 Acc 89.358%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.466 Acc 84.375%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.478 Acc 85.272%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.469 Acc 85.397%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.463 Acc 85.644%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.458 Acc 85.776%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.460 Acc 85.688%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.353 Acc 87.500%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.349 Acc 89.519%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.341 Acc 89.801%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.410 Acc 88.281%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.445 Acc 86.139%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.443 Acc 86.291%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.437 Acc 86.451%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.438 Acc 86.458%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.439 Acc 86.441%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.300 Acc 90.625%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.341 Acc 89.867%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.337 Acc 90.007%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.640 Acc 82.031%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.414 Acc 87.423%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.423 Acc 87.096%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.419 Acc 87.168%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.418 Acc 87.134%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.418 Acc 87.121%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.315 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.326 Acc 90.408%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.320 Acc 90.536%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.281 Acc 91.406%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.397 Acc 87.701%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.396 Acc 87.861%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.395 Acc 87.879%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.398 Acc 87.771%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.398 Acc 87.703%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.274 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.300 Acc 91.182%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.296 Acc 91.348%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.490 Acc 83.594%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.374 Acc 88.738%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.385 Acc 88.386%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.386 Acc 88.286%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.382 Acc 88.328%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.384 Acc 88.225%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.255 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.295 Acc 91.491%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.292 Acc 91.566%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.334 Acc 87.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.368 Acc 88.513%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.371 Acc 88.495%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.367 Acc 88.676%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.366 Acc 88.702%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.367 Acc 88.682%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.277 Acc 89.062%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.288 Acc 91.793%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.283 Acc 91.861%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.295 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.354 Acc 89.240%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.356 Acc 89.031%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.352 Acc 89.203%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.355 Acc 89.183%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.355 Acc 89.245%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.240 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.277 Acc 92.048%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.274 Acc 92.145%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.329 Acc 89.844%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.350 Acc 89.140%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.339 Acc 89.587%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.345 Acc 89.522%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.341 Acc 89.511%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.342 Acc 89.490%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.218 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.268 Acc 92.466%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.265 Acc 92.514%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.468 Acc 89.062%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.333 Acc 89.921%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.339 Acc 89.509%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.344 Acc 89.330%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.344 Acc 89.349%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.339 Acc 89.543%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.254 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.261 Acc 92.636%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.258 Acc 92.821%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.466 Acc 85.938%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.333 Acc 89.790%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.328 Acc 90.023%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.329 Acc 89.974%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.326 Acc 90.027%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.327 Acc 90.012%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.212 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.254 Acc 92.884%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.252 Acc 92.922%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.330 Acc 89.844%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.319 Acc 90.292%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.327 Acc 90.089%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.328 Acc 89.984%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.321 Acc 90.155%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.321 Acc 90.193%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.193 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.246 Acc 93.147%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.242 Acc 93.237%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.382 Acc 89.844%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.309 Acc 90.617%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.311 Acc 90.648%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.315 Acc 90.454%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.314 Acc 90.391%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.313 Acc 90.452%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.254 Acc 92.737%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.248 Acc 92.875%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.366 Acc 89.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.307 Acc 90.548%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.314 Acc 90.435%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.311 Acc 90.511%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.310 Acc 90.518%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.308 Acc 90.553%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.218 Acc 91.406%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.241 Acc 93.216%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.238 Acc 93.179%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.220 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.291 Acc 91.120%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.297 Acc 91.045%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.304 Acc 90.843%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.302 Acc 90.882%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.302 Acc 90.807%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.235 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.236 Acc 93.448%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.231 Acc 93.458%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.437 Acc 88.281%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.301 Acc 90.787%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.300 Acc 90.994%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.301 Acc 91.009%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.298 Acc 91.108%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.296 Acc 91.144%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.223 Acc 90.625%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.228 Acc 93.479%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.224 Acc 93.630%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.437 Acc 89.844%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.296 Acc 91.182%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.296 Acc 91.274%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.293 Acc 91.201%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.292 Acc 91.206%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.293 Acc 91.202%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.232 Acc 93.472%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.228 Acc 93.517%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.268 Acc 91.406%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.285 Acc 91.437%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.282 Acc 91.395%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.280 Acc 91.523%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.281 Acc 91.494%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.283 Acc 91.403%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.232 Acc 93.557%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.226 Acc 93.672%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.268 Acc 92.157%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.274 Acc 91.748%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.280 Acc 91.627%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.281 Acc 91.566%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.281 Acc 91.584%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.218 Acc 92.188%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.232 Acc 93.603%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.227 Acc 93.618%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.252 Acc 91.406%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.273 Acc 91.801%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.277 Acc 91.674%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.278 Acc 91.720%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.281 Acc 91.603%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.279 Acc 91.684%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.221 Acc 93.820%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.218 Acc 93.921%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.188 Acc 95.312%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.261 Acc 92.110%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.266 Acc 92.051%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.269 Acc 91.894%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.269 Acc 91.913%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.270 Acc 91.829%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.217 Acc 94.114%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.214 Acc 94.092%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.262 Acc 92.203%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.277 Acc 91.659%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.270 Acc 91.796%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.270 Acc 91.870%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.268 Acc 91.952%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.188 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.219 Acc 93.990%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.214 Acc 93.979%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.250 Acc 92.234%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.258 Acc 92.028%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.262 Acc 91.988%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.262 Acc 92.043%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.262 Acc 92.066%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.188 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.216 Acc 94.377%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.212 Acc 94.290%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.299 Acc 92.188%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.254 Acc 92.249%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.260 Acc 92.121%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.259 Acc 92.219%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.260 Acc 92.186%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.263 Acc 92.136%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.212 Acc 94.245%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.208 Acc 94.213%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.303 Acc 89.062%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.266 Acc 91.878%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.270 Acc 91.877%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.264 Acc 92.019%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.261 Acc 92.045%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.261 Acc 92.064%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.213 Acc 94.199%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.209 Acc 94.282%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.406 Acc 89.062%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.256 Acc 92.791%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.257 Acc 92.518%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.257 Acc 92.481%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.257 Acc 92.505%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.255 Acc 92.487%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.213 Acc 94.230%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.207 Acc 94.325%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.322 Acc 92.188%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.254 Acc 92.489%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.255 Acc 92.405%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.252 Acc 92.431%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.249 Acc 92.540%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.250 Acc 92.566%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.207 Acc 94.353%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.204 Acc 94.341%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.194 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.255 Acc 92.342%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.247 Acc 92.553%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.250 Acc 92.556%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.249 Acc 92.562%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.249 Acc 92.565%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.209 Acc 94.230%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.205 Acc 94.263%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.243 Acc 94.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.245 Acc 92.752%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.245 Acc 92.751%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.247 Acc 92.634%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.247 Acc 92.571%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.247 Acc 92.616%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.191 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.198 Acc 94.725%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.195 Acc 94.656%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.322 Acc 90.625%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.232 Acc 93.178%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.241 Acc 92.930%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.246 Acc 92.818%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.246 Acc 92.786%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.244 Acc 92.755%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.208 Acc 94.384%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.205 Acc 94.349%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.234 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.233 Acc 92.953%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.239 Acc 92.895%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.244 Acc 92.784%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.242 Acc 92.879%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.242 Acc 92.846%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.200 Acc 94.779%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.196 Acc 94.729%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.201 Acc 91.406%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.240 Acc 92.884%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.239 Acc 92.883%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.239 Acc 92.906%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.239 Acc 92.938%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.239 Acc 92.928%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.200 Acc 94.570%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.197 Acc 94.543%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.307 Acc 93.750%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.229 Acc 93.394%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.237 Acc 93.249%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.235 Acc 93.218%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.235 Acc 93.162%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.235 Acc 93.164%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.198 Acc 94.794%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.193 Acc 94.772%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.241 Acc 93.093%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.233 Acc 93.186%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.235 Acc 93.117%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.234 Acc 93.074%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.236 Acc 93.001%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.196 Acc 94.918%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.192 Acc 94.881%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.268 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.222 Acc 93.441%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.228 Acc 93.431%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.230 Acc 93.265%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.230 Acc 93.298%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.233 Acc 93.195%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.190 Acc 95.111%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.187 Acc 95.017%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.222 Acc 93.611%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.222 Acc 93.424%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.226 Acc 93.239%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.228 Acc 93.195%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.230 Acc 93.200%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.191 Acc 92.969%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.201 Acc 94.609%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.194 Acc 94.714%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.223 Acc 93.286%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.220 Acc 93.517%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.223 Acc 93.605%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.225 Acc 93.407%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.225 Acc 93.462%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.167 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.194 Acc 94.810%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.189 Acc 94.823%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.218 Acc 93.502%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.220 Acc 93.490%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.223 Acc 93.472%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.225 Acc 93.382%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.224 Acc 93.399%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.192 Acc 94.771%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.230 Acc 93.185%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.225 Acc 93.365%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.225 Acc 93.433%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.224 Acc 93.440%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.224 Acc 93.457%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.208 Acc 92.188%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.194 Acc 94.841%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.189 Acc 94.757%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.246 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.222 Acc 93.425%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.221 Acc 93.501%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.220 Acc 93.553%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.223 Acc 93.516%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.221 Acc 93.544%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.185 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.191 Acc 94.794%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.187 Acc 94.838%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.177 Acc 92.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.212 Acc 93.928%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.217 Acc 93.734%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.220 Acc 93.677%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.222 Acc 93.567%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.222 Acc 93.515%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.190 Acc 95.003%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.183 Acc 95.091%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.229 Acc 92.969%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.213 Acc 93.549%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.211 Acc 93.641%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.215 Acc 93.625%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.218 Acc 93.542%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.219 Acc 93.527%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.197 Acc 94.732%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.191 Acc 94.815%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.214 Acc 93.742%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.208 Acc 93.878%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.212 Acc 93.773%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.214 Acc 93.660%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.216 Acc 93.649%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.183 Acc 95.021%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.259 Acc 89.844%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.204 Acc 93.982%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.219 Acc 93.688%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.215 Acc 93.753%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.217 Acc 93.694%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.214 Acc 93.734%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.189 Acc 95.034%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.184 Acc 95.060%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.200 Acc 93.812%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.207 Acc 93.750%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.208 Acc 93.771%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.209 Acc 93.881%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.210 Acc 93.834%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.181 Acc 95.119%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.178 Acc 95.169%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.206 Acc 94.106%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.209 Acc 93.987%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.209 Acc 93.945%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.210 Acc 93.953%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.210 Acc 93.943%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.188 Acc 95.042%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.183 Acc 95.033%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.264 Acc 92.188%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.205 Acc 93.974%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.205 Acc 93.983%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.205 Acc 93.971%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.207 Acc 93.939%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.207 Acc 93.926%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.172 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.186 Acc 95.050%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.182 Acc 95.068%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.183 Acc 95.312%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.219 Acc 93.804%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.212 Acc 93.991%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.210 Acc 94.061%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.209 Acc 94.083%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.207 Acc 94.092%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.189 Acc 95.088%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.184 Acc 95.072%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.204 Acc 93.982%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.209 Acc 93.925%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.208 Acc 93.973%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.206 Acc 93.951%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.208 Acc 93.901%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.186 Acc 95.042%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.182 Acc 95.138%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.289 Acc 92.188%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.208 Acc 94.168%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.202 Acc 94.166%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.207 Acc 94.025%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.208 Acc 93.990%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.206 Acc 94.000%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.181 Acc 95.215%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.123 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.206 Acc 94.059%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.202 Acc 94.193%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.203 Acc 94.108%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.202 Acc 94.103%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.203 Acc 94.127%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.174 Acc 92.188%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.181 Acc 95.111%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.176 Acc 95.305%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.198 Acc 94.152%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.200 Acc 94.205%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.200 Acc 94.142%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.201 Acc 94.142%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.200 Acc 94.145%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.190 Acc 95.135%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.186 Acc 95.052%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.230 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.196 Acc 94.330%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.200 Acc 94.294%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.203 Acc 94.157%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.202 Acc 94.157%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.199 Acc 94.243%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.178 Acc 95.351%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.153 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.200 Acc 94.361%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.194 Acc 94.446%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.199 Acc 94.272%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.198 Acc 94.336%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.200 Acc 94.260%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.185 Acc 95.196%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.180 Acc 95.223%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.189 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.195 Acc 94.321%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.195 Acc 94.292%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.196 Acc 94.280%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.198 Acc 94.174%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.184 Acc 95.274%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.178 Acc 95.336%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.197 Acc 94.261%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.196 Acc 94.360%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.196 Acc 94.430%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.196 Acc 94.407%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.196 Acc 94.413%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.187 Acc 95.150%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.182 Acc 95.200%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.233 Acc 89.844%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.184 Acc 94.423%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.189 Acc 94.492%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.189 Acc 94.409%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.192 Acc 94.387%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.192 Acc 94.391%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.187 Acc 95.142%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.181 Acc 95.200%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.196 Acc 92.188%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.195 Acc 94.199%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.193 Acc 94.314%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.193 Acc 94.321%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.194 Acc 94.294%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.196 Acc 94.272%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.179 Acc 92.188%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.212%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.178 Acc 95.371%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.182 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.196 Acc 94.315%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.194 Acc 94.275%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.193 Acc 94.360%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.193 Acc 94.366%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.193 Acc 94.422%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.183 Acc 95.297%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.320%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.199 Acc 94.307%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.194 Acc 94.372%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.193 Acc 94.383%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.191 Acc 94.399%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.193 Acc 94.336%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.177 Acc 95.320%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.171 Acc 95.437%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.272 Acc 92.188%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.182 Acc 94.601%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.574%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.184 Acc 94.588%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.186 Acc 94.502%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.189 Acc 94.469%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.188 Acc 95.026%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.183 Acc 95.075%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.246 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.201 Acc 94.168%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.191 Acc 94.457%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.188 Acc 94.505%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.190 Acc 94.518%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.191 Acc 94.447%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.186 Acc 95.134%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.177 Acc 94.717%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.182 Acc 94.675%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.185 Acc 94.555%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.187 Acc 94.477%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.188 Acc 94.464%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.176 Acc 95.514%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.169 Acc 95.581%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.202 Acc 95.312%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.190 Acc 94.570%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.185 Acc 94.761%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.184 Acc 94.697%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.186 Acc 94.613%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.187 Acc 94.575%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.174 Acc 95.467%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.169 Acc 95.499%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.185 Acc 93.750%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.190 Acc 94.346%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.186 Acc 94.516%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.188 Acc 94.430%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.188 Acc 94.471%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.188 Acc 94.511%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.183 Acc 95.343%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.177 Acc 95.367%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.182 Acc 94.717%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.187 Acc 94.570%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.181 Acc 94.726%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.184 Acc 94.670%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.186 Acc 94.567%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.177 Acc 95.514%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.171 Acc 95.553%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.159 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.186 Acc 94.794%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.186 Acc 94.733%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.181 Acc 94.804%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.183 Acc 94.695%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.184 Acc 94.650%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.181 Acc 95.266%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.175 Acc 95.429%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.151 Acc 93.750%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.182 Acc 94.609%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.180 Acc 94.815%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.179 Acc 94.791%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.181 Acc 94.722%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.183 Acc 94.706%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.661%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.165 Acc 95.728%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.189 Acc 94.369%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.188 Acc 94.516%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.183 Acc 94.619%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.183 Acc 94.646%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.182 Acc 94.648%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.174 Acc 95.320%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.168 Acc 95.553%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.184 Acc 94.640%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.176 Acc 94.807%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.174 Acc 94.830%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.181 Acc 94.703%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.182 Acc 94.740%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.182 Acc 95.382%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.176 Acc 95.449%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.181 Acc 94.972%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.179 Acc 94.970%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.180 Acc 94.936%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.180 Acc 94.898%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.182 Acc 94.823%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.116 Acc 94.531%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.176 Acc 95.459%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.171 Acc 95.565%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.152 Acc 97.656%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.184 Acc 94.802%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.185 Acc 94.823%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.182 Acc 94.835%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.181 Acc 94.859%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.181 Acc 94.881%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.183 Acc 95.289%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.176 Acc 95.371%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.180 Acc 94.686%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.177 Acc 94.842%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.180 Acc 94.762%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.180 Acc 94.831%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.180 Acc 94.778%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.189 Acc 93.750%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.178 Acc 95.374%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.172 Acc 95.546%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.173 Acc 94.895%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.177 Acc 94.838%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.177 Acc 94.866%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.177 Acc 94.864%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.175 Acc 94.926%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.183 Acc 95.212%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.178 Acc 95.281%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.211 Acc 95.312%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.172 Acc 95.091%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.175 Acc 95.001%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.176 Acc 94.974%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.176 Acc 94.940%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.182 Acc 95.359%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.176 Acc 95.433%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.169 Acc 95.274%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.173 Acc 95.048%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.176 Acc 94.991%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.179 Acc 94.933%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.180 Acc 94.924%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.178 Acc 95.421%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.173 Acc 95.472%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.173 Acc 94.848%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.173 Acc 94.900%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.172 Acc 94.967%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.172 Acc 94.979%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.173 Acc 94.977%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.179 Acc 95.382%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.172 Acc 95.538%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.157 Acc 95.204%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.169 Acc 94.963%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.175 Acc 94.861%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.175 Acc 94.890%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.175 Acc 94.898%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.176 Acc 95.374%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.169 Acc 95.569%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.154 Acc 92.969%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.177 Acc 94.887%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.176 Acc 94.831%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.173 Acc 94.822%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.172 Acc 94.866%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.174 Acc 94.854%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.179 Acc 95.405%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.172 Acc 95.581%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.179 Acc 94.756%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.177 Acc 94.831%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.175 Acc 94.952%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.177 Acc 94.964%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.175 Acc 94.985%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.171 Acc 95.721%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.163 Acc 95.149%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.166 Acc 95.146%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.170 Acc 95.102%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.173 Acc 95.022%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.174 Acc 95.449%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.145 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.172 Acc 94.879%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.165 Acc 95.130%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.165 Acc 95.152%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.167 Acc 95.110%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.167 Acc 95.111%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.176 Acc 95.367%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.170 Acc 95.553%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.283 Acc 91.406%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.160 Acc 95.243%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.162 Acc 95.173%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.167 Acc 95.126%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.171 Acc 95.016%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.170 Acc 95.044%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.128 Acc 92.969%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.183 Acc 95.328%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.175 Acc 95.472%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.167 Acc 95.096%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.168 Acc 95.052%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.172 Acc 94.980%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.170 Acc 95.090%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.169 Acc 95.102%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.176 Acc 95.475%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.169 Acc 95.534%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.160 Acc 95.166%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.167 Acc 95.114%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.169 Acc 95.097%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.167 Acc 95.147%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.168 Acc 95.132%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.177 Acc 95.444%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.170 Acc 95.585%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.102 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.172 Acc 95.135%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.169 Acc 95.122%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.170 Acc 95.162%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.168 Acc 95.198%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.168 Acc 95.189%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.266%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.180 Acc 95.375%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.170 Acc 95.135%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.169 Acc 95.044%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.168 Acc 95.131%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.169 Acc 95.090%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.169 Acc 95.091%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.184 Acc 95.166%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.176 Acc 95.363%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.160 Acc 95.467%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.162 Acc 95.460%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.159 Acc 95.460%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.161 Acc 95.396%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.163 Acc 95.334%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.171 Acc 95.637%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.163 Acc 95.771%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.161 Acc 95.212%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.170 Acc 95.106%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.166 Acc 95.268%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.165 Acc 95.237%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.165 Acc 95.277%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.180 Acc 95.343%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.173 Acc 95.538%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.158 Acc 95.483%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.161 Acc 95.297%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.160 Acc 95.393%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.160 Acc 95.351%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.162 Acc 95.297%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.166 Acc 95.692%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.160 Acc 95.857%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.159 Acc 95.336%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.165 Acc 95.204%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.163 Acc 95.268%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.166 Acc 95.198%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.179 Acc 95.274%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.171 Acc 95.522%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.159 Acc 95.459%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.163 Acc 95.456%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.163 Acc 95.362%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.165 Acc 95.330%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.164 Acc 95.355%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.181 Acc 95.328%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.173 Acc 95.565%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.405 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.164 Acc 95.088%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.163 Acc 95.176%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.165 Acc 95.136%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.163 Acc 95.246%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.163 Acc 95.238%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.170 Acc 95.606%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.165 Acc 95.705%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.166 Acc 95.258%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.167 Acc 95.223%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.163 Acc 95.263%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.161 Acc 95.334%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.162 Acc 95.292%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.175 Acc 95.498%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.168 Acc 95.732%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.150 Acc 95.545%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.155 Acc 95.371%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.158 Acc 95.422%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.162 Acc 95.289%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.162 Acc 95.334%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.173 Acc 95.526%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.076 Acc 99.219%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.161 Acc 95.220%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.153 Acc 95.328%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.158 Acc 95.294%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.158 Acc 95.314%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.160 Acc 95.270%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 95.651%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.155 Acc 95.467%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.398%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.158 Acc 95.408%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.159 Acc 95.408%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.137 Acc 93.750%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.176 Acc 95.490%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.168 Acc 95.655%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.155 Acc 95.645%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.152 Acc 95.639%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.155 Acc 95.595%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.157 Acc 95.550%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.160 Acc 95.420%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.175 Acc 95.506%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.166 Acc 95.643%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.274 Acc 92.188%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.161 Acc 95.545%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.158 Acc 95.522%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.159 Acc 95.419%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.161 Acc 95.427%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.158 Acc 95.464%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.177 Acc 95.336%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.170 Acc 95.596%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.262 Acc 92.188%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.144 Acc 95.784%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.151 Acc 95.678%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.154 Acc 95.614%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.153 Acc 95.613%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.156 Acc 95.515%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.113 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.165 Acc 95.794%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.160 Acc 95.421%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.160 Acc 95.441%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.155 Acc 95.541%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.156 Acc 95.496%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.158 Acc 95.442%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.178 Acc 95.359%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.170 Acc 95.596%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.151 Acc 95.715%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.156 Acc 95.550%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.158 Acc 95.510%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.157 Acc 95.513%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.157 Acc 95.495%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.176 Acc 95.421%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.168 Acc 95.701%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.151 Acc 95.483%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.146 Acc 95.705%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.149 Acc 95.619%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.151 Acc 95.552%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.152 Acc 95.520%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.179 Acc 95.351%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.171 Acc 95.623%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.211 Acc 93.750%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.150 Acc 95.653%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.150 Acc 95.690%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.154 Acc 95.632%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.155 Acc 95.628%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.157 Acc 95.562%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.185 Acc 95.150%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.177 Acc 95.359%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.155 Acc 95.351%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.154 Acc 95.503%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.153 Acc 95.536%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.158 Acc 95.414%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.157 Acc 95.420%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.169 Acc 95.692%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.163 Acc 95.903%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.153 Acc 95.519%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.152 Acc 95.549%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.153 Acc 95.593%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.153 Acc 95.581%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.176 Acc 95.351%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.170 Acc 95.468%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.147 Acc 95.645%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.146 Acc 95.690%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.150 Acc 95.642%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.150 Acc 95.677%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.152 Acc 95.662%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.166 Acc 95.763%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.153 Acc 95.568%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.153 Acc 95.546%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.152 Acc 95.525%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.153 Acc 95.519%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.154 Acc 95.512%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.174 Acc 95.413%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.165 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.146 Acc 95.630%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.150 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.149 Acc 95.712%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.149 Acc 95.681%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.150 Acc 95.656%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.170 Acc 95.560%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.162 Acc 95.872%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.137 Acc 95.862%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.144 Acc 95.794%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.148 Acc 95.722%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.149 Acc 95.640%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.174 Acc 95.475%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.166 Acc 95.620%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.139 Acc 95.962%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.143 Acc 95.841%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.146 Acc 95.816%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.148 Acc 95.766%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.150 Acc 95.674%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.181 Acc 95.506%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.174 Acc 95.662%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.321 Acc 89.844%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.154 Acc 95.452%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.156 Acc 95.499%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.151 Acc 95.629%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.151 Acc 95.673%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.150 Acc 95.654%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.124 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.172 Acc 95.622%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.164 Acc 95.787%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.143 Acc 95.815%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.145 Acc 95.631%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.148 Acc 95.590%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.147 Acc 95.624%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.150 Acc 95.562%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.176 Acc 95.583%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.167 Acc 95.794%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.143 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.141 Acc 95.978%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.145 Acc 95.868%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.148 Acc 95.766%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.149 Acc 95.705%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.179 Acc 95.560%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.170 Acc 95.678%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.148 Acc 95.614%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.152 Acc 95.596%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.150 Acc 95.691%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.151 Acc 95.630%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.149 Acc 95.654%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.176 Acc 95.583%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.168 Acc 95.767%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.149 Acc 95.614%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.147 Acc 95.767%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.148 Acc 95.808%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.150 Acc 95.739%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.149 Acc 95.776%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.178 Acc 95.614%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.172 Acc 95.771%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.166 Acc 92.188%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.146 Acc 95.645%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.148 Acc 95.693%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.146 Acc 95.749%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.145 Acc 95.803%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.147 Acc 95.754%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.174 Acc 95.612%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.195 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.147 Acc 95.637%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.143 Acc 95.899%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.143 Acc 95.839%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.144 Acc 95.823%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.145 Acc 95.794%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.177 Acc 95.490%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.167 Acc 95.732%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.141 Acc 96.040%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.145 Acc 95.771%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.141 Acc 95.928%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.144 Acc 95.911%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.147 Acc 95.810%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.176 Acc 95.545%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.169 Acc 95.725%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.149 Acc 95.753%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.145 Acc 95.911%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.146 Acc 95.873%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.146 Acc 95.800%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.148 Acc 95.735%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.175 Acc 95.581%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.136 Acc 96.163%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.140 Acc 96.063%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.139 Acc 96.006%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.141 Acc 95.994%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.144 Acc 95.960%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.176 Acc 95.668%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.168 Acc 95.841%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.148 Acc 95.885%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.148 Acc 95.763%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.144 Acc 95.870%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.146 Acc 95.791%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.176 Acc 95.444%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.168 Acc 95.791%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.135 Acc 95.962%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.141 Acc 95.849%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.143 Acc 95.800%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.143 Acc 95.793%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.181 Acc 95.274%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.172 Acc 95.522%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.197 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.144 Acc 95.826%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.144 Acc 95.798%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.144 Acc 95.889%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.144 Acc 95.838%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.179 Acc 95.537%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.170 Acc 95.748%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.139 Acc 96.009%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.143 Acc 95.985%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.142 Acc 95.959%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.145 Acc 95.889%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.144 Acc 95.894%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.118 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.175 Acc 95.637%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.168 Acc 95.829%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.140 Acc 95.900%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.141 Acc 95.837%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.141 Acc 95.855%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.145 Acc 95.809%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.144 Acc 95.838%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.182 Acc 95.398%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.173 Acc 95.639%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.141 Acc 95.784%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.140 Acc 95.771%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.142 Acc 95.815%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.142 Acc 95.833%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.178 Acc 95.429%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.135 Acc 95.924%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.136 Acc 95.872%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.138 Acc 95.915%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.141 Acc 95.876%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.142 Acc 95.882%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.179 Acc 95.328%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.171 Acc 95.592%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.066 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.147 Acc 95.746%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.147 Acc 95.802%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.145 Acc 95.764%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.145 Acc 95.790%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.143 Acc 95.865%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.661%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.167 Acc 95.806%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.245 Acc 94.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.134 Acc 96.163%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.135 Acc 96.102%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.138 Acc 96.024%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.141 Acc 95.961%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.140 Acc 96.011%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.181 Acc 95.405%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.173 Acc 95.608%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.225 Acc 93.750%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.140 Acc 95.869%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.136 Acc 96.004%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.138 Acc 96.018%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.139 Acc 95.942%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.140 Acc 95.927%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.183 Acc 95.204%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.176 Acc 95.398%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.265 Acc 91.406%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.145 Acc 95.893%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.137 Acc 96.065%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.138 Acc 95.963%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.140 Acc 95.942%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.179 Acc 95.490%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.170 Acc 95.783%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.143 Acc 96.109%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.142 Acc 95.946%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.141 Acc 95.972%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.139 Acc 95.948%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.140 Acc 95.944%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.444%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.167 Acc 95.666%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.063 Acc 96.875%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.133 Acc 96.117%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.135 Acc 96.102%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.134 Acc 96.089%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.135 Acc 96.074%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.137 Acc 96.022%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.172 Acc 95.622%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.165 Acc 95.861%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.269 Acc 94.531%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.136 Acc 95.970%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.132 Acc 96.168%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.137 Acc 96.035%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.137 Acc 96.008%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.172 Acc 95.630%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.164 Acc 95.888%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.132 Acc 96.364%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.132 Acc 96.238%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.133 Acc 96.135%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.137 Acc 96.035%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.137 Acc 96.036%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.181 Acc 95.568%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.172 Acc 95.767%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.117 Acc 96.434%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.129 Acc 96.195%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.131 Acc 96.107%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.133 Acc 96.053%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.135 Acc 95.991%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.174 Acc 95.514%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.167 Acc 95.736%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.128 Acc 96.395%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.124 Acc 96.412%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.130 Acc 96.104%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.133 Acc 96.082%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.135 Acc 96.058%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.171 Acc 95.707%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.164 Acc 95.931%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.127 Acc 96.109%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.135 Acc 96.137%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.133 Acc 96.135%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.133 Acc 96.121%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.135 Acc 96.091%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.178 Acc 95.498%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.168 Acc 95.872%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.131 Acc 96.132%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.133 Acc 96.152%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.133 Acc 96.086%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.136 Acc 96.033%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.174 Acc 95.552%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.166 Acc 95.861%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.135 Acc 96.024%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.134 Acc 96.047%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.133 Acc 96.097%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.180 Acc 95.490%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.181 Acc 93.750%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.130 Acc 96.261%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.135 Acc 96.091%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.134 Acc 96.080%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.135 Acc 96.056%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.173 Acc 95.560%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.164 Acc 95.857%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.128 Acc 96.272%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.129 Acc 96.206%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.129 Acc 96.161%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.132 Acc 96.074%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.134 Acc 96.014%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.177 Acc 95.668%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.169 Acc 95.919%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.126 Acc 96.140%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.130 Acc 96.152%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.133 Acc 96.096%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.131 Acc 96.154%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.133 Acc 96.109%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.180 Acc 95.552%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.173 Acc 95.814%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.129 Acc 96.055%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.127 Acc 96.156%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.131 Acc 96.070%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.132 Acc 96.068%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.132 Acc 96.088%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.172 Acc 95.854%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.163 Acc 96.086%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.131 Acc 96.295%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.130 Acc 96.218%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.131 Acc 96.169%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.132 Acc 96.170%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.132 Acc 96.203%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.176 Acc 95.676%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.167 Acc 95.915%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.148 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.143 Acc 95.862%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.138 Acc 95.985%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.135 Acc 96.013%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.135 Acc 96.041%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.133 Acc 96.077%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.180 Acc 95.722%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.171 Acc 95.896%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.116 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.130 Acc 96.109%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.128 Acc 96.226%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.129 Acc 96.244%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.131 Acc 96.195%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.176 Acc 95.690%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.131 Acc 96.272%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.133 Acc 96.199%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.131 Acc 96.191%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.133 Acc 96.173%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.178 Acc 95.684%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.168 Acc 95.849%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.128 Acc 96.364%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.130 Acc 96.257%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.131 Acc 96.198%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.132 Acc 96.158%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.133 Acc 96.103%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.140 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.176 Acc 95.761%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.168 Acc 95.931%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.257 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.132 Acc 96.194%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.131 Acc 96.121%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.131 Acc 96.164%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.131 Acc 96.164%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.129 Acc 96.395%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.126 Acc 96.385%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.129 Acc 96.301%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.130 Acc 96.283%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.131 Acc 96.254%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.174 Acc 95.622%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.167 Acc 95.896%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.131 Acc 96.395%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.132 Acc 96.284%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.129 Acc 96.294%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.130 Acc 96.240%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.130 Acc 96.231%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.165 Acc 95.927%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.119 Acc 96.318%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.123 Acc 96.362%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.128 Acc 96.283%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.130 Acc 96.209%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.129 Acc 96.248%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.187 Acc 95.374%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.179 Acc 95.600%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.154 Acc 93.750%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.129 Acc 96.009%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.128 Acc 96.133%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.130 Acc 96.127%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.130 Acc 96.148%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.130 Acc 96.155%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.176 Acc 95.637%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.132 Acc 96.248%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.125 Acc 96.350%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.125 Acc 96.327%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.128 Acc 96.255%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.128 Acc 96.245%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.180 Acc 95.661%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.174 Acc 95.864%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.126 Acc 96.248%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.123 Acc 96.343%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.125 Acc 96.327%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.125 Acc 96.326%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.127 Acc 96.245%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.168 Acc 95.884%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.128 Acc 96.218%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.127 Acc 96.308%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.127 Acc 96.252%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.128 Acc 96.250%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.127 Acc 96.250%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.181 Acc 95.692%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.174 Acc 95.868%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.126 Acc 96.372%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.125 Acc 96.408%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.125 Acc 96.405%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.125 Acc 96.398%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.177 Acc 95.583%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.167 Acc 95.845%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.121 Acc 96.481%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.121 Acc 96.463%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.124 Acc 96.366%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.124 Acc 96.390%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.124 Acc 96.374%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.181 Acc 95.421%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.171 Acc 95.756%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.214 Acc 95.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.123 Acc 96.279%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.123 Acc 96.315%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.125 Acc 96.275%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.123 Acc 96.304%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.122 Acc 96.328%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.178 Acc 95.692%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.168 Acc 95.927%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.121 Acc 96.303%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.125 Acc 96.199%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.127 Acc 96.244%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.127 Acc 96.240%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.125 Acc 96.292%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.185 Acc 95.429%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.176 Acc 95.635%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.125 Acc 96.078%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.124 Acc 96.249%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.123 Acc 96.333%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.122 Acc 96.400%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.124 Acc 96.357%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.181 Acc 95.328%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.172 Acc 95.573%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.125 Acc 96.419%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.127 Acc 96.416%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.125 Acc 96.462%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.124 Acc 96.437%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.124 Acc 96.404%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.183 Acc 95.684%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.175 Acc 95.946%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.116 Acc 96.620%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.117 Acc 96.552%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.118 Acc 96.496%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.119 Acc 96.478%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.123 Acc 96.370%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.155 Acc 96.875%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.181 Acc 95.637%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.172 Acc 95.826%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.109 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.119 Acc 96.481%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.120 Acc 96.537%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.120 Acc 96.501%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.121 Acc 96.478%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.121 Acc 96.456%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.182 Acc 95.119%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.171 Acc 95.519%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.372 Acc 92.188%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.124 Acc 96.318%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.123 Acc 96.459%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.122 Acc 96.449%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.123 Acc 96.402%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.124 Acc 96.406%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.183 Acc 95.599%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.172 Acc 95.981%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.125 Acc 96.241%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.120 Acc 96.393%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.122 Acc 96.408%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.124 Acc 96.355%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.123 Acc 96.384%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.092 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.176 Acc 95.622%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.167 Acc 95.950%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.122 Acc 96.380%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.119 Acc 96.467%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.123 Acc 96.361%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.123 Acc 96.374%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.125 Acc 96.325%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.170 Acc 95.876%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.125 Acc 96.372%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.127 Acc 96.273%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.124 Acc 96.365%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.173 Acc 95.794%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.112 Acc 96.651%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.115 Acc 96.688%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.119 Acc 96.540%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.120 Acc 96.544%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.121 Acc 96.435%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.653%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.166 Acc 95.927%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.125 Acc 96.310%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.122 Acc 96.447%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.123 Acc 96.400%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.122 Acc 96.392%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.122 Acc 96.395%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.180 Acc 95.498%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.169 Acc 95.915%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.125 Acc 94.531%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.114 Acc 96.542%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.119 Acc 96.374%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.119 Acc 96.455%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.117 Acc 96.567%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.120 Acc 96.488%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.179 Acc 95.583%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.171 Acc 95.853%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.119 Acc 96.651%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.115 Acc 96.650%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.118 Acc 96.569%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.120 Acc 96.499%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.120 Acc 96.509%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.180 Acc 95.668%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.173 Acc 95.907%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.118 Acc 96.372%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.122 Acc 96.374%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.118 Acc 96.478%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.118 Acc 96.505%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.120 Acc 96.479%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.175 Acc 95.753%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.169 Acc 96.004%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.109 Acc 96.852%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.114 Acc 96.681%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.118 Acc 96.621%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.118 Acc 96.583%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.121 Acc 96.509%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.172 Acc 95.884%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.114 Acc 96.511%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.116 Acc 96.467%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.120 Acc 96.382%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.121 Acc 96.386%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.119 Acc 96.415%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.171 Acc 96.875%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.181 Acc 95.429%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.173 Acc 95.655%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.113 Acc 96.612%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.118 Acc 96.482%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.115 Acc 96.545%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.116 Acc 96.511%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.118 Acc 96.498%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.181 Acc 95.529%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.173 Acc 95.791%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.117 Acc 96.658%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.114 Acc 96.774%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.117 Acc 96.567%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.118 Acc 96.551%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.183 Acc 95.467%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.174 Acc 95.717%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.165 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.115 Acc 96.630%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.117 Acc 96.569%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.118 Acc 96.548%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.119 Acc 96.505%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.175 Acc 95.521%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.167 Acc 95.802%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.107 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.113 Acc 96.627%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.115 Acc 96.583%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.114 Acc 96.587%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.117 Acc 96.507%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.117 Acc 96.510%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.177 Acc 95.599%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.170 Acc 95.756%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.120 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.117 Acc 96.349%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.117 Acc 96.470%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.117 Acc 96.460%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.118 Acc 96.440%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.161 Acc 97.656%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.186 Acc 95.436%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.176 Acc 95.736%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.112 Acc 96.535%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.117 Acc 96.444%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.115 Acc 96.522%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.116 Acc 96.528%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.116 Acc 96.558%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.179 Acc 95.552%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.056 Acc 100.000%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.108 Acc 96.929%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.111 Acc 96.727%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.113 Acc 96.680%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.114 Acc 96.600%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.115 Acc 96.560%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.179 Acc 95.630%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.116 Acc 96.380%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.119 Acc 96.377%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.118 Acc 96.418%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.118 Acc 96.388%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.116 Acc 96.493%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.189 Acc 95.692%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.180 Acc 95.814%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.117 Acc 96.612%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.117 Acc 96.642%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.118 Acc 96.473%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.116 Acc 96.466%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.117 Acc 96.463%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.173 Acc 95.864%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.109 Acc 96.914%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.112 Acc 96.720%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.115 Acc 96.592%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.117 Acc 96.610%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.174 Acc 95.732%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.134 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.117 Acc 96.295%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.118 Acc 96.315%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.115 Acc 96.499%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.115 Acc 96.517%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.115 Acc 96.541%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.183 Acc 95.715%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.173 Acc 95.931%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.111 Acc 96.743%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.112 Acc 96.683%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.115 Acc 96.582%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.125 Acc 96.875%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.187 Acc 95.490%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.176 Acc 95.763%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.110 Acc 96.550%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.112 Acc 96.700%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.115 Acc 96.631%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.114 Acc 96.657%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.113 Acc 96.635%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.184 Acc 95.676%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.174 Acc 95.802%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.115 Acc 96.380%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.116 Acc 96.436%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.114 Acc 96.579%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.113 Acc 96.637%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.113 Acc 96.657%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.188 Acc 95.599%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.178 Acc 95.767%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.113 Acc 96.798%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.112 Acc 96.709%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.114 Acc 96.600%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.114 Acc 96.602%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.180 Acc 95.630%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.171 Acc 95.907%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.109 Acc 96.705%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.109 Acc 96.735%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.111 Acc 96.673%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.113 Acc 96.633%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.113 Acc 96.649%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.179 Acc 95.831%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.171 Acc 96.032%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775f86c4cd6346e49ea23d0a9ba6cec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.321 Acc 17.969%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.250 Acc 19.872%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.242 Acc 19.306%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.232 Acc 19.440%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.194 Acc 21.010%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.124 Acc 23.944%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.583 Acc 47.656%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.619 Acc 46.612%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.615 Acc 46.723%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.731 Acc 38.281%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.520 Acc 48.461%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.444 Acc 51.586%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.374 Acc 54.015%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.322 Acc 55.858%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.273 Acc 57.663%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.831 Acc 72.656%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.833 Acc 73.762%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.830 Acc 73.729%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.889 Acc 68.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.980 Acc 68.116%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.952 Acc 69.213%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.921 Acc 70.159%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.892 Acc 71.061%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.876 Acc 71.655%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.574 Acc 81.250%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.606 Acc 81.219%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.600 Acc 81.367%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.710 Acc 74.219%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.719 Acc 77.011%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.711 Acc 77.367%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.698 Acc 77.775%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.687 Acc 78.113%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.677 Acc 78.463%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.417 Acc 86.719%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.474 Acc 85.620%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.466 Acc 85.844%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.724 Acc 80.469%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.598 Acc 80.879%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.592 Acc 81.161%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.587 Acc 81.312%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.583 Acc 81.521%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.578 Acc 81.766%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.382 Acc 87.500%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.429 Acc 87.399%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.422 Acc 87.438%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.590 Acc 80.469%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.542 Acc 83.269%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.535 Acc 83.364%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.528 Acc 83.498%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.523 Acc 83.701%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.519 Acc 83.772%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.361 Acc 87.500%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.389 Acc 88.351%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.383 Acc 88.378%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.470 Acc 87.500%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.493 Acc 84.599%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.482 Acc 84.962%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.483 Acc 84.860%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.479 Acc 84.987%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.475 Acc 85.187%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.349 Acc 88.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.360 Acc 89.503%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.353 Acc 89.576%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.414 Acc 85.156%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.452 Acc 85.512%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.454 Acc 85.833%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.452 Acc 85.979%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.450 Acc 86.107%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.446 Acc 86.173%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.290 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.332 Acc 90.130%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.326 Acc 90.267%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.375 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.414 Acc 87.299%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.423 Acc 87.193%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.425 Acc 86.942%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.422 Acc 86.923%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.422 Acc 87.013%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.347 Acc 88.281%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.332 Acc 90.370%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.327 Acc 90.454%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.414 Acc 85.938%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.418 Acc 87.067%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.410 Acc 87.360%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.401 Acc 87.635%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.404 Acc 87.570%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.399 Acc 87.703%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.282 Acc 89.062%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.300 Acc 91.244%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.294 Acc 91.465%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.438 Acc 86.719%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.393 Acc 87.786%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.393 Acc 87.869%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.390 Acc 88.019%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.385 Acc 88.186%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.385 Acc 88.167%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.287 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.302 Acc 91.236%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.297 Acc 91.301%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.386 Acc 90.625%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.379 Acc 88.459%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.381 Acc 88.382%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.377 Acc 88.476%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.371 Acc 88.648%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.367 Acc 88.755%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.272 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.285 Acc 91.832%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.280 Acc 91.892%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.386 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.337 Acc 89.449%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.345 Acc 89.253%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.350 Acc 89.182%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.350 Acc 89.082%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.351 Acc 89.128%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.283 Acc 92.041%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.278 Acc 92.203%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.282 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.339 Acc 89.581%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.347 Acc 89.471%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.343 Acc 89.597%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.345 Acc 89.516%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.343 Acc 89.540%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.261 Acc 90.625%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.266 Acc 92.296%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.264 Acc 92.331%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.393 Acc 87.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.338 Acc 89.720%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.338 Acc 89.692%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.333 Acc 89.763%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.332 Acc 89.832%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.332 Acc 89.828%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.270 Acc 92.435%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.266 Acc 92.409%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.327 Acc 87.500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.322 Acc 90.339%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.323 Acc 90.089%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.321 Acc 90.134%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.322 Acc 90.120%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.322 Acc 90.198%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.260 Acc 93.015%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.255 Acc 92.872%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.384 Acc 86.719%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.309 Acc 90.486%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.310 Acc 90.726%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.311 Acc 90.690%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.315 Acc 90.594%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.314 Acc 90.675%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.239 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.246 Acc 93.239%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.242 Acc 93.179%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.310 Acc 90.478%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.307 Acc 90.730%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.306 Acc 90.794%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.304 Acc 90.849%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.304 Acc 90.889%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.235 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.237 Acc 93.626%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.233 Acc 93.528%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.414 Acc 83.594%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.294 Acc 91.298%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.294 Acc 91.231%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.294 Acc 91.087%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.298 Acc 90.982%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.299 Acc 90.923%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.229 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.236 Acc 93.487%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.231 Acc 93.455%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.284 Acc 91.252%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.287 Acc 91.212%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.289 Acc 91.276%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.292 Acc 91.132%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.292 Acc 91.219%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.234 Acc 93.704%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.231 Acc 93.610%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.227 Acc 93.750%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.290 Acc 91.244%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.288 Acc 90.990%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.291 Acc 90.949%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.289 Acc 91.048%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.289 Acc 91.074%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.231 Acc 93.773%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.229 Acc 93.661%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.195 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.276 Acc 91.739%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.282 Acc 91.643%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.277 Acc 91.775%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.279 Acc 91.654%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.279 Acc 91.671%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.223 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.224 Acc 94.005%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.222 Acc 93.878%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.327 Acc 92.969%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.279 Acc 91.762%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.278 Acc 91.772%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.276 Acc 91.798%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.275 Acc 91.815%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.277 Acc 91.742%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.223 Acc 93.773%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.219 Acc 93.832%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.227 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.267 Acc 91.955%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.265 Acc 92.125%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.265 Acc 92.120%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.267 Acc 92.059%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.271 Acc 91.960%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.258 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.229 Acc 93.735%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.225 Acc 93.664%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.292 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.258 Acc 92.373%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.262 Acc 92.300%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.265 Acc 92.089%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.267 Acc 92.032%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.268 Acc 92.028%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.212 Acc 94.431%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.207 Acc 94.380%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.260 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.268 Acc 92.025%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.270 Acc 92.009%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.263 Acc 92.203%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.260 Acc 92.289%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.261 Acc 92.295%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.217 Acc 94.168%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.215 Acc 93.964%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.217 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.245 Acc 92.659%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.258 Acc 92.273%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.259 Acc 92.317%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.259 Acc 92.367%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.258 Acc 92.331%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.230 Acc 92.969%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.208 Acc 94.454%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.203 Acc 94.360%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.320 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.256 Acc 92.257%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.257 Acc 92.242%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.260 Acc 92.224%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.256 Acc 92.423%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.254 Acc 92.420%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.180 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.212 Acc 94.261%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.208 Acc 94.135%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.137 Acc 94.531%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.249 Acc 92.528%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.255 Acc 92.374%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.253 Acc 92.411%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.250 Acc 92.515%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.252 Acc 92.499%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.213 Acc 94.361%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.208 Acc 94.236%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.178 Acc 94.531%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.238 Acc 92.868%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.244 Acc 92.736%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.244 Acc 92.652%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.245 Acc 92.614%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.247 Acc 92.541%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.197 Acc 94.787%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.193 Acc 94.776%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.267 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.236 Acc 92.961%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.244 Acc 92.868%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.241 Acc 92.912%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.244 Acc 92.795%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.243 Acc 92.861%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.205 Acc 94.701%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.200 Acc 94.640%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.276 Acc 90.625%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.231 Acc 93.069%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.238 Acc 93.004%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.240 Acc 92.899%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.240 Acc 92.926%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.243 Acc 92.855%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.200 Acc 94.732%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.195 Acc 94.710%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.250 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.233 Acc 93.139%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.237 Acc 93.109%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.239 Acc 92.964%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.238 Acc 92.938%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.238 Acc 92.909%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.201 Acc 92.188%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.202 Acc 94.686%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.196 Acc 94.640%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.131 Acc 95.312%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.244 Acc 92.822%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.236 Acc 92.965%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.235 Acc 93.039%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.236 Acc 93.025%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.238 Acc 92.967%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.197 Acc 95.011%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.192 Acc 94.869%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.147 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.221 Acc 93.441%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.226 Acc 93.078%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.227 Acc 93.171%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.231 Acc 93.070%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.231 Acc 93.143%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.957%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.193 Acc 94.862%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.232 Acc 93.170%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.225 Acc 93.287%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.230 Acc 93.161%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.232 Acc 93.109%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.231 Acc 93.140%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.199 Acc 94.802%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.195 Acc 94.757%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.227 Acc 93.255%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.224 Acc 93.462%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.229 Acc 93.285%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.227 Acc 93.374%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.228 Acc 93.302%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.196 Acc 94.810%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.190 Acc 94.873%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.233 Acc 93.054%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.229 Acc 93.194%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.228 Acc 93.200%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.226 Acc 93.331%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.227 Acc 93.321%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.185 Acc 94.998%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.329 Acc 89.062%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.226 Acc 93.301%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.234 Acc 93.291%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.413%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.223 Acc 93.473%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.224 Acc 93.446%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.199 Acc 94.740%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.194 Acc 94.675%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.221 Acc 93.704%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.221 Acc 93.602%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.221 Acc 93.498%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.220 Acc 93.528%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.220 Acc 93.558%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.190 Acc 95.111%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.187 Acc 95.052%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.283 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.229 Acc 93.433%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.227 Acc 93.540%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.231 Acc 93.374%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.228 Acc 93.390%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.224 Acc 93.504%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.193 Acc 94.879%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.225 Acc 93.402%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.220 Acc 93.462%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.216 Acc 93.529%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.220 Acc 93.458%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.221 Acc 93.455%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.183 Acc 95.141%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.212 Acc 92.969%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.216 Acc 93.680%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.211 Acc 93.711%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.213 Acc 93.680%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.215 Acc 93.631%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.216 Acc 93.624%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.194 Acc 94.748%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.189 Acc 94.799%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.185 Acc 93.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.216 Acc 93.595%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.205 Acc 93.878%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.209 Acc 93.856%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.210 Acc 93.826%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.212 Acc 93.823%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.192 Acc 95.003%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.186 Acc 95.072%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.383 Acc 90.625%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.213 Acc 93.472%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.215 Acc 93.602%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.212 Acc 93.724%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.213 Acc 93.762%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.213 Acc 93.717%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.173 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.184 Acc 95.173%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.179 Acc 95.246%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.208 Acc 93.982%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.205 Acc 94.030%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.207 Acc 93.973%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.211 Acc 93.816%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.212 Acc 93.867%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.183 Acc 95.320%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.180 Acc 95.215%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.244 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.207 Acc 93.889%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.206 Acc 93.925%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.207 Acc 93.994%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.208 Acc 93.943%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.210 Acc 93.822%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.180 Acc 95.328%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.176 Acc 95.355%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.212 Acc 93.758%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.214 Acc 93.777%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.210 Acc 93.838%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.209 Acc 93.869%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.207 Acc 93.937%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.183 Acc 95.328%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.179 Acc 95.289%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.155 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.212 Acc 94.044%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.210 Acc 93.933%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.209 Acc 93.903%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.207 Acc 93.957%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.207 Acc 93.936%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.180 Acc 95.320%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.177 Acc 95.285%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.251 Acc 90.625%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.200 Acc 94.191%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.201 Acc 94.216%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.203 Acc 94.134%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.205 Acc 94.097%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.206 Acc 94.057%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.174 Acc 95.386%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.207 Acc 94.083%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.204 Acc 94.123%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.204 Acc 93.989%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.206 Acc 93.939%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.204 Acc 94.028%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.266%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.174 Acc 95.433%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.194 Acc 92.969%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.191 Acc 94.384%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.196 Acc 94.279%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.198 Acc 94.264%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.199 Acc 94.171%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.200 Acc 94.112%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.188 Acc 94.972%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 94.935%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.196 Acc 94.245%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.200 Acc 93.983%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.200 Acc 94.015%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.202 Acc 94.013%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.200 Acc 94.056%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.174 Acc 95.421%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.170 Acc 95.484%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.189 Acc 94.183%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.189 Acc 94.267%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.195 Acc 94.298%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.198 Acc 94.216%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.198 Acc 94.176%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.178 Acc 95.270%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.129 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.194 Acc 94.291%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.191 Acc 94.345%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.192 Acc 94.334%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.195 Acc 94.276%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.197 Acc 94.243%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.172 Acc 95.526%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.189 Acc 94.701%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.194 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.196 Acc 94.376%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.195 Acc 94.368%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.196 Acc 94.363%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.182 Acc 95.367%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.176 Acc 95.390%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.094 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.189 Acc 94.670%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.197 Acc 94.356%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.191 Acc 94.443%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.192 Acc 94.430%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.194 Acc 94.442%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.186 Acc 95.212%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.182 Acc 95.211%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.169 Acc 93.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.190 Acc 94.508%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.184 Acc 94.632%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.190 Acc 94.425%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.193 Acc 94.424%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.193 Acc 94.402%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.192 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.170 Acc 95.568%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.546%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.196 Acc 94.493%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.190 Acc 94.551%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.188 Acc 94.614%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.189 Acc 94.533%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.190 Acc 94.519%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.176 Acc 95.405%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.173 Acc 95.425%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.175 Acc 94.964%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.183 Acc 94.698%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.185 Acc 94.630%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.189 Acc 94.559%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.189 Acc 94.520%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.177 Acc 95.374%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.172 Acc 95.464%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.186 Acc 94.810%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.186 Acc 94.698%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.189 Acc 94.557%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.191 Acc 94.549%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.190 Acc 94.523%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.661%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.169 Acc 95.623%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.182 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.186 Acc 94.554%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.188 Acc 94.543%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.185 Acc 94.570%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.186 Acc 94.522%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.188 Acc 94.467%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.171 Acc 95.476%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.216 Acc 92.188%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.191 Acc 94.168%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.188 Acc 94.325%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.187 Acc 94.396%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.190 Acc 94.352%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.188 Acc 94.427%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.177 Acc 95.405%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.172 Acc 95.553%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.188 Acc 94.717%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.191 Acc 94.597%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.186 Acc 94.671%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.186 Acc 94.642%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.187 Acc 94.648%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.177 Acc 95.343%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.173 Acc 95.398%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.135 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.176 Acc 94.802%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.181 Acc 94.679%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.185 Acc 94.583%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.518%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.186 Acc 94.537%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.174 Acc 95.459%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.169 Acc 95.561%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.182 Acc 94.949%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.179 Acc 94.850%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.180 Acc 94.801%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.183 Acc 94.726%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.184 Acc 94.731%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.178 Acc 95.297%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.171 Acc 95.390%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.205 Acc 94.531%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.184 Acc 94.686%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.179 Acc 94.823%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.180 Acc 94.835%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.182 Acc 94.814%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.184 Acc 94.700%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.167 Acc 92.188%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.175 Acc 95.490%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.170 Acc 95.546%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.144 Acc 92.969%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.183 Acc 94.632%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.345%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.185 Acc 94.464%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.186 Acc 94.496%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.186 Acc 94.522%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.171 Acc 95.661%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.368 Acc 92.969%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.185 Acc 94.686%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.182 Acc 94.737%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.180 Acc 94.679%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.180 Acc 94.718%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.181 Acc 94.693%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.182 Acc 92.188%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.173 Acc 95.475%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.168 Acc 95.534%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.176 Acc 94.771%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.177 Acc 94.726%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.179 Acc 94.786%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.178 Acc 94.804%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.181 Acc 94.801%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.172 Acc 95.538%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.166 Acc 95.050%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.168 Acc 94.990%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.172 Acc 94.931%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.174 Acc 94.921%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.176 Acc 94.888%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.169 Acc 95.405%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.163 Acc 95.553%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.184 Acc 92.969%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.167 Acc 95.026%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.172 Acc 95.017%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.176 Acc 94.887%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.177 Acc 94.864%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.176 Acc 94.896%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.214 Acc 90.625%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.174 Acc 95.460%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.163 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.183 Acc 94.895%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.177 Acc 95.044%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.175 Acc 95.050%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.177 Acc 95.026%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.178 Acc 94.988%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.173 Acc 95.421%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.515%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.163 Acc 95.119%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.166 Acc 95.157%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.170 Acc 95.066%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.173 Acc 95.009%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.173 Acc 94.993%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.170 Acc 95.722%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 95.709%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.172 Acc 94.918%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.174 Acc 94.982%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.173 Acc 94.991%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.176 Acc 94.907%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.176 Acc 94.882%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.630%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.166 Acc 95.709%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.169 Acc 94.933%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.171 Acc 94.943%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.173 Acc 94.934%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.174 Acc 94.905%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.175 Acc 94.941%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.174 Acc 95.467%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.170 Acc 95.565%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.105 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.178 Acc 94.624%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.173 Acc 94.799%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.173 Acc 94.939%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.172 Acc 94.958%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.173 Acc 94.963%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.189 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.173 Acc 95.459%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.167 Acc 95.569%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.176 Acc 92.969%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.175 Acc 94.879%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.172 Acc 95.029%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.174 Acc 94.991%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.175 Acc 94.974%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.175 Acc 94.962%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.166 Acc 95.707%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.163 Acc 95.794%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.161 Acc 95.320%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.175 Acc 95.068%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.175 Acc 94.949%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.174 Acc 94.952%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.172 Acc 94.954%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.172 Acc 95.591%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.166 Acc 95.736%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.161 Acc 95.258%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.169 Acc 95.048%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.170 Acc 95.006%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.171 Acc 95.065%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.172 Acc 95.099%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.138 Acc 93.750%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.170 Acc 95.483%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.608%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.105 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.170 Acc 94.895%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.166 Acc 95.141%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.164 Acc 95.271%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.166 Acc 95.221%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.166 Acc 95.211%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.343%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.173 Acc 95.507%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.240 Acc 92.188%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.170 Acc 95.088%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.173 Acc 94.970%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.171 Acc 95.048%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.171 Acc 95.067%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.170 Acc 95.069%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.169 Acc 95.560%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.165 Acc 95.604%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.162 Acc 95.374%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.174 Acc 95.068%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.173 Acc 95.105%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.170 Acc 95.184%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.170 Acc 95.150%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.169 Acc 95.630%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.164 Acc 95.686%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.137 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.155 Acc 95.336%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.161 Acc 95.293%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.165 Acc 95.227%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.166 Acc 95.131%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.166 Acc 95.169%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.173 Acc 95.405%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.169 Acc 95.476%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.188 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.159 Acc 95.166%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.163 Acc 95.130%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.167 Acc 95.081%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.166 Acc 95.087%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.166 Acc 95.085%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.173 Acc 95.506%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.167 Acc 95.655%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.167 Acc 95.235%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.165 Acc 95.196%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.164 Acc 95.227%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.167 Acc 95.213%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.166 Acc 95.182%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.176 Acc 95.421%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.171 Acc 95.573%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.155 Acc 95.568%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.161 Acc 95.476%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.162 Acc 95.471%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.161 Acc 95.404%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.162 Acc 95.364%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.215 Acc 92.188%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.529%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.174 Acc 95.569%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.164 Acc 95.297%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.166 Acc 95.281%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.165 Acc 95.214%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.163 Acc 95.291%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.186 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.175 Acc 95.490%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.171 Acc 95.519%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.159 Acc 95.490%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.160 Acc 95.437%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.159 Acc 95.528%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.162 Acc 95.431%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.162 Acc 95.434%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.198 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.169 Acc 95.707%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.164 Acc 95.814%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.161 Acc 95.514%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.163 Acc 95.336%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.163 Acc 95.315%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.161 Acc 95.326%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.162 Acc 95.353%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.560%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.169 Acc 95.639%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.155 Acc 95.413%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.157 Acc 95.484%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.159 Acc 95.449%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.161 Acc 95.369%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.170 Acc 95.717%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.162 Acc 95.212%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.164 Acc 95.324%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.163 Acc 95.268%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.162 Acc 95.291%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.162 Acc 95.291%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.145 Acc 92.969%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.168 Acc 95.722%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.164 Acc 95.779%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.187 Acc 92.969%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.153 Acc 95.475%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.157 Acc 95.433%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.159 Acc 95.359%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.159 Acc 95.308%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.171 Acc 95.568%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.167 Acc 95.674%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.110 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.155 Acc 95.444%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.155 Acc 95.452%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.155 Acc 95.447%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.156 Acc 95.406%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.157 Acc 95.433%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.168 Acc 95.684%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.162 Acc 95.771%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.147 Acc 95.869%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.153 Acc 95.604%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.154 Acc 95.564%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.155 Acc 95.542%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.157 Acc 95.520%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.166 Acc 95.756%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.157 Acc 95.220%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.480%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.154 Acc 95.525%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.157 Acc 95.494%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.157 Acc 95.482%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.170 Acc 95.490%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.164 Acc 95.631%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.148 Acc 96.875%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.153 Acc 95.715%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.157 Acc 95.647%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.156 Acc 95.562%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.158 Acc 95.463%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.158 Acc 95.428%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.168 Acc 95.645%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.163 Acc 95.810%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.155 Acc 95.591%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.153 Acc 95.530%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.156 Acc 95.450%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.156 Acc 95.503%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.155 Acc 95.497%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.168 Acc 95.769%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.163 Acc 95.779%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.160 Acc 95.189%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.154 Acc 95.421%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.154 Acc 95.536%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.156 Acc 95.457%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.155 Acc 95.478%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.171 Acc 95.668%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.165 Acc 95.756%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.147 Acc 95.668%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.151 Acc 95.616%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.153 Acc 95.611%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.156 Acc 95.500%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.156 Acc 95.565%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.174 Acc 95.490%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.169 Acc 95.635%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.151 Acc 95.777%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.150 Acc 95.794%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.153 Acc 95.575%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.156 Acc 95.513%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.157 Acc 95.487%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.168 Acc 95.666%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.152 Acc 95.545%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.153 Acc 95.686%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.153 Acc 95.582%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.152 Acc 95.599%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.153 Acc 95.523%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.171 Acc 95.653%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.165 Acc 95.787%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.154 Acc 95.699%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.159 Acc 95.495%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.156 Acc 95.559%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.155 Acc 95.568%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.153 Acc 95.587%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.174 Acc 95.514%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.169 Acc 95.577%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.156 Acc 95.297%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.316%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.156 Acc 95.388%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.154 Acc 95.461%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.167 Acc 95.777%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.162 Acc 95.880%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.152 Acc 95.483%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.156 Acc 95.301%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.151 Acc 95.505%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.150 Acc 95.583%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.150 Acc 95.570%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.169 Acc 95.637%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.166 Acc 95.798%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.189 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.147 Acc 95.777%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.151 Acc 95.676%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.151 Acc 95.696%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.150 Acc 95.709%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.163 Acc 95.792%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.160 Acc 95.798%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.206 Acc 92.969%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.152 Acc 95.653%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.147 Acc 95.655%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.149 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.150 Acc 95.554%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.150 Acc 95.581%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.167 Acc 95.622%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.163 Acc 95.697%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.251 Acc 92.969%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.145 Acc 95.846%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.146 Acc 95.783%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.150 Acc 95.681%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.152 Acc 95.650%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.151 Acc 95.719%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.167 Acc 95.792%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.163 Acc 95.861%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.131 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.147 Acc 95.639%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.146 Acc 95.704%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.148 Acc 95.663%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.150 Acc 95.682%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.170 Acc 95.588%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.152 Acc 95.668%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.151 Acc 95.637%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.149 Acc 95.651%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.150 Acc 95.651%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.475%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.168 Acc 95.620%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.169 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.152 Acc 95.575%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.150 Acc 95.608%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.153 Acc 95.505%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.152 Acc 95.544%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.150 Acc 95.615%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.165 Acc 95.800%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.162 Acc 95.872%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.151 Acc 95.560%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.144 Acc 95.736%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.144 Acc 95.717%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.145 Acc 95.720%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.146 Acc 95.654%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.164 Acc 95.808%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.159 Acc 95.954%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.183 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.144 Acc 95.684%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.142 Acc 95.787%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.145 Acc 95.793%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.146 Acc 95.807%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.147 Acc 95.741%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.167 Acc 95.823%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.163 Acc 95.833%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.148 Acc 95.800%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.149 Acc 95.818%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.146 Acc 95.847%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.144 Acc 95.885%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.145 Acc 95.840%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.176 Acc 95.452%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.168 Acc 95.612%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.148 Acc 95.893%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.146 Acc 95.876%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.146 Acc 95.718%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.146 Acc 95.705%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.170 Acc 95.831%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.164 Acc 95.923%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.169 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.142 Acc 95.792%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.145 Acc 95.639%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.145 Acc 95.660%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.148 Acc 95.632%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.147 Acc 95.681%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.172 Acc 95.639%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.142 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.136 Acc 95.985%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.140 Acc 95.962%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.145 Acc 95.850%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.144 Acc 95.836%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.167 Acc 95.792%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.162 Acc 95.927%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.149 Acc 95.661%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.145 Acc 95.806%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.144 Acc 95.856%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.145 Acc 95.818%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.166 Acc 95.748%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.145 Acc 95.560%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.146 Acc 95.620%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.142 Acc 95.699%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.142 Acc 95.778%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.144 Acc 95.713%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.166 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.175 Acc 95.498%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.169 Acc 95.682%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.145 Acc 95.792%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.143 Acc 95.806%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.143 Acc 95.829%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.144 Acc 95.741%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.145 Acc 95.744%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.170 Acc 95.738%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.167 Acc 95.798%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.138 Acc 96.132%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.144 Acc 95.883%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.143 Acc 95.907%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.170 Acc 95.715%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.137 Acc 95.831%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.141 Acc 95.896%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.140 Acc 95.941%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.142 Acc 95.811%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.142 Acc 95.813%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.168 Acc 95.815%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.166 Acc 95.822%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.140 Acc 96.034%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.142 Acc 95.950%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.141 Acc 95.925%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.168 Acc 95.908%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.163 Acc 95.938%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.142 Acc 95.970%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.141 Acc 95.969%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.140 Acc 95.977%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.140 Acc 95.930%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.141 Acc 95.921%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.164 Acc 95.962%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.160 Acc 95.946%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.140 Acc 95.823%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.138 Acc 95.903%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.140 Acc 95.805%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.141 Acc 95.802%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.168 Acc 95.777%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 95.759%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.142 Acc 95.777%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.138 Acc 95.907%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.137 Acc 95.896%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.139 Acc 95.864%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.140 Acc 95.849%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.166 Acc 95.837%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.197 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.135 Acc 96.000%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.136 Acc 95.974%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.136 Acc 95.942%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.139 Acc 95.911%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.614%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.167 Acc 95.631%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.137 Acc 96.125%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.141 Acc 95.993%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.141 Acc 95.995%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.140 Acc 95.961%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.140 Acc 95.972%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.174 Acc 95.622%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.169 Acc 95.783%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.128 Acc 96.442%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.134 Acc 96.175%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.136 Acc 96.156%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.138 Acc 96.055%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.137 Acc 96.056%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.174 Acc 95.529%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.169 Acc 95.693%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.141 Acc 95.861%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.140 Acc 95.873%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.139 Acc 95.895%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.140 Acc 95.871%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.165 Acc 95.862%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.160 Acc 95.965%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.136 Acc 96.003%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.134 Acc 96.080%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.137 Acc 96.017%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.174 Acc 95.684%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.170 Acc 95.732%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.137 Acc 96.001%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.135 Acc 96.034%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.135 Acc 96.103%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.135 Acc 96.055%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.174 Acc 95.537%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.167 Acc 95.608%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.106 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.126 Acc 96.349%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.129 Acc 96.304%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.131 Acc 96.208%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.134 Acc 96.121%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.135 Acc 96.123%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.173 Acc 95.606%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.167 Acc 95.857%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.245 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.133 Acc 96.295%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.136 Acc 96.102%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.134 Acc 96.051%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.136 Acc 96.010%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.174 Acc 95.568%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.170 Acc 95.655%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.201 Acc 92.188%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.138 Acc 95.893%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.132 Acc 96.024%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.132 Acc 96.006%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.133 Acc 95.952%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.134 Acc 95.952%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.169 Acc 95.815%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.132 Acc 95.893%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.131 Acc 95.946%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.131 Acc 96.073%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.133 Acc 96.055%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.136 Acc 96.019%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.134 Acc 95.985%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.134 Acc 96.042%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.133 Acc 96.092%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.135 Acc 96.030%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.170 Acc 95.645%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.166 Acc 95.853%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.133 Acc 96.210%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.135 Acc 96.129%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.134 Acc 96.164%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.133 Acc 96.220%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.134 Acc 96.198%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.167 Acc 95.854%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.163 Acc 95.942%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.141 Acc 95.985%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.140 Acc 96.012%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.136 Acc 96.078%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.135 Acc 96.055%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.134 Acc 96.038%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.166 Acc 95.900%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.162 Acc 95.997%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.135 Acc 96.109%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.131 Acc 96.214%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.134 Acc 96.099%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.134 Acc 96.115%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.133 Acc 96.133%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.599%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 95.752%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.122 Acc 96.287%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.128 Acc 96.102%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.131 Acc 96.161%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.132 Acc 96.121%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.132 Acc 96.098%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.171 Acc 95.583%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.167 Acc 95.744%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.125 Acc 96.380%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.135 Acc 96.222%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.132 Acc 96.242%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.132 Acc 96.174%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.132 Acc 96.176%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.169 Acc 95.670%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.125 Acc 96.346%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.126 Acc 96.294%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.129 Acc 96.218%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.130 Acc 96.186%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.165 Acc 95.746%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.161 Acc 95.857%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.129 Acc 96.310%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.127 Acc 96.428%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.131 Acc 96.135%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.131 Acc 96.150%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.170 Acc 95.784%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.165 Acc 95.864%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.129 Acc 96.210%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.128 Acc 96.323%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.130 Acc 96.320%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.130 Acc 96.244%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.131 Acc 96.201%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.170 Acc 95.614%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.166 Acc 95.794%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.123 Acc 96.357%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.126 Acc 96.206%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.127 Acc 96.296%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.130 Acc 96.215%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.132 Acc 96.170%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.169 Acc 95.568%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.164 Acc 95.849%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.201 Acc 93.750%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.122 Acc 96.488%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.123 Acc 96.381%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.127 Acc 96.307%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.128 Acc 96.228%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.129 Acc 96.209%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.165 Acc 95.769%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.162 Acc 95.958%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.121 Acc 96.498%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.125 Acc 96.351%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.132 Acc 96.151%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.127 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.129 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.131 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.130 Acc 96.201%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.128 Acc 96.248%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.169 Acc 95.792%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.162 Acc 95.934%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.163 Acc 95.312%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.121 Acc 96.349%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.125 Acc 96.276%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.127 Acc 96.205%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.127 Acc 96.228%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.129 Acc 96.203%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.171 Acc 95.931%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.166 Acc 95.942%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.126 Acc 96.279%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.127 Acc 96.137%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.130 Acc 96.144%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.129 Acc 96.175%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.166 Acc 95.806%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.120 Acc 96.666%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.124 Acc 96.529%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.125 Acc 96.403%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.127 Acc 96.335%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.128 Acc 96.262%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.177 Acc 95.413%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.172 Acc 95.542%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.125 Acc 96.287%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.123 Acc 96.346%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.124 Acc 96.371%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.126 Acc 96.318%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.127 Acc 96.314%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.171 Acc 95.730%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.165 Acc 95.837%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.134 Acc 96.109%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.131 Acc 96.199%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.130 Acc 96.203%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.126 Acc 96.324%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.126 Acc 96.268%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.176 Acc 95.459%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.171 Acc 95.588%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.123 Acc 96.300%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.125 Acc 96.257%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.127 Acc 96.269%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.129 Acc 96.184%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.167 Acc 95.705%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.147 Acc 93.750%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.127 Acc 96.354%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.128 Acc 96.335%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.129 Acc 96.292%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.129 Acc 96.239%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.171 Acc 95.784%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.168 Acc 95.818%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.123 Acc 96.457%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.124 Acc 96.358%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.126 Acc 96.269%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.125 Acc 96.323%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.189 Acc 92.188%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.175 Acc 95.777%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.171 Acc 95.876%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.139 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.127 Acc 96.295%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.121 Acc 96.440%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.122 Acc 96.366%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.125 Acc 96.339%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.126 Acc 96.348%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.197 Acc 92.188%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.182 Acc 95.506%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.175 Acc 95.662%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.121 Acc 96.506%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.123 Acc 96.416%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.123 Acc 96.384%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.125 Acc 96.282%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.176 Acc 95.591%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.171 Acc 95.690%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.124 Acc 96.403%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.125 Acc 96.335%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.124 Acc 96.322%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.125 Acc 96.284%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.177 Acc 95.637%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.172 Acc 95.763%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.125 Acc 96.426%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.120 Acc 96.502%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.122 Acc 96.410%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.124 Acc 96.354%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.176 Acc 95.552%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.171 Acc 95.670%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.122 Acc 96.434%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.124 Acc 96.257%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.125 Acc 96.211%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.123 Acc 96.310%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.123 Acc 96.321%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.171 Acc 95.777%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.164 Acc 95.903%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.119 Acc 96.728%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.121 Acc 96.545%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.120 Acc 96.488%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.123 Acc 96.386%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.124 Acc 96.348%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.170 Acc 95.730%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.166 Acc 95.845%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.189 Acc 92.969%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.115 Acc 96.457%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.120 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.122 Acc 96.353%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.121 Acc 96.353%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.164 Acc 95.818%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.121 Acc 96.542%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.120 Acc 96.514%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.122 Acc 96.426%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.122 Acc 96.423%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.164 Acc 95.826%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.122 Acc 95.312%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.119 Acc 96.589%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.122 Acc 96.432%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.122 Acc 96.423%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.123 Acc 96.329%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.122 Acc 96.443%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.175 Acc 95.707%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.168 Acc 95.810%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.114 Acc 96.798%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.118 Acc 96.479%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.120 Acc 96.473%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.120 Acc 96.485%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.123 Acc 96.403%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.176 Acc 95.661%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.169 Acc 95.806%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.115 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.118 Acc 96.419%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.120 Acc 96.401%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.123 Acc 96.330%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.122 Acc 96.368%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.123 Acc 96.329%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.174 Acc 95.899%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.243 Acc 91.406%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.117 Acc 96.558%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.121 Acc 96.393%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.122 Acc 96.390%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.124 Acc 96.316%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.123 Acc 96.356%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.132 Acc 92.969%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.167 Acc 95.900%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.163 Acc 95.954%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.127 Acc 96.125%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.121 Acc 96.308%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.122 Acc 96.288%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.123 Acc 96.283%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.122 Acc 96.329%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.173 Acc 95.800%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.168 Acc 95.896%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.134 Acc 92.969%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.115 Acc 96.473%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.117 Acc 96.521%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.120 Acc 96.496%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.120 Acc 96.464%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.121 Acc 96.403%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.181 Acc 95.521%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.174 Acc 95.674%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.181 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.119 Acc 96.527%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.122 Acc 96.385%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.119 Acc 96.426%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.119 Acc 96.433%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.119 Acc 96.446%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.180 Acc 95.614%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.173 Acc 95.767%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.113 Acc 96.736%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.120 Acc 96.498%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.121 Acc 96.421%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.120 Acc 96.444%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.120 Acc 96.465%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.176 Acc 95.529%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.171 Acc 95.725%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.114 Acc 96.658%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.119 Acc 96.545%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.121 Acc 96.457%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.123 Acc 96.433%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.122 Acc 96.456%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.186 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.174 Acc 95.869%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.115 Acc 96.643%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.119 Acc 96.479%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.119 Acc 96.474%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.121 Acc 96.421%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.167 Acc 95.857%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.116 Acc 96.612%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.115 Acc 96.630%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.116 Acc 96.634%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.118 Acc 96.542%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.118 Acc 96.533%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.176 Acc 95.753%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.172 Acc 95.849%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.150 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.109 Acc 96.767%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.112 Acc 96.766%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.113 Acc 96.683%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.114 Acc 96.614%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.116 Acc 96.593%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.166 Acc 95.761%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.161 Acc 95.868%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.114 Acc 96.504%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.115 Acc 96.607%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.116 Acc 96.532%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.115 Acc 96.489%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.118 Acc 96.406%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.514%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.165 Acc 95.779%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.190 Acc 96.094%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.121 Acc 96.457%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.117 Acc 96.490%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.117 Acc 96.517%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.118 Acc 96.458%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.119 Acc 96.445%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.170 Acc 95.753%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.166 Acc 95.896%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.117 Acc 96.651%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.118 Acc 96.568%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.119 Acc 96.519%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.118 Acc 96.462%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.182 Acc 95.413%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.174 Acc 95.600%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.112 Acc 96.682%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.112 Acc 96.630%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.111 Acc 96.641%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.114 Acc 96.569%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.116 Acc 96.499%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.171 Acc 95.514%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.164 Acc 95.759%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.041 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.111 Acc 96.573%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.116 Acc 96.479%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.116 Acc 96.538%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.117 Acc 96.537%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.170 Acc 95.868%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.116 Acc 96.612%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.119 Acc 96.583%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.119 Acc 96.522%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.119 Acc 96.523%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.175 Acc 95.684%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.169 Acc 95.822%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.102 Acc 96.960%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.109 Acc 96.677%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.112 Acc 96.628%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.113 Acc 96.555%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.114 Acc 96.532%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.174 Acc 95.908%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.169 Acc 95.927%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.091 Acc 96.094%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.112 Acc 96.488%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.114 Acc 96.510%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.119 Acc 96.405%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.118 Acc 96.501%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.119 Acc 96.495%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.166 Acc 95.965%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.113 Acc 96.674%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.116 Acc 96.595%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.115 Acc 96.673%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.116 Acc 96.645%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.117 Acc 96.576%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.167 Acc 95.868%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.112 Acc 96.762%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.114 Acc 96.649%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.114 Acc 96.659%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.115 Acc 96.601%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.169 Acc 95.965%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.138 Acc 97.656%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.112 Acc 96.678%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.115 Acc 96.583%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.171 Acc 96.001%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.167 Acc 96.000%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.179 Acc 96.094%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.112 Acc 96.689%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.118 Acc 96.506%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.119 Acc 96.452%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.117 Acc 96.530%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.115 Acc 96.568%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.176 Acc 95.692%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.171 Acc 95.806%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.116 Acc 96.627%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.114 Acc 96.615%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.114 Acc 96.597%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.115 Acc 96.571%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.114 Acc 96.577%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.169 Acc 95.908%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.163 Acc 96.039%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.126 Acc 92.969%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.111 Acc 96.736%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.112 Acc 96.699%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.113 Acc 96.616%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.112 Acc 96.627%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.175 Acc 95.769%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.169 Acc 95.857%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.196 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.109 Acc 96.713%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.111 Acc 96.587%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.111 Acc 96.610%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.112 Acc 96.579%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.165 Acc 95.769%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.159 Acc 95.993%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.108 Acc 96.836%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.111 Acc 96.700%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.113 Acc 96.610%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.115 Acc 96.604%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.115 Acc 96.551%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.182 Acc 95.653%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.177 Acc 95.721%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.114 Acc 96.728%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.110 Acc 96.743%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.111 Acc 96.636%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.115 Acc 96.555%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.114 Acc 96.529%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.183 Acc 95.738%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.176 Acc 95.802%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.107 Acc 96.728%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.112 Acc 96.595%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.114 Acc 96.594%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.177 Acc 95.596%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.117 Acc 96.620%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.115 Acc 96.638%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.112 Acc 96.692%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.112 Acc 96.650%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.173 Acc 95.808%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.167 Acc 95.896%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.106 Acc 96.713%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.109 Acc 96.688%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.111 Acc 96.722%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.111 Acc 96.727%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.111 Acc 96.722%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.179 Acc 95.715%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.106 Acc 96.713%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.106 Acc 96.793%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.110 Acc 96.683%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.109 Acc 96.659%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.111 Acc 96.616%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.180 Acc 95.630%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.174 Acc 95.791%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.114 Acc 96.589%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.112 Acc 96.634%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.112 Acc 96.644%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.111 Acc 96.657%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.114 Acc 96.615%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.174 Acc 95.722%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.168 Acc 95.814%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.108 Acc 96.705%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.109 Acc 96.747%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.112 Acc 96.602%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.113 Acc 96.546%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.113 Acc 96.548%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.176 Acc 95.661%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.170 Acc 95.775%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a3282cc94a49e0bb961a8f7ca197fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.338 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.285 Acc 15.231%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.265 Acc 16.818%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.250 Acc 17.720%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.200 Acc 20.244%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.115 Acc 23.832%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.376 Acc 50.781%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.383 Acc 52.591%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.379 Acc 52.394%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.413 Acc 53.906%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.261 Acc 57.805%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.181 Acc 60.969%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.116 Acc 63.164%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.059 Acc 65.272%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.008 Acc 67.066%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.654 Acc 75.781%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.618 Acc 80.879%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.608 Acc 81.429%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.808 Acc 78.906%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.715 Acc 77.669%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.695 Acc 78.152%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.676 Acc 78.914%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.655 Acc 79.454%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.643 Acc 79.818%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.511 Acc 83.594%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.468 Acc 85.466%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.464 Acc 85.665%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.684 Acc 82.812%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.539 Acc 83.199%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.535 Acc 83.306%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.523 Acc 83.638%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.519 Acc 83.775%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.516 Acc 83.935%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.383 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.382 Acc 88.877%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.380 Acc 88.685%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.747 Acc 86.719%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.450 Acc 86.077%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.447 Acc 86.151%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.450 Acc 86.161%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.449 Acc 86.187%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.445 Acc 86.263%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.354 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.358 Acc 89.411%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.355 Acc 89.335%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.320 Acc 89.844%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.416 Acc 87.013%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.420 Acc 86.952%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.414 Acc 87.163%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.408 Acc 87.369%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.404 Acc 87.506%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.320 Acc 90.888%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.314 Acc 90.913%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.434 Acc 85.938%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.381 Acc 88.498%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.382 Acc 88.413%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.378 Acc 88.491%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.376 Acc 88.556%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.374 Acc 88.618%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.261 Acc 92.188%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.301 Acc 91.360%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.297 Acc 91.418%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.364 Acc 89.062%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.352 Acc 89.434%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.353 Acc 89.237%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.347 Acc 89.418%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.350 Acc 89.349%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.351 Acc 89.382%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.230 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.277 Acc 92.071%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.273 Acc 92.125%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.302 Acc 91.406%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.335 Acc 89.759%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.337 Acc 89.727%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.335 Acc 89.805%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.333 Acc 89.883%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.329 Acc 89.933%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.269 Acc 92.296%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.266 Acc 92.347%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.353 Acc 89.062%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.307 Acc 90.501%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.314 Acc 90.400%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.318 Acc 90.301%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.315 Acc 90.454%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.315 Acc 90.449%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.293 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.268 Acc 92.396%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.266 Acc 92.409%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.252 Acc 92.969%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.309 Acc 90.880%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.306 Acc 90.885%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.307 Acc 90.830%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.305 Acc 90.880%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.304 Acc 90.854%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.252 Acc 92.938%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.251 Acc 92.833%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.423 Acc 86.719%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.295 Acc 91.143%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.293 Acc 91.091%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.291 Acc 91.271%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.288 Acc 91.385%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.288 Acc 91.431%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.262 Acc 92.481%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.257 Acc 92.491%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.276 Acc 91.515%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.277 Acc 91.737%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.274 Acc 91.788%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.279 Acc 91.687%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.280 Acc 91.684%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.248 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.238 Acc 93.356%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.235 Acc 93.350%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.323 Acc 92.969%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.270 Acc 91.979%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.265 Acc 92.055%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.272 Acc 91.770%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.270 Acc 91.917%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.270 Acc 91.908%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.230 Acc 93.758%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.228 Acc 93.692%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.264 Acc 92.079%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.262 Acc 92.176%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.257 Acc 92.322%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.260 Acc 92.314%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.261 Acc 92.304%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.231 Acc 93.580%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.226 Acc 93.521%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.334 Acc 90.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.250 Acc 92.597%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.248 Acc 92.697%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.253 Acc 92.476%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.255 Acc 92.460%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.255 Acc 92.425%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.243 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.232 Acc 93.595%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.228 Acc 93.657%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.127 Acc 96.094%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.245 Acc 92.729%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.247 Acc 92.658%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.250 Acc 92.668%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.249 Acc 92.624%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.251 Acc 92.548%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.225 Acc 93.704%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.224 Acc 93.672%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.245 Acc 92.675%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.246 Acc 92.837%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.242 Acc 92.919%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.245 Acc 92.840%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.246 Acc 92.797%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.212 Acc 94.160%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.209 Acc 94.174%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.213 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.230 Acc 93.031%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.233 Acc 93.062%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.238 Acc 92.964%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.238 Acc 93.016%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.237 Acc 93.003%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.218 Acc 94.075%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.214 Acc 94.065%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.236 Acc 92.775%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.234 Acc 93.074%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.235 Acc 93.041%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.235 Acc 93.031%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.236 Acc 93.028%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.214 Acc 94.144%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.210 Acc 94.154%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.247 Acc 92.188%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.240 Acc 92.930%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.230 Acc 93.260%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.229 Acc 93.376%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.229 Acc 93.308%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.228 Acc 93.327%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.205 Acc 94.462%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.204 Acc 94.349%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.241 Acc 92.188%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.219 Acc 93.487%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.226 Acc 93.408%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.226 Acc 93.420%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.226 Acc 93.353%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.227 Acc 93.370%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.214 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.212 Acc 94.268%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.210 Acc 94.154%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.295 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.219 Acc 93.580%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.223 Acc 93.482%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.222 Acc 93.449%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.222 Acc 93.514%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.219 Acc 93.621%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.215 Acc 95.312%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.209 Acc 94.400%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.208 Acc 94.267%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.191 Acc 92.969%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.225 Acc 93.765%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.219 Acc 93.789%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.216 Acc 93.794%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.218 Acc 93.680%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.217 Acc 93.666%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.197 Acc 94.810%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.195 Acc 94.687%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.239 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.204 Acc 94.036%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.211 Acc 93.828%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.210 Acc 93.906%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.210 Acc 93.884%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.210 Acc 93.909%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.198 Acc 94.856%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.198 Acc 94.737%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.205 Acc 94.083%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.210 Acc 93.972%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.212 Acc 93.776%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.210 Acc 93.793%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.208 Acc 93.850%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.210 Acc 94.129%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.206 Acc 94.076%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.141 Acc 98.438%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.198 Acc 94.230%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.200 Acc 94.150%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.203 Acc 94.025%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.203 Acc 94.048%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.204 Acc 94.034%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.186 Acc 95.013%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.256 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.193 Acc 94.407%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.199 Acc 94.131%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.203 Acc 94.010%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.203 Acc 94.015%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.201 Acc 94.087%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.202 Acc 94.740%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.197 Acc 94.652%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.196 Acc 94.516%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.194 Acc 94.352%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.195 Acc 94.277%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.197 Acc 94.220%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.199 Acc 94.159%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.194 Acc 94.825%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.192 Acc 94.819%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.253 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.178 Acc 95.073%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.181 Acc 94.862%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.186 Acc 94.718%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.190 Acc 94.584%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.194 Acc 94.525%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.190 Acc 94.725%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.187 Acc 94.733%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.184 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.187 Acc 94.656%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.190 Acc 94.604%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.192 Acc 94.580%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.192 Acc 94.833%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.135 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.196 Acc 94.369%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.195 Acc 94.391%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.189 Acc 94.472%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.191 Acc 94.488%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.196 Acc 94.802%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.192 Acc 94.803%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.235 Acc 89.844%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.179 Acc 94.601%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.181 Acc 94.582%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.183 Acc 94.622%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.186 Acc 94.543%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.187 Acc 94.548%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.193 Acc 94.995%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.189 Acc 94.904%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.192 Acc 94.771%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.185 Acc 94.710%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.184 Acc 94.679%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.184 Acc 94.681%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.186 Acc 94.654%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.200 Acc 94.740%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.195 Acc 94.772%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.181 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.185 Acc 94.794%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.184 Acc 94.811%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.187 Acc 94.638%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.185 Acc 94.590%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.184 Acc 94.639%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.185 Acc 95.189%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.181 Acc 95.134%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.182 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.171 Acc 95.009%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.176 Acc 94.957%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.177 Acc 94.960%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.178 Acc 94.851%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.182 Acc 95.270%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.255 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.167 Acc 95.274%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.175 Acc 94.959%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.177 Acc 94.918%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.177 Acc 94.876%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.177 Acc 94.885%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.128 Acc 96.875%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.191 Acc 94.903%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.189 Acc 94.908%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.173 Acc 95.119%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.171 Acc 95.095%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.171 Acc 95.074%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.176 Acc 94.956%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.176 Acc 94.955%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.184 Acc 95.204%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.181 Acc 95.149%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.164 Acc 95.266%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.169 Acc 95.110%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.167 Acc 95.198%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.171 Acc 95.094%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.173 Acc 95.030%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.191 Acc 94.787%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.186 Acc 94.850%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.165 Acc 95.343%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.168 Acc 95.134%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.172 Acc 95.030%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.171 Acc 95.032%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.172 Acc 94.994%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.186 Acc 95.104%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.182 Acc 95.173%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.243 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.163 Acc 95.467%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.162 Acc 95.293%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.166 Acc 95.229%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.213%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.169 Acc 95.147%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.175 Acc 95.464%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.158 Acc 95.343%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.161 Acc 95.285%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.163 Acc 95.341%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.166 Acc 95.256%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.168 Acc 95.182%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.184 Acc 95.328%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.180 Acc 95.285%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.160 Acc 95.490%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.162 Acc 95.386%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.164 Acc 95.364%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.164 Acc 95.294%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.184 Acc 95.088%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.179 Acc 95.169%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.169 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.167 Acc 95.328%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.164 Acc 95.325%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.163 Acc 95.377%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.163 Acc 95.358%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.187 Acc 95.080%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.181 Acc 95.161%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.168 Acc 95.204%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.163 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.163 Acc 95.333%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.163 Acc 95.305%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.162 Acc 95.342%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.193 Acc 95.135%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.189 Acc 95.176%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.161 Acc 95.212%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.162 Acc 95.417%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.161 Acc 95.372%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.159 Acc 95.435%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.159 Acc 95.428%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.183 Acc 95.274%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.181 Acc 95.149%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.149 Acc 95.630%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.152 Acc 95.522%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.153 Acc 95.479%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.156 Acc 95.418%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.158 Acc 95.389%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.176 Acc 95.382%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.175 Acc 95.355%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.149 Acc 95.792%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.151 Acc 95.569%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.489%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.154 Acc 95.511%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.156 Acc 95.492%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.180 Acc 95.359%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.178 Acc 95.336%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.145 Acc 95.676%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.152 Acc 95.588%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.153 Acc 95.544%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.155 Acc 95.478%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.155 Acc 95.484%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.183 Acc 95.181%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.179 Acc 95.281%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.147 Acc 96.024%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.143 Acc 95.923%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.146 Acc 95.829%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.149 Acc 95.763%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.151 Acc 95.688%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.183 Acc 95.110%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.193 Acc 92.188%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.148 Acc 95.784%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.151 Acc 95.713%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.156 Acc 95.616%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.156 Acc 95.622%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.152 Acc 95.665%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.177 Acc 95.429%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.148 Acc 95.728%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.148 Acc 95.704%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.148 Acc 95.718%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.149 Acc 95.642%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 95.336%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.183 Acc 95.297%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.151 Acc 95.846%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.149 Acc 95.678%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.151 Acc 95.660%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.149 Acc 95.706%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.149 Acc 95.702%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.177 Acc 95.568%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.175 Acc 95.542%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.133 Acc 96.047%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.139 Acc 96.043%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.144 Acc 95.878%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.146 Acc 95.819%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.137 Acc 96.875%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.183 Acc 95.367%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.179 Acc 95.367%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.142 Acc 95.958%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.140 Acc 96.016%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.141 Acc 95.959%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.143 Acc 95.904%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.178 Acc 95.490%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.235 Acc 90.625%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.142 Acc 95.722%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.142 Acc 95.829%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.143 Acc 95.824%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.143 Acc 95.848%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.144 Acc 95.812%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.183 Acc 95.135%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.181 Acc 95.118%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.128 Acc 96.481%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.136 Acc 96.102%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.139 Acc 96.013%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.141 Acc 95.965%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.141 Acc 95.944%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.181 Acc 95.204%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.176 Acc 95.297%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.228 Acc 95.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.132 Acc 96.163%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.135 Acc 96.090%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.135 Acc 96.073%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.137 Acc 96.010%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.138 Acc 96.005%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.179 Acc 95.266%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.131 Acc 96.357%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.137 Acc 96.144%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.139 Acc 96.109%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.138 Acc 96.090%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.140 Acc 96.027%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.095 Acc 96.875%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.197 Acc 95.104%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.196 Acc 95.114%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.134 Acc 96.295%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.140 Acc 96.133%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.138 Acc 96.081%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.137 Acc 96.041%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.139 Acc 96.028%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.166 Acc 96.875%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.183 Acc 95.529%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.182 Acc 95.542%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.141 Acc 95.931%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.137 Acc 95.993%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.137 Acc 95.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.135 Acc 96.084%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.137 Acc 96.034%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.187 Acc 95.297%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.185 Acc 95.332%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.978%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.140 Acc 95.931%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.140 Acc 95.941%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.136 Acc 96.103%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.136 Acc 96.064%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.173 Acc 95.599%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.170 Acc 95.678%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.128 Acc 96.318%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.128 Acc 96.331%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.129 Acc 96.273%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.128 Acc 96.326%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.270%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.081 Acc 97.656%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.188 Acc 95.359%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.184 Acc 95.309%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.131 Acc 96.349%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.135 Acc 96.273%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.134 Acc 96.255%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.132 Acc 96.259%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.132 Acc 96.159%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.258%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.183 Acc 95.243%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.124 Acc 96.233%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.128 Acc 96.230%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.131 Acc 96.211%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.132 Acc 96.160%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.133 Acc 96.170%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.100 Acc 96.875%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.181 Acc 95.441%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.162 Acc 95.312%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.121 Acc 96.542%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.126 Acc 96.482%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.128 Acc 96.348%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.127 Acc 96.337%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.129 Acc 96.290%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.186 Acc 95.231%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.123 Acc 96.496%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.122 Acc 96.401%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.122 Acc 96.439%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.125 Acc 96.353%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.126 Acc 96.335%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.194 Acc 95.351%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.191 Acc 95.316%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.218 Acc 95.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.126 Acc 96.465%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.127 Acc 96.315%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.125 Acc 96.269%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.127 Acc 96.229%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.080 Acc 97.656%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.178 Acc 95.545%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.530%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.117 Acc 96.581%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.125 Acc 96.440%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.122 Acc 96.473%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.123 Acc 96.444%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.125 Acc 96.346%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.178 Acc 95.452%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.175 Acc 95.441%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.120 Acc 96.568%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.121 Acc 96.447%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.125 Acc 96.335%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.172 Acc 95.658%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.124 Acc 96.287%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.122 Acc 96.331%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.122 Acc 96.309%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.124 Acc 96.250%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.124 Acc 96.250%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.183 Acc 95.452%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.180 Acc 95.449%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.121 Acc 96.558%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.122 Acc 96.444%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.123 Acc 96.361%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.122 Acc 96.384%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.124 Acc 96.329%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.183 Acc 95.436%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.182 Acc 95.417%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.116 Acc 96.774%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.118 Acc 96.618%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.119 Acc 96.564%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.119 Acc 96.563%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.121 Acc 96.519%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.192 Acc 95.065%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.188 Acc 95.095%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.116 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.112 Acc 96.805%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.545%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.120 Acc 96.519%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.120 Acc 96.522%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.120 Acc 96.533%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.180 Acc 95.599%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.178 Acc 95.534%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.121 Acc 96.432%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.117 Acc 96.558%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.119 Acc 96.505%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.119 Acc 96.529%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.179 Acc 95.382%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.176 Acc 95.414%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.116 Acc 96.457%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.114 Acc 96.599%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.115 Acc 96.561%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.116 Acc 96.548%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.117 Acc 96.527%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.193 Acc 95.135%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.189 Acc 95.208%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.114 Acc 96.720%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.116 Acc 96.580%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.114 Acc 96.680%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.117 Acc 96.616%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.117 Acc 96.610%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.181 Acc 95.490%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.180 Acc 95.495%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.106 Acc 96.867%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.108 Acc 96.774%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.114 Acc 96.573%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.115 Acc 96.562%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.182 Acc 95.506%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.181 Acc 95.557%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.117 Acc 96.448%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.117 Acc 96.484%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.184 Acc 95.661%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.184 Acc 95.616%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.115 Acc 96.674%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.117 Acc 96.665%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.117 Acc 96.587%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.115 Acc 96.616%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.114 Acc 96.646%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.184 Acc 95.521%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.181 Acc 95.487%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.113 Acc 96.751%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.109 Acc 96.778%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.113 Acc 96.696%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.113 Acc 96.697%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.599%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.178 Acc 95.480%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.682%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.113 Acc 96.636%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.188 Acc 95.390%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.186 Acc 95.367%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.108 Acc 96.906%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.112 Acc 96.774%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.110 Acc 96.789%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.111 Acc 96.760%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.092 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.180 Acc 95.480%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.108 Acc 96.739%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.106 Acc 96.735%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.110 Acc 96.668%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.111 Acc 96.661%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.197 Acc 95.297%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.195 Acc 95.297%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.108 Acc 96.867%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.105 Acc 96.836%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.107 Acc 96.823%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.104 Acc 96.873%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.084 Acc 97.656%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.188 Acc 95.467%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.185 Acc 95.464%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.105 Acc 96.727%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.106 Acc 96.766%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.106 Acc 96.780%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.107 Acc 96.786%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.186 Acc 95.158%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.186 Acc 95.165%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.094 Acc 97.231%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.104 Acc 96.888%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.106 Acc 96.832%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.107 Acc 96.810%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.187 Acc 95.405%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.186 Acc 95.402%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.118 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.105 Acc 96.910%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.105 Acc 96.924%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.106 Acc 96.870%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.186 Acc 95.444%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.186 Acc 95.433%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.103 Acc 97.073%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.105 Acc 96.984%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.105 Acc 96.951%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.104 Acc 96.965%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.200 Acc 95.328%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.197 Acc 95.285%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 97.169%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.102 Acc 96.949%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.102 Acc 96.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.104 Acc 96.943%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.105 Acc 96.897%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.195 Acc 95.243%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.194 Acc 95.270%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.102 Acc 96.828%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.101 Acc 96.914%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.103 Acc 96.844%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.103 Acc 96.847%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.201 Acc 95.189%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.199 Acc 95.106%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.097 Acc 97.200%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.102 Acc 96.953%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.101 Acc 97.020%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.101 Acc 97.019%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.101 Acc 96.986%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.103 Acc 97.656%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.188 Acc 95.343%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.188 Acc 95.324%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.099 Acc 96.890%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.103 Acc 96.786%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.100 Acc 96.870%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.101 Acc 96.863%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.102 Acc 96.820%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.183 Acc 95.777%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.183 Acc 95.643%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.093 Acc 97.003%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.100 Acc 96.893%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.101 Acc 96.858%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.189 Acc 95.498%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.189 Acc 95.379%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.096 Acc 96.952%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.097 Acc 96.995%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.100 Acc 97.015%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.102 Acc 96.922%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.102 Acc 96.926%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.197 Acc 95.305%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.194 Acc 95.363%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.098 Acc 97.092%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.099 Acc 97.178%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.100 Acc 97.072%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.099 Acc 97.009%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.100 Acc 96.997%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.199 Acc 95.235%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.201 Acc 95.130%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.056 Acc 96.875%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.099 Acc 97.084%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.101 Acc 96.933%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.099 Acc 97.007%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.098 Acc 97.060%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.097 Acc 97.098%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.198 Acc 95.367%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.195 Acc 95.239%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.089 Acc 97.239%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.094 Acc 97.093%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.096 Acc 97.007%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.096 Acc 97.056%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.098 Acc 97.018%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.189 Acc 95.452%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.186 Acc 95.542%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.092 Acc 97.037%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.094 Acc 97.116%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.097 Acc 97.076%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.189 Acc 95.577%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.224 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.091 Acc 97.300%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.094 Acc 97.139%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.096 Acc 97.077%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.097 Acc 97.037%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.099 Acc 97.009%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.198 Acc 95.351%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.195 Acc 95.375%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.088 Acc 97.393%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.090 Acc 97.306%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.090 Acc 97.308%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.092 Acc 97.255%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.094 Acc 97.182%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.200 Acc 95.421%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.198 Acc 95.351%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.153 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.087 Acc 97.339%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.095 Acc 97.159%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.095 Acc 97.088%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.094 Acc 97.154%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.094 Acc 97.153%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.192 Acc 95.320%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.090 Acc 97.370%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.091 Acc 97.314%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.092 Acc 97.207%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.096 Acc 97.095%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.095 Acc 97.131%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.134 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.206 Acc 95.266%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.204 Acc 95.176%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.077 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.085 Acc 97.378%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.085 Acc 97.326%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.093 Acc 97.176%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.092 Acc 97.142%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.199 Acc 95.065%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.195 Acc 95.083%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.093 Acc 97.208%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.093 Acc 97.236%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.092 Acc 97.239%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.092 Acc 97.209%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.151 Acc 97.656%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.205 Acc 95.467%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.202 Acc 95.390%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.279 Acc 93.750%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.090 Acc 97.146%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.089 Acc 97.236%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.090 Acc 97.282%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.091 Acc 97.232%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.194 Acc 95.289%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.190 Acc 95.425%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.085 Acc 97.432%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.087 Acc 97.225%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.090 Acc 97.224%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.091 Acc 97.170%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.118 Acc 97.656%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.199 Acc 95.251%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.196 Acc 95.289%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.092 Acc 97.269%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.092 Acc 97.318%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.091 Acc 97.264%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.092 Acc 97.169%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.092 Acc 97.163%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.199 Acc 95.382%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.198 Acc 95.316%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.088 Acc 97.208%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.086 Acc 97.334%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.089 Acc 97.244%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.088 Acc 97.259%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.090 Acc 97.274%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.194 Acc 95.459%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.191 Acc 95.480%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.092 Acc 97.200%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.091 Acc 97.198%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.090 Acc 97.238%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.091 Acc 97.204%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.090 Acc 97.204%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.166 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.207 Acc 95.119%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.204 Acc 95.141%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.081 Acc 97.525%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.084 Acc 97.380%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.086 Acc 97.368%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.087 Acc 97.352%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.093 Acc 97.656%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.196 Acc 95.459%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.193 Acc 95.503%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.079 Acc 97.594%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.086 Acc 97.384%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.087 Acc 97.368%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.086 Acc 97.389%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.088 Acc 97.346%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.198 Acc 95.057%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.195 Acc 95.103%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.085 Acc 97.347%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.084 Acc 97.291%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.084 Acc 97.363%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.085 Acc 97.346%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.087 Acc 97.310%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.205 Acc 95.111%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.205 Acc 95.021%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.084 Acc 97.362%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.085 Acc 97.373%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.084 Acc 97.386%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.085 Acc 97.276%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.085 Acc 97.241%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.197 Acc 95.289%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.198 Acc 95.266%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.079 Acc 97.532%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.082 Acc 97.474%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.083 Acc 97.423%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.085 Acc 97.387%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.087 Acc 97.277%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.206 Acc 95.073%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.202 Acc 95.126%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.082 Acc 97.493%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.084 Acc 97.428%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.084 Acc 97.458%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.084 Acc 97.464%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.204 Acc 95.274%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.203 Acc 95.246%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.080 Acc 97.440%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.082 Acc 97.477%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.084 Acc 97.451%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.083 Acc 97.475%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.084 Acc 97.376%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.203 Acc 95.158%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.198 Acc 95.250%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.083 Acc 97.339%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.084 Acc 97.357%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.083 Acc 97.412%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.084 Acc 97.385%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.085 Acc 97.337%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.200 Acc 95.119%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.198 Acc 95.208%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.194 Acc 94.531%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.086 Acc 97.330%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.084 Acc 97.358%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.084 Acc 97.378%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.083 Acc 97.396%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.200 Acc 95.320%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.197 Acc 95.344%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.081 Acc 97.556%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.077 Acc 97.567%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.080 Acc 97.488%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.079 Acc 97.491%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.082 Acc 97.386%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.201 Acc 95.196%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.202 Acc 95.118%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.083 Acc 97.471%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.084 Acc 97.431%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.084 Acc 97.425%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.085 Acc 97.385%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.084 Acc 97.418%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.195 Acc 95.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.196 Acc 95.592%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.084 Acc 97.331%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.081 Acc 97.410%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.081 Acc 97.413%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.083 Acc 97.386%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.208 Acc 95.398%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.205 Acc 95.355%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.152 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.073 Acc 97.811%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.074 Acc 97.695%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.079 Acc 97.571%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.081 Acc 97.533%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.209 Acc 95.328%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.206 Acc 95.305%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.072 Acc 97.765%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.076 Acc 97.676%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.076 Acc 97.659%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.079 Acc 97.582%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.080 Acc 97.522%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.200 Acc 95.289%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.197 Acc 95.398%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.067 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.076 Acc 97.579%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.076 Acc 97.560%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.078 Acc 97.456%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.080 Acc 97.419%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.205 Acc 95.196%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.202 Acc 95.270%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.075 Acc 97.579%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.081 Acc 97.467%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.080 Acc 97.510%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.081 Acc 97.507%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.219 Acc 95.065%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.213 Acc 95.165%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.070 Acc 97.749%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.075 Acc 97.660%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.074 Acc 97.646%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.075 Acc 97.615%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.077 Acc 97.589%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.197 Acc 95.382%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.196 Acc 95.371%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.074 Acc 97.734%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.071 Acc 97.746%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.073 Acc 97.633%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.076 Acc 97.569%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.077 Acc 97.556%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.202 Acc 95.467%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.200 Acc 95.433%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.114 Acc 94.531%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.077 Acc 97.532%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.077 Acc 97.439%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.075 Acc 97.508%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.076 Acc 97.491%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.076 Acc 97.494%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.208 Acc 95.065%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.201 Acc 95.165%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.071 Acc 97.826%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.072 Acc 97.761%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.074 Acc 97.674%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.076 Acc 97.597%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.212 Acc 95.490%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.212 Acc 95.476%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.133 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.073 Acc 97.649%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.076 Acc 97.652%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.075 Acc 97.680%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.075 Acc 97.639%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.076 Acc 97.585%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.197 Acc 95.359%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.193 Acc 95.476%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.070 Acc 97.649%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.071 Acc 97.660%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.072 Acc 97.700%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.074 Acc 97.662%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.214 Acc 95.196%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.211 Acc 95.235%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.079 Acc 97.455%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.075 Acc 97.629%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.078 Acc 97.537%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.078 Acc 97.516%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.090 Acc 97.656%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.213 Acc 95.150%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.208 Acc 95.297%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.067 Acc 97.912%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.071 Acc 97.788%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.072 Acc 97.713%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.072 Acc 97.715%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.074 Acc 97.670%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.208 Acc 95.483%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.205 Acc 95.449%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.070 Acc 97.811%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.074 Acc 97.695%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.073 Acc 97.700%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.074 Acc 97.659%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.208 Acc 95.235%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.203 Acc 95.309%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.070 Acc 97.788%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.073 Acc 97.761%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.073 Acc 97.706%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.073 Acc 97.682%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.073 Acc 97.680%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.151 Acc 96.875%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.212 Acc 95.266%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.209 Acc 95.266%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.070 Acc 97.659%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.072 Acc 97.629%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.072 Acc 97.613%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.208 Acc 95.374%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.074 Acc 97.633%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.072 Acc 97.641%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.070 Acc 97.698%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.071 Acc 97.709%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.208 Acc 95.336%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.205 Acc 95.336%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.070 Acc 97.769%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.071 Acc 97.716%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.209 Acc 95.328%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.067 Acc 97.851%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.069 Acc 97.752%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.071 Acc 97.709%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.207 Acc 95.235%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.202 Acc 95.281%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.104 Acc 94.531%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.067 Acc 97.772%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.071 Acc 97.628%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.072 Acc 97.645%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.216 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.212 Acc 95.270%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.069 Acc 97.857%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.070 Acc 97.718%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.069 Acc 97.711%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.072 Acc 97.681%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.176 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.215 Acc 95.204%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.212 Acc 95.200%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.068 Acc 97.826%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.069 Acc 97.800%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.070 Acc 97.755%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.070 Acc 97.728%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.070 Acc 97.733%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.212 Acc 95.227%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.207 Acc 95.266%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.069 Acc 97.695%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.066 Acc 97.816%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.066 Acc 97.866%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.069 Acc 97.751%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.200 Acc 95.258%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.198 Acc 95.351%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.065 Acc 97.858%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.069 Acc 97.796%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.069 Acc 97.789%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.070 Acc 97.770%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.213 Acc 95.235%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.210 Acc 95.145%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.070 Acc 97.772%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.067 Acc 97.831%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.068 Acc 97.861%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.069 Acc 97.798%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.069 Acc 97.795%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.214 Acc 95.173%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.211 Acc 95.211%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.068 Acc 97.796%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.070 Acc 97.693%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.070 Acc 97.730%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.210 Acc 95.367%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.210 Acc 95.355%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.066 Acc 97.887%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.066 Acc 97.859%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.068 Acc 97.817%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.221 Acc 94.848%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.219 Acc 94.935%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.044 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.061 Acc 98.089%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.067 Acc 97.901%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.066 Acc 97.916%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.066 Acc 97.880%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.066 Acc 97.843%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.223 Acc 94.910%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.219 Acc 95.091%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.062 Acc 98.028%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.062 Acc 97.944%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.064 Acc 97.915%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.066 Acc 97.832%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.151 Acc 96.875%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.042%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.211 Acc 95.204%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.068 Acc 97.802%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.068 Acc 97.803%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.225 Acc 95.196%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.218 Acc 95.246%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.063 Acc 97.901%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.065 Acc 97.817%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.066 Acc 97.810%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.066 Acc 97.829%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.210 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.224 Acc 95.104%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.222 Acc 95.130%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.068 Acc 97.803%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.064 Acc 97.944%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.065 Acc 97.859%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.067 Acc 97.836%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.229 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.227 Acc 95.011%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.222 Acc 95.079%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.057 Acc 98.089%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.063 Acc 97.991%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.063 Acc 97.955%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.064 Acc 97.917%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.066 Acc 97.823%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.233 Acc 94.740%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.230 Acc 94.819%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.064 Acc 98.066%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.065 Acc 97.956%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.064 Acc 97.986%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.065 Acc 97.915%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.067 Acc 97.831%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.219 Acc 95.390%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.216 Acc 95.394%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.062 Acc 97.847%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.065 Acc 97.737%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.065 Acc 97.779%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.065 Acc 97.798%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.216 Acc 95.289%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.213 Acc 95.402%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.063 Acc 97.893%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.064 Acc 97.906%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.064 Acc 97.906%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.224 Acc 94.980%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.221 Acc 95.068%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.065 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.056 Acc 98.229%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.059 Acc 98.084%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.062 Acc 97.981%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.062 Acc 97.954%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.062 Acc 97.931%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.215 Acc 95.274%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.215 Acc 95.270%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.067 Acc 97.757%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.065 Acc 97.778%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.064 Acc 97.830%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.064 Acc 97.854%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.220 Acc 95.065%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.216 Acc 95.180%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.054 Acc 98.167%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.054 Acc 98.193%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.058 Acc 98.066%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.059 Acc 98.048%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.060 Acc 98.013%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.216 Acc 95.150%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.210 Acc 95.394%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.063 Acc 97.803%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.065 Acc 97.835%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.065 Acc 97.856%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.064 Acc 97.871%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.065 Acc 97.828%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.223 Acc 94.964%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.222 Acc 95.072%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.057 Acc 98.028%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.059 Acc 97.936%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.062 Acc 97.905%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.061 Acc 97.933%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.062 Acc 97.912%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.226 Acc 95.011%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.220 Acc 95.040%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.063 Acc 97.888%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.061 Acc 97.998%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.061 Acc 98.014%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.062 Acc 97.938%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.230 Acc 95.328%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.226 Acc 95.340%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.068 Acc 99.219%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.054 Acc 98.244%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.058 Acc 98.084%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.060 Acc 98.056%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.061 Acc 98.048%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.060 Acc 98.029%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.209 Acc 95.374%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.472%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.059 Acc 98.035%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.058 Acc 98.045%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.059 Acc 98.020%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.059 Acc 98.023%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.061 Acc 97.988%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.189 Acc 91.406%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.232 Acc 94.941%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.229 Acc 95.075%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.065 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.058 Acc 98.113%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.061 Acc 97.987%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.062 Acc 97.908%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.062 Acc 97.939%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.063 Acc 97.935%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.227 Acc 95.243%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.226 Acc 95.188%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.059 Acc 98.159%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.059 Acc 98.150%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.060 Acc 98.074%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.061 Acc 98.024%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.062 Acc 98.001%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.211 Acc 95.312%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.216 Acc 95.305%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.212 Acc 95.367%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.052 Acc 98.205%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.053 Acc 98.216%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.055 Acc 98.108%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.057 Acc 98.099%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.058 Acc 98.079%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.229 Acc 95.336%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.224 Acc 95.460%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.059 Acc 98.012%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.058 Acc 97.998%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.059 Acc 97.955%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.060 Acc 97.950%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.060 Acc 97.967%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.229 Acc 95.080%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.228 Acc 95.079%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.055 Acc 98.082%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.057 Acc 98.014%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.060 Acc 97.973%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.060 Acc 97.982%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.059 Acc 97.992%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.220 Acc 95.452%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.220 Acc 95.375%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.055 Acc 98.236%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.056 Acc 98.212%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.058 Acc 98.136%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.061 Acc 98.015%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.061 Acc 97.988%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.221 Acc 95.367%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.219 Acc 95.340%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.056 Acc 98.120%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.058 Acc 98.099%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.058 Acc 98.131%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.059 Acc 98.054%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.060 Acc 98.034%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.223 Acc 95.405%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.222 Acc 95.281%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.054 Acc 98.154%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.056 Acc 98.092%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.058 Acc 98.046%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.058 Acc 98.034%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.215 Acc 95.475%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.217 Acc 95.487%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.051 Acc 98.376%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.054 Acc 98.193%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.056 Acc 98.108%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.056 Acc 98.122%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.058 Acc 98.066%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.097 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.220 Acc 95.266%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.216 Acc 95.336%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.054 Acc 98.208%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.057 Acc 98.087%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.057 Acc 98.102%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.057 Acc 98.108%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.234 Acc 95.080%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.232 Acc 95.002%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.052 Acc 98.267%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.055 Acc 98.216%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.056 Acc 98.136%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.058 Acc 98.079%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.059 Acc 98.029%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.150 Acc 96.875%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.227 Acc 95.336%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.219 Acc 95.340%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.054 Acc 98.144%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.057 Acc 98.084%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.056 Acc 98.095%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.056 Acc 98.114%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.057 Acc 98.088%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.230 Acc 95.034%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.227 Acc 94.932%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.060 Acc 98.058%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.057 Acc 98.181%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.059 Acc 98.085%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.059 Acc 98.051%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.231 Acc 95.227%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.228 Acc 95.250%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.050 Acc 98.345%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.053 Acc 98.220%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.055 Acc 98.147%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.058 Acc 98.084%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.231 Acc 95.189%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.227 Acc 95.266%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.055 Acc 98.291%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.059 Acc 98.177%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.058 Acc 98.123%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.057 Acc 98.137%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.056 Acc 98.124%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.230 Acc 95.282%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.225 Acc 95.320%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.053 Acc 98.260%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.056 Acc 98.115%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.056 Acc 98.064%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.057 Acc 98.069%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.059 Acc 98.041%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.238 Acc 94.988%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.234 Acc 95.064%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.054 Acc 98.105%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [200/573] Loss: 0.053 Acc 98.165%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.053 Acc 98.186%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.055 Acc 98.126%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.222 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.220 Acc 95.297%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.057 Acc 98.035%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.057 Acc 98.123%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.055 Acc 98.181%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.055 Acc 98.192%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.055 Acc 98.172%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.251 Acc 95.065%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.249 Acc 95.103%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.049 Acc 98.395%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.051 Acc 98.334%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.050 Acc 98.323%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.052 Acc 98.239%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.227 Acc 95.212%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.223 Acc 95.180%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.056 Acc 96.875%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.052 Acc 98.244%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.054 Acc 98.231%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.054 Acc 98.196%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.236 Acc 95.266%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.233 Acc 95.332%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.054 Acc 98.260%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.055 Acc 98.185%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.054 Acc 98.178%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.054 Acc 98.161%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.054 Acc 98.154%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.145 Acc 97.656%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.231 Acc 95.135%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.227 Acc 95.184%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.050 Acc 98.336%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.051 Acc 98.297%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.052 Acc 98.216%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.232 Acc 95.274%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.229 Acc 95.305%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.059 Acc 96.875%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.056 Acc 98.082%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.055 Acc 98.134%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.055 Acc 98.113%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.055 Acc 98.079%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.055 Acc 98.060%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.219 Acc 95.475%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.216 Acc 95.437%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.053 Acc 98.198%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.054 Acc 98.196%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.053 Acc 98.207%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.238 Acc 95.204%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.236 Acc 95.192%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.096 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.052 Acc 98.244%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.056 Acc 98.100%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.055 Acc 98.132%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.054 Acc 98.172%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.242 Acc 94.964%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.237 Acc 95.072%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.045 Acc 98.608%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.050 Acc 98.418%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.048 Acc 98.440%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.048 Acc 98.418%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.050 Acc 98.364%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.226 Acc 95.305%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.226 Acc 95.200%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.051 Acc 98.453%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.050 Acc 98.395%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.051 Acc 98.328%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.052 Acc 98.293%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.053 Acc 98.238%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.242 Acc 95.220%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.241 Acc 95.223%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.059 Acc 97.989%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.054 Acc 98.146%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.050 Acc 98.274%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.053 Acc 98.207%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.231 Acc 95.166%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.227 Acc 95.141%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.051 Acc 98.267%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.052 Acc 98.278%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.053 Acc 98.212%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.053 Acc 98.225%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.053 Acc 98.247%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.169 Acc 97.656%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.233 Acc 95.537%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.231 Acc 95.484%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.051 Acc 98.267%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.052 Acc 98.329%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.051 Acc 98.323%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.053 Acc 98.249%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.054 Acc 98.224%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.233 Acc 95.204%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.228 Acc 95.293%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.047 Acc 98.453%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.048 Acc 98.461%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.049 Acc 98.419%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.050 Acc 98.356%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.051 Acc 98.299%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.242 Acc 95.251%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.237 Acc 95.274%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.049 Acc 98.321%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.049 Acc 98.309%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [300/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.051 Acc 98.245%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.052 Acc 98.225%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.229 Acc 95.096%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.225 Acc 95.153%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.051 Acc 98.229%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.051 Acc 98.208%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.049 Acc 98.287%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.050 Acc 98.262%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.051 Acc 98.263%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.109 Acc 97.656%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.241 Acc 94.926%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.237 Acc 95.079%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.050 Acc 98.283%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.048 Acc 98.386%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.049 Acc 98.340%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.050 Acc 98.311%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.236 Acc 95.158%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.232 Acc 95.141%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.041 Acc 98.592%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.048 Acc 98.348%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.050 Acc 98.284%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.050 Acc 98.274%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.051 Acc 98.249%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.244 Acc 94.957%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.240 Acc 94.955%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc176bbbc354a0d94deb269ca94e442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.306 Acc 10.938%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.264 Acc 17.628%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.249 Acc 18.412%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.724%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.212 Acc 20.011%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.165 Acc 22.062%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.777 Acc 39.844%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.796 Acc 38.289%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.798 Acc 38.130%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.881 Acc 28.906%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.831 Acc 37.554%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.780 Acc 39.521%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.719 Acc 41.998%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.659 Acc 44.377%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.597 Acc 46.613%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.011 Acc 66.406%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.105 Acc 64.349%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.106 Acc 64.183%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.196 Acc 58.594%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.183 Acc 61.750%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.140 Acc 63.083%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.091 Acc 64.779%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.058 Acc 65.835%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.027 Acc 66.918%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.701 Acc 73.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.715 Acc 77.769%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.713 Acc 77.694%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.787 Acc 78.125%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.798 Acc 74.667%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.782 Acc 75.078%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.765 Acc 75.571%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.748 Acc 76.066%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.735 Acc 76.509%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.574 Acc 80.469%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.555 Acc 82.882%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.550 Acc 82.995%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.838 Acc 76.562%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.627 Acc 80.252%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.618 Acc 80.527%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.611 Acc 80.855%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.598 Acc 81.223%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.588 Acc 81.563%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.474 Acc 84.375%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.463 Acc 86.200%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.455 Acc 86.373%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.589 Acc 83.594%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.536 Acc 83.192%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.524 Acc 83.497%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.517 Acc 83.726%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.510 Acc 84.034%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.504 Acc 84.199%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.511 Acc 85.156%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.420 Acc 87.129%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.415 Acc 87.348%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.532 Acc 86.719%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.467 Acc 85.419%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.460 Acc 85.627%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.457 Acc 85.766%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.453 Acc 85.920%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.445 Acc 86.075%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.394 Acc 86.719%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.376 Acc 88.916%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.372 Acc 89.024%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.375 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.412 Acc 87.392%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.412 Acc 87.290%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.410 Acc 87.383%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.412 Acc 87.278%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.406 Acc 87.436%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.329 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.345 Acc 89.952%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.339 Acc 90.081%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.423 Acc 88.281%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.385 Acc 88.080%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.380 Acc 88.293%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.377 Acc 88.349%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.375 Acc 88.525%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.375 Acc 88.531%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.317 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.326 Acc 90.486%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.320 Acc 90.637%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.288 Acc 90.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.353 Acc 89.109%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.346 Acc 89.323%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.349 Acc 89.281%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.352 Acc 89.158%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.351 Acc 89.234%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.302 Acc 90.625%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.300 Acc 91.259%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.297 Acc 91.309%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.255 Acc 91.406%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.333 Acc 89.913%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.334 Acc 89.844%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.333 Acc 89.818%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.332 Acc 89.861%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.330 Acc 89.954%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.279 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.295 Acc 91.476%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.289 Acc 91.690%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.243 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.301 Acc 90.571%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.310 Acc 90.411%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.310 Acc 90.358%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.311 Acc 90.374%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.311 Acc 90.435%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.296 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.283 Acc 91.808%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.277 Acc 92.005%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.350 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.302 Acc 90.888%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.299 Acc 90.905%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.301 Acc 90.864%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.303 Acc 90.859%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.300 Acc 90.954%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.264 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.261 Acc 92.597%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.256 Acc 92.739%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.269 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.275 Acc 91.731%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.278 Acc 91.519%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.278 Acc 91.570%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.282 Acc 91.459%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.283 Acc 91.486%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.264 Acc 92.621%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.260 Acc 92.650%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.319 Acc 89.062%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.279 Acc 91.847%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.276 Acc 91.554%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.274 Acc 91.702%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.274 Acc 91.741%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.276 Acc 91.727%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.249 Acc 93.139%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.244 Acc 93.214%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.153 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.266 Acc 92.319%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.262 Acc 92.289%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.267 Acc 92.138%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.268 Acc 92.069%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.266 Acc 92.064%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.246 Acc 93.178%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.242 Acc 93.218%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.301 Acc 91.406%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.251 Acc 92.512%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.255 Acc 92.238%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.258 Acc 92.286%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.260 Acc 92.258%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.238 Acc 93.394%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.235 Acc 93.466%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.272 Acc 92.969%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.251 Acc 92.644%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.255 Acc 92.600%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.256 Acc 92.579%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.254 Acc 92.638%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.253 Acc 92.574%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.238 Acc 93.417%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.234 Acc 93.575%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.301 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.253 Acc 92.884%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.248 Acc 92.860%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.247 Acc 92.784%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.247 Acc 92.758%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.246 Acc 92.774%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.225 Acc 93.688%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.221 Acc 93.816%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.247 Acc 92.814%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.241 Acc 92.883%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.239 Acc 92.862%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.239 Acc 92.936%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.238 Acc 92.942%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.225 Acc 93.874%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.221 Acc 93.851%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.189 Acc 95.312%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.227 Acc 93.247%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.227 Acc 93.210%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.227 Acc 93.176%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.229 Acc 93.243%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.232 Acc 93.182%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.216 Acc 93.735%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.212 Acc 93.937%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.166 Acc 92.969%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.234 Acc 93.193%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.222 Acc 93.490%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.224 Acc 93.480%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.227 Acc 93.339%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.229 Acc 93.310%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.216 Acc 93.920%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.212 Acc 94.127%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.189 Acc 93.750%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.221 Acc 93.619%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.219 Acc 93.676%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.221 Acc 93.555%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.223 Acc 93.514%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.223 Acc 93.496%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.214 Acc 94.036%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.209 Acc 94.115%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.193 Acc 93.750%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.221 Acc 93.626%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.219 Acc 93.696%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.218 Acc 93.631%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.220 Acc 93.608%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.220 Acc 93.605%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.209 Acc 94.338%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.206 Acc 94.286%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.201 Acc 93.874%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.217 Acc 93.618%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.216 Acc 93.639%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.216 Acc 93.669%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.214 Acc 93.874%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.212 Acc 94.045%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.228 Acc 92.188%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.218 Acc 93.773%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.213 Acc 93.828%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.213 Acc 93.817%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.212 Acc 93.805%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.212 Acc 93.766%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.213 Acc 94.067%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.208 Acc 94.228%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.207 Acc 92.188%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.206 Acc 94.237%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.205 Acc 94.115%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.205 Acc 94.116%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.204 Acc 94.144%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.208 Acc 94.018%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.202 Acc 94.570%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.200 Acc 94.609%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.272 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.198 Acc 94.400%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.201 Acc 94.220%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.204 Acc 94.147%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.202 Acc 94.167%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.204 Acc 94.026%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.203 Acc 94.291%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.201 Acc 94.465%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.198 Acc 94.090%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.197 Acc 94.286%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.200 Acc 94.212%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.199 Acc 94.221%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.202 Acc 94.196%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.196 Acc 94.585%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.193 Acc 94.753%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.192 Acc 94.361%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.194 Acc 94.251%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.198 Acc 94.189%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.197 Acc 94.288%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.196 Acc 94.257%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.205 Acc 94.315%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.204 Acc 94.395%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.253 Acc 91.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.195 Acc 94.098%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.189 Acc 94.271%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.189 Acc 94.321%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.191 Acc 94.368%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.193 Acc 94.353%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.200 Acc 94.554%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.196 Acc 94.628%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.184 Acc 92.188%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.169 Acc 95.019%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.838%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.182 Acc 94.674%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.188 Acc 94.523%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.189 Acc 94.484%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.194 Acc 94.794%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.190 Acc 94.959%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.196 Acc 94.268%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.191 Acc 94.566%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.184 Acc 94.638%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.184 Acc 94.652%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.188 Acc 94.586%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.194 Acc 94.709%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.192 Acc 94.780%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.180 Acc 95.312%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.182 Acc 94.802%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.188 Acc 94.652%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.187 Acc 94.695%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.188 Acc 94.646%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.187 Acc 94.636%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.195 Acc 94.748%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.192 Acc 94.788%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.179 Acc 94.926%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.185 Acc 94.722%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.825%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.184 Acc 94.769%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.184 Acc 94.754%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.197 Acc 94.709%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.196 Acc 94.776%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.173 Acc 95.073%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.179 Acc 94.788%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.182 Acc 94.747%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.180 Acc 94.783%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.181 Acc 94.753%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.187 Acc 94.841%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.185 Acc 94.939%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.168 Acc 95.184%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.174 Acc 94.985%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.178 Acc 94.882%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.193 Acc 94.748%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.191 Acc 94.885%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.166 Acc 95.080%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.174 Acc 94.932%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.179 Acc 94.866%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.177 Acc 94.862%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.176 Acc 94.856%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.194 Acc 94.841%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.193 Acc 94.811%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.170 Acc 95.251%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.173 Acc 95.165%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.172 Acc 95.123%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.171 Acc 95.124%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.174 Acc 95.071%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.189 Acc 94.964%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.189 Acc 94.955%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.162 Acc 95.189%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.165 Acc 95.211%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.102%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.171 Acc 95.044%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.170 Acc 95.075%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.193 Acc 94.740%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.192 Acc 94.807%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.203 Acc 91.406%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.173 Acc 95.189%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.171 Acc 95.126%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.167 Acc 95.258%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.219%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.166 Acc 95.253%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.161 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.193 Acc 94.694%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.192 Acc 94.745%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 92.188%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.162 Acc 95.258%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.164 Acc 95.223%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.168 Acc 95.089%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.166 Acc 95.137%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.168 Acc 95.086%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.186 Acc 94.926%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.185 Acc 95.052%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.162 Acc 95.282%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.166 Acc 95.200%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.166 Acc 95.211%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.165 Acc 95.237%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.180 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.188 Acc 94.918%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.190 Acc 94.920%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.163 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.161 Acc 95.417%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.163 Acc 95.349%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.164 Acc 95.346%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.162 Acc 95.350%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.192 Acc 94.663%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.191 Acc 94.788%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.161 Acc 95.441%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.161 Acc 95.450%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.161 Acc 95.406%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.160 Acc 95.395%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.188 Acc 94.841%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.187 Acc 94.877%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.151 Acc 95.753%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.155 Acc 95.569%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.157 Acc 95.536%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.159 Acc 95.507%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.159 Acc 95.443%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.187 Acc 94.794%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.182 Acc 95.005%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.157 Acc 95.498%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.156 Acc 95.511%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.162 Acc 95.372%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.162 Acc 95.353%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.158 Acc 95.411%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.192 Acc 94.879%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.192 Acc 94.904%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.154 Acc 95.653%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.156 Acc 95.472%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.388%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.155 Acc 95.500%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.154 Acc 95.514%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.193 Acc 94.632%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.191 Acc 94.761%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.149 Acc 95.606%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.149 Acc 95.635%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.150 Acc 95.642%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.152 Acc 95.591%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.153 Acc 95.565%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.188 Acc 94.872%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.186 Acc 95.017%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.149 Acc 95.900%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.149 Acc 95.833%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.151 Acc 95.749%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.153 Acc 95.687%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.154 Acc 95.690%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.183 Acc 95.189%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.182 Acc 95.235%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.138 Acc 95.815%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.147 Acc 95.627%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.150 Acc 95.582%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.150 Acc 95.589%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.152 Acc 95.581%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.190 Acc 94.833%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.189 Acc 94.928%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.277 Acc 95.312%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.141 Acc 95.838%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.143 Acc 95.759%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.145 Acc 95.741%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.148 Acc 95.689%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.149 Acc 95.663%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.157 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 94.825%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 94.998%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.241 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.146 Acc 95.885%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.142 Acc 95.899%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.145 Acc 95.829%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.146 Acc 95.819%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.148 Acc 95.802%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.195 Acc 94.833%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.194 Acc 94.998%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.140 Acc 95.969%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.143 Acc 95.930%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.144 Acc 95.881%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.145 Acc 95.852%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.188 Acc 94.787%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.025%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.142 Acc 96.071%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.144 Acc 95.919%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.145 Acc 95.839%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.145 Acc 95.825%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.145 Acc 95.850%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.180 Acc 95.251%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.355%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.136 Acc 95.808%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.145 Acc 95.713%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.144 Acc 95.808%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.142 Acc 95.879%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.144 Acc 95.832%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.187 Acc 94.988%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.184 Acc 95.184%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.307 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.135 Acc 95.908%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.140 Acc 95.861%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.139 Acc 95.917%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.141 Acc 95.946%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.140 Acc 95.938%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.190 Acc 94.787%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.189 Acc 94.893%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.138 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.136 Acc 95.970%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.134 Acc 96.067%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.134 Acc 96.081%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.136 Acc 96.068%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.138 Acc 96.014%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.189 Acc 95.096%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.188 Acc 95.141%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.130 Acc 97.656%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.129 Acc 96.318%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.132 Acc 96.296%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.135 Acc 96.226%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.136 Acc 96.119%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.137 Acc 96.105%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.192 Acc 95.173%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.189 Acc 95.293%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.291 Acc 92.188%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.126 Acc 96.372%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.131 Acc 96.210%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.132 Acc 96.151%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.134 Acc 96.111%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.136 Acc 96.069%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.190 Acc 94.941%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.189 Acc 94.998%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.136 Acc 96.187%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.128 Acc 96.280%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.132 Acc 96.138%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.135 Acc 96.043%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.136 Acc 96.022%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.191 Acc 95.080%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.190 Acc 95.157%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.133 Acc 95.978%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.132 Acc 96.057%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.134 Acc 96.045%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.135 Acc 96.011%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.199 Acc 94.941%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.198 Acc 95.017%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.156 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.128 Acc 96.388%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.135 Acc 96.222%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.131 Acc 96.255%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.132 Acc 96.154%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.164%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.193 Acc 94.802%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.192 Acc 94.947%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.134 Acc 96.040%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.129 Acc 96.200%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.133 Acc 96.139%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.132 Acc 96.190%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.196 Acc 94.756%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.194 Acc 94.850%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.132 Acc 95.947%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.128 Acc 96.152%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.129 Acc 96.177%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.129 Acc 96.187%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.127 Acc 96.231%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.180 Acc 95.250%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.115 Acc 96.682%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.119 Acc 96.510%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.126 Acc 96.317%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.127 Acc 96.259%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.311%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.188 Acc 95.158%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.188 Acc 95.231%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.123 Acc 96.620%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.127 Acc 96.416%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.125 Acc 96.426%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.127 Acc 96.368%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.127 Acc 96.339%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.192 Acc 94.972%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.190 Acc 95.091%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.123 Acc 96.498%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.123 Acc 96.444%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.126 Acc 96.326%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.218 Acc 92.188%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.186 Acc 95.165%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.114 Acc 96.535%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.116 Acc 96.482%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.118 Acc 96.468%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.120 Acc 96.415%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.121 Acc 96.427%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.183 Acc 95.251%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.181 Acc 95.332%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.111 Acc 96.883%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.117 Acc 96.653%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.118 Acc 96.571%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.118 Acc 96.563%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.121 Acc 96.509%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.190 Acc 95.065%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.190 Acc 95.048%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.122 Acc 96.496%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.117 Acc 96.583%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.117 Acc 96.597%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.119 Acc 96.489%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.120 Acc 96.438%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.190 Acc 92.188%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.189 Acc 95.227%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.189 Acc 95.239%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.113 Acc 96.767%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.110 Acc 96.762%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.113 Acc 96.641%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.117 Acc 96.487%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.118 Acc 96.445%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.196 Acc 94.903%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.195 Acc 94.866%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.111 Acc 96.689%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.114 Acc 96.720%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.116 Acc 96.623%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.117 Acc 96.507%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.119 Acc 96.468%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.191 Acc 94.895%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.189 Acc 95.060%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.117 Acc 96.442%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.498%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.116 Acc 96.558%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.117 Acc 96.555%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.119 Acc 96.515%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.203 Acc 94.562%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.201 Acc 94.586%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.651%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.112 Acc 96.688%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.116 Acc 96.587%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.115 Acc 96.631%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.116 Acc 96.587%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.194 Acc 95.042%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.193 Acc 95.130%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.119 Acc 96.426%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.118 Acc 96.494%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.117 Acc 96.545%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.118 Acc 96.491%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.116 Acc 96.523%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.191 Acc 95.034%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.188 Acc 95.270%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.130 Acc 94.531%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.115 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.114 Acc 96.595%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.111 Acc 96.644%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.112 Acc 96.596%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.114 Acc 96.579%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.196 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.190 Acc 95.134%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.100 Acc 97.223%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.108 Acc 96.937%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.112 Acc 96.745%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.112 Acc 96.725%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.111 Acc 96.705%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.191 Acc 94.833%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 94.974%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.108 Acc 96.767%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.113 Acc 96.720%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.110 Acc 96.784%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.111 Acc 96.746%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.114 Acc 96.622%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.202 Acc 94.872%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.198 Acc 94.986%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.101 Acc 96.890%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.107 Acc 96.778%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.110 Acc 96.740%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.112 Acc 96.683%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.202 Acc 94.748%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.203 Acc 94.823%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.097 Acc 97.030%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.108 Acc 96.739%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.111 Acc 96.626%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.111 Acc 96.631%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.112 Acc 96.643%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.206 Acc 94.508%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.203 Acc 94.745%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.100 Acc 96.960%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.104 Acc 96.922%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.106 Acc 96.832%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.108 Acc 96.819%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.200 Acc 94.833%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.198 Acc 94.959%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.097 Acc 96.906%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.106 Acc 96.731%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.109 Acc 96.623%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.108 Acc 96.674%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.108 Acc 96.680%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.206 Acc 95.011%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.204 Acc 95.040%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.118 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.103 Acc 96.945%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.107 Acc 96.805%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.106 Acc 96.823%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.105 Acc 96.838%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.204 Acc 94.841%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.203 Acc 94.877%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.275 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.099 Acc 96.929%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.103 Acc 96.918%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.104 Acc 96.901%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.105 Acc 96.850%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.106 Acc 96.805%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.202 Acc 94.802%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.200 Acc 94.873%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.105 Acc 96.945%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.105 Acc 96.848%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.104 Acc 96.772%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.104 Acc 96.774%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.203 Acc 94.856%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.201 Acc 94.928%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.103 Acc 96.829%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.105 Acc 96.863%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.104 Acc 96.871%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.105 Acc 96.864%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.280 Acc 90.625%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.211 Acc 94.609%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.209 Acc 94.784%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.094 Acc 97.076%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.099 Acc 97.000%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.101 Acc 96.974%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.102 Acc 96.934%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.191 Acc 95.142%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.189 Acc 95.141%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.096 Acc 97.007%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.096 Acc 97.020%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.098 Acc 97.021%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.101 Acc 96.981%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.202 Acc 94.624%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.200 Acc 94.823%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 97.153%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.101 Acc 97.019%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.101 Acc 96.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.101 Acc 96.959%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.099 Acc 96.997%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.203 Acc 94.872%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.200 Acc 95.029%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.104 Acc 96.972%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.100 Acc 97.070%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.100 Acc 97.031%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.099 Acc 96.989%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.186 Acc 92.969%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.194 Acc 95.158%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.194 Acc 95.231%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.137 Acc 94.531%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.099 Acc 97.014%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.100 Acc 96.927%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.100 Acc 96.978%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.100 Acc 96.950%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.194 Acc 95.065%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.193 Acc 95.173%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.201 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.094 Acc 97.223%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.095 Acc 97.174%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.094 Acc 97.168%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.094 Acc 97.198%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.097 Acc 97.125%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.204 Acc 94.918%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.202 Acc 95.017%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.096 Acc 97.073%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.096 Acc 97.013%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.098 Acc 96.931%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.099 Acc 96.970%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.204 Acc 94.933%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.201 Acc 95.056%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.091 Acc 97.161%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.093 Acc 97.073%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.097 Acc 97.078%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.213 Acc 94.547%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.209 Acc 94.687%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.101 Acc 96.960%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.098 Acc 97.007%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.097 Acc 97.028%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.097 Acc 97.060%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.097 Acc 97.053%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.204 Acc 95.011%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.202 Acc 95.149%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.097 Acc 97.053%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.090 Acc 97.252%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.091 Acc 97.254%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.090 Acc 97.265%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.093 Acc 97.173%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.210 Acc 94.864%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.206 Acc 95.009%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.030 Acc 100.000%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.087 Acc 97.277%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.089 Acc 97.334%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.092 Acc 97.208%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.092 Acc 97.173%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.215 Acc 94.732%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.209 Acc 94.834%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.111 Acc 94.531%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.090 Acc 97.147%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.092 Acc 97.158%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.092 Acc 97.124%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.201 Acc 94.995%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.198 Acc 95.099%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.122 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.090 Acc 97.339%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.089 Acc 97.314%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.091 Acc 97.181%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.091 Acc 97.216%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.092 Acc 97.170%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.206 Acc 94.910%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.206 Acc 94.904%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.083 Acc 97.378%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.088 Acc 97.268%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.090 Acc 97.228%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.091 Acc 97.189%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.091 Acc 97.193%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.208 Acc 94.709%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.207 Acc 94.912%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.088 Acc 97.269%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.090 Acc 97.260%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.090 Acc 97.244%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.092 Acc 97.157%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.090 Acc 97.215%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.214 Acc 94.554%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.212 Acc 94.640%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.085 Acc 97.300%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.085 Acc 97.349%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.087 Acc 97.340%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.088 Acc 97.346%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.089 Acc 97.326%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.205 Acc 95.057%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.205 Acc 95.122%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.156 Acc 96.875%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.086 Acc 97.355%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.086 Acc 97.392%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.088 Acc 97.353%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.089 Acc 97.302%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.089 Acc 97.312%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.207 Acc 94.941%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.205 Acc 95.029%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.087 Acc 97.200%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.087 Acc 97.310%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.088 Acc 97.293%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.088 Acc 97.267%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.088 Acc 97.255%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.212 Acc 94.616%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.211 Acc 94.733%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.088 Acc 97.308%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.086 Acc 97.319%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.088 Acc 97.286%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.217 Acc 94.848%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.214 Acc 94.955%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.165 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.082 Acc 97.440%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.085 Acc 97.301%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.086 Acc 97.274%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.087 Acc 97.288%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.213 Acc 94.879%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.211 Acc 94.963%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.091 Acc 98.438%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.087 Acc 97.146%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.083 Acc 97.388%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.082 Acc 97.394%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.087 Acc 97.287%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.211 Acc 94.748%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.212 Acc 94.873%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.082 Acc 97.509%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.082 Acc 97.407%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.083 Acc 97.451%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.086 Acc 97.317%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.085 Acc 97.341%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.208 Acc 94.988%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.205 Acc 95.118%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.083 Acc 97.401%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.085 Acc 97.427%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.085 Acc 97.394%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.086 Acc 97.343%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.084 Acc 97.421%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.219 Acc 94.787%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.216 Acc 94.932%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.078 Acc 97.548%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.078 Acc 97.501%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.083 Acc 97.337%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.084 Acc 97.326%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.156 Acc 92.969%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.204 Acc 95.050%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.204 Acc 95.138%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.071 Acc 97.772%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.078 Acc 97.582%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.078 Acc 97.503%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.080 Acc 97.467%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.083 Acc 97.399%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.207 Acc 95.034%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.205 Acc 95.040%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.077 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.072 Acc 97.517%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.075 Acc 97.493%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.078 Acc 97.438%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.080 Acc 97.397%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.082 Acc 97.369%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.208 Acc 95.073%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.208 Acc 95.072%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.123 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.079 Acc 97.563%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.081 Acc 97.489%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.082 Acc 97.443%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.081 Acc 97.498%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.081 Acc 97.503%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.227 Acc 94.485%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.221 Acc 94.671%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.079 Acc 97.765%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.080 Acc 97.571%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.080 Acc 97.526%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.083 Acc 97.434%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.082 Acc 97.424%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.213 Acc 94.964%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.209 Acc 95.118%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.072 Acc 97.602%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.073 Acc 97.672%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.077 Acc 97.549%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.217 Acc 92.188%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.232 Acc 94.493%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.228 Acc 94.512%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.072 Acc 97.625%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.076 Acc 97.610%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.080 Acc 97.495%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.080 Acc 97.508%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.079 Acc 97.517%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.266 Acc 92.188%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.230 Acc 94.655%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.226 Acc 94.768%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.076 Acc 97.401%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.073 Acc 97.606%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.074 Acc 97.584%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.075 Acc 97.555%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.076 Acc 97.524%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.236 Acc 94.547%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.233 Acc 94.551%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.072 Acc 97.726%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.077 Acc 97.506%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.077 Acc 97.516%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.077 Acc 97.485%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.211 Acc 95.011%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.211 Acc 94.974%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.107 Acc 94.531%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.075 Acc 97.532%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.073 Acc 97.635%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.075 Acc 97.592%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.075 Acc 97.600%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.254 Acc 92.969%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.224 Acc 94.640%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.224 Acc 94.640%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.071 Acc 97.857%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.071 Acc 97.808%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.073 Acc 97.703%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.075 Acc 97.606%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.076 Acc 97.588%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.218 Acc 94.833%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.219 Acc 94.792%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.071 Acc 97.664%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.071 Acc 97.680%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.072 Acc 97.654%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.073 Acc 97.616%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.225 Acc 94.895%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.225 Acc 94.912%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.070 Acc 97.749%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.069 Acc 97.711%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.071 Acc 97.742%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.073 Acc 97.658%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.217 Acc 94.995%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.216 Acc 95.083%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.071 Acc 97.761%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.073 Acc 97.611%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.074 Acc 97.609%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.233 Acc 94.787%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.228 Acc 94.850%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.070 Acc 97.713%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.071 Acc 97.728%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.072 Acc 97.678%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.226 Acc 94.864%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.223 Acc 94.873%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.066 Acc 97.772%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.070 Acc 97.715%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.069 Acc 97.724%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.070 Acc 97.687%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.071 Acc 97.658%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.202 Acc 92.969%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.227 Acc 94.949%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.226 Acc 94.932%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.068 Acc 97.795%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.069 Acc 97.742%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.072 Acc 97.630%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.071 Acc 97.678%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.072 Acc 97.670%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.235 Acc 94.678%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.232 Acc 94.691%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.068 Acc 97.795%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.069 Acc 97.715%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.071 Acc 97.719%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.071 Acc 97.689%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.212 Acc 91.406%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.230 Acc 94.601%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.227 Acc 94.698%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.074 Acc 97.571%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.067 Acc 97.742%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.068 Acc 97.783%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.072 Acc 97.633%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.232 Acc 94.879%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.229 Acc 94.970%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.068 Acc 97.842%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.068 Acc 97.917%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.071 Acc 97.763%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.071 Acc 97.703%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.190 Acc 92.188%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.225 Acc 94.709%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.224 Acc 94.815%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.066 Acc 97.850%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.069 Acc 97.715%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.070 Acc 97.703%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.071 Acc 97.705%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.232 Acc 94.485%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.232 Acc 94.617%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.152 Acc 94.531%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.066 Acc 97.927%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.068 Acc 97.835%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.069 Acc 97.789%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.069 Acc 97.763%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.070 Acc 97.739%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.236 Acc 94.670%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.234 Acc 94.722%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.061 Acc 98.198%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.068 Acc 97.889%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.068 Acc 97.879%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.070 Acc 97.775%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.071 Acc 97.736%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.236 Acc 94.678%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.230 Acc 94.819%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.067 Acc 97.812%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.068 Acc 97.809%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.068 Acc 97.769%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.069 Acc 97.734%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.224 Acc 94.740%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.223 Acc 94.885%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.063 Acc 97.904%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.064 Acc 97.839%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.067 Acc 97.770%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.068 Acc 97.723%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.235 Acc 94.879%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.234 Acc 94.982%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.065 Acc 97.862%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.068 Acc 97.732%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.067 Acc 97.785%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.067 Acc 97.786%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.230 Acc 94.787%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.229 Acc 94.842%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.062 Acc 97.857%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.062 Acc 97.913%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.065 Acc 97.817%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.067 Acc 97.785%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.068 Acc 97.751%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.228 Acc 94.841%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.228 Acc 94.842%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.060 Acc 98.190%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.063 Acc 98.033%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.064 Acc 97.911%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.066 Acc 97.845%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.067 Acc 97.836%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.230 Acc 94.686%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.228 Acc 94.799%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.056 Acc 97.997%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.062 Acc 97.909%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.063 Acc 97.885%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.064 Acc 97.859%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.065 Acc 97.837%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.257 Acc 94.400%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.250 Acc 94.469%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.068 Acc 97.912%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.068 Acc 97.781%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.068 Acc 97.779%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.068 Acc 97.747%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.255 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.235 Acc 94.810%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.233 Acc 94.924%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.062 Acc 98.014%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.063 Acc 97.955%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.065 Acc 97.831%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.233 Acc 95.019%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.228 Acc 95.173%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.058 Acc 98.028%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.058 Acc 98.076%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.060 Acc 98.020%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.062 Acc 97.962%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.062 Acc 97.974%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.220 Acc 92.188%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.239 Acc 94.756%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.235 Acc 94.819%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.064 Acc 97.901%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.063 Acc 97.924%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.062 Acc 97.941%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.063 Acc 97.901%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.273 Acc 92.969%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.238 Acc 94.771%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.234 Acc 94.842%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.063 Acc 97.850%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.064 Acc 97.905%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.063 Acc 97.947%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.064 Acc 97.895%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.235 Acc 94.964%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.232 Acc 95.056%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.079 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.061 Acc 97.983%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.062 Acc 97.921%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.062 Acc 97.941%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.062 Acc 97.910%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.241 Acc 94.848%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.239 Acc 94.986%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.062 Acc 97.873%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.062 Acc 97.913%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.060 Acc 97.965%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.061 Acc 97.945%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.062 Acc 97.931%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.235 Acc 95.080%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.233 Acc 95.157%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.056 Acc 98.252%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.061 Acc 98.018%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.064 Acc 97.910%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.063 Acc 97.918%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.242 Acc 94.446%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.237 Acc 94.636%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.057 Acc 98.159%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.058 Acc 98.084%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.059 Acc 98.066%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.060 Acc 97.989%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.062 Acc 97.973%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.238 Acc 94.740%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.237 Acc 94.869%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.058 Acc 98.120%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.059 Acc 98.041%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.063 Acc 97.869%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.063 Acc 97.882%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.234 Acc 94.779%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.230 Acc 94.869%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.061 Acc 97.888%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.058 Acc 98.002%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.060 Acc 97.903%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.061 Acc 97.923%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.060 Acc 97.946%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.268 Acc 92.969%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.236 Acc 94.794%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.232 Acc 94.924%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.073 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.062 Acc 97.850%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.060 Acc 97.956%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.060 Acc 97.999%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.060 Acc 97.978%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.061 Acc 97.920%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.243 Acc 94.794%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.240 Acc 94.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.056 Acc 98.105%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.056 Acc 98.189%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.058 Acc 98.079%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.059 Acc 98.032%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.060 Acc 98.016%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.271 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.257 Acc 94.454%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.251 Acc 94.531%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.058 Acc 98.028%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.059 Acc 98.033%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.059 Acc 98.051%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.058 Acc 98.065%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.058 Acc 98.063%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.255 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.239 Acc 94.732%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.234 Acc 94.974%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.052 Acc 98.190%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.057 Acc 98.103%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.056 Acc 98.056%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.057 Acc 98.056%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.058 Acc 98.031%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.285 Acc 91.406%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.238 Acc 94.678%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.236 Acc 94.706%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.055 Acc 98.298%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.057 Acc 98.189%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.057 Acc 98.126%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.058 Acc 98.050%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.060 Acc 97.982%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.241 Acc 94.732%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.242 Acc 94.733%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.052 Acc 98.275%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.054 Acc 98.150%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.055 Acc 98.142%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.055 Acc 98.161%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.056 Acc 98.123%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.208 Acc 93.750%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.244 Acc 94.848%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.241 Acc 95.002%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.053 Acc 98.144%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.055 Acc 98.082%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.055 Acc 98.073%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.057 Acc 98.046%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.248 Acc 94.732%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.246 Acc 94.714%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.054 Acc 98.136%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.054 Acc 98.181%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.054 Acc 98.162%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.056 Acc 98.097%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.056 Acc 98.101%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.260 Acc 94.531%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.244 Acc 94.392%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.240 Acc 94.597%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.052 Acc 98.329%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.057 Acc 98.115%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.057 Acc 98.079%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.059 Acc 98.040%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.057 Acc 98.071%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.259 Acc 92.969%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.244 Acc 94.701%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.242 Acc 94.900%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.060 Acc 97.857%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.057 Acc 97.944%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.057 Acc 97.965%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.058 Acc 97.952%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.058 Acc 97.984%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.274 Acc 90.625%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.240 Acc 94.879%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.237 Acc 94.947%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.053 Acc 98.213%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.050 Acc 98.313%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.051 Acc 98.297%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.054 Acc 98.223%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.055 Acc 98.199%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.241 Acc 94.694%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.241 Acc 94.733%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.048 Acc 98.229%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.052 Acc 98.146%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.053 Acc 98.144%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.053 Acc 98.137%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.056 Acc 98.101%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.279 Acc 92.969%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.254 Acc 94.562%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.253 Acc 94.636%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.051 Acc 98.244%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.050 Acc 98.235%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.054 Acc 98.134%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.054 Acc 98.106%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.056 Acc 98.055%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.238 Acc 94.810%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.236 Acc 94.788%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.051 Acc 98.383%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.052 Acc 98.282%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.051 Acc 98.274%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.053 Acc 98.192%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.054 Acc 98.143%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.251 Acc 92.969%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.248 Acc 94.524%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.245 Acc 94.745%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.049 Acc 98.247%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.053 Acc 98.175%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.054 Acc 98.130%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.054 Acc 98.143%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.267 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.249 Acc 94.810%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.244 Acc 94.924%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.054 Acc 98.229%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.052 Acc 98.231%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.053 Acc 98.217%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.054 Acc 98.178%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.055 Acc 98.146%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.254 Acc 94.725%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.249 Acc 94.881%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.043 Acc 99.219%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [100/573] Loss: 0.055 Acc 98.120%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.052 Acc 98.228%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.052 Acc 98.219%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.054 Acc 98.204%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.054 Acc 98.158%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.277 Acc 91.406%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.257 Acc 94.585%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.255 Acc 94.601%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.053 Acc 98.252%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.051 Acc 98.298%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.054 Acc 98.186%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.054 Acc 98.188%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.260 Acc 94.864%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.258 Acc 94.881%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.046 Acc 98.383%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.051 Acc 98.270%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.052 Acc 98.201%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.052 Acc 98.174%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.054 Acc 98.146%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.217 Acc 92.188%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.250 Acc 94.817%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.243 Acc 94.982%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.048 Acc 98.376%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.053 Acc 98.191%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.055 Acc 98.169%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.053 Acc 98.225%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.293 Acc 92.969%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.253 Acc 94.261%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.248 Acc 94.566%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.052 Acc 98.128%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.050 Acc 98.224%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.052 Acc 98.136%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.053 Acc 98.128%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.053 Acc 98.126%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.246 Acc 94.771%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.243 Acc 94.947%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.043 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.049 Acc 98.383%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.052 Acc 98.290%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.053 Acc 98.269%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.052 Acc 98.270%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.052 Acc 98.300%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.251 Acc 94.794%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.248 Acc 94.974%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.082 Acc 99.219%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.047 Acc 98.252%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.049 Acc 98.309%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.049 Acc 98.336%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.051 Acc 98.274%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.052 Acc 98.233%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.232 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.260 Acc 94.547%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.257 Acc 94.706%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.049 Acc 98.244%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.048 Acc 98.266%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.050 Acc 98.225%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.050 Acc 98.221%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.051 Acc 98.219%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.246 Acc 94.647%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.242 Acc 94.827%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.050 Acc 98.221%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.050 Acc 98.248%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.050 Acc 98.233%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.051 Acc 98.230%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.268 Acc 94.895%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.263 Acc 94.990%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.051 Acc 98.260%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.049 Acc 98.270%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.051 Acc 98.238%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.052 Acc 98.215%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.053 Acc 98.183%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.236 Acc 92.969%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.248 Acc 94.616%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.248 Acc 94.718%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.048 Acc 98.391%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.050 Acc 98.309%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.051 Acc 98.256%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.052 Acc 98.208%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.051 Acc 98.222%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.262 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.251 Acc 94.647%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.249 Acc 94.714%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.062 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.047 Acc 98.383%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.049 Acc 98.356%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.049 Acc 98.352%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.051 Acc 98.289%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.052 Acc 98.233%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.256 Acc 92.969%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.262 Acc 94.763%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.258 Acc 94.862%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.043 Acc 98.577%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.045 Acc 98.476%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.047 Acc 98.344%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.049 Acc 98.286%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.050 Acc 98.269%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.281 Acc 91.406%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.251 Acc 94.926%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.244 Acc 95.083%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.048 Acc 98.356%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.049 Acc 98.349%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.049 Acc 98.346%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.049 Acc 98.322%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.300 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.254 Acc 94.841%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.251 Acc 94.916%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.029 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.047 Acc 98.283%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.049 Acc 98.266%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.050 Acc 98.227%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.050 Acc 98.225%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.050 Acc 98.268%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.149 Acc 96.875%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.256 Acc 94.787%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.253 Acc 94.916%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.046 Acc 98.461%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.046 Acc 98.434%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.048 Acc 98.386%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.049 Acc 98.313%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.050 Acc 98.263%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.306 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.247 Acc 94.872%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.242 Acc 95.025%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.045 Acc 98.530%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.048 Acc 98.352%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.048 Acc 98.336%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.049 Acc 98.315%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.051 Acc 98.235%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.248 Acc 92.188%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.252 Acc 94.624%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.249 Acc 94.772%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.047 Acc 98.267%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.047 Acc 98.364%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.047 Acc 98.352%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.046 Acc 98.393%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.047 Acc 98.383%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.254 Acc 94.438%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.253 Acc 94.566%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.046 Acc 98.352%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.046 Acc 98.371%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.048 Acc 98.334%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.048 Acc 98.350%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.048 Acc 98.347%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.263 Acc 94.787%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.257 Acc 94.866%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.045 Acc 98.399%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.046 Acc 98.441%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.046 Acc 98.443%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.048 Acc 98.366%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.266 Acc 94.686%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.262 Acc 94.807%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.043 Acc 98.523%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.044 Acc 98.519%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.046 Acc 98.466%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.046 Acc 98.441%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.047 Acc 98.413%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.265 Acc 94.593%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.261 Acc 94.706%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.046 Acc 98.360%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.044 Acc 98.422%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.046 Acc 98.425%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.048 Acc 98.385%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.049 Acc 98.358%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.257 Acc 94.732%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.254 Acc 94.866%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.045 Acc 98.345%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.046 Acc 98.387%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.047 Acc 98.378%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.047 Acc 98.379%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.047 Acc 98.411%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.251 Acc 94.787%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.246 Acc 94.893%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.041 Acc 98.507%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.043 Acc 98.453%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.044 Acc 98.416%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.045 Acc 98.414%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.307 Acc 91.406%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.265 Acc 94.678%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.261 Acc 94.772%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.028 Acc 100.000%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.047 Acc 98.476%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.048 Acc 98.403%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.049 Acc 98.365%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.047 Acc 98.431%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.270 Acc 92.969%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.251 Acc 94.601%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.251 Acc 94.671%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.045 Acc 98.383%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.045 Acc 98.410%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.046 Acc 98.378%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.046 Acc 98.389%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.046 Acc 98.366%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.252 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.257 Acc 94.624%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.250 Acc 94.831%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.042 Acc 98.530%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.044 Acc 98.434%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.045 Acc 98.409%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.047 Acc 98.338%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.047 Acc 98.353%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.268 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.261 Acc 94.640%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.260 Acc 94.764%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.043 Acc 98.492%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.044 Acc 98.461%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.047 Acc 98.334%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.047 Acc 98.356%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.046 Acc 98.388%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.216 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.259 Acc 94.678%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.254 Acc 94.733%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.042 Acc 98.523%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.044 Acc 98.472%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.045 Acc 98.414%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.046 Acc 98.413%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.335 Acc 91.406%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.269 Acc 94.500%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.263 Acc 94.780%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.037 Acc 98.675%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.040 Acc 98.630%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.042 Acc 98.545%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.044 Acc 98.472%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.261 Acc 94.531%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.263 Acc 94.725%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.261 Acc 94.850%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [100/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.043 Acc 98.465%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.046 Acc 98.408%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.046 Acc 98.406%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.220 Acc 92.188%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.258 Acc 94.508%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.251 Acc 94.733%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.040 Acc 98.675%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.042 Acc 98.609%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.041 Acc 98.630%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.042 Acc 98.586%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.236 Acc 93.750%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.259 Acc 94.825%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.256 Acc 94.811%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.041 Acc 98.584%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.043 Acc 98.469%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.043 Acc 98.482%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.044 Acc 98.439%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.045 Acc 98.413%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.260 Acc 94.701%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.260 Acc 94.842%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.045 Acc 98.461%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.046 Acc 98.410%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.047 Acc 98.349%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.046 Acc 98.377%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.046 Acc 98.366%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.263 Acc 94.562%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.258 Acc 94.737%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcedda52b8c4468c80b990ce4a16d1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8536e2b5567c499f933d1c6046d62456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.292 Acc 21.875%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.239 Acc 19.143%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.999%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.231 Acc 19.014%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.840 Acc 40.625%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.912 Acc 32.488%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.914 Acc 32.210%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.957 Acc 35.938%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.623 Acc 43.897%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.406 Acc 52.099%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.247 Acc 57.955%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.118 Acc 62.634%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.020 Acc 66.180%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.516 Acc 83.594%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.462 Acc 86.193%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.449 Acc 86.505%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.411 Acc 89.844%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.528 Acc 83.849%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.505 Acc 84.542%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.490 Acc 85.021%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.482 Acc 85.265%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.470 Acc 85.576%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.436 Acc 86.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.338 Acc 90.548%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.333 Acc 90.516%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.270 Acc 95.312%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.379 Acc 88.745%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.387 Acc 88.452%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.388 Acc 88.372%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.386 Acc 88.396%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.384 Acc 88.500%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.413 Acc 88.281%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.304 Acc 91.476%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.298 Acc 91.519%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.264 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.353 Acc 89.233%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.356 Acc 89.214%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.351 Acc 89.392%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.349 Acc 89.477%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.349 Acc 89.566%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.298 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.290 Acc 91.754%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.280 Acc 91.873%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.593 Acc 81.250%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.329 Acc 90.408%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.325 Acc 90.493%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.318 Acc 90.674%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.320 Acc 90.559%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.319 Acc 90.558%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.270 Acc 92.621%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.263 Acc 92.802%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.340 Acc 85.938%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.311 Acc 90.594%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.308 Acc 90.792%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.307 Acc 90.942%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.306 Acc 90.974%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.305 Acc 90.995%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.316 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.267 Acc 92.744%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.257 Acc 92.825%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.295 Acc 91.298%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.298 Acc 91.002%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.295 Acc 91.032%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.293 Acc 91.213%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.291 Acc 91.311%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.256 Acc 93.270%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.245 Acc 93.396%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.365 Acc 87.500%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.272 Acc 91.855%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.284 Acc 91.643%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.284 Acc 91.725%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.284 Acc 91.683%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.285 Acc 91.657%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.230 Acc 93.727%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.222 Acc 93.894%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.273 Acc 92.273%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.275 Acc 91.908%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.273 Acc 92.027%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.272 Acc 92.026%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.272 Acc 92.064%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.304 Acc 89.844%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.250 Acc 93.224%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.244 Acc 93.237%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.338 Acc 88.281%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.273 Acc 91.971%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.266 Acc 92.238%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.268 Acc 92.226%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.269 Acc 92.182%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.265 Acc 92.275%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.240 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.215 Acc 94.114%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.210 Acc 94.201%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.271 Acc 91.406%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.240 Acc 92.961%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.249 Acc 92.666%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.256 Acc 92.553%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.258 Acc 92.519%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.262 Acc 92.417%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.190 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.227 Acc 93.851%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.221 Acc 93.975%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.342 Acc 91.406%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.258 Acc 92.644%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.261 Acc 92.615%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.256 Acc 92.730%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.257 Acc 92.583%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.258 Acc 92.517%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.250 Acc 93.131%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.243 Acc 93.116%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.171 Acc 91.406%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.261 Acc 92.481%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.250 Acc 92.802%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.249 Acc 92.686%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.252 Acc 92.643%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.255 Acc 92.554%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.230 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.211 Acc 94.284%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.204 Acc 94.415%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.385 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.246 Acc 92.659%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.248 Acc 92.802%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.250 Acc 92.753%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.249 Acc 92.807%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.248 Acc 92.836%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.212 Acc 94.825%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.203 Acc 94.932%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.229 Acc 92.953%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.238 Acc 92.934%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.236 Acc 93.026%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.238 Acc 93.037%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.239 Acc 93.062%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.251 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.217 Acc 94.485%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.206 Acc 94.590%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.247 Acc 92.690%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.244 Acc 92.895%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.244 Acc 92.909%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.242 Acc 92.969%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.243 Acc 92.970%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.225 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.206 Acc 94.663%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.198 Acc 94.683%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.285 Acc 90.625%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.229 Acc 93.348%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.229 Acc 93.151%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.231 Acc 93.202%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.235 Acc 93.154%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.238 Acc 93.047%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.205 Acc 94.825%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.199 Acc 94.803%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.204 Acc 91.406%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.219 Acc 93.796%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.225 Acc 93.571%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.228 Acc 93.459%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.231 Acc 93.347%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.232 Acc 93.313%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.198 Acc 95.065%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.190 Acc 95.079%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.181 Acc 96.094%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.229 Acc 93.510%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.233 Acc 93.377%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.231 Acc 93.389%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.230 Acc 93.368%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.230 Acc 93.384%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.258 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.206 Acc 94.508%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.201 Acc 94.597%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.249 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.228 Acc 93.309%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.223 Acc 93.458%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.226 Acc 93.464%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.226 Acc 93.487%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.225 Acc 93.502%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.207 Acc 94.732%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.198 Acc 94.862%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.159 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.215 Acc 93.804%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.221 Acc 93.458%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.222 Acc 93.332%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.223 Acc 93.399%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.227 Acc 93.402%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.272 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.206 Acc 94.524%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.199 Acc 94.660%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.319 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.225 Acc 93.889%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.216 Acc 93.894%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.220 Acc 93.768%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.222 Acc 93.625%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.221 Acc 93.628%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.257 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.205 Acc 94.446%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.196 Acc 94.656%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.205 Acc 94.052%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.213 Acc 93.952%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.210 Acc 93.932%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.213 Acc 93.898%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.214 Acc 93.825%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.201 Acc 95.312%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.204 Acc 94.485%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.194 Acc 94.667%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.294 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.219 Acc 93.526%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.221 Acc 93.528%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.217 Acc 93.664%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.219 Acc 93.619%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.218 Acc 93.666%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.211 Acc 94.291%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.202 Acc 94.558%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.477 Acc 89.844%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.215 Acc 93.765%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.215 Acc 93.738%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.216 Acc 93.644%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.215 Acc 93.697%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.215 Acc 93.688%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.211 Acc 94.469%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.203 Acc 94.523%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.218 Acc 93.665%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.213 Acc 93.754%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.214 Acc 93.734%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.214 Acc 93.707%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.214 Acc 93.656%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.206 Acc 95.104%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.196 Acc 95.091%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.276 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.204 Acc 93.959%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.210 Acc 93.797%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.208 Acc 93.986%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.209 Acc 93.927%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.212 Acc 93.844%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.200 Acc 94.655%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.192 Acc 94.788%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.227 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.202 Acc 94.059%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.203 Acc 94.162%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.205 Acc 94.087%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.207 Acc 94.031%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.210 Acc 93.951%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.200 Acc 94.895%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.191 Acc 95.103%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.304 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.204 Acc 93.881%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.204 Acc 93.925%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.212 Acc 93.802%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.213 Acc 93.828%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.211 Acc 93.884%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.204 Acc 94.864%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.194 Acc 94.970%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.290 Acc 91.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.211 Acc 93.889%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.209 Acc 93.894%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.208 Acc 93.955%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.207 Acc 93.957%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.208 Acc 93.981%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.197 Acc 94.817%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.189 Acc 95.009%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.171 Acc 93.750%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.199 Acc 94.377%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.205 Acc 94.088%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.203 Acc 94.080%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.204 Acc 94.089%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.207 Acc 93.940%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.221 Acc 94.469%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.209 Acc 94.718%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.200 Acc 91.406%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.206 Acc 93.796%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.208 Acc 93.905%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.212 Acc 93.882%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.207 Acc 93.966%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.210 Acc 93.917%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.159 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.188 Acc 95.196%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.181 Acc 95.281%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.203 Acc 94.106%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.199 Acc 94.139%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.201 Acc 94.129%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.202 Acc 94.103%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.200 Acc 94.116%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.616%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.195 Acc 94.780%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.236 Acc 91.406%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.194 Acc 94.315%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.193 Acc 94.380%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.198 Acc 94.254%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.200 Acc 94.169%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.202 Acc 94.146%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.206 Acc 95.274%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.196 Acc 95.262%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.111 Acc 95.312%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.199 Acc 93.951%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.206 Acc 93.890%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.202 Acc 94.108%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.200 Acc 94.087%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.201 Acc 94.054%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.194 Acc 95.019%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.183 Acc 95.278%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.209 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.196 Acc 94.330%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.195 Acc 94.356%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.198 Acc 94.272%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.199 Acc 94.243%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.200 Acc 94.215%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.347 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.215 Acc 94.562%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.205 Acc 94.644%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.196 Acc 94.315%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.205 Acc 94.100%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.198 Acc 94.212%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.197 Acc 94.233%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.199 Acc 94.159%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.204 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.186 Acc 95.599%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.179 Acc 95.491%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.180 Acc 94.670%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.192 Acc 94.403%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.195 Acc 94.274%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.196 Acc 94.296%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.197 Acc 94.291%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.207 Acc 95.135%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.197 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.174 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.189 Acc 94.640%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.190 Acc 94.570%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.192 Acc 94.479%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.193 Acc 94.430%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.196 Acc 94.355%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.204 Acc 94.547%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.195 Acc 94.764%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.183 Acc 94.539%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.192 Acc 94.282%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.192 Acc 94.373%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.195 Acc 94.225%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.194 Acc 94.343%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.177 Acc 95.565%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.204 Acc 92.188%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.187 Acc 94.168%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.191 Acc 94.251%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.195 Acc 94.238%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.195 Acc 94.258%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.194 Acc 94.291%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.186 Acc 95.145%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.229 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.187 Acc 94.547%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.191 Acc 94.457%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.193 Acc 94.305%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.194 Acc 94.266%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.194 Acc 94.272%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.187 Acc 95.421%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.182 Acc 95.464%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.177 Acc 94.988%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.187 Acc 94.643%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.188 Acc 94.533%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.194 Acc 95.328%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.189 Acc 95.390%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.188 Acc 94.361%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.186 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.188 Acc 94.547%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.189 Acc 94.471%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.190 Acc 94.428%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.193 Acc 94.972%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.186 Acc 95.040%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.156 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.174 Acc 94.779%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.182 Acc 94.555%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.185 Acc 94.560%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.188 Acc 94.492%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.190 Acc 94.460%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.187 Acc 95.467%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.181 Acc 95.484%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.265 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.178 Acc 94.879%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.185 Acc 94.562%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.185 Acc 94.572%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.188 Acc 94.475%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.199 Acc 95.173%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.192 Acc 95.204%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.162 Acc 93.750%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.180 Acc 94.554%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.186 Acc 94.523%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.190 Acc 94.457%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.192 Acc 94.369%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.188 Acc 95.073%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.180 Acc 95.219%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.174 Acc 94.941%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.180 Acc 94.757%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.182 Acc 94.645%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.190 Acc 94.489%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.202 Acc 94.988%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.194 Acc 95.110%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.281 Acc 91.406%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.186 Acc 94.547%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.181 Acc 94.691%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.185 Acc 94.542%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.187 Acc 94.514%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.187 Acc 94.523%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.206 Acc 95.336%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.198 Acc 95.305%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.153 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.185 Acc 94.647%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.180 Acc 94.788%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.181 Acc 94.731%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.185 Acc 94.600%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.191 Acc 92.188%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.201 Acc 94.787%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.193 Acc 94.869%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.180 Acc 94.825%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.178 Acc 94.873%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.181 Acc 94.830%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.183 Acc 94.751%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.184 Acc 94.656%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.189 Acc 95.592%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.156 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.181 Acc 94.725%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.184 Acc 94.617%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.186 Acc 94.482%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.185 Acc 94.477%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.187 Acc 94.436%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.184 Acc 95.359%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.179 Acc 95.379%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.253 Acc 91.406%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.182 Acc 94.771%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.186 Acc 94.565%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.186 Acc 94.566%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.186 Acc 94.575%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.425%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.337 Acc 92.188%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.185 Acc 94.299%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.187 Acc 94.333%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.185 Acc 94.469%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.188 Acc 94.481%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.187 Acc 94.456%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.207 Acc 95.042%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.194 Acc 95.219%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.175 Acc 94.903%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.177 Acc 94.698%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.177 Acc 94.739%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.179 Acc 94.638%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.180 Acc 94.667%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.164 Acc 92.188%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.205 Acc 94.903%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.196 Acc 94.978%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.181 Acc 94.740%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.176 Acc 94.846%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.177 Acc 94.791%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.178 Acc 94.746%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.181 Acc 94.659%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.208 Acc 94.887%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.201 Acc 95.040%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.203 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.174 Acc 94.663%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.178 Acc 94.628%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.179 Acc 94.586%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.179 Acc 94.586%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.182 Acc 94.562%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.202 Acc 95.088%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.193 Acc 95.188%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.232 Acc 96.094%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.182 Acc 94.817%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.175 Acc 94.897%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.180 Acc 94.734%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.183 Acc 94.677%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.184 Acc 94.681%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.187 Acc 95.452%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.167 Acc 95.026%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.173 Acc 94.916%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.174 Acc 94.791%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.177 Acc 94.710%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.178 Acc 94.745%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.200 Acc 91.406%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.194 Acc 95.459%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.188 Acc 95.491%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.168 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.175 Acc 94.872%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.182 Acc 94.593%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.181 Acc 94.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.183 Acc 94.594%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.181 Acc 94.703%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.184 Acc 95.483%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.175 Acc 95.717%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.260 Acc 91.406%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.176 Acc 94.725%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.178 Acc 94.780%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.180 Acc 94.770%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.178 Acc 94.823%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.180 Acc 94.736%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.206 Acc 95.096%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.196 Acc 95.320%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.248 Acc 90.625%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.183 Acc 94.508%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.179 Acc 94.593%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.175 Acc 94.775%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.181 Acc 94.648%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.181 Acc 94.622%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.200 Acc 95.166%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.187 Acc 95.316%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.229 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.166 Acc 94.926%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.177 Acc 94.601%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.181 Acc 94.568%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.178 Acc 94.633%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.178 Acc 94.645%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.192 Acc 95.135%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.181 Acc 95.340%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.221 Acc 94.531%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.180 Acc 94.740%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.176 Acc 94.866%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.175 Acc 94.876%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.178 Acc 94.794%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.176 Acc 94.842%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.225 Acc 93.750%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.429%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.179 Acc 95.484%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.169 Acc 95.026%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.169 Acc 94.959%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.169 Acc 94.983%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.175 Acc 94.818%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.174 Acc 94.846%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.221 Acc 95.189%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.206 Acc 95.297%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.183 Acc 94.485%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.177 Acc 94.737%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.174 Acc 94.773%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.177 Acc 94.744%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.179 Acc 94.731%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.231 Acc 92.188%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.222 Acc 95.042%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.210 Acc 95.243%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.169 Acc 94.864%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.173 Acc 94.889%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.175 Acc 94.856%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.178 Acc 94.773%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.175 Acc 94.868%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.223 Acc 95.096%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.212 Acc 95.211%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.175 Acc 90.625%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.174 Acc 94.794%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.172 Acc 95.037%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.175 Acc 94.939%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.177 Acc 94.831%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.177 Acc 94.795%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.273 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.233 Acc 94.949%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.220 Acc 95.083%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.226 Acc 93.750%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.172 Acc 94.887%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.167 Acc 95.025%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.170 Acc 94.892%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.169 Acc 94.859%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.172 Acc 94.848%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.204 Acc 94.910%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.197 Acc 95.025%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.167 Acc 95.042%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.175 Acc 94.924%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.175 Acc 94.949%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.174 Acc 94.950%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.176 Acc 94.879%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.199 Acc 95.266%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.187 Acc 95.433%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.168 Acc 95.065%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.167 Acc 95.173%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.172 Acc 94.947%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.172 Acc 94.907%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.174 Acc 94.807%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.223 Acc 94.825%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.213 Acc 94.963%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.162 Acc 95.019%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.173 Acc 94.967%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.173 Acc 94.921%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.172 Acc 94.962%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.173 Acc 94.910%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.214 Acc 94.918%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.198 Acc 95.297%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.175 Acc 94.872%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.172 Acc 94.998%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.174 Acc 94.918%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.174 Acc 94.857%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.173 Acc 94.848%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.298 Acc 92.969%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.221 Acc 95.111%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.205 Acc 95.371%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.162 Acc 95.243%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.165 Acc 95.141%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.169 Acc 95.040%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.170 Acc 95.034%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.170 Acc 94.988%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.226 Acc 92.188%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.207 Acc 95.181%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.196 Acc 95.421%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.159 Acc 95.297%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.165 Acc 95.075%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.168 Acc 94.952%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.170 Acc 94.952%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.169 Acc 94.996%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.198 Acc 95.096%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.190 Acc 95.262%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.162 Acc 95.088%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.161 Acc 95.110%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.163 Acc 95.092%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.168 Acc 94.979%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.168 Acc 94.969%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.277 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.205 Acc 95.204%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.197 Acc 95.281%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.162 Acc 92.969%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.176 Acc 94.933%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.172 Acc 94.935%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.175 Acc 94.814%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.175 Acc 94.818%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.172 Acc 94.870%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.206 Acc 95.135%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.196 Acc 95.270%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.163 Acc 95.080%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.169 Acc 95.005%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.172 Acc 94.944%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.172 Acc 94.958%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.172 Acc 94.965%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.229 Acc 92.188%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.209 Acc 94.732%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.200 Acc 94.897%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.166 Acc 95.019%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.075%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.165 Acc 95.141%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.166 Acc 95.092%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.170 Acc 94.998%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.241 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.204 Acc 95.104%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.194 Acc 95.274%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.162 Acc 95.189%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.167 Acc 95.009%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.168 Acc 95.006%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.167 Acc 95.098%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.170 Acc 94.954%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.221 Acc 91.406%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.211 Acc 95.096%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.196 Acc 95.421%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.169 Acc 94.802%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.166 Acc 94.897%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.169 Acc 94.871%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.166 Acc 94.962%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.167 Acc 94.946%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.272 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.216 Acc 94.933%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.205 Acc 95.176%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.166 Acc 94.988%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.162 Acc 95.153%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.164 Acc 95.089%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.167 Acc 94.991%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.167 Acc 94.979%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.206 Acc 95.166%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.198 Acc 95.266%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.250 Acc 92.188%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.160 Acc 95.289%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.168 Acc 95.106%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.170 Acc 95.019%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.171 Acc 94.933%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.171 Acc 94.943%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.214 Acc 94.926%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.206 Acc 95.087%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.164 Acc 95.034%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.160 Acc 95.149%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.164 Acc 95.074%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.167 Acc 94.997%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.168 Acc 94.957%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.187 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.211 Acc 95.243%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.200 Acc 95.355%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.167 Acc 94.978%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.167 Acc 95.022%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.169 Acc 94.933%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.169 Acc 94.948%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.215 Acc 95.003%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.208 Acc 95.114%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.199 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.157 Acc 95.367%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.166 Acc 95.122%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.166 Acc 95.053%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.168 Acc 95.009%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.167 Acc 95.018%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.203 Acc 94.817%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.197 Acc 94.904%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.174 Acc 93.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.152 Acc 95.150%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.155 Acc 95.180%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.159 Acc 95.170%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.163 Acc 95.051%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.165 Acc 95.051%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.206 Acc 95.019%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.195 Acc 95.254%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.164 Acc 94.872%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.161 Acc 95.021%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.163 Acc 95.001%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.166 Acc 94.919%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.166 Acc 94.969%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.203 Acc 95.065%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.065%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.165 Acc 95.017%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.162 Acc 95.152%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.164 Acc 95.112%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.166 Acc 95.077%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.194 Acc 95.235%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.188 Acc 95.515%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.231 Acc 92.969%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.164 Acc 95.173%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.157 Acc 95.246%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.164 Acc 95.120%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.165 Acc 95.125%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.283 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.226 Acc 95.019%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.217 Acc 95.153%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.162 Acc 95.320%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.163 Acc 95.200%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.162 Acc 95.159%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.165 Acc 95.048%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.165 Acc 95.054%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.242 Acc 92.969%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.220 Acc 94.779%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.208 Acc 95.029%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.233 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.154 Acc 95.274%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.160 Acc 95.211%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.162 Acc 95.159%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.160 Acc 95.184%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.162 Acc 95.063%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.230 Acc 94.833%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.215 Acc 95.110%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.117 Acc 94.531%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.154 Acc 95.429%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.160 Acc 95.258%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.163 Acc 95.110%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.165 Acc 95.005%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.167 Acc 94.952%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.204 Acc 95.119%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.192 Acc 95.309%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.159 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.164 Acc 95.099%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.164 Acc 95.113%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.164 Acc 95.098%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.164 Acc 95.052%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.297 Acc 91.406%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.219 Acc 95.065%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.208 Acc 95.316%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.167 Acc 93.750%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.166 Acc 95.336%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.160 Acc 95.301%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.162 Acc 95.242%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.162 Acc 95.198%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.164 Acc 95.091%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.214 Acc 94.802%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.201 Acc 94.982%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.160 Acc 95.212%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.161 Acc 95.153%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.163 Acc 95.105%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.161 Acc 95.159%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.162 Acc 95.172%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.229 Acc 95.096%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.219 Acc 95.254%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.166 Acc 94.918%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.169 Acc 94.796%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.165 Acc 94.991%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.166 Acc 94.942%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.167 Acc 94.969%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.222 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.206 Acc 95.367%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.194 Acc 95.484%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.148 Acc 95.436%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.153 Acc 95.382%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.158 Acc 95.248%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.163 Acc 95.105%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.198 Acc 95.189%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.188 Acc 95.402%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.160 Acc 95.158%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.158 Acc 95.141%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.158 Acc 95.227%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.161 Acc 95.219%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.163 Acc 95.130%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.228 Acc 94.895%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.213 Acc 95.138%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.152 Acc 95.460%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.159 Acc 95.203%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.160 Acc 95.182%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.163 Acc 95.122%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.206 Acc 94.980%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.197 Acc 95.165%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.147 Acc 95.444%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.160 Acc 95.099%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.161 Acc 95.110%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.161 Acc 95.147%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.161 Acc 95.147%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.225 Acc 95.119%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.209 Acc 95.324%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.153 Acc 95.467%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.158 Acc 95.227%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.159 Acc 95.185%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.159 Acc 95.238%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.160 Acc 95.205%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.176 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.210 Acc 95.142%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.146 Acc 96.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.149 Acc 95.777%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.491%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.159 Acc 95.364%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.161 Acc 95.293%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.160 Acc 95.266%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.262 Acc 92.969%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.219 Acc 95.235%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.209 Acc 95.262%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.149 Acc 95.382%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.151 Acc 95.250%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.158 Acc 95.146%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.160 Acc 95.079%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.160 Acc 95.119%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.209 Acc 95.429%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.197 Acc 95.546%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.197 Acc 92.969%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.157 Acc 95.266%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.149 Acc 95.588%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.154 Acc 95.414%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.158 Acc 95.314%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.160 Acc 95.281%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.217 Acc 95.506%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.207 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.229 Acc 94.531%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.154 Acc 95.266%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.158 Acc 95.184%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.158 Acc 95.237%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.157 Acc 95.285%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.158 Acc 95.220%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.227 Acc 95.119%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.209 Acc 95.328%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.155 Acc 94.980%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.159 Acc 94.982%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.160 Acc 95.081%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.159 Acc 95.067%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.160 Acc 95.136%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.204 Acc 95.413%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.196 Acc 95.542%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.224 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.159 Acc 95.289%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.159 Acc 95.250%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.163 Acc 95.094%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.165 Acc 95.049%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.165 Acc 95.086%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.251 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.209 Acc 95.251%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.201 Acc 95.375%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.145 Acc 95.552%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.148 Acc 95.538%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.154 Acc 95.401%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.156 Acc 95.299%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.159 Acc 95.252%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.220 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.246 Acc 94.887%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.235 Acc 95.114%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.159 Acc 93.750%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.157 Acc 95.374%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.157 Acc 95.285%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.160 Acc 95.120%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.161 Acc 95.096%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.162 Acc 95.107%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.281 Acc 93.750%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.213 Acc 94.879%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.199 Acc 95.180%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.144 Acc 95.792%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.152 Acc 95.421%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.153 Acc 95.326%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.154 Acc 95.345%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.218 Acc 95.227%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.206 Acc 95.460%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.157 Acc 95.088%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.158 Acc 95.161%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.160 Acc 95.149%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.158 Acc 95.153%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.159 Acc 95.150%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.215 Acc 95.119%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.207 Acc 95.293%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.336 Acc 92.969%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.162 Acc 95.180%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.163 Acc 95.063%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.162 Acc 95.174%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.162 Acc 95.163%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.216 Acc 95.142%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.204 Acc 95.359%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.144 Acc 95.591%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.145 Acc 95.608%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.155 Acc 95.409%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.154 Acc 95.433%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.158 Acc 95.309%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.210 Acc 92.969%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.233 Acc 94.918%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.229 Acc 94.994%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.160 Acc 95.166%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.160 Acc 95.138%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.158 Acc 95.193%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.157 Acc 95.244%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.160 Acc 95.189%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.213 Acc 95.258%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.204 Acc 95.468%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.160 Acc 95.266%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.154 Acc 95.324%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.155 Acc 95.315%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.156 Acc 95.277%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.158 Acc 95.228%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.258 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.214 Acc 95.297%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.201 Acc 95.530%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.148 Acc 95.575%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.152 Acc 95.522%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.155 Acc 95.398%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.156 Acc 95.350%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.159 Acc 95.302%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.242 Acc 94.446%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.230 Acc 94.613%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.146 Acc 95.514%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.155 Acc 95.305%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.156 Acc 95.328%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.156 Acc 95.363%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.156 Acc 95.359%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.229 Acc 92.969%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.210 Acc 95.382%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.198 Acc 95.616%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.156 Acc 95.235%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.159 Acc 95.237%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.158 Acc 95.256%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.158 Acc 95.199%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.215 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.266 Acc 94.980%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.250 Acc 95.165%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.154 Acc 95.173%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.153 Acc 95.246%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.155 Acc 95.300%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.156 Acc 95.299%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.157 Acc 95.263%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.234 Acc 94.616%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.218 Acc 94.955%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.197 Acc 91.406%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.154 Acc 95.537%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.150 Acc 95.534%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.152 Acc 95.473%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.153 Acc 95.359%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.156 Acc 95.228%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.216 Acc 94.918%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.204 Acc 95.099%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.154 Acc 95.521%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.148 Acc 95.546%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.152 Acc 95.406%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.155 Acc 95.377%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.157 Acc 95.334%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.224 Acc 95.104%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.216 Acc 95.184%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.212 Acc 94.531%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.151 Acc 95.289%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.152 Acc 95.188%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.153 Acc 95.206%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.154 Acc 95.201%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.156 Acc 95.211%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.254 Acc 92.188%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.251 Acc 94.903%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.240 Acc 95.134%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.157 Acc 95.119%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.152 Acc 95.340%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.151 Acc 95.388%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.152 Acc 95.404%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.152 Acc 95.431%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.218 Acc 95.227%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.210 Acc 95.235%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.150 Acc 95.545%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.151 Acc 95.440%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.153 Acc 95.371%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.154 Acc 95.344%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.231 Acc 96.875%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.218 Acc 95.328%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.204 Acc 95.515%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.152 Acc 95.243%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.153 Acc 95.239%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.153 Acc 95.263%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.156 Acc 95.244%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.154 Acc 95.288%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.261 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.236 Acc 95.119%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.225 Acc 95.390%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.144 Acc 95.483%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.146 Acc 95.542%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.152 Acc 95.292%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.154 Acc 95.217%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.158 Acc 95.122%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.217 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.219 Acc 95.181%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.209 Acc 95.223%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.141 Acc 95.560%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.154 Acc 95.307%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.152 Acc 95.363%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.154 Acc 95.319%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.319 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.241 Acc 95.405%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.227 Acc 95.499%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.150 Acc 95.591%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.157 Acc 95.367%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.155 Acc 95.371%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.153 Acc 95.417%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.269 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.231 Acc 95.282%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.218 Acc 95.410%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.152 Acc 95.490%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.150 Acc 95.480%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.150 Acc 95.455%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.153 Acc 95.338%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.153 Acc 95.337%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.243 Acc 92.969%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.227 Acc 95.135%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.216 Acc 95.266%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.148 Acc 95.421%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.150 Acc 95.455%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.151 Acc 95.449%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.151 Acc 95.453%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.232 Acc 95.127%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.216 Acc 95.394%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.142 Acc 95.583%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.147 Acc 95.522%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.148 Acc 95.510%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.151 Acc 95.476%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.152 Acc 95.423%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.226 Acc 95.189%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.213 Acc 95.312%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.167 Acc 95.235%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.159 Acc 95.452%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.157 Acc 95.411%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.156 Acc 95.377%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.156 Acc 95.298%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.223 Acc 94.972%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.215 Acc 95.044%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.195 Acc 95.312%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.146 Acc 95.367%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.151 Acc 95.386%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.151 Acc 95.385%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.152 Acc 95.403%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.212 Acc 94.949%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.205 Acc 95.025%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.147 Acc 95.436%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.148 Acc 95.507%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.154 Acc 95.388%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.155 Acc 95.363%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.155 Acc 95.320%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.220 Acc 95.305%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.208 Acc 95.367%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.290 Acc 89.062%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.143 Acc 95.661%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.150 Acc 95.464%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.153 Acc 95.396%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.153 Acc 95.400%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.154 Acc 95.387%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.233 Acc 95.034%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.220 Acc 95.227%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.145 Acc 95.722%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.152 Acc 95.398%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.154 Acc 95.320%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.153 Acc 95.307%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.156 Acc 95.233%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.224 Acc 95.367%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.214 Acc 95.464%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.148 Acc 95.452%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.152 Acc 95.382%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.151 Acc 95.427%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.154 Acc 95.363%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.153 Acc 95.361%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.211 Acc 95.150%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.199 Acc 95.351%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.137 Acc 95.568%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.144 Acc 95.441%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.145 Acc 95.476%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.150 Acc 95.361%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.152 Acc 95.314%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.246 Acc 90.625%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.213 Acc 95.050%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.204 Acc 95.180%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.173 Acc 93.750%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.142 Acc 95.753%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.145 Acc 95.585%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.147 Acc 95.538%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.150 Acc 95.424%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.151 Acc 95.434%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.223 Acc 93.750%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.220 Acc 95.297%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.210 Acc 95.305%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.124 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.148 Acc 95.459%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.147 Acc 95.456%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.149 Acc 95.409%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.149 Acc 95.412%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.148 Acc 95.454%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.327 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.212 Acc 95.258%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.205 Acc 95.386%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.161 Acc 95.243%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.155 Acc 95.250%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.153 Acc 95.307%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.154 Acc 95.277%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.156 Acc 95.186%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.225 Acc 95.413%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.213 Acc 95.631%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.144 Acc 95.529%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.147 Acc 95.425%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.153 Acc 95.305%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.149 Acc 95.357%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.150 Acc 95.386%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.229 Acc 94.848%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.217 Acc 94.920%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.151 Acc 95.498%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.156 Acc 95.332%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.153 Acc 95.357%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.151 Acc 95.406%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.152 Acc 95.395%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.236 Acc 95.073%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.228 Acc 95.180%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.148 Acc 95.445%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.144 Acc 95.541%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.147 Acc 95.496%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.148 Acc 95.479%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.250 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.227 Acc 95.080%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.218 Acc 95.239%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.150 Acc 95.390%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.152 Acc 95.287%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.153 Acc 95.235%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.151 Acc 95.334%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.253 Acc 92.969%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.271 Acc 94.346%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.261 Acc 94.446%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.233 Acc 92.969%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.141 Acc 95.591%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.145 Acc 95.596%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.147 Acc 95.551%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.149 Acc 95.498%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.150 Acc 95.437%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.316 Acc 91.406%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.241 Acc 95.390%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.230 Acc 95.394%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.189 Acc 93.750%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.156 Acc 95.042%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.151 Acc 95.301%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.148 Acc 95.424%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.149 Acc 95.400%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.152 Acc 95.322%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.253 Acc 94.918%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.242 Acc 94.920%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.148 Acc 95.398%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.147 Acc 95.406%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.152 Acc 95.393%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.151 Acc 95.422%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.151 Acc 95.409%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.179 Acc 96.875%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.211 Acc 95.429%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.203 Acc 95.460%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.257 Acc 92.188%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.151 Acc 95.436%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.148 Acc 95.449%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.148 Acc 95.463%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.151 Acc 95.373%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.153 Acc 95.328%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.230 Acc 95.104%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.220 Acc 95.254%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.150 Acc 95.436%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.148 Acc 95.445%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.150 Acc 95.429%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.152 Acc 95.396%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.151 Acc 95.401%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.311 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.228 Acc 95.196%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.218 Acc 95.274%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.139 Acc 95.769%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.139 Acc 95.763%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.145 Acc 95.616%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.146 Acc 95.515%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.147 Acc 95.498%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.267 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.233 Acc 95.552%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.220 Acc 95.725%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.138 Acc 95.769%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.146 Acc 95.491%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.146 Acc 95.471%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.146 Acc 95.500%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.149 Acc 95.443%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.313 Acc 92.188%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.253 Acc 94.972%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.241 Acc 95.145%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.129 Acc 95.815%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.141 Acc 95.530%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.144 Acc 95.492%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.146 Acc 95.503%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.147 Acc 95.459%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.272 Acc 90.625%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.232 Acc 95.011%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.215 Acc 95.188%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.206 Acc 92.969%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.155 Acc 94.988%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.156 Acc 95.200%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.155 Acc 95.235%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.152 Acc 95.324%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.153 Acc 95.319%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.301 Acc 91.406%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.258 Acc 94.872%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.244 Acc 94.959%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.142 Acc 95.653%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.147 Acc 95.449%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.154 Acc 95.285%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.153 Acc 95.328%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.274 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.218 Acc 95.204%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.209 Acc 95.285%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.134 Acc 95.715%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.140 Acc 95.655%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.146 Acc 95.453%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.147 Acc 95.427%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.150 Acc 95.367%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.328 Acc 91.406%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.237 Acc 94.918%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.220 Acc 95.072%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.137 Acc 95.862%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.139 Acc 95.826%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.142 Acc 95.668%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.144 Acc 95.642%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.144 Acc 95.587%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.238 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.233 Acc 95.227%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.221 Acc 95.367%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.138 Acc 95.761%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.138 Acc 95.658%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.146 Acc 95.518%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.148 Acc 95.463%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.150 Acc 95.406%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.286 Acc 93.750%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.231 Acc 95.080%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.218 Acc 95.258%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.398 Acc 92.188%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.149 Acc 95.374%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.147 Acc 95.519%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.146 Acc 95.523%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.148 Acc 95.490%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.146 Acc 95.504%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.226 Acc 95.065%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.214 Acc 95.250%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.144 Acc 95.715%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.142 Acc 95.693%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.142 Acc 95.614%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.146 Acc 95.476%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.148 Acc 95.420%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.256 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.225 Acc 95.282%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.216 Acc 95.332%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.143 Acc 93.750%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.146 Acc 95.413%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.146 Acc 95.484%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.143 Acc 95.588%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.148 Acc 95.519%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.149 Acc 95.512%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.229 Acc 95.289%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.218 Acc 95.367%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.149 Acc 95.575%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.145 Acc 95.651%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.145 Acc 95.598%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.145 Acc 95.603%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.146 Acc 95.595%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.258 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.212 Acc 95.467%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.487%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.146 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.141 Acc 95.552%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.139 Acc 95.647%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.141 Acc 95.712%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.144 Acc 95.603%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.145 Acc 95.613%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.244 Acc 94.972%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.236 Acc 95.138%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.151 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.148 Acc 95.444%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.150 Acc 95.328%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.145 Acc 95.523%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.149 Acc 95.461%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.149 Acc 95.451%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.251 Acc 93.750%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.226 Acc 94.957%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.217 Acc 95.103%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.154 Acc 95.390%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.154 Acc 95.301%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.150 Acc 95.401%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.150 Acc 95.422%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.150 Acc 95.406%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.258 Acc 95.243%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.240 Acc 95.347%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.207 Acc 96.094%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.130 Acc 96.024%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.139 Acc 95.771%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.141 Acc 95.681%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.143 Acc 95.675%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.145 Acc 95.613%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.247 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.237 Acc 95.073%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.227 Acc 95.250%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.265 Acc 92.969%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.140 Acc 95.637%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.146 Acc 95.445%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.144 Acc 95.520%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.146 Acc 95.494%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.148 Acc 95.428%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.228 Acc 95.166%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.215 Acc 95.355%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.147 Acc 95.374%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.148 Acc 95.402%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.147 Acc 95.401%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.147 Acc 95.443%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.146 Acc 95.481%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.277 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.231 Acc 95.328%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.220 Acc 95.487%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.137 Acc 95.753%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.145 Acc 95.530%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.149 Acc 95.440%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.150 Acc 95.402%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.150 Acc 95.439%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.282 Acc 92.188%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.252 Acc 94.609%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.238 Acc 94.799%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.148 Acc 95.490%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.149 Acc 95.394%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.146 Acc 95.531%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.147 Acc 95.492%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.147 Acc 95.458%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.235 Acc 94.864%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.223 Acc 95.040%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.128 Acc 93.750%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.143 Acc 95.490%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.142 Acc 95.526%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.143 Acc 95.582%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.145 Acc 95.490%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.146 Acc 95.470%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.230 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.230 Acc 95.398%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.215 Acc 95.620%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.129 Acc 94.531%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.141 Acc 95.452%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.140 Acc 95.608%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.146 Acc 95.486%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.147 Acc 95.433%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.148 Acc 95.451%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.286 Acc 92.969%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.267 Acc 94.663%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.252 Acc 94.819%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.138 Acc 95.676%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.142 Acc 95.623%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.144 Acc 95.593%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.144 Acc 95.605%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.145 Acc 95.578%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.285 Acc 93.750%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.253 Acc 94.964%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.245 Acc 95.002%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.134 Acc 95.769%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.136 Acc 95.756%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.138 Acc 95.730%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.141 Acc 95.618%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.145 Acc 95.514%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.224 Acc 94.670%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.215 Acc 94.885%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.135 Acc 95.993%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.145 Acc 95.655%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.146 Acc 95.554%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.146 Acc 95.484%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.148 Acc 95.428%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.218 Acc 95.413%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.206 Acc 95.402%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.145 Acc 95.622%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.145 Acc 95.581%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.148 Acc 95.554%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.146 Acc 95.576%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.148 Acc 95.528%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.252 Acc 92.188%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.253 Acc 94.841%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.239 Acc 94.881%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.138 Acc 95.761%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.145 Acc 95.468%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.145 Acc 95.440%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.147 Acc 95.439%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.147 Acc 95.423%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.267 Acc 94.864%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.253 Acc 95.138%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.132 Acc 95.815%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.141 Acc 95.585%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.144 Acc 95.489%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.145 Acc 95.463%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.146 Acc 95.420%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.253 Acc 94.531%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.229 Acc 95.297%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.222 Acc 95.281%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.142 Acc 95.645%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.141 Acc 95.623%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.144 Acc 95.523%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.146 Acc 95.470%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.145 Acc 95.498%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.271 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.236 Acc 95.150%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.226 Acc 95.281%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.100 Acc 95.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.131 Acc 95.738%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.136 Acc 95.728%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.144 Acc 95.535%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.147 Acc 95.443%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.263 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.220 Acc 95.266%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.208 Acc 95.437%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.134 Acc 95.939%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.139 Acc 95.861%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.143 Acc 95.665%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.147 Acc 95.521%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.146 Acc 95.512%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.231 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.211 Acc 95.212%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.199 Acc 95.460%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.264 Acc 90.625%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.142 Acc 95.661%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.144 Acc 95.596%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.144 Acc 95.601%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.147 Acc 95.496%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.146 Acc 95.531%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.307 Acc 92.969%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.254 Acc 94.756%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.245 Acc 94.924%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.145 Acc 95.452%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.143 Acc 95.616%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.146 Acc 95.590%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.147 Acc 95.523%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.145 Acc 95.520%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.323 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.233 Acc 94.802%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.225 Acc 94.924%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.138 Acc 95.591%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.142 Acc 95.577%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.144 Acc 95.479%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.144 Acc 95.488%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.145 Acc 95.489%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.287 Acc 92.969%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.250 Acc 95.104%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.239 Acc 95.355%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.241 Acc 94.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.146 Acc 95.537%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.149 Acc 95.371%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.146 Acc 95.476%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.144 Acc 95.509%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.145 Acc 95.521%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.235 Acc 94.841%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.229 Acc 94.998%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.155 Acc 95.258%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.145 Acc 95.495%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.146 Acc 95.479%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.147 Acc 95.478%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.146 Acc 95.515%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.337 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.248 Acc 95.111%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.236 Acc 95.153%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.139 Acc 95.645%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.137 Acc 95.744%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.140 Acc 95.686%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.143 Acc 95.640%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.142 Acc 95.623%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.253 Acc 92.188%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.230 Acc 94.864%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.217 Acc 94.986%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.147 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.139 Acc 95.715%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.138 Acc 95.759%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.139 Acc 95.767%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.139 Acc 95.735%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.140 Acc 95.705%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.252 Acc 93.750%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.259 Acc 94.895%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.245 Acc 94.986%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.140 Acc 95.777%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.146 Acc 95.530%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.148 Acc 95.437%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.146 Acc 95.449%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.147 Acc 95.439%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.245 Acc 94.980%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.238 Acc 95.002%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.133 Acc 96.875%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.149 Acc 95.150%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.144 Acc 95.246%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.146 Acc 95.266%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.145 Acc 95.348%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.146 Acc 95.367%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.251 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.264 Acc 94.717%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.252 Acc 94.796%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.138 Acc 95.436%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.144 Acc 95.367%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.142 Acc 95.471%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.143 Acc 95.463%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.142 Acc 95.537%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.305 Acc 94.531%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.237 Acc 95.258%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.228 Acc 95.449%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.153 Acc 94.531%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.143 Acc 95.459%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.138 Acc 95.573%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.144 Acc 95.463%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.143 Acc 95.474%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.143 Acc 95.481%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.278 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.245 Acc 95.181%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.232 Acc 95.235%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.141 Acc 92.188%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.150 Acc 95.351%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.146 Acc 95.526%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.142 Acc 95.653%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.143 Acc 95.587%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.144 Acc 95.556%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.240 Acc 93.750%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.229 Acc 95.251%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.213 Acc 95.507%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.132 Acc 95.962%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.132 Acc 95.896%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.139 Acc 95.668%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.142 Acc 95.626%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.144 Acc 95.607%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.237 Acc 95.227%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.223 Acc 95.363%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.179 Acc 96.094%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.132 Acc 95.939%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.136 Acc 95.849%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.143 Acc 95.653%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.146 Acc 95.546%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.147 Acc 95.534%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.265 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.243 Acc 95.019%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.226 Acc 95.211%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.135 Acc 95.846%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.142 Acc 95.647%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.142 Acc 95.567%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.142 Acc 95.550%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.144 Acc 95.498%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.195 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.244 Acc 95.034%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.232 Acc 95.196%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.272 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.136 Acc 95.614%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.137 Acc 95.767%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.137 Acc 95.790%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.139 Acc 95.718%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.140 Acc 95.712%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.255 Acc 94.802%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.243 Acc 94.834%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.141 Acc 95.728%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.140 Acc 95.751%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.141 Acc 95.679%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.140 Acc 95.715%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.251 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.254 Acc 95.382%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.239 Acc 95.491%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd442e70148474499c761bba69a6c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.355 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.219 Acc 19.601%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.057 Acc 25.610%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.875 Acc 32.254%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.691 Acc 39.955%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.522 Acc 47.006%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.546 Acc 85.938%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.550 Acc 83.601%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.541 Acc 83.835%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.623 Acc 82.812%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.583 Acc 82.689%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.536 Acc 84.227%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.512 Acc 84.892%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.489 Acc 85.622%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.471 Acc 86.093%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.375 Acc 85.938%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.357 Acc 89.264%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.355 Acc 89.199%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.459 Acc 87.500%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.377 Acc 88.591%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.362 Acc 89.043%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.358 Acc 89.239%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.356 Acc 89.238%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.354 Acc 89.370%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.362 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.353 Acc 88.962%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.345 Acc 89.300%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.326 Acc 89.062%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.325 Acc 90.037%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.312 Acc 90.629%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.312 Acc 90.604%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.313 Acc 90.594%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.311 Acc 90.662%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.337 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.291 Acc 91.399%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.285 Acc 91.500%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.310 Acc 92.969%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.300 Acc 91.205%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.297 Acc 91.266%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.292 Acc 91.365%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.290 Acc 91.414%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.287 Acc 91.466%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.288 Acc 92.188%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.274 Acc 91.917%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.275 Acc 91.954%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.329 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.265 Acc 92.048%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.266 Acc 91.880%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.266 Acc 91.969%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.270 Acc 91.870%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.269 Acc 91.913%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.320 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.250 Acc 92.930%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.241 Acc 93.167%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.225 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.257 Acc 92.311%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.255 Acc 92.390%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.255 Acc 92.343%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.256 Acc 92.330%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.257 Acc 92.312%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.288 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.252 Acc 92.791%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.245 Acc 92.953%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.248 Acc 92.342%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.251 Acc 92.327%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.248 Acc 92.517%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.248 Acc 92.643%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.248 Acc 92.646%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.236 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.228 Acc 93.588%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.224 Acc 93.610%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.355 Acc 88.281%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.235 Acc 92.721%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.240 Acc 92.833%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.239 Acc 92.834%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.241 Acc 92.747%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.242 Acc 92.785%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.281 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.203 Acc 94.268%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.202 Acc 94.457%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.187 Acc 95.312%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.235 Acc 93.108%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.238 Acc 92.957%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.240 Acc 92.990%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.239 Acc 93.025%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.236 Acc 93.079%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.176 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.191 Acc 94.756%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.186 Acc 94.862%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.274 Acc 93.750%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.218 Acc 93.619%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.222 Acc 93.575%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.229 Acc 93.317%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.231 Acc 93.236%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.227 Acc 93.312%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.301 Acc 90.625%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.220 Acc 93.959%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.216 Acc 93.995%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.227 Acc 93.278%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.224 Acc 93.334%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.222 Acc 93.410%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.222 Acc 93.415%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.222 Acc 93.410%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.167 Acc 92.969%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.196 Acc 94.701%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.189 Acc 94.877%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.186 Acc 96.094%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.219 Acc 93.773%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.218 Acc 93.591%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.218 Acc 93.633%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.219 Acc 93.596%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.217 Acc 93.617%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.202 Acc 94.462%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.197 Acc 94.605%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.209 Acc 93.928%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.211 Acc 93.820%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.210 Acc 93.815%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.212 Acc 93.816%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.215 Acc 93.752%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.213 Acc 94.152%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.209 Acc 94.267%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.314 Acc 92.188%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.200 Acc 93.881%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.207 Acc 93.804%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.209 Acc 93.755%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.208 Acc 93.832%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.208 Acc 93.876%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.245 Acc 92.188%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.189 Acc 94.694%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.183 Acc 94.928%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.094 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.207 Acc 93.796%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.208 Acc 93.882%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.205 Acc 94.015%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.206 Acc 93.970%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.205 Acc 93.984%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.204 Acc 94.330%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.203 Acc 94.255%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.193 Acc 94.446%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.198 Acc 94.302%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.201 Acc 94.163%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.202 Acc 94.107%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.203 Acc 94.110%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.233 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.188 Acc 94.988%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.186 Acc 95.048%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.207 Acc 91.406%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.204 Acc 93.998%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.201 Acc 94.197%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.197 Acc 94.324%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.197 Acc 94.218%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.198 Acc 94.205%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.206 Acc 93.750%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.198 Acc 94.825%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.192 Acc 94.939%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.181 Acc 94.686%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.190 Acc 94.403%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.193 Acc 94.339%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.193 Acc 94.344%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.195 Acc 94.343%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.179 Acc 95.227%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.174 Acc 95.359%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.244 Acc 92.188%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.192 Acc 94.407%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.191 Acc 94.465%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.191 Acc 94.459%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.193 Acc 94.424%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.195 Acc 94.325%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.195 Acc 94.469%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.188 Acc 94.698%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.326 Acc 92.969%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.187 Acc 94.709%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.193 Acc 94.504%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.189 Acc 94.586%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.191 Acc 94.518%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.191 Acc 94.486%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.191 Acc 94.810%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.187 Acc 94.974%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.178 Acc 94.957%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.181 Acc 94.761%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.187 Acc 94.570%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.188 Acc 94.533%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.190 Acc 94.488%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.152 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.167 Acc 95.583%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.163 Acc 95.658%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.227 Acc 92.188%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.180 Acc 94.949%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.185 Acc 94.687%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.184 Acc 94.677%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.183 Acc 94.677%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.182 Acc 94.721%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.174 Acc 95.382%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.168 Acc 95.515%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.287 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.181 Acc 94.725%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.175 Acc 94.904%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.176 Acc 94.884%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.182 Acc 94.672%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.182 Acc 94.714%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.229 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.170 Acc 95.506%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.168 Acc 95.639%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.179 Acc 94.841%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.176 Acc 95.040%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.177 Acc 94.928%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.180 Acc 94.823%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.181 Acc 94.834%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.171 Acc 95.359%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.165 Acc 95.596%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.184 Acc 94.701%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.173 Acc 94.970%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.173 Acc 94.944%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.175 Acc 94.864%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.175 Acc 94.898%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.204 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.174 Acc 95.243%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.167 Acc 95.503%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.161 Acc 97.656%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.180 Acc 94.686%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.177 Acc 94.846%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.179 Acc 94.830%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.179 Acc 94.866%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.177 Acc 94.909%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.185 Acc 95.282%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.402%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.199 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.180 Acc 94.794%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.175 Acc 95.130%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.176 Acc 95.045%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.173 Acc 95.094%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.173 Acc 95.072%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.182 Acc 95.251%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.192 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.171 Acc 94.941%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.172 Acc 94.877%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.172 Acc 94.996%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.173 Acc 94.962%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.172 Acc 95.013%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.172 Acc 95.467%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.201 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.165 Acc 95.452%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.171 Acc 95.184%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.172 Acc 95.056%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.174 Acc 95.003%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.173 Acc 95.046%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.171 Acc 95.483%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.164 Acc 95.756%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.164 Acc 93.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.168 Acc 95.297%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.163 Acc 95.340%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.164 Acc 95.385%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.167 Acc 95.221%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.168 Acc 95.216%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.180 Acc 95.405%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.173 Acc 95.546%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.162 Acc 95.359%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.163 Acc 95.208%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.167 Acc 95.120%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.168 Acc 95.094%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.168 Acc 95.082%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.168 Acc 95.529%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.162 Acc 95.717%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.148 Acc 95.769%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.153 Acc 95.600%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.158 Acc 95.486%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.163 Acc 95.383%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.165 Acc 95.323%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.177 Acc 95.429%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.171 Acc 95.464%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.157 Acc 95.425%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.164 Acc 95.281%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.244%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.164 Acc 95.288%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.170 Acc 95.467%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.164 Acc 95.627%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.157 Acc 95.402%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.159 Acc 95.427%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.160 Acc 95.411%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.171 Acc 95.498%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.169 Acc 95.507%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.170 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.155 Acc 95.846%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.155 Acc 95.771%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.162 Acc 95.512%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.160 Acc 95.511%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.159 Acc 95.475%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.125 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.175 Acc 95.467%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.148 Acc 95.622%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.160 Acc 95.292%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.162 Acc 95.246%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.160 Acc 95.292%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.363%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.226 Acc 92.969%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.141 Acc 95.823%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.149 Acc 95.639%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.155 Acc 95.515%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.155 Acc 95.540%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.156 Acc 95.546%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.146 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.168 Acc 95.583%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.164 Acc 95.775%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.149 Acc 95.599%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.157 Acc 95.414%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.154 Acc 95.492%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.155 Acc 95.468%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.155 Acc 95.436%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.170 Acc 95.637%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.164 Acc 95.697%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.197 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.149 Acc 95.877%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.151 Acc 95.562%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.152 Acc 95.531%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.154 Acc 95.534%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.194 Acc 91.406%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.175 Acc 95.459%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.168 Acc 95.639%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.074 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.160 Acc 95.483%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.159 Acc 95.410%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.153 Acc 95.572%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.155 Acc 95.548%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.155 Acc 95.501%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.162 Acc 95.746%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.157 Acc 95.993%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.189 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.149 Acc 95.877%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.156 Acc 95.705%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.154 Acc 95.624%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.155 Acc 95.665%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.153 Acc 95.670%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.170 Acc 95.575%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.162 Acc 95.756%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.151 Acc 95.815%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.147 Acc 95.899%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.147 Acc 95.891%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.150 Acc 95.766%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.150 Acc 95.766%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.240 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.173 Acc 95.715%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.167 Acc 95.845%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.142 Acc 95.908%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.149 Acc 95.736%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.148 Acc 95.746%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.149 Acc 95.704%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.150 Acc 95.702%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.171 Acc 95.467%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.167 Acc 95.585%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.144 Acc 95.630%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.144 Acc 95.814%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.147 Acc 95.761%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.148 Acc 95.721%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.169 Acc 95.653%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.163 Acc 95.802%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.147 Acc 95.924%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.148 Acc 95.818%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.148 Acc 95.803%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.149 Acc 95.835%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.149 Acc 95.762%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.160 Acc 95.838%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.157 Acc 95.934%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.133 Acc 96.156%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.138 Acc 96.000%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.140 Acc 95.967%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.143 Acc 95.829%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.146 Acc 95.774%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.180 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.166 Acc 95.831%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.163 Acc 95.853%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.144 Acc 95.864%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.147 Acc 95.860%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.144 Acc 95.879%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.145 Acc 95.838%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.113 Acc 94.531%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.161 Acc 95.792%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.156 Acc 96.032%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.144 Acc 95.970%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.145 Acc 95.837%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.146 Acc 95.808%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.144 Acc 95.876%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.144 Acc 95.821%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.167 Acc 95.777%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.163 Acc 95.845%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.135 Acc 96.071%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.138 Acc 95.997%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.139 Acc 95.972%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.141 Acc 95.926%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.143 Acc 95.894%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.170 Acc 95.753%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.166 Acc 95.899%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.136 Acc 95.939%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.139 Acc 96.004%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.139 Acc 96.024%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.139 Acc 95.955%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.178 Acc 95.374%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.171 Acc 95.460%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.129 Acc 96.395%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.130 Acc 96.393%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.137 Acc 96.174%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.140 Acc 96.020%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.140 Acc 95.958%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.161 Acc 95.893%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.157 Acc 96.028%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.137 Acc 95.972%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.137 Acc 95.963%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.140 Acc 95.913%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.170 Acc 95.568%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.165 Acc 95.732%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.134 Acc 96.016%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.138 Acc 96.043%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.138 Acc 96.029%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.138 Acc 95.977%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.137 Acc 95.986%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.166 Acc 95.862%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.162 Acc 95.903%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.122 Acc 96.550%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.131 Acc 96.172%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.135 Acc 96.061%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.137 Acc 96.013%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.167 Acc 95.808%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.162 Acc 95.880%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.159 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.136 Acc 96.132%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.138 Acc 95.948%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.139 Acc 95.983%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.138 Acc 96.013%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.167 Acc 95.916%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.162 Acc 96.024%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.256 Acc 96.094%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.129 Acc 96.542%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.129 Acc 96.339%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.132 Acc 96.199%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.133 Acc 96.181%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.164 Acc 95.900%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.159 Acc 95.993%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.139 Acc 95.924%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.131 Acc 96.151%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.131 Acc 96.150%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.131 Acc 96.123%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.171 Acc 95.738%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.775%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.131 Acc 96.253%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.131 Acc 96.226%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.132 Acc 96.218%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.134 Acc 96.155%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.162 Acc 95.815%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.158 Acc 96.020%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.126 Acc 96.527%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.127 Acc 96.374%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.129 Acc 96.237%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.131 Acc 96.168%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.132 Acc 96.125%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.167 Acc 95.761%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.163 Acc 95.934%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.120 Acc 96.612%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.122 Acc 96.471%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.124 Acc 96.416%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.126 Acc 96.347%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.130 Acc 96.267%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.305%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.178 Acc 95.410%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.128 Acc 96.187%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.130 Acc 96.098%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.133 Acc 96.045%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.133 Acc 96.067%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.164 Acc 95.877%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.161 Acc 95.985%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.127 Acc 93.750%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.131 Acc 96.248%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.126 Acc 96.319%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.128 Acc 96.234%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.128 Acc 96.203%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.129 Acc 96.195%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.157 Acc 96.163%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.154 Acc 96.226%\n",
      "Saving..\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.115 Acc 96.782%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.121 Acc 96.657%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.123 Acc 96.574%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.126 Acc 96.480%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.127 Acc 96.409%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.174 Acc 95.676%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.168 Acc 95.802%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.110 Acc 98.438%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.122 Acc 96.519%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.123 Acc 96.502%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.124 Acc 96.356%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.127 Acc 96.291%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.127 Acc 96.296%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.134 Acc 97.656%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.168 Acc 95.931%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.126 Acc 96.295%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.126 Acc 96.311%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.124 Acc 96.379%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.286%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.104 Acc 96.875%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.162 Acc 96.001%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.161 Acc 96.067%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.125 Acc 96.381%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.128 Acc 96.356%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.127 Acc 96.285%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.128 Acc 96.254%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.178 Acc 95.599%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.172 Acc 95.682%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.115 Acc 96.682%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.115 Acc 96.653%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.119 Acc 96.543%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.124 Acc 96.376%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.168 Acc 95.738%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.164 Acc 95.919%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.109 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.122 Acc 96.411%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.124 Acc 96.471%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.125 Acc 96.343%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.126 Acc 96.308%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.126 Acc 96.334%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.178 Acc 95.753%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.752%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.120 Acc 96.357%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.119 Acc 96.389%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.119 Acc 96.418%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.122 Acc 96.355%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.125 Acc 96.307%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.172 Acc 95.746%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.166 Acc 95.880%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.103 Acc 94.531%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.133 Acc 96.009%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.124 Acc 96.346%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.123 Acc 96.394%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.126 Acc 96.326%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.172 Acc 95.748%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.114 Acc 96.697%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.114 Acc 96.685%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.116 Acc 96.626%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.117 Acc 96.542%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.118 Acc 96.510%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.134 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.176 Acc 95.552%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.171 Acc 95.721%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.115 Acc 96.581%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.118 Acc 96.486%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.121 Acc 96.384%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.122 Acc 96.399%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.167 Acc 95.837%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.108 Acc 96.867%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.110 Acc 96.782%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.113 Acc 96.701%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.116 Acc 96.668%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.119 Acc 96.579%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.172 Acc 95.955%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.114 Acc 96.716%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.117 Acc 96.649%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.118 Acc 96.604%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.120 Acc 96.526%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.761%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.169 Acc 95.810%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.114 Acc 96.813%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.115 Acc 96.743%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.118 Acc 96.621%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.118 Acc 96.614%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.119 Acc 96.530%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.086 Acc 97.656%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.167 Acc 95.838%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.162 Acc 95.997%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.212 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.115 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.114 Acc 96.618%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.116 Acc 96.584%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.117 Acc 96.544%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.118 Acc 96.540%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.156 Acc 96.248%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.153 Acc 96.343%\n",
      "Saving..\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.110 Acc 96.744%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.113 Acc 96.704%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.114 Acc 96.696%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.114 Acc 96.670%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.115 Acc 96.636%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.168 Acc 95.777%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.164 Acc 95.911%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.161 Acc 95.312%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.118 Acc 96.434%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.117 Acc 96.486%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.117 Acc 96.506%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.118 Acc 96.516%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.164 Acc 95.931%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.162 Acc 95.969%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.117 Acc 96.589%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.113 Acc 96.735%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.114 Acc 96.717%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.114 Acc 96.698%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.115 Acc 96.619%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.171 Acc 95.777%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.896%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.126 Acc 93.750%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.112 Acc 96.697%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.111 Acc 96.797%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.112 Acc 96.645%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.114 Acc 96.593%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.075 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.161 Acc 96.070%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.107 Acc 96.770%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.109 Acc 96.670%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.606%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.114 Acc 96.568%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.101 Acc 97.656%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.171 Acc 95.767%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.108 Acc 96.852%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.110 Acc 96.800%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.111 Acc 96.709%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.115 Acc 96.613%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.170 Acc 95.854%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.165 Acc 96.000%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.161 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.100 Acc 97.107%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.109 Acc 96.848%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.112 Acc 96.727%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.114 Acc 96.647%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.114 Acc 96.666%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.161 Acc 95.993%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.160 Acc 96.035%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.145 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.108 Acc 96.744%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.109 Acc 96.832%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.107 Acc 96.836%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.112 Acc 96.716%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.170 Acc 96.009%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.164 Acc 96.082%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.114 Acc 96.364%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.118 Acc 96.447%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.119 Acc 96.447%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.118 Acc 96.439%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.117 Acc 96.470%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.169 Acc 95.800%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.166 Acc 95.880%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.031 Acc 100.000%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.104 Acc 96.728%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.108 Acc 96.751%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.110 Acc 96.667%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.112 Acc 96.631%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.113 Acc 96.594%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.167 Acc 96.071%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.163 Acc 96.210%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.069 Acc 99.219%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.104 Acc 96.960%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.110 Acc 96.727%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.113 Acc 96.614%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.115 Acc 96.576%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.177 Acc 95.753%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.170 Acc 95.899%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.231 Acc 93.750%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.102 Acc 96.952%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.103 Acc 96.949%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.103 Acc 96.927%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.108 Acc 96.764%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.110 Acc 96.683%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.174 Acc 95.684%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.170 Acc 95.845%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.102 Acc 96.736%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.108 Acc 96.771%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.108 Acc 96.780%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.107 Acc 96.824%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.172 Acc 95.903%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.146 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.105 Acc 96.759%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.102 Acc 96.840%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.105 Acc 96.828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.107 Acc 96.768%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.108 Acc 96.718%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.172 Acc 95.815%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.166 Acc 95.969%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.104 Acc 96.689%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.105 Acc 96.786%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.105 Acc 96.787%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.107 Acc 96.799%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.108 Acc 96.750%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.178 Acc 95.429%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.095 Acc 97.146%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.106 Acc 96.863%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.107 Acc 96.805%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.091 Acc 96.875%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.169 Acc 95.831%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.165 Acc 96.059%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.098 Acc 97.045%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.100 Acc 96.961%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.106 Acc 96.820%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.107 Acc 96.811%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.175 Acc 95.924%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.168 Acc 95.969%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.075 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.100 Acc 97.045%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.099 Acc 97.100%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.101 Acc 97.039%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.103 Acc 97.021%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.106 Acc 96.905%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.171 Acc 95.985%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.167 Acc 96.020%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.099 Acc 97.061%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.102 Acc 97.042%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.104 Acc 97.015%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.102 Acc 96.996%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.103 Acc 96.990%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.086 Acc 97.656%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.173 Acc 95.831%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.167 Acc 96.020%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.104 Acc 96.976%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.102 Acc 97.054%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.103 Acc 97.018%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.103 Acc 96.984%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.105 Acc 96.887%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.170 Acc 95.919%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.102 Acc 96.860%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.103 Acc 96.856%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.104 Acc 96.839%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.104 Acc 96.857%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.105 Acc 96.852%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.171 Acc 96.001%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.166 Acc 96.113%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.105 Acc 96.929%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.102 Acc 96.968%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.103 Acc 96.889%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.104 Acc 96.847%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.181 Acc 95.846%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.179 Acc 95.771%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.106 Acc 96.960%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.103 Acc 96.941%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.107 Acc 96.810%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.104 Acc 96.894%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.104 Acc 96.902%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.175 Acc 95.838%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.172 Acc 95.919%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.100 Acc 97.192%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.104 Acc 96.941%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.104 Acc 96.883%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.102 Acc 96.928%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.173 Acc 95.916%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.169 Acc 96.047%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.098 Acc 97.099%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.099 Acc 97.072%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.101 Acc 97.035%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.102 Acc 97.009%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.166 Acc 96.063%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.161 Acc 96.148%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.098 Acc 97.061%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.098 Acc 97.030%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.099 Acc 97.005%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.100 Acc 96.972%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.101 Acc 96.956%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.869%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 95.942%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.100 Acc 97.076%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.101 Acc 97.085%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.099 Acc 97.127%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.102 Acc 97.021%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.103 Acc 96.955%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.071 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.173 Acc 95.761%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.171 Acc 95.779%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.093 Acc 97.192%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.097 Acc 97.089%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.099 Acc 96.949%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.100 Acc 96.939%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.099 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.183 Acc 95.784%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.178 Acc 95.829%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.136 Acc 94.531%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.097 Acc 96.906%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.098 Acc 96.937%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.098 Acc 97.044%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.098 Acc 97.043%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [105/200]Batch [500/573] Loss: 0.100 Acc 97.026%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.179 Acc 95.792%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.173 Acc 95.892%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.105 Acc 96.929%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.104 Acc 96.867%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.101 Acc 96.898%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.101 Acc 96.916%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.101 Acc 96.958%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.175 Acc 95.893%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.170 Acc 95.896%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.095 Acc 97.092%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.096 Acc 97.046%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.098 Acc 97.013%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.099 Acc 97.007%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.098 Acc 96.995%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.160 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.180 Acc 95.537%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.176 Acc 95.682%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.100 Acc 97.022%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.095 Acc 97.112%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.097 Acc 97.067%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.098 Acc 97.048%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.100 Acc 96.978%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.173 Acc 95.877%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.169 Acc 95.907%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.103 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.099 Acc 97.014%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.097 Acc 97.030%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.097 Acc 97.059%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.167 Acc 95.993%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.059 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.096 Acc 97.269%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.097 Acc 97.178%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.099 Acc 97.075%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.097 Acc 97.105%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.098 Acc 97.048%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.170 Acc 95.893%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.167 Acc 96.035%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.128 Acc 97.656%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.090 Acc 97.161%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.097 Acc 96.992%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.097 Acc 97.046%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.098 Acc 97.034%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.166 Acc 95.893%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.162 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.091 Acc 97.200%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.092 Acc 97.201%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.097 Acc 97.041%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.097 Acc 97.019%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.098 Acc 96.953%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 96.047%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.167 Acc 96.148%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.089 Acc 97.208%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.091 Acc 97.190%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.093 Acc 97.111%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.094 Acc 97.142%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.095 Acc 97.132%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.171 Acc 95.985%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.047 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.096 Acc 97.068%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.095 Acc 97.213%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.095 Acc 97.137%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.097 Acc 97.048%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.098 Acc 97.029%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.076 Acc 98.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.181 Acc 95.885%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.174 Acc 96.125%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.090 Acc 97.316%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.091 Acc 97.233%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.092 Acc 97.155%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.093 Acc 97.136%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.094 Acc 97.142%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.104 Acc 97.656%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 96.001%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.171 Acc 96.059%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.095 Acc 96.988%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.095 Acc 96.992%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.096 Acc 96.992%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.095 Acc 97.037%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.167 Acc 95.985%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.165 Acc 96.074%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.175 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.093 Acc 97.169%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.094 Acc 97.120%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.097 Acc 97.035%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.097 Acc 97.067%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.097 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.176 Acc 95.970%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 96.109%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.092 Acc 97.161%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.088 Acc 97.236%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.092 Acc 97.199%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.092 Acc 97.208%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.093 Acc 97.153%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.172 Acc 95.872%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.091 Acc 97.262%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.094 Acc 97.182%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.096 Acc 97.051%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.095 Acc 97.082%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.093 Acc 97.162%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.168 Acc 96.163%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.165 Acc 96.276%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.089 Acc 97.316%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.093 Acc 97.173%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.092 Acc 97.181%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.094 Acc 97.137%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.178 Acc 95.746%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.175 Acc 95.962%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.090 Acc 97.223%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.092 Acc 97.229%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.091 Acc 97.259%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.092 Acc 97.202%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.100 Acc 96.875%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.180 Acc 95.947%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.175 Acc 95.981%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.093 Acc 97.061%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.093 Acc 97.135%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.094 Acc 97.113%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.094 Acc 97.089%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.176 Acc 96.001%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.096 Acc 97.107%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.094 Acc 97.124%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.092 Acc 97.176%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.091 Acc 97.210%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.093 Acc 97.181%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.181 Acc 95.761%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.176 Acc 95.923%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.086 Acc 97.215%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.089 Acc 97.135%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.091 Acc 97.103%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.093 Acc 97.076%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.095 Acc 97.059%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.091 Acc 97.656%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.171 Acc 96.063%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 96.133%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.086 Acc 97.347%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.087 Acc 97.318%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.090 Acc 97.244%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.092 Acc 97.198%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.092 Acc 97.210%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.169 Acc 96.194%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.164 Acc 96.253%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.085 Acc 97.355%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.090 Acc 97.229%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.091 Acc 97.202%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.091 Acc 97.157%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.090 Acc 97.207%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.069 Acc 98.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.182 Acc 95.916%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.178 Acc 95.911%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.088 Acc 97.246%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.086 Acc 97.322%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.090 Acc 97.185%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.090 Acc 97.163%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.072 Acc 97.656%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.178 Acc 95.900%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.173 Acc 95.993%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.088 Acc 97.334%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.088 Acc 97.262%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.088 Acc 97.339%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.088 Acc 97.280%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.072 Acc 96.875%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.173 Acc 95.885%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.171 Acc 95.973%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.090 Acc 97.246%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.085 Acc 97.314%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.086 Acc 97.321%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.087 Acc 97.304%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.089 Acc 97.245%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.079 Acc 96.875%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.172 Acc 96.179%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.168 Acc 96.148%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.088 Acc 97.169%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.084 Acc 97.330%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.087 Acc 97.244%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.086 Acc 97.350%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.088 Acc 97.298%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.176 Acc 95.838%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.176 Acc 95.791%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.117 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.083 Acc 97.269%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.086 Acc 97.381%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.086 Acc 97.370%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.088 Acc 97.305%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.185 Acc 95.692%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.086 Acc 97.509%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.089 Acc 97.384%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.092 Acc 97.205%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.090 Acc 97.232%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.091 Acc 97.212%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.185 Acc 95.769%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.183 Acc 95.818%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.085 Acc 97.200%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.087 Acc 97.306%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.087 Acc 97.282%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.088 Acc 97.270%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.179 Acc 95.962%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.174 Acc 96.016%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.085 Acc 97.370%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.089 Acc 97.252%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.089 Acc 97.272%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.090 Acc 97.263%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.089 Acc 97.285%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.176 Acc 95.978%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.173 Acc 96.082%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.091 Acc 97.190%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.089 Acc 97.246%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.089 Acc 97.204%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.087 Acc 97.260%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.178 Acc 95.738%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.177 Acc 95.845%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.080 Acc 97.757%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.084 Acc 97.540%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.086 Acc 97.464%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.089 Acc 97.374%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.088 Acc 97.374%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.178 Acc 95.792%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.176 Acc 95.938%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.086 Acc 97.463%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.085 Acc 97.509%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.086 Acc 97.410%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.086 Acc 97.399%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.086 Acc 97.390%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.180 Acc 95.722%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.175 Acc 95.911%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.083 Acc 97.404%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.083 Acc 97.392%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.085 Acc 97.378%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.086 Acc 97.344%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.181 Acc 95.947%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.176 Acc 96.020%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.077 Acc 97.641%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.078 Acc 97.590%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.081 Acc 97.534%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.082 Acc 97.504%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.085 Acc 97.422%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.177 Acc 95.900%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.173 Acc 96.039%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.084 Acc 97.379%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.084 Acc 97.368%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.086 Acc 97.326%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.178 Acc 95.947%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.175 Acc 96.070%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.080 Acc 97.401%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.082 Acc 97.404%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.084 Acc 97.319%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.087 Acc 97.270%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.086 Acc 97.301%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.170 Acc 95.931%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.171 Acc 96.020%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.080 Acc 97.525%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.082 Acc 97.497%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.085 Acc 97.373%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.084 Acc 97.346%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.085 Acc 97.354%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.178 Acc 95.947%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.177 Acc 95.954%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.082 Acc 97.512%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.084 Acc 97.456%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.084 Acc 97.422%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.085 Acc 97.352%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.183 Acc 95.777%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.177 Acc 95.907%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.076 Acc 97.587%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.076 Acc 97.571%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.079 Acc 97.501%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.080 Acc 97.485%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.082 Acc 97.422%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.062 Acc 98.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.180 Acc 95.969%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.082 Acc 97.540%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.084 Acc 97.386%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.084 Acc 97.291%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.189 Acc 95.599%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.183 Acc 95.767%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.097 Acc 95.312%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.071 Acc 97.780%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.076 Acc 97.625%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.080 Acc 97.545%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.082 Acc 97.461%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.083 Acc 97.394%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.076 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.181 Acc 95.761%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.173 Acc 96.055%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.076 Acc 97.633%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.079 Acc 97.621%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.079 Acc 97.581%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.081 Acc 97.526%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.082 Acc 97.418%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.187 Acc 95.746%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.181 Acc 95.849%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.068 Acc 97.826%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.075 Acc 97.610%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.078 Acc 97.529%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.080 Acc 97.483%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.081 Acc 97.463%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.174 Acc 96.163%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.170 Acc 96.261%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.122 Acc 94.531%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.078 Acc 97.447%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.078 Acc 97.547%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.079 Acc 97.552%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.082 Acc 97.483%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.083 Acc 97.425%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.862%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 95.954%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.082 Acc 97.439%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.084 Acc 97.335%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.185 Acc 95.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.180 Acc 95.787%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.071 Acc 96.094%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.085 Acc 97.269%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.078 Acc 97.540%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.079 Acc 97.555%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.080 Acc 97.502%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.080 Acc 97.488%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.085 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.174 Acc 96.040%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.168 Acc 96.199%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.076 Acc 97.649%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.081 Acc 97.493%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.081 Acc 97.513%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.081 Acc 97.485%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.083 Acc 97.436%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.184 Acc 95.846%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.179 Acc 96.051%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.092 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.080 Acc 97.517%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.078 Acc 97.524%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.079 Acc 97.477%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.081 Acc 97.422%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.081 Acc 97.438%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.065 Acc 97.656%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.184 Acc 95.993%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.179 Acc 96.074%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.131 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.086 Acc 97.308%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.079 Acc 97.512%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.077 Acc 97.594%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.081 Acc 97.487%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.082 Acc 97.455%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.187 Acc 95.800%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.958%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.077 Acc 97.486%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.078 Acc 97.526%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.079 Acc 97.481%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.079 Acc 97.468%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.159 Acc 96.875%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.189 Acc 95.846%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.183 Acc 96.016%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.078 Acc 97.560%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.079 Acc 97.508%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.181 Acc 95.722%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.176 Acc 95.954%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.075 Acc 97.826%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.075 Acc 97.699%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.076 Acc 97.620%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.079 Acc 97.534%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.079 Acc 97.522%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.089 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.189 Acc 95.908%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.185 Acc 95.954%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.116 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.073 Acc 97.579%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.076 Acc 97.470%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.079 Acc 97.419%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.080 Acc 97.380%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.080 Acc 96.875%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.183 Acc 95.854%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.179 Acc 95.876%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.070 Acc 97.780%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.074 Acc 97.711%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.078 Acc 97.557%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.079 Acc 97.513%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.182 Acc 95.777%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.177 Acc 95.903%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.093 Acc 94.531%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.079 Acc 97.610%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.077 Acc 97.637%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.077 Acc 97.565%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.077 Acc 97.547%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.078 Acc 97.517%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.120 Acc 96.875%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.182 Acc 95.993%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.176 Acc 96.129%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.078 Acc 97.587%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.077 Acc 97.607%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.079 Acc 97.549%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.080 Acc 97.508%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.126 Acc 96.875%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.182 Acc 95.939%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.176 Acc 96.078%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.072 Acc 97.734%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.075 Acc 97.645%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.078 Acc 97.519%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.078 Acc 97.506%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.080 Acc 97.466%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.187 Acc 95.916%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.179 Acc 96.032%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.076 Acc 97.602%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.078 Acc 97.509%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.077 Acc 97.542%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.077 Acc 97.567%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.089 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.175 Acc 96.047%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.172 Acc 96.113%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.074 Acc 97.645%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.075 Acc 97.621%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.077 Acc 97.561%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.191 Acc 95.862%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.184 Acc 95.896%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.065 Acc 98.012%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.072 Acc 97.831%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.073 Acc 97.763%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.075 Acc 97.701%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.075 Acc 97.658%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.190 Acc 95.862%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.183 Acc 95.931%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.074 Acc 97.610%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.076 Acc 97.629%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.075 Acc 97.669%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.076 Acc 97.609%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.077 Acc 97.544%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.186 Acc 95.962%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.182 Acc 96.082%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.076 Acc 97.494%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.075 Acc 97.511%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.078 Acc 97.458%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.077 Acc 97.488%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.188 Acc 95.877%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.183 Acc 96.121%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.073 Acc 97.757%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.074 Acc 97.726%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.074 Acc 97.668%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.075 Acc 97.628%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.188 Acc 95.939%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.185 Acc 96.117%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.070 Acc 97.679%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.073 Acc 97.610%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.074 Acc 97.617%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.077 Acc 97.549%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.076 Acc 97.592%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.184 Acc 96.070%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.073 Acc 97.703%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.075 Acc 97.659%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.075 Acc 97.617%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.193 Acc 95.831%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.188 Acc 95.997%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.071 Acc 97.765%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.071 Acc 97.812%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.181 Acc 96.078%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.178 Acc 96.179%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.070 Acc 97.857%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.071 Acc 97.690%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.073 Acc 97.654%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.074 Acc 97.628%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.196 Acc 95.622%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.189 Acc 95.923%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.069 Acc 97.718%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.074 Acc 97.576%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.076 Acc 97.527%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.191 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.189 Acc 95.684%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.184 Acc 95.934%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.075 Acc 97.587%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.077 Acc 97.575%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.076 Acc 97.638%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.075 Acc 97.648%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.189 Acc 95.815%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.183 Acc 96.016%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.070 Acc 97.785%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.071 Acc 97.799%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.072 Acc 97.728%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.072 Acc 97.765%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.209 Acc 95.289%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.200 Acc 95.581%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.079 Acc 97.579%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.075 Acc 97.621%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.072 Acc 97.721%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.072 Acc 97.740%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.074 Acc 97.695%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.090 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.184 Acc 95.815%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.181 Acc 96.016%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.074 Acc 97.587%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.074 Acc 97.646%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.074 Acc 97.639%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.189 Acc 95.924%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.185 Acc 96.012%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.072 Acc 97.788%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.071 Acc 97.695%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.072 Acc 97.670%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.186 Acc 96.047%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.182 Acc 96.218%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.065 Acc 97.842%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.069 Acc 97.742%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.068 Acc 97.812%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.072 Acc 97.694%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.181 Acc 96.156%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.179 Acc 96.245%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.033 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.072 Acc 97.610%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.073 Acc 97.613%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.075 Acc 97.571%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.076 Acc 97.569%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.194 Acc 95.931%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.189 Acc 95.989%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.065 Acc 98.028%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.069 Acc 97.897%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.068 Acc 97.879%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.069 Acc 97.865%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.071 Acc 97.781%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.180 Acc 96.016%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.177 Acc 96.144%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.067 Acc 97.865%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.068 Acc 97.843%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.070 Acc 97.807%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.071 Acc 97.769%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.072 Acc 97.756%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.101 Acc 96.875%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.184 Acc 96.047%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.181 Acc 96.140%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.076 Acc 97.618%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.071 Acc 97.711%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.071 Acc 97.713%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.073 Acc 97.673%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.185 Acc 96.098%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.073 Acc 97.757%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.070 Acc 97.804%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.070 Acc 97.773%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.071 Acc 97.721%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.072 Acc 97.691%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.184 Acc 95.862%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.181 Acc 96.024%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.070 Acc 97.742%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.071 Acc 97.659%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.072 Acc 97.682%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.072 Acc 97.641%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.195 Acc 95.599%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.193 Acc 95.623%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.073 Acc 97.587%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.071 Acc 97.685%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.070 Acc 97.719%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.808%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.915%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.065 Acc 97.981%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.068 Acc 97.882%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.067 Acc 97.918%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.069 Acc 97.814%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.070 Acc 97.787%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.199 Acc 95.653%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.193 Acc 95.763%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.095 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.070 Acc 97.734%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.069 Acc 97.854%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.070 Acc 97.781%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.070 Acc 97.777%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.071 Acc 97.742%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.188 Acc 95.831%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.187 Acc 95.927%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.100 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.067 Acc 97.912%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.067 Acc 97.799%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.070 Acc 97.721%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.071 Acc 97.703%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.194 Acc 95.846%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.190 Acc 95.927%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.070 Acc 97.618%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.070 Acc 97.667%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.072 Acc 97.705%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.206 Acc 95.537%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.197 Acc 95.752%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.068 Acc 97.788%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.069 Acc 97.773%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.071 Acc 97.700%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.072 Acc 97.711%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.072 Acc 97.680%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.188 Acc 95.946%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.071 Acc 97.857%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.072 Acc 97.683%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.073 Acc 97.628%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.073 Acc 97.617%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.073 Acc 97.619%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.194 Acc 95.931%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.189 Acc 96.016%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.039 Acc 97.656%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.067 Acc 97.896%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.067 Acc 97.778%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.069 Acc 97.748%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.202 Acc 95.854%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.194 Acc 95.927%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.068 Acc 97.765%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.066 Acc 97.851%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.066 Acc 97.859%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.066 Acc 97.863%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.068 Acc 97.789%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.210 Acc 95.661%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.204 Acc 95.779%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.065 Acc 97.919%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.067 Acc 97.816%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.070 Acc 97.723%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.194 Acc 96.117%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.190 Acc 96.117%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.066 Acc 97.888%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [200/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.068 Acc 97.719%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.069 Acc 97.719%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.069 Acc 97.739%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.194 Acc 95.831%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.189 Acc 95.981%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.066%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.066 Acc 97.812%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.069 Acc 97.734%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.070 Acc 97.747%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.193 Acc 95.862%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.191 Acc 95.899%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.064 Acc 98.012%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.066 Acc 97.936%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.068 Acc 97.830%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.069 Acc 97.740%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.070 Acc 97.736%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.193 Acc 95.823%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.190 Acc 95.864%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.061 Acc 97.966%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.064 Acc 97.851%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.065 Acc 97.807%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.067 Acc 97.763%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.070 Acc 97.722%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.134 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.195 Acc 95.808%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.191 Acc 95.837%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a834b66fe94d4a87e65b66a341bf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.322 Acc 10.156%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.241 Acc 18.951%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.241 Acc 18.983%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.958%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.239 Acc 18.953%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.237 Acc 19.176%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.057 Acc 27.344%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.027 Acc 27.235%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.028 Acc 27.282%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.171 Acc 20.312%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.858 Acc 34.878%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.637 Acc 43.653%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.484 Acc 49.359%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.381 Acc 53.335%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.296 Acc 56.501%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.860 Acc 75.781%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.828 Acc 73.507%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.825 Acc 73.465%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.846 Acc 73.438%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.813 Acc 74.103%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.764 Acc 75.952%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.734 Acc 76.993%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.705 Acc 77.991%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.679 Acc 78.825%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.438 Acc 85.938%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.445 Acc 86.549%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.435 Acc 86.738%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.401 Acc 87.500%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.530 Acc 83.385%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.513 Acc 83.889%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.509 Acc 84.191%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.500 Acc 84.451%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.495 Acc 84.649%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.426 Acc 87.500%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.400 Acc 88.382%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.386 Acc 88.522%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.394 Acc 87.500%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.445 Acc 86.394%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.443 Acc 86.350%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.433 Acc 86.732%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.431 Acc 86.752%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.428 Acc 86.792%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.353 Acc 89.844%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.346 Acc 90.022%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.336 Acc 90.186%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.352 Acc 88.281%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.391 Acc 88.041%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.395 Acc 87.885%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.398 Acc 87.876%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.400 Acc 87.839%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.394 Acc 88.035%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.335 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.324 Acc 90.470%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.313 Acc 90.718%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.377 Acc 88.281%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.379 Acc 88.622%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.372 Acc 88.588%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.367 Acc 88.754%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.367 Acc 88.772%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.369 Acc 88.777%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.351 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.293 Acc 91.445%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.282 Acc 91.752%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.423 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.360 Acc 89.086%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.353 Acc 89.296%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.348 Acc 89.423%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.346 Acc 89.487%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.346 Acc 89.496%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.321 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.283 Acc 91.909%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.274 Acc 92.016%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.336 Acc 89.844%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.323 Acc 89.975%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.332 Acc 90.011%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.330 Acc 90.114%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.331 Acc 90.101%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.330 Acc 90.118%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.278 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.274 Acc 92.474%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.261 Acc 92.743%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.300 Acc 89.844%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.337 Acc 89.882%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.323 Acc 90.108%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.318 Acc 90.282%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.317 Acc 90.376%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.314 Acc 90.450%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.250 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.291 Acc 91.770%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.278 Acc 92.071%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.690 Acc 84.375%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.309 Acc 90.756%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.310 Acc 90.738%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.305 Acc 90.851%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.309 Acc 90.732%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.309 Acc 90.736%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.273 Acc 92.311%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.261 Acc 92.568%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.492 Acc 87.500%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.305 Acc 90.787%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.307 Acc 90.854%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.307 Acc 90.804%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.303 Acc 90.894%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.298 Acc 91.068%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.241 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.246 Acc 93.417%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.235 Acc 93.404%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.210 Acc 93.750%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.282 Acc 91.422%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.289 Acc 91.262%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.289 Acc 91.313%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.286 Acc 91.439%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.287 Acc 91.425%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.250 Acc 93.023%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.239 Acc 93.264%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.279 Acc 88.281%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.287 Acc 91.476%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.283 Acc 91.639%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.283 Acc 91.632%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.282 Acc 91.658%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.281 Acc 91.682%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.252 Acc 93.054%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.243 Acc 93.179%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.248 Acc 90.625%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.274 Acc 91.491%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.268 Acc 92.001%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.272 Acc 91.967%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.272 Acc 91.907%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.271 Acc 91.844%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.230 Acc 93.704%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.224 Acc 93.762%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.274 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.252 Acc 92.304%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.258 Acc 92.176%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.261 Acc 92.120%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.265 Acc 92.086%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.267 Acc 92.060%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.231 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.240 Acc 93.502%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.232 Acc 93.622%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.169 Acc 95.312%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.257 Acc 92.466%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.260 Acc 92.257%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.262 Acc 92.289%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.262 Acc 92.263%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.262 Acc 92.237%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.243 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.238 Acc 93.425%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.231 Acc 93.626%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.402 Acc 87.500%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.265 Acc 92.350%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.259 Acc 92.281%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.258 Acc 92.278%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.254 Acc 92.396%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.257 Acc 92.311%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.221 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.231 Acc 93.827%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.224 Acc 93.867%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.315 Acc 90.625%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.262 Acc 92.296%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.258 Acc 92.417%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.257 Acc 92.538%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.254 Acc 92.511%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.254 Acc 92.492%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.177 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.220 Acc 94.261%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.213 Acc 94.298%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.215 Acc 92.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.245 Acc 92.737%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.242 Acc 92.903%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.245 Acc 92.823%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.244 Acc 92.854%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.245 Acc 92.861%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.220 Acc 94.291%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.213 Acc 94.399%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.237 Acc 92.984%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.240 Acc 92.922%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.241 Acc 92.891%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.241 Acc 92.910%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.243 Acc 92.900%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.206 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.201 Acc 94.817%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.194 Acc 94.908%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.286 Acc 89.844%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.238 Acc 93.038%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.236 Acc 92.949%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.238 Acc 92.961%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.241 Acc 92.920%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.240 Acc 92.947%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.217 Acc 94.137%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.208 Acc 94.244%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.324 Acc 89.062%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.226 Acc 93.286%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.233 Acc 93.167%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.234 Acc 93.080%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.236 Acc 93.060%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.237 Acc 93.111%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.210 Acc 94.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.204 Acc 94.562%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.335 Acc 89.062%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.235 Acc 93.015%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.230 Acc 93.128%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.227 Acc 93.249%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.227 Acc 93.228%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.229 Acc 93.204%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.215 Acc 94.361%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.207 Acc 94.380%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.366 Acc 89.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.228 Acc 93.502%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.226 Acc 93.501%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.230 Acc 93.348%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.231 Acc 93.343%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.230 Acc 93.352%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.213 Acc 94.438%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.205 Acc 94.586%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.226 Acc 92.188%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.222 Acc 93.526%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.219 Acc 93.587%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.221 Acc 93.480%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.225 Acc 93.405%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.225 Acc 93.380%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.243 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.213 Acc 94.083%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.203 Acc 94.314%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.301 Acc 95.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.217 Acc 93.642%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.220 Acc 93.439%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.220 Acc 93.558%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.220 Acc 93.522%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.222 Acc 93.500%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.202 Acc 94.941%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.193 Acc 95.009%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.212 Acc 94.531%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.202 Acc 94.137%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.217 Acc 93.672%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.219 Acc 93.631%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.219 Acc 93.592%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.219 Acc 93.631%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.202 Acc 94.794%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.196 Acc 94.877%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.232 Acc 93.487%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.219 Acc 93.781%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.219 Acc 93.807%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.218 Acc 93.773%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.217 Acc 93.759%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.202 Acc 94.732%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.193 Acc 94.842%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.222 Acc 93.441%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.215 Acc 93.680%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.214 Acc 93.690%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.215 Acc 93.707%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.218 Acc 93.649%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.200 Acc 94.756%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.192 Acc 94.831%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.200 Acc 94.307%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.204 Acc 94.131%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.211 Acc 93.981%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.209 Acc 93.966%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.212 Acc 93.895%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.201 Acc 94.709%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.192 Acc 94.850%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.210 Acc 93.765%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.205 Acc 94.080%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.209 Acc 93.926%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.210 Acc 93.902%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.210 Acc 93.903%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.196 Acc 94.787%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.189 Acc 94.842%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.199 Acc 92.188%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.198 Acc 94.222%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.197 Acc 94.282%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.201 Acc 94.157%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.202 Acc 94.099%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.203 Acc 94.060%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.187 Acc 95.196%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.180 Acc 95.254%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.238 Acc 92.969%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.204 Acc 94.090%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.207 Acc 93.960%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.204 Acc 94.113%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.205 Acc 94.097%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.206 Acc 94.065%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.185 Acc 95.382%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.178 Acc 95.371%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.198 Acc 94.183%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.204 Acc 93.999%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.202 Acc 94.090%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.201 Acc 94.190%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.202 Acc 94.190%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.194 Acc 95.005%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.100 Acc 98.438%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.195 Acc 94.500%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.196 Acc 94.395%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.197 Acc 94.324%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.201 Acc 94.202%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.200 Acc 94.247%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.210 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.185 Acc 95.095%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.205 Acc 93.982%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.199 Acc 94.174%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.198 Acc 94.228%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.198 Acc 94.229%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.200 Acc 94.219%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.191 Acc 95.073%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.182 Acc 95.138%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.219 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.198 Acc 94.454%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.196 Acc 94.442%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.192 Acc 94.472%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.192 Acc 94.453%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.193 Acc 94.397%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.192 Acc 95.096%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.183 Acc 95.192%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.186 Acc 94.686%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.193 Acc 94.516%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.192 Acc 94.568%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.193 Acc 94.500%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.196 Acc 94.414%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.176 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.191 Acc 95.065%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.182 Acc 95.270%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.173 Acc 94.763%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.184 Acc 94.609%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.192 Acc 94.445%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.198 Acc 94.825%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.191 Acc 94.994%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.276 Acc 94.531%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.189 Acc 94.748%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.192 Acc 94.539%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.191 Acc 94.560%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.194 Acc 94.467%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.193 Acc 94.466%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.198 Acc 94.856%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.191 Acc 94.935%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.187 Acc 94.926%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.190 Acc 94.535%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.189 Acc 94.586%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.184 Acc 95.382%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.178 Acc 95.476%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.281 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.182 Acc 94.624%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.185 Acc 94.601%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.188 Acc 94.557%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.188 Acc 94.568%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.188 Acc 94.580%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.270 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.199 Acc 94.980%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.191 Acc 95.075%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.142 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.185 Acc 94.570%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.190 Acc 94.481%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.187 Acc 94.591%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.188 Acc 94.623%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.187 Acc 95.413%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.178 Acc 95.480%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.285 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.171 Acc 94.995%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.168 Acc 94.924%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.174 Acc 94.780%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.180 Acc 94.726%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.185 Acc 94.622%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.188 Acc 95.204%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.246%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.315 Acc 92.188%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.179 Acc 94.732%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.177 Acc 94.799%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.179 Acc 94.835%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.181 Acc 94.777%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.180 Acc 94.785%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.182 Acc 95.421%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.499%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.272 Acc 95.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.176 Acc 95.019%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.179 Acc 94.850%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.186 Acc 94.700%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.187 Acc 94.761%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.183 Acc 94.818%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.174 Acc 95.777%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.165 Acc 95.899%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.226 Acc 94.531%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.158 Acc 95.189%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.175 Acc 94.974%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.183 Acc 94.804%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.179 Acc 94.931%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.179 Acc 94.895%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.168 Acc 95.721%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.162 Acc 95.235%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.176 Acc 94.842%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.175 Acc 94.967%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.175 Acc 95.009%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.177 Acc 94.915%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.181 Acc 95.459%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.174 Acc 95.456%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.182 Acc 94.895%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.182 Acc 94.796%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.180 Acc 94.770%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.178 Acc 94.796%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.179 Acc 94.793%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.250 Acc 92.969%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.189 Acc 95.606%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.181 Acc 95.759%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.176 Acc 95.003%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.176 Acc 94.897%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.177 Acc 94.915%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.179 Acc 94.876%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.179 Acc 94.863%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.184 Acc 95.498%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.179 Acc 95.561%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.282 Acc 93.750%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.171 Acc 94.903%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.174 Acc 94.908%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.175 Acc 94.874%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.176 Acc 94.880%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.175 Acc 94.887%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.177 Acc 95.661%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.171 Acc 95.709%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.166 Acc 95.359%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.169 Acc 95.208%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.167 Acc 95.201%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.170 Acc 95.116%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.173 Acc 95.013%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.175 Acc 95.606%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.167 Acc 95.686%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.165 Acc 95.274%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.169 Acc 95.146%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.171 Acc 95.125%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.172 Acc 95.158%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.529%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.171 Acc 95.585%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.169 Acc 95.166%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.170 Acc 95.134%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.173 Acc 95.123%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.171 Acc 95.153%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.171 Acc 95.068%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.187 Acc 95.367%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.180 Acc 95.472%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.171 Acc 94.988%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.171 Acc 95.048%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.169 Acc 95.133%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.167 Acc 95.170%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.169 Acc 95.138%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.184 Acc 95.552%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.176 Acc 95.608%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.177 Acc 95.080%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.174 Acc 95.099%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.172 Acc 94.991%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.170 Acc 95.046%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.170 Acc 95.043%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.170 Acc 95.845%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.158 Acc 92.188%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.158 Acc 95.351%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.156 Acc 95.526%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.161 Acc 95.325%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.167 Acc 95.219%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.180 Acc 95.351%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.174 Acc 95.452%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.275 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.157 Acc 95.560%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.164 Acc 95.270%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.166 Acc 95.216%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.165 Acc 95.233%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.165 Acc 95.231%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.168 Acc 95.854%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.163 Acc 95.927%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.158 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.166 Acc 95.305%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.165 Acc 95.324%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.164 Acc 95.279%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.164 Acc 95.211%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.166 Acc 95.186%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.162 Acc 95.829%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.162 Acc 95.343%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.156 Acc 95.472%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.159 Acc 95.359%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.162 Acc 95.332%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.162 Acc 95.362%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.823%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.170 Acc 95.969%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.155 Acc 95.606%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.159 Acc 95.449%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.161 Acc 95.419%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.161 Acc 95.422%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.162 Acc 95.339%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.173 Acc 95.730%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.166 Acc 95.829%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.197 Acc 93.750%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.160 Acc 95.243%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.157 Acc 95.292%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.162 Acc 95.260%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.162 Acc 95.259%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.180 Acc 95.297%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.174 Acc 95.487%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.130 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.155 Acc 95.630%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.159 Acc 95.417%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.159 Acc 95.432%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.161 Acc 95.365%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.161 Acc 95.384%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.390%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.176 Acc 95.511%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.132 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.158 Acc 95.483%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.155 Acc 95.495%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.159 Acc 95.549%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.161 Acc 95.451%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.162 Acc 95.389%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.179 Acc 95.614%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.172 Acc 95.600%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.151 Acc 95.552%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.159 Acc 95.442%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.158 Acc 95.470%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.160 Acc 95.403%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.413%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.511%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.158 Acc 95.637%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.156 Acc 95.620%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.157 Acc 95.562%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.157 Acc 95.533%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.158 Acc 95.509%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.190 Acc 95.173%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.182 Acc 95.367%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.162 Acc 95.212%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.156 Acc 95.414%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.158 Acc 95.367%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.157 Acc 95.361%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.158 Acc 95.367%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.167 Acc 95.678%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.185 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.163 Acc 95.328%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.156 Acc 95.390%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.155 Acc 95.393%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.154 Acc 95.425%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.155 Acc 95.420%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.193 Acc 95.166%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.184 Acc 95.347%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.146 Acc 95.730%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.147 Acc 95.701%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.154 Acc 95.577%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.155 Acc 95.574%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.156 Acc 95.545%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.182 Acc 95.893%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.173 Acc 95.977%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.154 Acc 95.583%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.152 Acc 95.678%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.152 Acc 95.595%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.154 Acc 95.558%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.154 Acc 95.528%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.176 Acc 95.800%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.169 Acc 95.814%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.081 Acc 96.094%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.149 Acc 95.591%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.148 Acc 95.674%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.152 Acc 95.502%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.153 Acc 95.443%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.154 Acc 95.476%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.167 Acc 93.750%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.186 Acc 95.421%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.180 Acc 95.476%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.149 Acc 95.684%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.150 Acc 95.715%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.152 Acc 95.632%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.153 Acc 95.604%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.176 Acc 95.599%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.146 Acc 95.676%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.153 Acc 95.620%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.148 Acc 95.646%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.150 Acc 95.624%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.177 Acc 95.792%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.239 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.155 Acc 95.514%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.150 Acc 95.577%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.148 Acc 95.658%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.150 Acc 95.640%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.150 Acc 95.635%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.184 Acc 95.575%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.178 Acc 95.655%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.252 Acc 91.406%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.151 Acc 95.606%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.154 Acc 95.522%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.151 Acc 95.598%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.147 Acc 95.685%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.152 Acc 95.564%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.182 Acc 95.529%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.546%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.153 Acc 95.490%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.154 Acc 95.604%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.148 Acc 95.689%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.150 Acc 95.613%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.149 Acc 95.637%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.186 Acc 95.800%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.177 Acc 95.833%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.141 Acc 96.009%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.138 Acc 96.037%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.143 Acc 95.907%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.147 Acc 95.768%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.182 Acc 95.363%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.145 Acc 95.908%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.146 Acc 95.748%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.148 Acc 95.671%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.151 Acc 95.583%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.149 Acc 95.652%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.174 Acc 96.001%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.169 Acc 96.039%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.150 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.135 Acc 96.194%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.142 Acc 95.981%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.144 Acc 95.850%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.146 Acc 95.772%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.148 Acc 95.674%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.138 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.176 Acc 95.931%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.169 Acc 96.051%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.160 Acc 96.875%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.130 Acc 96.364%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.136 Acc 96.191%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.141 Acc 96.070%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.144 Acc 95.965%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.143 Acc 95.935%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.151 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.173 Acc 95.838%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.166 Acc 95.954%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.142 Acc 96.047%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.145 Acc 95.880%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.149 Acc 95.759%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.149 Acc 95.747%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.148 Acc 95.751%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.185 Acc 95.730%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.179 Acc 95.748%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.147 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.145 Acc 95.744%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.143 Acc 95.798%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.145 Acc 95.745%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.145 Acc 95.777%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.183 Acc 95.722%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.176 Acc 95.779%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.069 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.149 Acc 95.931%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.143 Acc 95.989%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.142 Acc 95.925%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.143 Acc 95.918%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.144 Acc 95.836%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.175 Acc 95.722%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.168 Acc 95.884%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.148 Acc 95.560%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.147 Acc 95.740%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.143 Acc 95.800%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.144 Acc 95.803%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.144 Acc 95.826%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.098 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.174 Acc 95.877%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.170 Acc 95.849%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.143 Acc 95.900%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.141 Acc 96.032%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.144 Acc 95.933%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.144 Acc 95.895%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.143 Acc 95.886%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.174 Acc 96.055%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.167 Acc 96.125%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.127 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.151 Acc 95.661%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.145 Acc 95.821%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.142 Acc 95.907%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.142 Acc 95.910%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.173 Acc 95.746%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.166 Acc 95.872%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.130 Acc 96.140%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.140 Acc 95.888%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.141 Acc 95.819%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.141 Acc 95.831%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.140 Acc 95.868%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.118 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.166 Acc 95.862%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.160 Acc 95.989%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.131 Acc 96.303%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.133 Acc 96.137%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.134 Acc 96.073%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.138 Acc 95.979%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.139 Acc 95.938%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.174 Acc 95.722%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.168 Acc 95.903%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.213 Acc 92.969%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.140 Acc 95.861%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.139 Acc 95.863%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.140 Acc 95.934%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.139 Acc 95.978%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.176 Acc 95.900%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.168 Acc 96.008%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.127 Acc 96.248%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.135 Acc 96.078%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.140 Acc 95.905%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.138 Acc 95.930%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.209 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.184 Acc 95.738%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.130 Acc 96.055%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.133 Acc 95.954%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.138 Acc 95.894%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.136 Acc 96.022%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.137 Acc 95.989%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.179 Acc 95.692%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.171 Acc 95.876%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.131 Acc 96.202%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.132 Acc 96.070%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.137 Acc 95.964%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.140 Acc 95.862%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.140 Acc 95.880%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.645%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.176 Acc 95.896%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.141 Acc 95.846%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.136 Acc 95.967%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.139 Acc 95.936%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.137 Acc 95.974%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.180 Acc 95.684%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.174 Acc 95.806%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.189 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.141 Acc 95.823%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.134 Acc 96.008%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.138 Acc 95.948%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.134 Acc 96.039%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.135 Acc 96.014%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.174 Acc 95.893%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.167 Acc 96.004%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.132 Acc 95.955%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.132 Acc 96.086%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.131 Acc 96.153%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.131 Acc 96.172%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.133 Acc 96.117%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.169 Acc 95.927%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.128 Acc 96.411%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.130 Acc 96.304%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.130 Acc 96.198%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.132 Acc 96.146%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.133 Acc 96.080%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.124 Acc 94.531%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.176 Acc 95.653%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.170 Acc 95.752%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.195 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.126 Acc 96.179%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.135 Acc 96.016%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.135 Acc 95.933%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.135 Acc 95.930%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.134 Acc 96.010%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.186 Acc 95.722%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.282 Acc 91.406%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.122 Acc 96.233%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.126 Acc 96.265%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.130 Acc 96.198%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.131 Acc 96.133%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.132 Acc 96.122%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.178 Acc 95.707%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.173 Acc 95.752%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.139 Acc 96.148%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.132 Acc 96.169%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.132 Acc 96.176%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.134 Acc 96.131%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.123 Acc 93.750%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.174 Acc 95.896%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.185 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.123 Acc 96.496%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.126 Acc 96.343%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.131 Acc 96.195%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.132 Acc 96.127%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.133 Acc 96.108%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.166 Acc 95.993%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.161 Acc 96.020%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.121 Acc 96.279%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.128 Acc 96.308%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.130 Acc 96.190%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.133 Acc 96.084%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.133 Acc 96.027%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.129 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.169 Acc 95.815%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.162 Acc 95.923%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.118 Acc 96.658%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.121 Acc 96.416%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.125 Acc 96.320%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.126 Acc 96.310%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.130 Acc 96.229%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.180 Acc 96.016%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 96.028%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.125 Acc 96.272%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.122 Acc 96.397%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.126 Acc 96.221%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.127 Acc 96.168%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.128 Acc 96.151%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.169 Acc 95.938%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.130 Acc 96.295%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.126 Acc 96.401%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.129 Acc 96.296%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.128 Acc 96.335%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.128 Acc 96.311%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.183 Acc 95.916%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.178 Acc 95.965%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.122 Acc 96.403%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.127 Acc 96.265%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.126 Acc 96.340%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.127 Acc 96.281%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.128 Acc 96.233%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.179 Acc 95.692%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.177 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.124 Acc 96.194%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.126 Acc 96.234%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.127 Acc 96.244%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.130 Acc 96.207%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.129 Acc 96.223%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.637%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.174 Acc 95.798%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.141 Acc 95.908%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.132 Acc 96.140%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.128 Acc 96.236%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.129 Acc 96.187%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.192 Acc 95.707%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.184 Acc 95.771%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.199 Acc 90.625%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.126 Acc 96.225%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.123 Acc 96.234%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.126 Acc 96.166%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.128 Acc 96.150%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.129 Acc 96.123%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.082 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.183 Acc 95.939%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.177 Acc 96.043%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.130 Acc 96.442%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.130 Acc 96.174%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.129 Acc 96.239%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.189 Acc 95.854%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.181 Acc 95.872%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.130 Acc 95.970%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.127 Acc 96.133%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.129 Acc 96.200%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.129 Acc 96.230%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.129 Acc 96.254%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.171 Acc 96.032%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.162 Acc 96.121%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.109 Acc 94.531%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.124 Acc 96.401%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.126 Acc 96.301%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.124 Acc 96.386%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.126 Acc 96.339%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.161 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.189 Acc 95.429%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.185 Acc 95.577%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.182 Acc 92.188%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.130 Acc 96.241%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.128 Acc 96.182%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.125 Acc 96.216%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.126 Acc 96.209%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.181 Acc 95.614%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.173 Acc 95.732%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.113 Acc 96.682%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.121 Acc 96.416%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.122 Acc 96.400%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.125 Acc 96.265%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.124 Acc 96.257%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.169 Acc 95.939%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.163 Acc 96.070%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.120 Acc 96.426%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.122 Acc 96.374%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.121 Acc 96.418%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.124 Acc 96.320%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.185 Acc 95.962%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.177 Acc 96.090%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.111 Acc 96.736%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.115 Acc 96.580%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.120 Acc 96.447%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.123 Acc 96.339%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.124 Acc 96.304%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 95.815%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.165 Acc 95.962%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.118 Acc 96.450%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.119 Acc 96.482%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.120 Acc 96.442%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.122 Acc 96.409%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.123 Acc 96.345%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.146 Acc 93.750%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.182 Acc 95.537%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.175 Acc 95.779%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.112 Acc 96.666%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.115 Acc 96.482%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.120 Acc 96.371%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.123 Acc 96.261%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.126 Acc 96.237%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.164 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.178 Acc 95.645%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 95.783%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.121 Acc 96.419%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.115 Acc 96.545%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.119 Acc 96.480%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.121 Acc 96.431%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.124 Acc 96.378%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.187 Acc 95.630%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.179 Acc 95.759%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.119 Acc 96.527%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.118 Acc 96.521%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.119 Acc 96.517%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.119 Acc 96.465%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.199 Acc 95.893%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.193 Acc 95.872%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.121 Acc 96.444%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.120 Acc 96.429%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.120 Acc 96.415%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.121 Acc 96.395%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.174 Acc 95.978%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.165 Acc 96.067%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.115 Acc 96.607%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.118 Acc 96.553%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.119 Acc 96.474%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.121 Acc 96.384%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.176 Acc 95.869%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.170 Acc 96.028%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.112 Acc 96.666%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.112 Acc 96.564%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.116 Acc 96.483%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.116 Acc 96.437%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.117 Acc 96.490%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.182 Acc 95.985%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.174 Acc 96.012%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.120 Acc 96.372%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.121 Acc 96.354%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.119 Acc 96.405%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.120 Acc 96.402%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.120 Acc 96.432%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.171 Acc 95.997%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.089 Acc 95.312%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.112 Acc 96.612%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.119 Acc 96.444%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.117 Acc 96.457%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.120 Acc 96.474%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.119 Acc 96.480%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.184 Acc 95.645%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.178 Acc 95.759%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.113 Acc 96.697%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.114 Acc 96.665%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.117 Acc 96.548%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.117 Acc 96.557%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.119 Acc 96.468%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.193 Acc 95.730%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.186 Acc 95.752%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.111 Acc 96.689%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.116 Acc 96.556%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.121 Acc 96.392%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.122 Acc 96.392%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.120 Acc 96.424%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.204 Acc 95.769%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.194 Acc 95.826%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.120 Acc 96.581%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.117 Acc 96.556%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.115 Acc 96.561%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.116 Acc 96.491%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.119 Acc 96.449%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.201 Acc 95.552%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.194 Acc 95.542%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.275 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.119 Acc 96.496%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.118 Acc 96.490%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.118 Acc 96.480%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.119 Acc 96.437%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.118 Acc 96.462%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.201 Acc 95.591%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.194 Acc 95.623%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.204 Acc 92.188%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.110 Acc 96.689%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.115 Acc 96.556%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.114 Acc 96.584%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.116 Acc 96.532%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.116 Acc 96.552%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.208 Acc 95.320%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.200 Acc 95.379%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.116 Acc 96.666%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.119 Acc 96.576%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.118 Acc 96.535%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.118 Acc 96.515%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.192 Acc 95.699%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.184 Acc 95.787%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.116 Acc 96.395%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.116 Acc 96.424%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.117 Acc 96.423%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.116 Acc 96.513%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.116 Acc 96.457%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.193 Acc 95.715%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.183 Acc 95.822%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.109 Acc 96.566%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.112 Acc 96.587%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.112 Acc 96.564%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.114 Acc 96.503%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.113 Acc 96.538%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.186 Acc 95.924%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.175 Acc 96.078%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.218 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.107 Acc 96.682%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.110 Acc 96.696%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.114 Acc 96.626%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.113 Acc 96.641%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.114 Acc 96.608%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.205 Acc 95.483%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.195 Acc 95.507%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.110 Acc 96.708%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.111 Acc 96.636%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.111 Acc 96.626%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.114 Acc 96.583%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.182 Acc 95.916%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.176 Acc 95.938%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.103 Acc 96.790%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.110 Acc 96.622%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.111 Acc 96.605%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.114 Acc 96.577%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.166 Acc 95.939%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.160 Acc 96.016%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.108 Acc 96.758%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.113 Acc 96.613%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.114 Acc 96.602%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.170 Acc 96.067%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.190 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.107 Acc 96.968%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.108 Acc 96.786%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.111 Acc 96.732%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.112 Acc 96.684%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.115 Acc 96.610%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.193 Acc 95.862%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.187 Acc 95.938%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.114 Acc 96.682%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.108 Acc 96.789%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.109 Acc 96.795%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.110 Acc 96.725%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.176 Acc 95.831%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.168 Acc 95.950%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.115 Acc 96.689%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.115 Acc 96.533%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.115 Acc 96.577%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.113 Acc 96.637%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.113 Acc 96.611%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.178 Acc 95.893%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.170 Acc 95.969%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.110 Acc 96.697%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.113 Acc 96.603%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.111 Acc 96.709%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.113 Acc 96.620%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.111 Acc 96.663%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.188 Acc 95.452%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.182 Acc 95.608%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.106 Acc 96.744%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.110 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.109 Acc 96.753%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.111 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.111 Acc 96.719%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.199 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.185 Acc 95.908%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.177 Acc 95.923%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.107 Acc 96.914%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.112 Acc 96.743%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.111 Acc 96.766%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.111 Acc 96.737%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.113 Acc 96.685%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.188 Acc 95.614%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.180 Acc 95.791%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.101 Acc 96.805%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.100 Acc 96.937%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.107 Acc 96.758%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.111 Acc 96.581%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.112 Acc 96.557%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.193 Acc 95.823%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.185 Acc 95.931%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.108 Acc 96.782%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.107 Acc 96.776%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.110 Acc 96.743%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.111 Acc 96.685%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.196 Acc 95.521%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.190 Acc 95.519%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.085 Acc 99.219%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.105 Acc 96.890%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.105 Acc 96.898%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.108 Acc 96.833%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.107 Acc 96.799%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.110 Acc 96.753%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.191 Acc 95.630%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.184 Acc 95.705%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.107 Acc 96.736%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.107 Acc 96.688%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.109 Acc 96.631%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.110 Acc 96.624%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.109 Acc 96.605%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.188 Acc 95.701%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.108 Acc 96.798%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.104 Acc 96.848%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.105 Acc 96.810%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.104 Acc 96.830%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.106 Acc 96.794%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.179 Acc 95.911%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.105 Acc 96.906%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.104 Acc 96.840%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.106 Acc 96.823%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.105 Acc 96.811%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.107 Acc 96.750%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.199 Acc 95.769%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.189 Acc 95.853%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.095 Acc 97.130%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.102 Acc 96.968%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.104 Acc 96.909%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.109 Acc 96.809%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.107 Acc 96.847%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.194 Acc 95.808%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.185 Acc 95.864%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.102 Acc 96.774%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.108 Acc 96.801%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.108 Acc 96.813%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.107 Acc 96.820%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.108 Acc 96.813%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.193 Acc 95.506%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.183 Acc 95.763%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.130 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.104 Acc 96.860%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.104 Acc 96.805%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.107 Acc 96.761%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.108 Acc 96.744%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.108 Acc 96.744%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.205 Acc 95.746%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.194 Acc 95.841%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.108 Acc 96.968%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.104 Acc 96.904%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.103 Acc 96.879%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.105 Acc 96.822%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.195 Acc 95.429%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.187 Acc 95.573%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.130 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.101 Acc 97.161%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.104 Acc 96.910%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.106 Acc 96.808%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.107 Acc 96.809%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.109 Acc 96.736%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.187 Acc 95.877%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.179 Acc 95.993%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.126 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.101 Acc 97.030%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.103 Acc 96.988%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.104 Acc 96.958%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.106 Acc 96.856%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.105 Acc 96.853%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.192 Acc 95.746%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.919%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.101 Acc 96.697%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.104 Acc 96.731%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.104 Acc 96.763%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.105 Acc 96.797%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.104 Acc 96.827%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 96.001%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.181 Acc 96.016%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.174 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.097 Acc 97.084%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.100 Acc 96.909%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.101 Acc 96.815%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.102 Acc 96.791%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.181 Acc 95.924%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.172 Acc 96.051%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.146 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.100 Acc 97.014%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.102 Acc 96.867%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.104 Acc 96.780%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.105 Acc 96.761%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.191 Acc 95.730%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.104 Acc 97.022%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.102 Acc 96.984%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.102 Acc 97.013%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.101 Acc 96.994%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.101 Acc 97.034%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.116 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.191 Acc 95.800%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.184 Acc 95.853%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.080 Acc 96.094%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.102 Acc 96.759%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.103 Acc 96.786%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.105 Acc 96.793%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.104 Acc 96.836%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.196 Acc 95.746%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.187 Acc 95.841%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.096 Acc 96.968%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.097 Acc 96.941%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.101 Acc 96.857%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.101 Acc 96.854%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.102 Acc 96.831%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.191 Acc 95.978%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.183 Acc 96.051%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.092 Acc 97.300%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.101 Acc 96.922%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.103 Acc 96.865%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.104 Acc 96.833%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.200 Acc 95.568%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.192 Acc 95.565%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.100 Acc 96.898%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.100 Acc 96.898%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.104 Acc 96.842%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.104 Acc 96.803%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.196 Acc 95.568%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.094 Acc 97.053%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.100 Acc 96.859%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.100 Acc 96.896%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.099 Acc 96.883%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.101 Acc 96.842%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.196 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.190 Acc 95.697%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.101 Acc 96.890%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.099 Acc 96.852%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.101 Acc 96.857%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.101 Acc 96.865%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.103 Acc 96.838%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.190 Acc 96.024%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.183 Acc 96.004%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.101 Acc 96.999%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.102 Acc 96.999%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.102 Acc 96.958%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.102 Acc 96.959%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.101 Acc 96.959%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.196 Acc 95.591%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.187 Acc 95.802%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.100 Acc 96.960%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.100 Acc 96.945%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.099 Acc 96.971%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.103 Acc 96.845%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.199 Acc 95.738%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.191 Acc 95.818%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.091 Acc 97.254%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.096 Acc 97.065%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.098 Acc 97.018%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.098 Acc 97.023%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.099 Acc 96.975%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.190 Acc 95.900%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.181 Acc 95.946%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.098 Acc 97.053%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.101 Acc 96.984%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.102 Acc 96.880%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.101 Acc 96.891%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.102 Acc 96.856%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.197 Acc 95.722%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.189 Acc 95.759%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.100 Acc 96.999%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.104 Acc 96.898%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.103 Acc 96.870%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.102 Acc 96.883%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.102 Acc 96.889%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.194 Acc 95.622%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.185 Acc 95.791%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.036 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.094 Acc 96.976%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.097 Acc 96.929%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.101 Acc 96.898%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.099 Acc 96.982%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.100 Acc 96.922%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.207 Acc 95.506%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.202 Acc 95.573%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.096 Acc 97.107%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.095 Acc 97.143%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.099 Acc 96.958%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.098 Acc 97.025%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.099 Acc 96.979%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.199 Acc 95.653%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.193 Acc 95.767%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.099 Acc 96.887%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.096 Acc 96.948%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.098 Acc 96.931%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.098 Acc 96.947%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.186 Acc 95.880%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.102 Acc 96.844%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.099 Acc 96.859%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.102 Acc 96.865%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.100 Acc 96.930%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.205 Acc 95.560%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.198 Acc 95.542%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.090 Acc 97.215%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.096 Acc 97.114%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.094 Acc 97.105%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.097 Acc 97.026%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.110 Acc 96.875%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.194 Acc 95.746%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.112 Acc 93.750%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.088 Acc 97.254%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.091 Acc 97.201%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.096 Acc 97.096%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.098 Acc 96.981%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.144 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.191 Acc 95.838%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.182 Acc 95.973%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.099 Acc 96.968%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.100 Acc 96.863%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.098 Acc 96.927%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.097 Acc 96.949%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.099 Acc 96.908%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.186 Acc 95.849%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.092 Acc 97.246%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.095 Acc 97.087%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.097 Acc 97.012%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.199 Acc 95.637%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.193 Acc 95.787%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.035 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.090 Acc 97.293%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.094 Acc 97.108%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.096 Acc 97.033%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.097 Acc 96.984%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.184 Acc 95.722%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.101 Acc 96.736%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.097 Acc 96.972%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.096 Acc 96.997%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.096 Acc 97.000%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.096 Acc 97.017%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.132 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.184 Acc 95.869%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.180 Acc 95.950%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.094 Acc 97.231%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.094 Acc 97.097%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.094 Acc 97.155%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.094 Acc 97.091%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.096 Acc 97.020%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.189 Acc 95.792%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.182 Acc 95.868%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.093 Acc 97.277%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.095 Acc 97.062%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.094 Acc 97.098%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.095 Acc 97.095%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.096 Acc 97.071%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.273 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.200 Acc 95.722%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.193 Acc 95.713%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.091 Acc 97.151%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.093 Acc 97.116%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.093 Acc 97.146%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.096 Acc 97.070%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.196 Acc 95.924%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.188 Acc 95.997%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.094 Acc 97.177%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.097 Acc 97.046%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.097 Acc 96.932%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.097 Acc 96.975%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.186 Acc 95.815%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.179 Acc 95.942%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.085 Acc 97.463%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.092 Acc 97.225%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.093 Acc 97.148%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.094 Acc 97.136%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.095 Acc 97.078%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.191 Acc 96.001%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.184 Acc 95.969%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.137 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.086 Acc 97.262%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.091 Acc 97.248%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.091 Acc 97.171%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.093 Acc 97.120%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.094 Acc 97.106%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.183 Acc 95.947%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.179 Acc 95.954%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.091 Acc 97.100%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.091 Acc 97.064%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.094 Acc 97.031%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.093 Acc 97.086%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.209 Acc 95.568%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.200 Acc 95.705%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.092 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.088 Acc 97.192%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.097 Acc 96.989%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.096 Acc 96.986%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.096 Acc 97.036%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.207 Acc 95.398%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.200 Acc 95.565%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.090 Acc 97.061%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.096 Acc 96.898%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.095 Acc 96.981%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.095 Acc 97.011%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.096 Acc 96.969%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.197 Acc 95.792%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.189 Acc 95.911%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.089 Acc 97.246%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.093 Acc 97.170%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.093 Acc 97.140%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.092 Acc 97.175%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.093 Acc 97.156%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.182 Acc 95.753%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.174 Acc 95.899%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.092 Acc 97.277%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.091 Acc 97.217%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.092 Acc 97.179%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.092 Acc 97.163%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.093 Acc 97.123%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.202 Acc 95.792%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.194 Acc 95.849%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.082 Acc 97.424%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.088 Acc 97.209%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.091 Acc 97.130%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.091 Acc 97.120%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.198 Acc 95.707%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.190 Acc 95.826%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.091 Acc 97.192%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.090 Acc 97.182%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.091 Acc 97.225%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.092 Acc 97.191%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.092 Acc 97.167%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.191 Acc 95.746%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.186 Acc 95.833%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.086 Acc 97.208%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.089 Acc 97.143%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.091 Acc 97.119%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.091 Acc 97.103%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.092 Acc 97.062%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.210 Acc 95.282%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.204 Acc 95.254%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.091 Acc 97.123%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.086 Acc 97.248%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.090 Acc 97.197%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.089 Acc 97.167%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.092 Acc 97.132%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.197 Acc 95.908%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.190 Acc 95.892%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.082 Acc 97.362%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.085 Acc 97.260%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.087 Acc 97.161%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.089 Acc 97.154%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.090 Acc 97.103%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.191 Acc 96.024%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.184 Acc 96.059%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.088 Acc 97.194%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.090 Acc 97.119%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.091 Acc 97.105%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.195 Acc 95.792%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.190 Acc 95.771%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.087 Acc 97.092%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.088 Acc 97.186%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.091 Acc 97.090%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.091 Acc 97.105%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.092 Acc 97.128%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.197 Acc 95.514%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.191 Acc 95.538%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.082 Acc 97.563%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.084 Acc 97.415%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.088 Acc 97.270%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.089 Acc 97.252%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.199 Acc 95.877%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.194 Acc 95.802%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.088 Acc 97.223%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.088 Acc 97.178%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.089 Acc 97.129%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.090 Acc 97.161%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.090 Acc 97.167%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.204 Acc 95.545%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.198 Acc 95.585%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb75da2af4764a89a9b833909cc030a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.321 Acc 16.406%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.235 Acc 18.665%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.023 Acc 27.585%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.743 Acc 38.668%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.526 Acc 46.842%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.356 Acc 53.219%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.451 Acc 85.938%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.482 Acc 84.878%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.476 Acc 85.055%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.511 Acc 84.375%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.546 Acc 82.898%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.532 Acc 83.403%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.514 Acc 84.071%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.499 Acc 84.546%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.486 Acc 84.924%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.392 Acc 86.719%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.376 Acc 89.117%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.370 Acc 89.234%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.453 Acc 87.500%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.418 Acc 87.067%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.408 Acc 87.310%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.401 Acc 87.627%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.396 Acc 87.845%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.391 Acc 87.990%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.385 Acc 86.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.350 Acc 89.472%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.344 Acc 89.486%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.332 Acc 89.844%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.368 Acc 88.691%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.357 Acc 88.899%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.352 Acc 89.229%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.351 Acc 89.267%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.348 Acc 89.416%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.377 Acc 87.500%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.289 Acc 91.507%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.283 Acc 91.659%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.233 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.330 Acc 90.084%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.326 Acc 90.155%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.321 Acc 90.179%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.321 Acc 90.313%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.318 Acc 90.427%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.267 Acc 92.690%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.261 Acc 92.701%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.390 Acc 85.938%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.302 Acc 90.780%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.301 Acc 90.901%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.297 Acc 90.952%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.296 Acc 91.087%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.296 Acc 91.082%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.304 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.258 Acc 92.628%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.252 Acc 92.712%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.242 Acc 93.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.278 Acc 91.700%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.282 Acc 91.577%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.282 Acc 91.604%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.281 Acc 91.580%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.279 Acc 91.724%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.253 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.245 Acc 92.822%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.241 Acc 93.008%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.278 Acc 95.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.246 Acc 92.474%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.258 Acc 92.040%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.264 Acc 92.071%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.266 Acc 92.113%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.267 Acc 92.081%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.220 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.219 Acc 94.067%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.212 Acc 94.045%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.194 Acc 92.969%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.273 Acc 92.002%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.265 Acc 92.273%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.262 Acc 92.367%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.260 Acc 92.330%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.204 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.216 Acc 93.936%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.209 Acc 94.042%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.120 Acc 97.656%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.247 Acc 92.683%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.257 Acc 92.456%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.254 Acc 92.564%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.252 Acc 92.607%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.239 Acc 89.844%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.235 Acc 93.634%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.229 Acc 93.571%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.269 Acc 89.844%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.255 Acc 92.636%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.247 Acc 92.654%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.249 Acc 92.551%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.247 Acc 92.671%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.246 Acc 92.749%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.222 Acc 94.121%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.218 Acc 94.096%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.237 Acc 92.969%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.233 Acc 93.170%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.234 Acc 93.151%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.236 Acc 93.041%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.239 Acc 93.019%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.236 Acc 93.075%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.254 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.202 Acc 94.446%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.196 Acc 94.663%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.233 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.234 Acc 93.363%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.234 Acc 93.198%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.234 Acc 93.278%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.236 Acc 93.129%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.233 Acc 93.203%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.209 Acc 94.346%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.205 Acc 94.306%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.094 Acc 98.438%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.222 Acc 93.209%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.230 Acc 93.245%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.227 Acc 93.381%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.226 Acc 93.473%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.226 Acc 93.433%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.173 Acc 92.188%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.216 Acc 94.075%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.211 Acc 94.096%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.163 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.223 Acc 93.502%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.225 Acc 93.424%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.222 Acc 93.548%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.222 Acc 93.534%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.222 Acc 93.502%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.197 Acc 94.833%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.193 Acc 94.799%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.311 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.209 Acc 93.773%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.212 Acc 93.668%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.213 Acc 93.737%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.215 Acc 93.674%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.218 Acc 93.568%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.210 Acc 94.438%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.205 Acc 94.345%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.268 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.203 Acc 93.912%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.207 Acc 93.734%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.207 Acc 93.869%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.208 Acc 93.869%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.212 Acc 93.809%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.191 Acc 94.825%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.187 Acc 94.838%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.208 Acc 93.944%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.205 Acc 94.051%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.207 Acc 93.966%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.209 Acc 93.909%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.189 Acc 90.625%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.196 Acc 94.717%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.192 Acc 94.753%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.263 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.199 Acc 94.593%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.200 Acc 94.352%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.202 Acc 94.251%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.204 Acc 94.161%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.204 Acc 94.154%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.195 Acc 94.949%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.189 Acc 94.897%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.193 Acc 94.291%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.200 Acc 94.189%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.204 Acc 94.098%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.202 Acc 94.171%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.203 Acc 94.129%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.194 Acc 94.628%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.204 Acc 94.407%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.202 Acc 94.333%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.201 Acc 94.300%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.203 Acc 94.227%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.199 Acc 94.330%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.137 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.190 Acc 94.895%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.183 Acc 95.048%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.188 Acc 94.407%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.190 Acc 94.446%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.195 Acc 94.269%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.194 Acc 94.334%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.195 Acc 94.382%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.203 Acc 94.415%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.196 Acc 94.667%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.190 Acc 94.593%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.191 Acc 94.555%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.193 Acc 94.503%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.194 Acc 94.527%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.195 Acc 94.441%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.184 Acc 95.258%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.181 Acc 95.254%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.186 Acc 94.609%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.186 Acc 94.601%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.188 Acc 94.567%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.185 Acc 95.150%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.181 Acc 95.266%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.176 Acc 95.057%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.175 Acc 95.040%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.184 Acc 94.778%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.184 Acc 94.759%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.187 Acc 94.683%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.185 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.181 Acc 95.289%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.179 Acc 95.192%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.124 Acc 94.531%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.191 Acc 94.400%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.180 Acc 94.784%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.183 Acc 94.716%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.187 Acc 94.701%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.187 Acc 94.728%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.179 Acc 95.429%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.173 Acc 95.472%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.184 Acc 94.787%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.184 Acc 94.718%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.185 Acc 94.651%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.181 Acc 94.734%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.182 Acc 94.734%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.183 Acc 95.258%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.184%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.210 Acc 92.969%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.174 Acc 94.856%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.175 Acc 94.885%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.177 Acc 94.879%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.176 Acc 94.954%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.179 Acc 94.890%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.161 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.187 Acc 94.841%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.183 Acc 94.955%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.168 Acc 95.111%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.169 Acc 95.075%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.175 Acc 94.934%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.178 Acc 94.872%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.178 Acc 94.884%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.146 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.186 Acc 95.166%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.181 Acc 95.161%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.176 Acc 94.957%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.175 Acc 94.994%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.178 Acc 94.892%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.176 Acc 94.993%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.176 Acc 94.957%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.185 Acc 95.274%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.181 Acc 95.211%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.207 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.163 Acc 95.258%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.164 Acc 95.208%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.170 Acc 95.032%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.173 Acc 95.018%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.174 Acc 94.996%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.148 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.170 Acc 95.699%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.163 Acc 95.783%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.146 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.164 Acc 95.320%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.165 Acc 95.274%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.167 Acc 95.255%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.166 Acc 95.254%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.168 Acc 95.192%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.182 Acc 95.243%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.176 Acc 95.336%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.168 Acc 95.158%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.169 Acc 95.107%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.171 Acc 95.079%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.171 Acc 95.090%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.162 Acc 95.759%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.247 Acc 96.875%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.166 Acc 95.367%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.166 Acc 95.219%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.165 Acc 95.307%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.311%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.165 Acc 95.306%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.182 Acc 95.367%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.177 Acc 95.359%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.184 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.174 Acc 95.289%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.164 Acc 95.324%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.167 Acc 95.305%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.166 Acc 95.305%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.166 Acc 95.303%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.186 Acc 95.305%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.184 Acc 95.099%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.148 Acc 95.753%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.157 Acc 95.542%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.160 Acc 95.538%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.163 Acc 95.367%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.163 Acc 95.320%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.166 Acc 95.701%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.152 Acc 95.413%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.156 Acc 95.421%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.158 Acc 95.367%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.158 Acc 95.408%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.163 Acc 95.283%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.144 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.168 Acc 95.746%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.161 Acc 95.829%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.170 Acc 95.243%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.159 Acc 95.390%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.160 Acc 95.403%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.159 Acc 95.396%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.160 Acc 95.356%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.188 Acc 95.127%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.181 Acc 95.169%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.191 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.163 Acc 95.475%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.162 Acc 95.445%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.164 Acc 95.294%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.160 Acc 95.406%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.159 Acc 95.409%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.177 Acc 95.382%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.170 Acc 95.546%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.148 Acc 95.684%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.149 Acc 95.653%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.153 Acc 95.593%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.157 Acc 95.465%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.167 Acc 95.670%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.150 Acc 95.779%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.154 Acc 95.699%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.157 Acc 95.616%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.157 Acc 95.595%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.174 Acc 95.390%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.225 Acc 93.750%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.145 Acc 96.040%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.151 Acc 95.802%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.156 Acc 95.736%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.154 Acc 95.745%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.155 Acc 95.663%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.170 Acc 95.722%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.165 Acc 95.802%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.087 Acc 98.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.150 Acc 95.823%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.152 Acc 95.559%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.152 Acc 95.519%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.153 Acc 95.543%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.167 Acc 95.730%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.164 Acc 95.686%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.144 Acc 95.916%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.153 Acc 95.725%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.151 Acc 95.717%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.152 Acc 95.644%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.153 Acc 95.654%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.172 Acc 95.583%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.166 Acc 95.740%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.142 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.142 Acc 95.506%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.143 Acc 95.639%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.146 Acc 95.697%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.148 Acc 95.696%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.152 Acc 95.649%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.182 Acc 95.405%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.178 Acc 95.406%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.191 Acc 93.750%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.142 Acc 95.846%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.148 Acc 95.717%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.150 Acc 95.684%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.149 Acc 95.724%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.150 Acc 95.695%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.179 Acc 95.560%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.170 Acc 95.623%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.143 Acc 95.792%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.141 Acc 95.833%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.145 Acc 95.710%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.145 Acc 95.763%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.146 Acc 95.741%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.191 Acc 94.918%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.183 Acc 95.114%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.138 Acc 96.063%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.138 Acc 95.927%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.145 Acc 95.811%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.145 Acc 95.813%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.146 Acc 95.785%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.179 Acc 95.514%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.174 Acc 95.577%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.150 Acc 95.521%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.149 Acc 95.779%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.146 Acc 95.775%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.145 Acc 95.796%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.146 Acc 95.751%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.178 Acc 95.614%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.173 Acc 95.713%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.175 Acc 96.875%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.142 Acc 96.024%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.146 Acc 95.791%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.146 Acc 95.850%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.145 Acc 95.850%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.145 Acc 95.854%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.173 Acc 95.722%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.166 Acc 95.818%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.139 Acc 95.893%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.138 Acc 95.923%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.141 Acc 95.858%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.141 Acc 95.907%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.141 Acc 95.942%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.170 Acc 95.581%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.131 Acc 96.450%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.137 Acc 96.226%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.140 Acc 96.151%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.139 Acc 96.109%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.141 Acc 95.992%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.173 Acc 95.561%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.139 Acc 96.194%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.133 Acc 96.249%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.136 Acc 96.185%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.139 Acc 96.033%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.140 Acc 96.028%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.177 Acc 95.792%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.169 Acc 95.884%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.136 Acc 96.171%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.138 Acc 96.021%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.137 Acc 96.066%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.139 Acc 96.066%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.177 Acc 95.483%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.171 Acc 95.542%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.135 Acc 96.032%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.135 Acc 96.070%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.136 Acc 96.065%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.136 Acc 96.068%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.134 Acc 96.114%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.175 Acc 95.560%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.168 Acc 95.744%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.168 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.128 Acc 96.171%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.133 Acc 96.078%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.134 Acc 96.068%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.136 Acc 96.017%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.177 Acc 95.630%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.207 Acc 93.750%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.144 Acc 96.140%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.136 Acc 96.195%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.138 Acc 96.102%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.136 Acc 96.111%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.104 Acc 98.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.173 Acc 95.596%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.273 Acc 93.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.129 Acc 96.403%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.134 Acc 96.168%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.132 Acc 96.143%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.133 Acc 96.063%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.133 Acc 96.091%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.174 Acc 95.552%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.167 Acc 95.627%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.132 Acc 96.113%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.136 Acc 96.080%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.133 Acc 96.176%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.172 Acc 95.815%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.164 Acc 95.915%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.130 Acc 96.148%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.132 Acc 96.160%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.131 Acc 96.187%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.131 Acc 96.220%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.130 Acc 96.262%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.170 Acc 95.668%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.162 Acc 95.787%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.128 Acc 96.233%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.128 Acc 96.206%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.130 Acc 96.172%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.131 Acc 96.109%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.133 Acc 96.106%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.173 Acc 95.591%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.166 Acc 95.771%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.140 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.124 Acc 96.248%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.123 Acc 96.273%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.127 Acc 96.262%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.127 Acc 96.248%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.130 Acc 96.203%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.125 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.174 Acc 95.630%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.170 Acc 95.670%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.130 Acc 96.295%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.128 Acc 96.385%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.127 Acc 96.343%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.129 Acc 96.254%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.178%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.176 Acc 95.738%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.168 Acc 95.969%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.119 Acc 96.434%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.126 Acc 96.261%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.127 Acc 96.348%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.129 Acc 96.296%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.130 Acc 96.256%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.173 Acc 96.071%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.164 Acc 96.113%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.127 Acc 96.349%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.125 Acc 96.292%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.127 Acc 96.216%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.128 Acc 96.198%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.185 Acc 95.653%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.177 Acc 95.713%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.118 Acc 96.272%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.124 Acc 96.323%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.125 Acc 96.361%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.126 Acc 96.341%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.303%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.182 Acc 95.692%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.175 Acc 95.693%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.127 Acc 96.481%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.127 Acc 96.300%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.130 Acc 96.229%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.128 Acc 96.223%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.181 Acc 95.622%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.172 Acc 95.794%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.123 Acc 96.457%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.123 Acc 96.440%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.127 Acc 96.366%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.126 Acc 96.353%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.126 Acc 96.348%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.186 Acc 95.367%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.596%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.122 Acc 96.455%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.120 Acc 96.455%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.121 Acc 96.429%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.122 Acc 96.446%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.182 Acc 95.320%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.503%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.222 Acc 92.969%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.121 Acc 96.426%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.122 Acc 96.455%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.126 Acc 96.397%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.125 Acc 96.400%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.124 Acc 96.418%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.808%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.168 Acc 95.903%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.117 Acc 96.357%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.119 Acc 96.420%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.122 Acc 96.431%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.123 Acc 96.384%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.124 Acc 96.353%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.175 Acc 95.614%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.147 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.116 Acc 96.697%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.118 Acc 96.591%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.118 Acc 96.504%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.120 Acc 96.476%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.123 Acc 96.420%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.173 Acc 95.676%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.165 Acc 95.826%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.123 Acc 96.504%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.116 Acc 96.681%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.118 Acc 96.593%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.119 Acc 96.510%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.180 Acc 95.637%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.172 Acc 95.864%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.126 Acc 96.163%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.393%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.122 Acc 96.294%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.122 Acc 96.345%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.120 Acc 96.396%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.177 Acc 95.661%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.111 Acc 96.716%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.114 Acc 96.631%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.116 Acc 96.579%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.117 Acc 96.572%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.185 Acc 95.668%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.179 Acc 95.779%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.109 Acc 96.782%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.116 Acc 96.571%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.118 Acc 96.518%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.191 Acc 95.653%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.183 Acc 95.756%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.114 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.113 Acc 96.665%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.114 Acc 96.582%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.116 Acc 96.577%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.117 Acc 96.530%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.182 Acc 95.599%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.111 Acc 96.767%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.115 Acc 96.533%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.114 Acc 96.579%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.116 Acc 96.530%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.118 Acc 96.502%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.177 Acc 95.653%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.169 Acc 95.829%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.079 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.114 Acc 96.612%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.114 Acc 96.613%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.116 Acc 96.610%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.116 Acc 96.571%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.182 Acc 95.591%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.120 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.107 Acc 96.627%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.109 Acc 96.716%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.112 Acc 96.647%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.114 Acc 96.606%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.115 Acc 96.582%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.467%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.179 Acc 95.643%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.112 Acc 96.419%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.112 Acc 96.552%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.566%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.115 Acc 96.557%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.114 Acc 96.568%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.194 Acc 95.289%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.187 Acc 95.546%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.110 Acc 96.774%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.111 Acc 96.622%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.112 Acc 96.644%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.672%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.113 Acc 96.616%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.178 Acc 95.690%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.095 Acc 96.983%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.109 Acc 96.789%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.110 Acc 96.748%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.112 Acc 96.675%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.170 Acc 95.784%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.164 Acc 95.919%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.086 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.107 Acc 96.705%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.107 Acc 96.716%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.110 Acc 96.675%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.111 Acc 96.672%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.185 Acc 95.560%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.176 Acc 95.740%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.104 Acc 96.883%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.107 Acc 96.840%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.111 Acc 96.740%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.110 Acc 96.817%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.110 Acc 96.766%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.195 Acc 95.382%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.186 Acc 95.519%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.103 Acc 96.952%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.107 Acc 96.739%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.108 Acc 96.735%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.109 Acc 96.721%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.137 Acc 96.875%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.180 Acc 95.692%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.176 Acc 95.763%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.101 Acc 96.914%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.108 Acc 96.763%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.107 Acc 96.774%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.108 Acc 96.766%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.183 Acc 95.591%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.176 Acc 95.709%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.107 Acc 96.728%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.109 Acc 96.731%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.110 Acc 96.750%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.110 Acc 96.707%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.108 Acc 96.725%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.182 Acc 95.583%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.173 Acc 95.744%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.109 Acc 96.805%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.107 Acc 96.817%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.108 Acc 96.760%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.107 Acc 96.799%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.188 Acc 95.560%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.180 Acc 95.725%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 96.898%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.099 Acc 96.937%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.103 Acc 96.844%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.107 Acc 96.769%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.134 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.924%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.168 Acc 95.977%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.096 Acc 96.983%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.099 Acc 97.011%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.103 Acc 96.930%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.108 Acc 96.791%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.189 Acc 95.475%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.180 Acc 95.585%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.104 Acc 96.813%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.103 Acc 96.891%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.105 Acc 96.857%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.106 Acc 96.785%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.221 Acc 93.750%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.194 Acc 95.367%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.185 Acc 95.588%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.099 Acc 97.027%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.102 Acc 96.927%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.102 Acc 96.906%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.104 Acc 96.870%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.182 Acc 95.761%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.174 Acc 95.849%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.110 Acc 96.658%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.108 Acc 96.758%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.106 Acc 96.834%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.105 Acc 96.825%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.191 Acc 95.390%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.184 Acc 95.507%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.106 Acc 96.945%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.103 Acc 97.023%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.104 Acc 96.984%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.104 Acc 96.951%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.106 Acc 96.872%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.190 Acc 95.490%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.179 Acc 95.732%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.095 Acc 97.045%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.099 Acc 96.992%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.100 Acc 96.979%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.101 Acc 96.931%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.103 Acc 96.933%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.192 Acc 95.684%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.181 Acc 95.802%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.104 Acc 96.844%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.103 Acc 96.856%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.102 Acc 96.818%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.103 Acc 96.805%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.104 Acc 96.822%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.176 Acc 95.622%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.168 Acc 95.837%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.101 Acc 96.832%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.103 Acc 96.800%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.103 Acc 96.799%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.103 Acc 96.855%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.194 Acc 95.475%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.184 Acc 95.627%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.132 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.099 Acc 97.076%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.097 Acc 97.062%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.101 Acc 96.911%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.101 Acc 96.887%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.194 Acc 95.374%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.186 Acc 95.476%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.104 Acc 96.705%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.100 Acc 96.918%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.103 Acc 96.878%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.102 Acc 96.854%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.102 Acc 96.850%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.148 Acc 92.969%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.192 Acc 95.591%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.183 Acc 95.810%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.094 Acc 97.023%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.099 Acc 96.951%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.100 Acc 96.944%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.137 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.175 Acc 95.907%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.092 Acc 97.030%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.093 Acc 97.111%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.097 Acc 97.031%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.100 Acc 96.965%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.177 Acc 95.862%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.170 Acc 96.012%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.091 Acc 97.153%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.093 Acc 97.042%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.097 Acc 96.945%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.098 Acc 96.920%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.098 Acc 96.969%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.191 Acc 95.692%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.186 Acc 95.794%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.101 Acc 97.053%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.097 Acc 97.217%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.096 Acc 97.127%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.097 Acc 97.050%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.099 Acc 96.990%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.195 Acc 95.599%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.186 Acc 95.798%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.098 Acc 97.037%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.098 Acc 96.941%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.097 Acc 96.992%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.097 Acc 96.986%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.098 Acc 97.003%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.201 Acc 95.444%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.189 Acc 95.604%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.093 Acc 96.976%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.095 Acc 96.988%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.096 Acc 97.049%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.098 Acc 97.027%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.097 Acc 97.054%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.183 Acc 95.676%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.173 Acc 95.841%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.097 Acc 97.107%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.096 Acc 97.077%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.098 Acc 97.034%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.199 Acc 95.746%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.187 Acc 95.931%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.184 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.099 Acc 96.968%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.097 Acc 97.155%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.095 Acc 97.150%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.095 Acc 97.148%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.097 Acc 97.093%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.202 Acc 95.452%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.189 Acc 95.693%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.102 Acc 96.890%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.104 Acc 96.824%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.098 Acc 96.996%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.098 Acc 96.997%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.201 Acc 95.575%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.190 Acc 95.736%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.161 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.097 Acc 97.177%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.095 Acc 97.111%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.096 Acc 97.037%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.097 Acc 97.022%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.189 Acc 95.738%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.179 Acc 95.888%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.091 Acc 97.120%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.090 Acc 97.155%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.093 Acc 97.095%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.095 Acc 97.011%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.194 Acc 95.483%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.183 Acc 95.670%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.093 Acc 97.099%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.095 Acc 97.030%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.094 Acc 97.116%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.093 Acc 97.132%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.096 Acc 97.042%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.194 Acc 95.583%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.187 Acc 95.623%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.093 Acc 97.231%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.092 Acc 97.104%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.093 Acc 97.096%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.095 Acc 97.051%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.192 Acc 95.614%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.180 Acc 95.771%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.094 Acc 97.146%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.091 Acc 97.194%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.096 Acc 97.039%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.097 Acc 97.039%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.095 Acc 97.106%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.194 Acc 95.514%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.186 Acc 95.682%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.101 Acc 97.076%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.095 Acc 97.062%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.094 Acc 97.099%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.094 Acc 97.109%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.200 Acc 95.746%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.187 Acc 95.977%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.092 Acc 97.200%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.090 Acc 97.279%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.093 Acc 97.106%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.091 Acc 97.179%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.092 Acc 97.162%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.198 Acc 95.459%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.187 Acc 95.662%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.087 Acc 97.262%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.091 Acc 97.233%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.090 Acc 97.210%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.090 Acc 97.216%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.091 Acc 97.176%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.120 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.196 Acc 95.707%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.187 Acc 95.888%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.090 Acc 97.285%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.092 Acc 97.171%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.092 Acc 97.132%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.183 Acc 95.622%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.174 Acc 95.818%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.086 Acc 97.409%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.092 Acc 97.221%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.092 Acc 97.155%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.092 Acc 97.156%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.093 Acc 97.110%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.198 Acc 95.800%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.189 Acc 95.884%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.085 Acc 97.355%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.085 Acc 97.330%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.085 Acc 97.290%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.088 Acc 97.206%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.090 Acc 97.173%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.205 Acc 95.266%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.193 Acc 95.495%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.163 Acc 94.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.089 Acc 97.386%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.092 Acc 97.283%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.092 Acc 97.218%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.091 Acc 97.202%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.092 Acc 97.174%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.132 Acc 92.188%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.202 Acc 95.490%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.190 Acc 95.767%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.086 Acc 97.494%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.088 Acc 97.365%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.090 Acc 97.272%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.090 Acc 97.265%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.190 Acc 95.545%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.083 Acc 97.458%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.088 Acc 97.218%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.192 Acc 95.606%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.186 Acc 95.670%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.091 Acc 97.138%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.084 Acc 97.260%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.085 Acc 97.270%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.087 Acc 97.239%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.088 Acc 97.217%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.181 Acc 95.903%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.083 Acc 97.409%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.083 Acc 97.400%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.084 Acc 97.329%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.085 Acc 97.317%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.086 Acc 97.298%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.193 Acc 95.542%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.084 Acc 97.463%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.086 Acc 97.388%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.087 Acc 97.371%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.087 Acc 97.352%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.088 Acc 97.312%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.199 Acc 95.235%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.190 Acc 95.530%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.080 Acc 97.462%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.085 Acc 97.327%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.087 Acc 97.285%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.202 Acc 95.444%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.078 Acc 97.316%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.086 Acc 97.198%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.085 Acc 97.249%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.087 Acc 97.249%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.221 Acc 95.452%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.205 Acc 95.588%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.081 Acc 97.455%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.082 Acc 97.349%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.084 Acc 97.340%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.085 Acc 97.308%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.086 Acc 97.232%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.205 Acc 95.405%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.193 Acc 95.542%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.091 Acc 97.161%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.086 Acc 97.337%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.086 Acc 97.335%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.086 Acc 97.360%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.198 Acc 95.777%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.188 Acc 95.934%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.082 Acc 97.378%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.085 Acc 97.326%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.086 Acc 97.298%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.086 Acc 97.348%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.087 Acc 97.307%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.212 Acc 95.753%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.199 Acc 95.899%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.073 Acc 97.795%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.081 Acc 97.483%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.085 Acc 97.338%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.199 Acc 95.413%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.190 Acc 95.519%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.080 Acc 97.512%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.081 Acc 97.392%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.083 Acc 97.331%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.084 Acc 97.307%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.196 Acc 95.792%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.185 Acc 95.923%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.078 Acc 97.540%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.081 Acc 97.427%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.081 Acc 97.462%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.084 Acc 97.315%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.196 Acc 95.614%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.184 Acc 95.868%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.080 Acc 97.361%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.081 Acc 97.379%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.081 Acc 97.360%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.082 Acc 97.291%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.206 Acc 95.699%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.196 Acc 95.849%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.083 Acc 97.316%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.083 Acc 97.334%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.084 Acc 97.363%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.084 Acc 97.331%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.086 Acc 97.287%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.198 Acc 95.521%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.187 Acc 95.794%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.085 Acc 97.269%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.085 Acc 97.295%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.084 Acc 97.311%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.084 Acc 97.296%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.085 Acc 97.270%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.192 Acc 95.823%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.180 Acc 95.989%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.074 Acc 97.633%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.077 Acc 97.579%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.077 Acc 97.576%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.079 Acc 97.528%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.081 Acc 97.455%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.200 Acc 95.514%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.189 Acc 95.779%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.083 Acc 97.347%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.081 Acc 97.446%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.081 Acc 97.475%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.080 Acc 97.475%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.081 Acc 97.419%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.215 Acc 95.753%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.202 Acc 95.907%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.077 Acc 97.672%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.083 Acc 97.376%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.084 Acc 97.358%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.084 Acc 97.325%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.083 Acc 97.346%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.196 Acc 95.444%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.186 Acc 95.655%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.084 Acc 97.277%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.083 Acc 97.365%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.079 Acc 97.467%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.080 Acc 97.448%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.082 Acc 97.390%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.204 Acc 95.715%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.195 Acc 95.829%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.105 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.078 Acc 97.509%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.078 Acc 97.555%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.078 Acc 97.604%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.078 Acc 97.598%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.079 Acc 97.533%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.197 Acc 95.343%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.187 Acc 95.662%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.079 Acc 97.528%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.080 Acc 97.498%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.080 Acc 97.500%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.081 Acc 97.466%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.204 Acc 95.606%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.195 Acc 95.674%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.070 Acc 97.633%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.080 Acc 97.451%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.080 Acc 97.465%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.080 Acc 97.486%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.201 Acc 95.606%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.191 Acc 95.662%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.079 Acc 97.525%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.078 Acc 97.512%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.081 Acc 97.451%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.082 Acc 97.397%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.209 Acc 95.467%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.197 Acc 95.534%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.071 Acc 97.710%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.071 Acc 97.613%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.076 Acc 97.513%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.076 Acc 97.532%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.077 Acc 97.471%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.213 Acc 95.552%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.204 Acc 95.616%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.085 Acc 97.277%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.081 Acc 97.411%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.079 Acc 97.446%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.079 Acc 97.467%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.079 Acc 97.444%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.210 Acc 95.707%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.198 Acc 95.872%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.075 Acc 97.455%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.078 Acc 97.469%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.079 Acc 97.481%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.080 Acc 97.436%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.219 Acc 95.560%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.208 Acc 95.709%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.077 Acc 97.633%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.075 Acc 97.630%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.076 Acc 97.613%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.079 Acc 97.555%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.220 Acc 95.537%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.206 Acc 95.748%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.075 Acc 97.649%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.076 Acc 97.641%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.077 Acc 97.539%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.078 Acc 97.549%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.079 Acc 97.483%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.382%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.202 Acc 95.569%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.081 Acc 97.486%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.084 Acc 97.407%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.080 Acc 97.529%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.078 Acc 97.578%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.080 Acc 97.510%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.218 Acc 95.475%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.205 Acc 95.686%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.070 Acc 97.865%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.072 Acc 97.711%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.074 Acc 97.643%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.077 Acc 97.555%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.194 Acc 95.514%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.185 Acc 95.674%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.081 Acc 97.455%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.079 Acc 97.436%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.078 Acc 97.512%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.079 Acc 97.469%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.194 Acc 95.637%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.184 Acc 95.771%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.074 Acc 97.602%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.077 Acc 97.491%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.078 Acc 97.477%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.208 Acc 95.467%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.201 Acc 95.631%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.071 Acc 97.726%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.074 Acc 97.652%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.077 Acc 97.552%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.075 Acc 97.611%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.141 Acc 92.969%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.208 Acc 95.637%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.198 Acc 95.864%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.073 Acc 97.819%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.074 Acc 97.750%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.075 Acc 97.706%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.075 Acc 97.668%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.075 Acc 97.638%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.205 Acc 95.753%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.195 Acc 95.861%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.074 Acc 97.525%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.075 Acc 97.559%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.074 Acc 97.586%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.076 Acc 97.569%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.206 Acc 95.390%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.194 Acc 95.616%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.071 Acc 97.726%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.076 Acc 97.573%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.078 Acc 97.493%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.078 Acc 97.486%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.215 Acc 95.668%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.205 Acc 95.818%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.071 Acc 97.587%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.072 Acc 97.555%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.072 Acc 97.628%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.075 Acc 97.596%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.075 Acc 97.583%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.205 Acc 95.490%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.192 Acc 95.791%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.075 Acc 97.548%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.074 Acc 97.637%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.073 Acc 97.635%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.073 Acc 97.629%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.073 Acc 97.608%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.191 Acc 95.761%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.184 Acc 95.892%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.074 Acc 97.610%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.073 Acc 97.652%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.073 Acc 97.677%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.074 Acc 97.647%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.074 Acc 97.620%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.206 Acc 95.815%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.196 Acc 95.903%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.072 Acc 97.676%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.073 Acc 97.664%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.074 Acc 97.678%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.075 Acc 97.617%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.202 Acc 95.475%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.191 Acc 95.639%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.072 Acc 97.643%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.072 Acc 97.650%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.216 Acc 95.560%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.204 Acc 95.841%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.066 Acc 97.749%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.070 Acc 97.715%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.072 Acc 97.638%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.072 Acc 97.652%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.074 Acc 97.599%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.216 Acc 95.413%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.204 Acc 95.588%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.075 Acc 97.637%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.075 Acc 97.634%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.222 Acc 95.297%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.213 Acc 95.433%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.082 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.071 Acc 97.687%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.072 Acc 97.594%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.072 Acc 97.612%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.072 Acc 97.623%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.074 Acc 97.608%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.220 Acc 95.413%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.210 Acc 95.526%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.068 Acc 97.757%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.070 Acc 97.672%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.072 Acc 97.659%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.072 Acc 97.637%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.073 Acc 97.613%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.209 Acc 95.452%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.198 Acc 95.526%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.063 Acc 99.219%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.073 Acc 97.618%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.073 Acc 97.637%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.073 Acc 97.643%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.072 Acc 97.680%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.073 Acc 97.624%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.204 Acc 95.568%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.194 Acc 95.767%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.067 Acc 97.734%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.070 Acc 97.718%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.072 Acc 97.669%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.072 Acc 97.631%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.205 Acc 95.908%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.195 Acc 96.059%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.064 Acc 97.795%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.067 Acc 97.777%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.070 Acc 97.706%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.070 Acc 97.678%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.212 Acc 95.444%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.202 Acc 95.581%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.064 Acc 97.857%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.069 Acc 97.738%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.070 Acc 97.707%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.072 Acc 97.666%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.220 Acc 95.637%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.210 Acc 95.806%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.064 Acc 97.873%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.069 Acc 97.757%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.069 Acc 97.798%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.069 Acc 97.758%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.212 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.225 Acc 95.661%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.215 Acc 95.666%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.068 Acc 97.749%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.067 Acc 97.839%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.070 Acc 97.744%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.071 Acc 97.728%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.071 Acc 97.716%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.202 Acc 95.537%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.194 Acc 95.740%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.053 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.068 Acc 97.803%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.069 Acc 97.769%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.069 Acc 97.737%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.069 Acc 97.722%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.070 Acc 97.728%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.202 Acc 95.746%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.194 Acc 95.911%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.065 Acc 97.866%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.070 Acc 97.714%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.220 Acc 95.606%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.209 Acc 95.798%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.069 Acc 97.726%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.067 Acc 97.776%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.068 Acc 97.750%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.070 Acc 97.730%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.213 Acc 95.668%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.203 Acc 95.810%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.051 Acc 96.875%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.067 Acc 97.679%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.066 Acc 97.804%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.069 Acc 97.700%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.069 Acc 97.684%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.070 Acc 97.683%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.205 Acc 95.591%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.198 Acc 95.775%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.066 Acc 97.795%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.063 Acc 97.835%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.066 Acc 97.812%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.069 Acc 97.752%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.069 Acc 97.734%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.192 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.224 Acc 95.545%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.211 Acc 95.709%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.065 Acc 97.857%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.066 Acc 97.827%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.069 Acc 97.737%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.208 Acc 95.591%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.200 Acc 95.756%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.068 Acc 97.881%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.067 Acc 97.827%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.070 Acc 97.752%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.069 Acc 97.750%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.070 Acc 97.726%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.207 Acc 95.676%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.197 Acc 95.775%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.065 Acc 97.842%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.069 Acc 97.699%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.070 Acc 97.744%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.072 Acc 97.695%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.217 Acc 95.637%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.205 Acc 95.775%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.038 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.066 Acc 97.757%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.065 Acc 97.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.065 Acc 97.838%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.067 Acc 97.752%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.068 Acc 97.725%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.231 Acc 95.575%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.222 Acc 95.553%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.060 Acc 98.035%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.067 Acc 97.808%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.068 Acc 97.794%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.068 Acc 97.806%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.068 Acc 97.814%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.223 Acc 95.336%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.210 Acc 95.658%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.013 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.063 Acc 97.987%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.065 Acc 97.895%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.066 Acc 97.890%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.066 Acc 97.882%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.240 Acc 95.537%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.227 Acc 95.678%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.066 Acc 97.563%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.065 Acc 97.757%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.066 Acc 97.825%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.067 Acc 97.765%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.201 Acc 95.792%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.194 Acc 95.888%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.065 Acc 97.741%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.069 Acc 97.699%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.069 Acc 97.729%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.070 Acc 97.703%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.069 Acc 97.720%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.221 Acc 95.560%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.213 Acc 95.690%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.067 Acc 97.812%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.067 Acc 97.783%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.069 Acc 97.678%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.070 Acc 97.675%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.212 Acc 95.645%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.202 Acc 95.802%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.060 Acc 97.826%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.065 Acc 97.823%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.066 Acc 97.757%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.065 Acc 97.795%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.065 Acc 97.806%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.217 Acc 95.661%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.207 Acc 95.783%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.065 Acc 97.811%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.067 Acc 97.841%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.066 Acc 97.857%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.068 Acc 97.784%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.208 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.209 Acc 95.483%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.197 Acc 95.651%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.063 Acc 97.958%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.065 Acc 97.924%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.068 Acc 97.804%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.067 Acc 97.829%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.197 Acc 95.955%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.190 Acc 95.969%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.058 Acc 98.058%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.066 Acc 97.858%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.064 Acc 97.895%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.065 Acc 97.849%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.066 Acc 97.839%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.187 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.217 Acc 95.622%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.204 Acc 95.783%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.061 Acc 97.981%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.064 Acc 97.897%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.067 Acc 97.820%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.066 Acc 97.861%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.068 Acc 97.793%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.211 Acc 95.746%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.201 Acc 95.880%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.066 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.062 Acc 97.927%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.064 Acc 97.901%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.064 Acc 97.911%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.067 Acc 97.818%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.068 Acc 97.776%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.223 Acc 95.746%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.210 Acc 95.946%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.058 Acc 98.144%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.060 Acc 98.041%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.063 Acc 97.902%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.065 Acc 97.868%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.222 Acc 95.413%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.209 Acc 95.557%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.029 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.062 Acc 98.004%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.063 Acc 97.952%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.063 Acc 97.965%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.065 Acc 97.876%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.066 Acc 97.854%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.208 Acc 95.583%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.199 Acc 95.759%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.065 Acc 97.795%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.063 Acc 97.917%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.063 Acc 97.921%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.063 Acc 97.913%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.064 Acc 97.889%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.207 Acc 95.676%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.198 Acc 95.853%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.064 Acc 97.834%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.065 Acc 97.823%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.063 Acc 97.835%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.065 Acc 97.804%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.065 Acc 97.789%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.224 Acc 95.738%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.213 Acc 95.868%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.043%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.059 Acc 98.060%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.061 Acc 97.934%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.062 Acc 97.935%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.062 Acc 97.924%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.229 Acc 95.382%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.219 Acc 95.577%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.057 Acc 98.058%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.063 Acc 97.858%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.066 Acc 97.786%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.066 Acc 97.818%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.066 Acc 97.837%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.212 Acc 95.784%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.206 Acc 95.981%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.059 Acc 98.051%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.060 Acc 98.018%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.060 Acc 97.988%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.061 Acc 97.997%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.061 Acc 97.965%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.223 Acc 95.746%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.214 Acc 95.845%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ffe3c76f3843cb9b340569af0bcc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.309 Acc 10.156%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.213 Acc 20.227%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 1.997 Acc 28.895%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.762 Acc 37.972%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.580 Acc 44.933%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.431 Acc 50.535%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.645 Acc 78.125%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.597 Acc 81.969%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.587 Acc 82.035%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.846 Acc 75.781%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.662 Acc 79.517%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.633 Acc 80.372%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.612 Acc 81.102%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.584 Acc 81.871%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.564 Acc 82.493%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.355 Acc 89.062%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.406 Acc 88.181%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.400 Acc 88.188%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.424 Acc 88.281%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.455 Acc 85.442%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.454 Acc 85.681%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.444 Acc 86.132%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.434 Acc 86.481%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.425 Acc 86.800%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.326 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.355 Acc 89.457%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.349 Acc 89.700%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.372 Acc 85.156%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.384 Acc 88.297%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.384 Acc 88.378%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.382 Acc 88.372%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.378 Acc 88.513%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.372 Acc 88.674%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.323 Acc 91.406%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.304 Acc 91.066%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.299 Acc 91.247%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.335 Acc 89.844%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.344 Acc 89.643%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.337 Acc 89.548%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.341 Acc 89.470%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.338 Acc 89.659%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.335 Acc 89.730%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.291 Acc 91.406%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.277 Acc 92.110%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.271 Acc 92.156%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.268 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.336 Acc 89.851%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.328 Acc 90.174%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.327 Acc 90.249%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.318 Acc 90.475%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.316 Acc 90.500%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.273 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.277 Acc 91.847%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.275 Acc 91.810%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.287 Acc 91.267%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.292 Acc 91.317%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.293 Acc 91.201%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.290 Acc 91.278%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.295 Acc 91.146%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.243 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.273 Acc 92.412%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.269 Acc 92.351%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.291 Acc 91.406%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.277 Acc 91.499%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.282 Acc 91.531%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.282 Acc 91.484%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.282 Acc 91.480%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.282 Acc 91.537%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.216 Acc 88.281%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.245 Acc 92.953%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.242 Acc 92.980%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.237 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.271 Acc 91.778%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.271 Acc 91.888%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.274 Acc 91.824%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.277 Acc 91.671%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.277 Acc 91.713%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.288 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.245 Acc 93.363%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.242 Acc 93.136%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.163 Acc 91.406%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.270 Acc 91.948%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.261 Acc 92.316%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.265 Acc 92.229%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.265 Acc 92.213%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.264 Acc 92.177%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.234 Acc 93.564%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.230 Acc 93.470%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.254 Acc 92.466%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.257 Acc 92.281%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.256 Acc 92.416%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.257 Acc 92.388%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.256 Acc 92.425%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.261 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.243 Acc 93.147%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.234 Acc 93.322%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.246 Acc 90.625%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.254 Acc 92.876%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.249 Acc 92.806%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.254 Acc 92.707%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.252 Acc 92.628%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.253 Acc 92.621%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.213 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.209 Acc 94.322%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.204 Acc 94.356%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.321 Acc 93.750%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.248 Acc 92.922%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.247 Acc 92.821%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.244 Acc 92.839%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.245 Acc 92.825%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.244 Acc 92.816%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.229 Acc 93.851%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.225 Acc 93.816%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.205 Acc 94.531%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.249 Acc 92.938%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.242 Acc 93.093%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.241 Acc 93.080%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.238 Acc 93.136%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.238 Acc 93.045%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.234 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.213 Acc 94.276%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.208 Acc 94.380%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.236 Acc 93.100%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.236 Acc 93.054%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.235 Acc 93.166%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.235 Acc 93.169%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.234 Acc 93.223%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.256 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.224 Acc 93.611%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.218 Acc 93.676%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.288 Acc 90.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.233 Acc 93.232%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.232 Acc 93.260%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.231 Acc 93.374%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.228 Acc 93.466%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.231 Acc 93.368%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.194 Acc 94.763%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.188 Acc 94.831%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.311 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.234 Acc 93.286%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.224 Acc 93.482%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.220 Acc 93.605%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.222 Acc 93.571%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.225 Acc 93.494%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.211 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.220 Acc 94.067%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.214 Acc 94.255%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.208 Acc 94.036%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.216 Acc 93.905%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.219 Acc 93.792%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.217 Acc 93.773%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.216 Acc 93.781%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.232 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.200 Acc 94.678%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.194 Acc 94.796%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.183 Acc 94.531%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.214 Acc 93.704%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.215 Acc 93.789%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.216 Acc 93.708%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.216 Acc 93.746%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.218 Acc 93.748%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.200 Acc 94.748%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.196 Acc 94.726%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.201 Acc 94.005%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.209 Acc 93.991%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.209 Acc 93.950%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.209 Acc 93.958%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.214 Acc 93.836%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.186 Acc 95.111%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.181 Acc 95.118%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.198 Acc 94.261%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.200 Acc 94.263%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.203 Acc 94.189%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.208 Acc 94.048%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.208 Acc 94.034%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.169 Acc 92.188%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.203 Acc 94.423%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.198 Acc 94.512%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.195 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.208 Acc 93.889%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.210 Acc 93.925%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.208 Acc 93.906%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.207 Acc 93.943%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.207 Acc 93.962%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.199 Acc 94.593%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.196 Acc 94.551%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.196 Acc 94.423%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.199 Acc 94.333%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.198 Acc 94.269%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.203 Acc 94.163%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.201 Acc 94.190%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.194 Acc 94.856%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.188 Acc 94.951%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.236 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.202 Acc 94.485%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.195 Acc 94.422%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.198 Acc 94.269%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.200 Acc 94.268%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.202 Acc 94.191%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.171 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.187 Acc 95.073%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.182 Acc 95.114%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.194 Acc 94.454%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.193 Acc 94.446%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.196 Acc 94.448%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.194 Acc 94.447%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.197 Acc 94.357%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.213 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.198 Acc 94.655%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.193 Acc 94.660%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.192 Acc 94.438%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.199 Acc 94.376%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.197 Acc 94.435%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.196 Acc 94.409%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.196 Acc 94.396%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.186 Acc 95.042%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.181 Acc 95.106%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.183 Acc 92.969%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.196 Acc 94.346%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.198 Acc 94.306%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.191 Acc 94.518%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.194 Acc 94.442%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.195 Acc 94.444%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.186 Acc 95.243%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.351%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.182 Acc 94.848%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.187 Acc 94.671%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.187 Acc 94.599%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.187 Acc 94.543%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.188 Acc 94.561%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.190 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.191 Acc 94.895%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.184 Acc 94.994%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.184 Acc 94.686%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.189 Acc 94.586%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.188 Acc 94.518%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.189 Acc 94.584%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.189 Acc 94.553%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.184 Acc 95.258%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.178 Acc 95.254%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.219 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.183 Acc 94.833%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.185 Acc 94.671%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.184 Acc 94.695%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.188 Acc 94.582%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.186 Acc 94.623%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.177 Acc 95.250%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.184 Acc 94.616%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.188 Acc 94.586%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.191 Acc 94.599%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.188 Acc 94.627%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.187 Acc 94.640%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.187 Acc 95.042%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.182 Acc 95.002%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.176 Acc 94.887%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.831%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.180 Acc 94.861%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.180 Acc 94.843%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.181 Acc 94.812%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.175 Acc 95.410%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.174 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.177 Acc 94.926%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.182 Acc 94.955%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.181 Acc 94.962%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.181 Acc 94.890%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.181 Acc 94.891%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.187 Acc 95.119%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.181 Acc 95.130%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.173 Acc 94.957%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.179 Acc 94.873%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.180 Acc 94.804%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.180 Acc 94.761%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.179 Acc 94.754%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.184 Acc 95.166%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.178 Acc 95.340%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.180 Acc 94.918%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.180 Acc 94.846%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.843%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.181 Acc 94.872%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.180 Acc 94.873%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.173 Acc 92.188%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.539%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.192 Acc 94.648%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.327 Acc 93.750%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.174 Acc 94.895%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.181 Acc 94.873%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.177 Acc 94.960%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.176 Acc 94.985%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.175 Acc 94.987%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.184 Acc 95.390%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.178 Acc 95.367%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.171 Acc 95.196%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.169 Acc 95.118%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.170 Acc 95.092%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.172 Acc 95.034%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.173 Acc 95.047%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.183 Acc 95.065%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.178 Acc 95.239%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.137 Acc 98.438%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.163 Acc 95.080%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.174 Acc 94.928%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.171 Acc 95.022%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.173 Acc 95.112%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.173 Acc 95.085%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.173 Acc 95.413%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.167 Acc 95.623%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.418 Acc 90.625%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.167 Acc 94.995%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.168 Acc 95.083%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.169 Acc 95.058%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.170 Acc 95.042%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.172 Acc 95.010%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.176 Acc 95.266%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.164 Acc 95.135%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.168 Acc 95.095%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.074%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.170 Acc 95.125%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.171 Acc 95.118%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.421%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.171 Acc 95.390%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.199 Acc 92.969%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.173 Acc 94.949%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.168 Acc 95.103%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.168 Acc 95.079%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.137%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.167 Acc 95.146%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.182 Acc 95.359%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.177 Acc 95.421%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.165 Acc 95.374%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.165 Acc 95.359%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.170 Acc 95.253%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.170 Acc 95.196%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.169 Acc 95.213%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.187 Acc 95.243%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.179 Acc 95.351%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.114 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.162 Acc 95.266%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.159 Acc 95.476%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.160 Acc 95.416%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.162 Acc 95.377%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.165 Acc 95.341%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.190 Acc 95.374%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.184 Acc 95.367%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.155 Acc 95.475%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.164 Acc 95.250%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.160 Acc 95.341%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.161 Acc 95.318%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.162 Acc 95.291%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.176 Acc 95.475%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.172 Acc 95.425%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.163 Acc 95.413%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.168 Acc 95.176%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.165 Acc 95.266%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.163 Acc 95.344%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.164 Acc 95.345%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.170 Acc 95.591%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.163 Acc 95.744%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.160 Acc 95.421%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.157 Acc 95.507%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.159 Acc 95.437%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.160 Acc 95.414%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.161 Acc 95.414%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.088 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.179 Acc 95.336%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.417%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.164 Acc 95.243%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.164 Acc 95.246%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.161 Acc 95.287%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.163 Acc 95.266%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.161 Acc 95.339%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.182 Acc 95.351%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.177 Acc 95.363%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.155 Acc 95.506%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.154 Acc 95.546%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.157 Acc 95.489%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.157 Acc 95.484%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.159 Acc 95.461%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.102 Acc 96.875%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.178 Acc 95.336%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.173 Acc 95.402%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.089 Acc 98.438%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.148 Acc 95.753%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.155 Acc 95.569%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.155 Acc 95.564%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.157 Acc 95.542%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.157 Acc 95.540%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.185 Acc 95.266%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.152 Acc 95.630%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.152 Acc 95.666%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.154 Acc 95.593%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.158 Acc 95.488%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.158 Acc 95.531%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.172 Acc 95.676%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.165 Acc 95.763%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.156 Acc 95.421%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.155 Acc 95.449%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.154 Acc 95.538%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.153 Acc 95.624%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.153 Acc 95.646%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.180 Acc 92.969%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.192 Acc 95.096%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.186 Acc 95.095%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.142 Acc 96.009%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.146 Acc 95.833%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.146 Acc 95.832%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.151 Acc 95.727%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.150 Acc 95.777%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.177 Acc 95.459%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.172 Acc 95.522%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.171 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.151 Acc 95.730%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.154 Acc 95.763%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.155 Acc 95.699%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.154 Acc 95.712%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.155 Acc 95.660%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.165 Acc 95.869%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.161 Acc 95.915%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.151 Acc 95.612%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.151 Acc 95.614%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.153 Acc 95.622%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.152 Acc 95.621%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.182 Acc 95.545%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.174 Acc 95.553%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.144 Acc 95.978%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.150 Acc 95.697%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.151 Acc 95.640%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.150 Acc 95.700%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.150 Acc 95.765%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.128 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.176 Acc 95.707%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.172 Acc 95.666%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.140 Acc 95.900%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.145 Acc 95.965%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.144 Acc 95.871%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.149 Acc 95.764%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.149 Acc 95.707%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.135 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.174 Acc 95.484%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.147 Acc 95.947%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.148 Acc 95.934%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.149 Acc 95.806%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.147 Acc 95.763%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.149 Acc 95.780%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.138 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.184 Acc 95.343%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.178 Acc 95.375%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.141 Acc 96.009%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.144 Acc 95.839%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.148 Acc 95.743%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.149 Acc 95.648%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.174 Acc 95.707%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.658%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.299 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.134 Acc 96.248%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.136 Acc 96.137%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.142 Acc 95.907%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.144 Acc 95.872%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.145 Acc 95.807%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.172 Acc 95.467%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.168 Acc 95.499%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.201 Acc 96.094%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.147 Acc 95.900%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.149 Acc 95.829%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.147 Acc 95.832%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.143 Acc 95.911%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.145 Acc 95.893%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.171 Acc 95.684%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.168 Acc 95.756%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.142 Acc 95.962%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.143 Acc 95.861%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.143 Acc 95.881%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.144 Acc 95.887%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.145 Acc 95.858%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.560%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.170 Acc 95.600%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.191 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.722%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.139 Acc 95.977%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.142 Acc 95.920%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.144 Acc 95.874%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.146 Acc 95.847%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.183 Acc 95.591%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.176 Acc 95.588%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.141 Acc 95.885%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.143 Acc 95.833%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.142 Acc 95.785%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.143 Acc 95.850%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.143 Acc 95.879%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.181 Acc 95.374%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.174 Acc 95.557%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.152 Acc 95.885%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.148 Acc 95.814%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.144 Acc 95.876%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.144 Acc 95.903%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.142 Acc 95.910%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.165 Acc 95.869%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.160 Acc 95.864%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.131 Acc 96.233%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.136 Acc 96.051%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.141 Acc 95.967%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.178 Acc 95.668%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.175 Acc 95.592%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.131 Acc 96.241%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.136 Acc 96.012%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.136 Acc 96.125%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.138 Acc 96.029%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.139 Acc 96.033%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.181 Acc 95.722%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.174 Acc 95.794%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.141 Acc 95.978%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.138 Acc 96.028%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.141 Acc 96.006%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.143 Acc 95.928%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.141 Acc 95.986%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.179 Acc 95.684%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.174 Acc 95.565%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.146 Acc 95.715%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.138 Acc 95.892%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.136 Acc 95.938%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.137 Acc 95.963%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.138 Acc 95.988%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.170 Acc 95.748%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.136 Acc 95.978%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.135 Acc 96.067%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.137 Acc 96.022%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.139 Acc 95.936%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.115 Acc 97.656%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.179 Acc 95.622%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.172 Acc 95.752%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.066 Acc 99.219%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.134 Acc 96.264%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.134 Acc 96.230%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.134 Acc 96.234%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.136 Acc 96.107%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.136 Acc 96.102%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.168 Acc 95.643%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.095 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.130 Acc 96.152%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.134 Acc 96.083%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.134 Acc 96.065%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.136 Acc 96.081%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.167 Acc 95.885%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.162 Acc 95.927%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.072 Acc 99.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.129 Acc 96.380%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.132 Acc 96.241%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.131 Acc 96.205%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.135 Acc 96.113%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.136 Acc 96.064%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.173 Acc 95.784%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.167 Acc 95.822%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.127 Acc 96.496%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.131 Acc 96.323%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.135 Acc 96.084%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.069 Acc 97.656%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.168 Acc 95.893%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.162 Acc 95.931%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.137 Acc 96.279%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.138 Acc 96.160%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.136 Acc 96.120%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.134 Acc 96.109%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.134 Acc 96.084%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.179 Acc 95.661%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.175 Acc 95.600%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.140 Acc 97.656%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.140 Acc 96.109%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.138 Acc 96.109%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.138 Acc 96.078%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.139 Acc 96.000%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.137 Acc 96.064%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.181 Acc 95.800%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.176 Acc 95.783%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.121 Acc 96.604%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.128 Acc 96.292%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.131 Acc 96.268%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.130 Acc 96.246%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.131 Acc 96.215%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.168 Acc 95.707%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.164 Acc 95.892%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.132 Acc 96.187%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.132 Acc 96.164%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.129 Acc 96.203%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.132 Acc 96.133%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.133 Acc 96.131%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.173 Acc 95.521%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.120 Acc 96.558%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.126 Acc 96.377%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.128 Acc 96.377%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.128 Acc 96.320%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.129 Acc 96.298%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.126 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.174 Acc 95.614%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.169 Acc 95.662%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.125 Acc 96.397%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.126 Acc 96.416%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.131 Acc 96.289%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.131 Acc 96.231%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.179 Acc 95.483%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.173 Acc 95.596%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.123 Acc 96.210%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.122 Acc 96.343%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.124 Acc 96.369%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.126 Acc 96.347%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.127 Acc 96.335%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.123 Acc 96.875%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.166 Acc 96.009%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.162 Acc 96.070%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.124 Acc 96.388%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.133 Acc 96.122%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.131 Acc 96.178%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.132 Acc 96.151%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.175 Acc 95.833%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.292 Acc 94.531%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.125 Acc 96.233%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.124 Acc 96.292%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.128 Acc 96.239%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.126 Acc 96.308%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.128 Acc 96.275%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.177 Acc 95.577%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.130 Acc 96.310%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.128 Acc 96.261%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.127 Acc 96.249%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.128 Acc 96.226%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.129 Acc 96.201%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.071 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.171 Acc 95.769%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.165 Acc 95.907%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.124 Acc 96.481%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.132 Acc 96.238%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.127 Acc 96.307%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.126 Acc 96.341%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.126 Acc 96.329%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.081 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.182 Acc 95.869%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.174 Acc 95.903%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.127 Acc 96.272%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.125 Acc 96.401%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.126 Acc 96.358%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.128 Acc 96.289%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.186 Acc 95.529%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.178 Acc 95.573%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.122 Acc 96.318%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.122 Acc 96.397%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.126 Acc 96.286%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.124 Acc 96.329%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.127 Acc 96.247%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.172 Acc 95.947%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.165 Acc 96.012%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.124 Acc 96.426%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.125 Acc 96.420%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.122 Acc 96.452%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.124 Acc 96.419%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.124 Acc 96.393%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.082 Acc 96.875%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.722%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.170 Acc 95.787%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.190 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.129 Acc 96.078%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.122 Acc 96.253%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.122 Acc 96.322%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.121 Acc 96.337%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.122 Acc 96.334%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.181 Acc 95.468%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.120 Acc 96.419%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.126 Acc 96.343%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.124 Acc 96.309%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.124 Acc 96.242%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.124 Acc 96.254%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.114 Acc 97.656%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.166 Acc 95.978%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.161 Acc 95.993%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.124 Acc 96.496%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.124 Acc 96.335%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.121 Acc 96.436%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.123 Acc 96.401%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.179 Acc 95.575%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.173 Acc 95.775%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.111 Acc 96.566%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.116 Acc 96.541%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.118 Acc 96.538%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.120 Acc 96.495%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.121 Acc 96.501%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.199 Acc 95.328%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.193 Acc 95.324%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.120 Acc 96.475%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.122 Acc 96.470%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.120 Acc 96.520%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.122 Acc 96.482%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.175 Acc 95.583%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.170 Acc 95.682%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.118 Acc 96.479%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.120 Acc 96.411%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.121 Acc 96.420%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.084 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.178 Acc 95.753%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.171 Acc 95.822%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.113 Acc 96.774%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.115 Acc 96.786%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.115 Acc 96.724%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.116 Acc 96.643%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.118 Acc 96.601%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.179 Acc 95.645%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.171 Acc 95.759%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.121 Acc 96.350%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.119 Acc 96.457%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.121 Acc 96.415%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.121 Acc 96.392%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.181 Acc 95.668%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.176 Acc 95.670%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.176 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.119 Acc 96.627%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.115 Acc 96.657%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.114 Acc 96.667%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.118 Acc 96.557%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.120 Acc 96.496%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.078 Acc 98.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.171 Acc 95.908%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.165 Acc 95.911%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.114 Acc 96.426%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.118 Acc 96.416%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.118 Acc 96.457%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.116 Acc 96.552%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.117 Acc 96.513%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.180 Acc 95.668%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.174 Acc 95.725%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.112 Acc 96.689%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.116 Acc 96.692%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.115 Acc 96.711%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.117 Acc 96.608%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.119 Acc 96.571%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.087 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.184 Acc 95.622%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.178 Acc 95.647%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.124 Acc 94.531%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.109 Acc 96.542%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.108 Acc 96.549%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.111 Acc 96.623%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.113 Acc 96.585%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.115 Acc 96.579%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.183 Acc 95.575%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.178 Acc 95.608%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.113 Acc 96.558%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.114 Acc 96.661%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.111 Acc 96.763%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.112 Acc 96.686%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.114 Acc 96.633%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.096 Acc 98.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.172 Acc 95.970%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.166 Acc 96.020%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.106 Acc 96.898%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.110 Acc 96.727%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.112 Acc 96.683%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.115 Acc 96.624%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.116 Acc 96.552%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.132 Acc 97.656%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.181 Acc 95.661%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.175 Acc 95.631%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.051 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.107 Acc 96.914%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.113 Acc 96.692%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.115 Acc 96.628%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.116 Acc 96.591%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.192 Acc 95.475%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.185 Acc 95.604%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.106 Acc 96.937%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.112 Acc 96.747%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.110 Acc 96.808%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.112 Acc 96.744%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.113 Acc 96.664%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.128 Acc 97.656%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.529%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.169 Acc 95.627%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.106 Acc 96.782%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.109 Acc 96.688%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.113 Acc 96.605%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.115 Acc 96.559%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.114 Acc 96.562%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.183 Acc 95.343%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.176 Acc 95.382%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.103 Acc 96.860%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.110 Acc 96.708%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.113 Acc 96.654%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.114 Acc 96.625%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.142 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.175 Acc 95.862%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.169 Acc 95.876%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.109 Acc 96.821%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.113 Acc 96.683%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.114 Acc 96.624%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.174 Acc 95.661%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.167 Acc 95.802%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.096 Acc 97.239%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.102 Acc 97.003%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.105 Acc 96.924%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.108 Acc 96.830%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.109 Acc 96.799%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.614%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.178 Acc 95.748%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.107 Acc 97.084%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.106 Acc 96.968%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.107 Acc 96.922%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.111 Acc 96.803%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.113 Acc 96.728%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.184 Acc 95.645%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.178 Acc 95.709%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.105 Acc 96.860%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.108 Acc 96.770%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.109 Acc 96.735%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.110 Acc 96.704%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.113 Acc 96.668%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.115 Acc 96.875%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.187 Acc 95.661%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.178 Acc 95.833%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.103 Acc 96.890%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.104 Acc 96.891%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.108 Acc 96.810%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.109 Acc 96.776%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.110 Acc 96.744%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.168 Acc 95.845%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.106 Acc 96.782%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.108 Acc 96.844%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.110 Acc 96.771%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.110 Acc 96.774%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.111 Acc 96.744%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.182 Acc 95.715%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.175 Acc 95.837%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.111 Acc 96.686%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.189 Acc 95.568%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.179 Acc 95.728%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.151 Acc 96.875%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.104 Acc 96.852%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.103 Acc 96.883%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.105 Acc 96.761%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.108 Acc 96.709%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.110 Acc 96.685%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 95.784%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.165 Acc 95.880%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.126 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.106 Acc 96.968%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.107 Acc 96.906%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.108 Acc 96.911%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.107 Acc 96.879%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.108 Acc 96.817%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.123 Acc 96.875%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.182 Acc 95.545%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.175 Acc 95.623%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.105 Acc 96.829%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.103 Acc 96.922%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.106 Acc 96.870%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.107 Acc 96.865%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.109 Acc 96.820%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.179 Acc 95.715%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.172 Acc 95.837%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.123 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.101 Acc 96.813%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.103 Acc 96.747%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.107 Acc 96.711%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.106 Acc 96.700%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.108 Acc 96.650%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.180 Acc 95.893%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.172 Acc 95.861%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.100 Acc 97.037%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.100 Acc 97.011%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.104 Acc 96.901%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.105 Acc 96.869%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.107 Acc 96.834%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.183 Acc 95.715%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.176 Acc 95.713%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.094 Acc 97.161%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.103 Acc 96.957%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.105 Acc 96.932%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.106 Acc 96.857%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.107 Acc 96.834%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.187 Acc 95.328%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.181 Acc 95.515%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.152 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.104 Acc 96.790%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.106 Acc 96.770%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.105 Acc 96.823%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.105 Acc 96.834%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.107 Acc 96.792%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.102 Acc 97.656%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.185 Acc 95.637%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.178 Acc 95.771%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.100 Acc 96.976%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.095 Acc 97.042%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.101 Acc 96.901%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.105 Acc 96.828%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.106 Acc 96.791%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.189 Acc 95.405%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.182 Acc 95.608%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.098 Acc 97.246%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.097 Acc 97.287%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.098 Acc 97.168%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.102 Acc 97.058%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.102 Acc 97.008%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.076 Acc 98.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.184 Acc 95.583%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.176 Acc 95.682%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.100 Acc 95.312%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.097 Acc 97.115%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.097 Acc 97.034%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.101 Acc 96.994%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.103 Acc 96.904%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.104 Acc 96.898%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.189 Acc 95.429%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.183 Acc 95.522%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.135 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.099 Acc 97.068%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.101 Acc 97.062%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.102 Acc 96.981%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.101 Acc 96.988%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.104 Acc 96.908%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.192 Acc 95.653%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.183 Acc 95.740%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.103 Acc 96.852%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.105 Acc 96.758%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.106 Acc 96.776%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.106 Acc 96.764%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.106 Acc 96.778%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.113 Acc 96.875%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.181 Acc 95.459%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.172 Acc 95.701%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.103 Acc 97.045%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.104 Acc 96.887%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.104 Acc 96.922%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.104 Acc 96.887%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.106 Acc 96.810%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.173 Acc 95.800%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 95.868%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.100 Acc 97.014%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.098 Acc 96.980%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.100 Acc 96.888%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.103 Acc 96.832%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.102 Acc 96.861%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.054 Acc 98.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.180 Acc 95.715%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.173 Acc 95.783%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.099 Acc 96.983%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.101 Acc 96.980%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.104 Acc 96.888%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.103 Acc 96.894%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.182 Acc 96.001%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.173 Acc 96.051%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.076 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.094 Acc 97.138%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.097 Acc 97.038%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.102 Acc 96.869%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.105 Acc 96.777%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.181 Acc 95.684%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.177 Acc 95.713%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.097 Acc 97.058%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.102 Acc 96.966%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.102 Acc 96.939%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.103 Acc 96.883%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.186 Acc 95.545%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.178 Acc 95.655%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.092 Acc 97.239%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.096 Acc 97.108%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.100 Acc 96.987%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.102 Acc 96.912%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.116 Acc 97.656%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.184 Acc 95.661%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.833%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.095 Acc 97.092%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.098 Acc 96.979%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.102 Acc 96.924%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.102 Acc 96.914%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.194 Acc 95.792%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.184 Acc 95.837%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.092 Acc 97.432%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.095 Acc 97.275%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.097 Acc 97.140%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.098 Acc 97.070%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.099 Acc 97.022%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.174 Acc 95.822%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.102 Acc 96.960%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.100 Acc 96.997%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.099 Acc 97.031%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.099 Acc 97.012%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.190 Acc 95.715%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.181 Acc 95.798%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.106 Acc 96.728%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.102 Acc 96.824%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.103 Acc 96.776%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.103 Acc 96.811%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.105 Acc 96.799%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.076 Acc 97.656%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.196 Acc 95.653%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.187 Acc 95.752%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.195 Acc 92.969%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.106 Acc 96.852%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.101 Acc 97.120%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.098 Acc 97.145%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.098 Acc 97.083%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.100 Acc 97.054%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.192 Acc 95.374%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.182 Acc 95.596%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.094 Acc 97.192%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.094 Acc 97.178%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.096 Acc 97.153%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.098 Acc 97.072%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.098 Acc 97.040%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.080 Acc 98.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.187 Acc 95.521%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.181 Acc 95.651%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.091 Acc 97.215%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.097 Acc 97.108%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.097 Acc 97.057%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.097 Acc 97.117%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.099 Acc 97.051%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.194 Acc 95.467%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.186 Acc 95.643%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.095 Acc 96.898%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.098 Acc 96.987%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.097 Acc 96.994%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.098 Acc 96.961%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.182 Acc 95.643%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.094 Acc 97.200%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.097 Acc 97.069%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.100 Acc 96.982%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.098 Acc 97.043%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.073 Acc 98.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.182 Acc 95.815%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.175 Acc 95.880%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.095 Acc 96.960%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.093 Acc 97.104%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.094 Acc 97.114%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.097 Acc 97.083%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.124 Acc 97.656%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.196 Acc 95.707%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.187 Acc 95.725%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.093 Acc 96.991%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.095 Acc 97.044%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.095 Acc 97.037%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.097 Acc 97.020%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.083 Acc 97.656%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.183 Acc 95.645%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.176 Acc 95.697%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.092 Acc 97.123%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.095 Acc 97.062%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.096 Acc 97.080%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.096 Acc 97.079%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.098 Acc 97.656%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.183 Acc 95.637%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.176 Acc 95.713%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.101 Acc 98.438%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.089 Acc 97.416%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.094 Acc 97.209%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.095 Acc 97.199%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.094 Acc 97.189%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.094 Acc 97.178%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.188 Acc 95.645%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.179 Acc 95.736%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.112 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.096 Acc 96.991%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.094 Acc 97.174%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.094 Acc 97.127%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.095 Acc 97.107%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.098 Acc 97.032%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.187 Acc 95.738%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.178 Acc 95.857%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.145 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.094 Acc 97.174%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.093 Acc 97.166%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.094 Acc 97.173%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.096 Acc 97.139%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.092 Acc 96.875%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.184 Acc 95.614%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.177 Acc 95.666%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.089 Acc 97.260%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.091 Acc 97.207%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.094 Acc 97.089%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.094 Acc 97.081%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.188 Acc 95.722%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.181 Acc 95.841%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.083 Acc 97.556%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.087 Acc 97.419%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.089 Acc 97.293%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.092 Acc 97.157%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.094 Acc 97.129%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.077 Acc 98.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.189 Acc 95.560%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.177 Acc 95.740%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.087 Acc 97.287%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.090 Acc 97.210%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.092 Acc 97.113%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.092 Acc 97.146%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.177 Acc 95.810%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.087 Acc 97.370%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.092 Acc 97.349%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.093 Acc 97.259%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.096 Acc 97.146%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.096 Acc 97.125%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.177 Acc 95.705%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.088 Acc 97.401%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.091 Acc 97.341%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.092 Acc 97.285%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.091 Acc 97.241%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.093 Acc 97.185%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.097 Acc 97.656%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.196 Acc 95.606%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.188 Acc 95.635%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.092 Acc 97.037%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.090 Acc 97.170%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.093 Acc 97.046%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.095 Acc 97.029%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.096 Acc 96.987%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.125 Acc 97.656%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.207 Acc 95.336%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.196 Acc 95.484%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.090 Acc 97.138%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.090 Acc 97.104%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.091 Acc 97.137%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.092 Acc 97.120%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.093 Acc 97.115%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.192 Acc 95.552%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.186 Acc 95.651%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.085 Acc 97.316%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.086 Acc 97.330%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.090 Acc 97.184%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.092 Acc 97.146%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.090 Acc 97.171%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.077 Acc 97.656%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.197 Acc 95.506%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.187 Acc 95.666%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.076 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.093 Acc 97.115%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.091 Acc 97.159%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.092 Acc 97.153%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.092 Acc 97.146%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.093 Acc 97.129%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.190 Acc 95.692%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.180 Acc 95.853%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.088 Acc 97.299%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.093 Acc 97.158%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.094 Acc 97.095%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.095 Acc 97.051%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.200 Acc 95.336%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.190 Acc 95.538%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.089 Acc 97.239%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.092 Acc 97.143%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.092 Acc 97.168%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.093 Acc 97.087%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.093 Acc 97.092%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.089 Acc 96.875%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.193 Acc 95.583%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.182 Acc 95.763%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.082 Acc 97.463%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.093 Acc 97.109%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.092 Acc 97.154%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.083 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.189 Acc 95.661%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.182 Acc 95.728%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.099 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.090 Acc 97.099%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.091 Acc 97.077%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.090 Acc 97.140%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.088 Acc 97.167%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.090 Acc 97.149%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.191 Acc 95.738%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.087 Acc 97.177%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.088 Acc 97.194%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.090 Acc 97.212%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.090 Acc 97.245%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.091 Acc 97.188%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.199 Acc 95.490%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.186 Acc 95.728%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.185 Acc 94.531%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.089 Acc 97.228%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.091 Acc 97.224%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.092 Acc 97.181%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.198 Acc 95.568%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.190 Acc 95.697%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.091 Acc 97.061%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.090 Acc 97.097%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.090 Acc 97.202%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.090 Acc 97.209%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.133 Acc 98.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.198 Acc 95.707%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.190 Acc 95.721%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.080 Acc 97.486%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.087 Acc 97.345%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.089 Acc 97.243%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.090 Acc 97.268%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.203 Acc 95.173%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.192 Acc 95.390%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.086 Acc 97.198%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.089 Acc 97.181%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.089 Acc 97.216%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.090 Acc 97.202%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.207 Acc 95.405%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.198 Acc 95.553%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.090 Acc 97.239%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.088 Acc 97.268%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.090 Acc 97.251%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.090 Acc 97.195%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.091 Acc 97.149%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.132 Acc 97.656%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.190 Acc 95.506%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.181 Acc 95.643%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.085 Acc 97.362%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.087 Acc 97.310%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.088 Acc 97.288%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.088 Acc 97.284%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.088 Acc 97.260%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.193 Acc 95.467%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.184 Acc 95.635%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.083 Acc 97.362%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.089 Acc 97.201%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.088 Acc 97.251%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.088 Acc 97.241%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.090 Acc 97.235%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.118 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.189 Acc 95.692%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.181 Acc 95.771%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.089 Acc 97.260%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.089 Acc 97.282%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.089 Acc 97.269%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.089 Acc 97.262%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.197 Acc 95.444%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.187 Acc 95.596%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.117 Acc 94.531%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.083 Acc 97.409%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.085 Acc 97.334%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.087 Acc 97.228%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.088 Acc 97.212%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.089 Acc 97.182%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.200 Acc 95.637%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.190 Acc 95.787%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.081 Acc 97.300%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.084 Acc 97.310%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.084 Acc 97.366%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.084 Acc 97.385%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.087 Acc 97.294%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.193 Acc 95.699%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.184 Acc 95.783%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.078 Acc 97.517%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.082 Acc 97.357%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.084 Acc 97.290%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.083 Acc 97.366%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.085 Acc 97.329%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.199 Acc 95.614%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.188 Acc 95.791%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.082 Acc 97.494%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.085 Acc 97.299%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.088 Acc 97.251%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.086 Acc 97.294%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.087 Acc 97.271%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.198 Acc 95.653%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.189 Acc 95.767%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.087 Acc 97.316%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.090 Acc 97.186%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.092 Acc 97.127%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.092 Acc 97.119%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.090 Acc 97.160%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.133 Acc 96.875%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.195 Acc 95.351%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.187 Acc 95.522%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.078 Acc 97.525%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.083 Acc 97.322%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.088 Acc 97.224%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.089 Acc 97.248%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.127 Acc 98.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.196 Acc 95.684%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.186 Acc 95.931%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.082 Acc 97.409%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.084 Acc 97.338%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.085 Acc 97.358%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.086 Acc 97.346%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.123 Acc 97.656%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.199 Acc 95.336%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.191 Acc 95.487%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.081 Acc 97.478%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.084 Acc 97.419%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.088 Acc 97.301%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.086 Acc 97.323%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.086 Acc 97.319%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.205 Acc 95.722%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.194 Acc 95.759%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.085 Acc 97.215%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.085 Acc 97.275%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.087 Acc 97.225%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.085 Acc 97.329%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.086 Acc 97.294%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.201 Acc 95.421%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.191 Acc 95.596%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.083 Acc 97.478%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.084 Acc 97.388%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.084 Acc 97.433%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.085 Acc 97.360%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.086 Acc 97.324%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.135 Acc 98.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.208 Acc 95.320%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.200 Acc 95.484%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.081 Acc 97.339%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.083 Acc 97.396%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.083 Acc 97.428%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.084 Acc 97.372%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.086 Acc 97.284%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.098 Acc 97.656%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.187 Acc 95.761%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.179 Acc 95.911%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.086 Acc 97.177%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.084 Acc 97.291%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.084 Acc 97.332%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.084 Acc 97.337%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.084 Acc 97.340%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.102 Acc 97.656%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.205 Acc 95.514%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.192 Acc 95.736%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.077 Acc 97.509%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.080 Acc 97.392%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.084 Acc 97.282%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.087 Acc 97.196%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.086 Acc 97.202%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.108 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.220 Acc 95.676%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.207 Acc 95.787%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.076 Acc 97.602%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.079 Acc 97.563%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.083 Acc 97.381%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.084 Acc 97.371%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.056 Acc 98.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.201 Acc 95.490%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.190 Acc 95.759%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.187 Acc 93.750%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.088 Acc 97.198%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.086 Acc 97.265%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.088 Acc 97.234%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.114 Acc 97.656%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.208 Acc 95.467%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.196 Acc 95.565%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.203 Acc 89.844%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.080 Acc 97.277%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.079 Acc 97.338%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.081 Acc 97.399%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.083 Acc 97.329%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.084 Acc 97.291%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.107 Acc 97.656%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.201 Acc 95.568%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.192 Acc 95.779%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.080 Acc 97.532%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.081 Acc 97.493%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.083 Acc 97.448%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.082 Acc 97.441%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.081 Acc 98.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.191 Acc 95.777%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.182 Acc 95.896%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.078 Acc 97.579%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.080 Acc 97.560%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.081 Acc 97.473%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.083 Acc 97.425%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.208 Acc 95.475%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.199 Acc 95.612%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.076 Acc 97.556%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.083 Acc 97.353%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.083 Acc 97.341%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.083 Acc 97.365%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.089 Acc 97.656%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.201 Acc 95.753%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.190 Acc 95.849%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.080 Acc 97.525%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.082 Acc 97.469%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.084 Acc 97.407%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.083 Acc 97.439%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.205 Acc 95.606%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.194 Acc 95.713%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.077 Acc 97.525%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.082 Acc 97.411%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.081 Acc 97.459%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.081 Acc 97.432%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.082 Acc 97.404%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.200 Acc 95.707%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.189 Acc 95.849%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.082 Acc 97.415%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.083 Acc 97.387%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.083 Acc 97.362%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.104 Acc 97.656%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.195 Acc 95.637%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.188 Acc 95.721%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.078 Acc 97.424%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.080 Acc 97.431%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.081 Acc 97.397%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.082 Acc 97.374%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.197 Acc 95.637%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.189 Acc 95.779%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.078 Acc 97.424%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.081 Acc 97.334%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.082 Acc 97.379%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.081 Acc 97.440%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.082 Acc 97.377%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.203 Acc 95.398%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.191 Acc 95.573%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.079 Acc 97.401%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.081 Acc 97.396%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.081 Acc 97.379%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.080 Acc 97.450%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.206 Acc 95.560%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.194 Acc 95.697%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.078 Acc 97.625%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.080 Acc 97.586%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.079 Acc 97.597%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.079 Acc 97.592%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.081 Acc 97.555%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.436%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.188 Acc 95.484%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.079 Acc 97.432%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.077 Acc 97.501%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.078 Acc 97.508%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.080 Acc 97.450%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.081 Acc 97.429%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.198 Acc 95.684%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.190 Acc 95.767%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.072 Acc 97.811%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.075 Acc 97.651%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.078 Acc 97.567%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.201 Acc 95.637%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.192 Acc 95.682%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.075 Acc 97.625%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.079 Acc 97.458%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.078 Acc 97.501%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.079 Acc 97.485%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.081 Acc 97.450%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.132 Acc 96.875%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.204 Acc 95.351%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.193 Acc 95.522%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.075 Acc 97.556%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.078 Acc 97.431%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.078 Acc 97.469%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.079 Acc 97.456%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.079 Acc 97.478%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.203 Acc 95.661%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.195 Acc 95.756%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.076 Acc 97.664%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.078 Acc 97.602%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.079 Acc 97.550%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.078 Acc 97.516%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.079 Acc 97.513%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.209 Acc 95.436%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.200 Acc 95.655%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.072 Acc 97.757%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.080 Acc 97.528%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.079 Acc 97.519%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.079 Acc 97.496%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.079 Acc 97.475%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.206 Acc 95.359%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.200 Acc 95.472%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.076 Acc 97.641%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.080 Acc 97.428%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.080 Acc 97.426%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.080 Acc 97.416%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.213 Acc 95.537%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.202 Acc 95.658%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3569378e5fdb44eb92ce969047f8df3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.315 Acc 12.500%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.246 Acc 18.967%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.060 Acc 26.322%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.784 Acc 37.111%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.570 Acc 45.225%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.394 Acc 51.790%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.626 Acc 80.469%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.592 Acc 81.095%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.579 Acc 81.573%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.633 Acc 74.219%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.516 Acc 84.120%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.495 Acc 84.810%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.474 Acc 85.535%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.460 Acc 85.955%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.449 Acc 86.320%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.370 Acc 87.500%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.362 Acc 89.163%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.355 Acc 89.401%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.345 Acc 88.281%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.372 Acc 88.846%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.369 Acc 88.895%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.364 Acc 88.995%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.363 Acc 89.022%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.356 Acc 89.240%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.353 Acc 89.712%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.350 Acc 89.848%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.317 Acc 90.625%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.322 Acc 89.975%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.319 Acc 90.302%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.319 Acc 90.238%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.321 Acc 90.253%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.318 Acc 90.349%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.264 Acc 90.625%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.293 Acc 91.925%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.287 Acc 91.985%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.330 Acc 91.406%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.310 Acc 90.702%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.298 Acc 91.053%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.296 Acc 91.230%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.291 Acc 91.301%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.289 Acc 91.372%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.320 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.291 Acc 91.499%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.286 Acc 91.402%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.399 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.280 Acc 91.654%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.277 Acc 91.589%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.272 Acc 91.780%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.272 Acc 91.835%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.273 Acc 91.852%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.246 Acc 92.969%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.243 Acc 93.108%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.237 Acc 93.229%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.242 Acc 93.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.270 Acc 92.133%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.255 Acc 92.510%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.257 Acc 92.413%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.255 Acc 92.515%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.255 Acc 92.527%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.250 Acc 93.688%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.247 Acc 93.738%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.187 Acc 95.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.236 Acc 92.969%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.246 Acc 92.829%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.244 Acc 92.777%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.245 Acc 92.700%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.244 Acc 92.763%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.221 Acc 94.083%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.218 Acc 94.100%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.168 Acc 96.094%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.238 Acc 93.069%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.242 Acc 92.953%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.237 Acc 93.088%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.237 Acc 93.080%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.236 Acc 93.126%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.222 Acc 94.106%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.219 Acc 94.034%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.231 Acc 93.317%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.233 Acc 93.151%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.234 Acc 93.174%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.231 Acc 93.224%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.230 Acc 93.306%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.245 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.222 Acc 94.044%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.218 Acc 94.030%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.215 Acc 93.657%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.212 Acc 93.769%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.215 Acc 93.760%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.220 Acc 93.678%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.222 Acc 93.613%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.215 Acc 94.253%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.211 Acc 94.298%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.168 Acc 96.875%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.218 Acc 93.742%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.215 Acc 93.773%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.214 Acc 93.721%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.214 Acc 93.732%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.215 Acc 93.775%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.206 Acc 94.578%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.204 Acc 94.547%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.240 Acc 91.406%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.191 Acc 94.400%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.201 Acc 94.290%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.204 Acc 94.124%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.206 Acc 94.103%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.208 Acc 94.038%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.228 Acc 93.936%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.227 Acc 93.925%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.249 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.207 Acc 93.912%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.205 Acc 94.030%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.204 Acc 94.202%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.205 Acc 94.116%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.204 Acc 94.141%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.231 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.210 Acc 94.678%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.208 Acc 94.706%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.193 Acc 94.307%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.195 Acc 94.317%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.194 Acc 94.427%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.196 Acc 94.401%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.197 Acc 94.357%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.205 Acc 94.361%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.207 Acc 94.201%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.163 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.192 Acc 94.570%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.193 Acc 94.430%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.191 Acc 94.534%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.190 Acc 94.601%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.193 Acc 94.537%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.254 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.216 Acc 94.237%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.214 Acc 94.201%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.251 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.182 Acc 94.670%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.184 Acc 94.609%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.188 Acc 94.557%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.190 Acc 94.494%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.192 Acc 94.438%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.193 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.192 Acc 95.011%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.189 Acc 94.990%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.172 Acc 94.995%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.181 Acc 94.819%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.180 Acc 94.923%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.181 Acc 94.859%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.181 Acc 94.835%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.284 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.224 Acc 94.175%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.225 Acc 94.038%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.209 Acc 95.312%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.169 Acc 95.251%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.172 Acc 94.982%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.173 Acc 94.931%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.177 Acc 94.827%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.181 Acc 94.762%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.188 Acc 94.988%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.186 Acc 95.052%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.175 Acc 95.189%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.177 Acc 95.079%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.179 Acc 94.939%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.180 Acc 94.977%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.178 Acc 94.987%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.189 Acc 94.810%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.188 Acc 94.838%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.176 Acc 95.173%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.169 Acc 95.344%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.171 Acc 95.219%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.171 Acc 95.225%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.171 Acc 95.186%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.186 Acc 95.343%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.185 Acc 95.278%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.165 Acc 95.506%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.168 Acc 95.417%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.171 Acc 95.294%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.169 Acc 95.342%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.170 Acc 95.309%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.187 Acc 95.289%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.187 Acc 95.297%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.166 Acc 95.459%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.159 Acc 95.561%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.159 Acc 95.528%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.162 Acc 95.437%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.162 Acc 95.422%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.204 Acc 94.949%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.203 Acc 94.885%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.166 Acc 95.374%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.161 Acc 95.441%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.161 Acc 95.393%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.159 Acc 95.453%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.160 Acc 95.461%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.192 Acc 95.483%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.193 Acc 95.347%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.165 Acc 97.656%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.159 Acc 95.575%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.156 Acc 95.588%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.160 Acc 95.476%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.159 Acc 95.509%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.158 Acc 95.545%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.177 Acc 95.235%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.174 Acc 95.344%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.147 Acc 95.761%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.153 Acc 95.666%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.155 Acc 95.559%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.155 Acc 95.515%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.159 Acc 95.433%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.180 Acc 95.627%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.146 Acc 95.746%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.154 Acc 95.674%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.151 Acc 95.715%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.155 Acc 95.599%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.154 Acc 95.582%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.146 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.168 Acc 95.561%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.153 Acc 95.761%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.151 Acc 95.690%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.151 Acc 95.673%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.149 Acc 95.700%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.152 Acc 95.559%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.171 Acc 95.707%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.170 Acc 95.736%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.144 Acc 95.939%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.143 Acc 95.884%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.145 Acc 95.904%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.147 Acc 95.874%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.149 Acc 95.799%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.206 Acc 94.338%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.203 Acc 94.512%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.137 Acc 96.125%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.141 Acc 96.024%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.146 Acc 95.883%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.147 Acc 95.869%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.130 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.170 Acc 95.591%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.168 Acc 95.588%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.104 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.136 Acc 96.148%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.141 Acc 96.070%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.144 Acc 96.021%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.144 Acc 96.000%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.145 Acc 95.904%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.167 Acc 95.738%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.164 Acc 95.721%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.133 Acc 96.256%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.141 Acc 96.055%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.140 Acc 96.073%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.141 Acc 96.014%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.141 Acc 96.036%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.129 Acc 96.272%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.133 Acc 96.241%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.138 Acc 96.102%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.140 Acc 96.016%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.139 Acc 96.044%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.169 Acc 95.645%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.167 Acc 95.678%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.133 Acc 96.127%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.135 Acc 96.084%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.138 Acc 96.064%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.172 Acc 95.599%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.169 Acc 95.577%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.124 Acc 96.372%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.127 Acc 96.288%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.131 Acc 96.252%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.135 Acc 96.198%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.118 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.167 Acc 95.653%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.162 Acc 95.864%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.170 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.127 Acc 96.419%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.135 Acc 96.121%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.134 Acc 96.198%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.132 Acc 96.193%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.134 Acc 96.139%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.169 Acc 95.561%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.127 Acc 96.504%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.130 Acc 96.432%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.132 Acc 96.325%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.131 Acc 96.292%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.131 Acc 96.278%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.177 Acc 95.351%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.468%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.264 Acc 95.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.123 Acc 96.566%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.124 Acc 96.568%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.124 Acc 96.543%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.125 Acc 96.452%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.127 Acc 96.401%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.171 Acc 95.452%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.170 Acc 95.569%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.119 Acc 96.612%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.122 Acc 96.545%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.122 Acc 96.540%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.124 Acc 96.442%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.125 Acc 96.445%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.148 Acc 96.875%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.174 Acc 95.614%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.171 Acc 95.732%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.120 Acc 96.705%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.117 Acc 96.681%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.122 Acc 96.548%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.123 Acc 96.493%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.123 Acc 96.473%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.192 Acc 95.042%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.189 Acc 95.048%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.085 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.114 Acc 96.597%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.119 Acc 96.421%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.122 Acc 96.390%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.189 Acc 95.583%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.189 Acc 95.519%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.117 Acc 96.836%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.119 Acc 96.805%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.121 Acc 96.665%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.119 Acc 96.668%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.121 Acc 96.621%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.187 Acc 95.065%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.182 Acc 95.188%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.122 Acc 96.416%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.119 Acc 96.462%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.119 Acc 96.472%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.120 Acc 96.540%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.164 Acc 95.808%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.160 Acc 95.958%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.115 Acc 96.627%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.114 Acc 96.673%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.115 Acc 96.639%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.116 Acc 96.606%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.117 Acc 96.591%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.179 Acc 95.235%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.175 Acc 95.417%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.117 Acc 97.656%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.113 Acc 96.682%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.115 Acc 96.673%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.114 Acc 96.737%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.115 Acc 96.741%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.114 Acc 96.699%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.175 Acc 91.406%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.185 Acc 95.119%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.204%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.107 Acc 96.945%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.105 Acc 96.953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.109 Acc 96.841%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.111 Acc 96.772%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.112 Acc 96.750%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.181 Acc 95.514%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.507%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.110 Acc 96.805%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.108 Acc 96.815%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.110 Acc 96.748%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.111 Acc 96.728%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.194 Acc 95.142%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.191 Acc 95.145%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.109 Acc 96.666%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.113 Acc 96.572%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.111 Acc 96.665%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.112 Acc 96.725%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.113 Acc 96.694%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.184 Acc 95.297%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.182 Acc 95.417%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.099 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.105 Acc 96.945%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.108 Acc 96.859%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.111 Acc 96.800%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.111 Acc 96.778%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.110 Acc 96.746%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.167 Acc 95.748%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.106 Acc 97.037%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.107 Acc 96.964%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.106 Acc 96.966%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.106 Acc 96.982%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.105 Acc 96.962%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.180 Acc 95.421%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.176 Acc 95.569%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.224 Acc 92.969%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.101 Acc 97.061%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.102 Acc 96.945%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.105 Acc 96.894%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.106 Acc 96.877%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.467%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.176 Acc 95.456%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.100 Acc 97.027%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.104 Acc 96.885%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.105 Acc 96.856%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.105 Acc 96.858%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.171 Acc 95.616%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.228 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.095 Acc 97.277%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.099 Acc 97.116%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.101 Acc 96.974%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.104 Acc 96.961%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.103 Acc 96.983%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.182 Acc 95.390%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.179 Acc 95.328%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.098 Acc 97.138%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.098 Acc 97.050%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.097 Acc 97.083%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.099 Acc 96.998%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.100 Acc 96.976%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.467%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.174 Acc 95.553%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.091 Acc 97.236%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.097 Acc 97.088%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.098 Acc 97.019%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.099 Acc 97.026%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.098 Acc 97.231%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.098 Acc 97.170%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.097 Acc 97.158%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.097 Acc 97.152%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.097 Acc 97.109%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.178 Acc 95.475%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.175 Acc 95.480%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.089 Acc 97.236%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.091 Acc 97.166%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.095 Acc 97.120%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.096 Acc 97.071%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.178 Acc 95.560%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.174 Acc 95.526%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.085 Acc 97.525%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.092 Acc 97.197%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.095 Acc 97.074%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.097 Acc 97.068%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.186 Acc 95.483%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.181 Acc 95.557%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.086 Acc 97.300%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.093 Acc 97.186%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.091 Acc 97.246%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.092 Acc 97.233%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.093 Acc 97.201%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.180 Acc 95.514%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.176 Acc 95.484%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.087 Acc 97.334%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.089 Acc 97.199%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.091 Acc 97.183%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.093 Acc 97.117%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.175 Acc 95.599%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.173 Acc 95.581%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.082 Acc 97.494%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.087 Acc 97.314%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.087 Acc 97.295%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.089 Acc 97.235%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.092 Acc 97.178%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.176 Acc 95.429%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.173 Acc 95.499%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.056 Acc 99.219%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.082 Acc 97.540%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.084 Acc 97.431%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.086 Acc 97.334%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.088 Acc 97.315%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.089 Acc 97.321%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.178 Acc 95.515%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.048 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.090 Acc 97.246%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.089 Acc 97.213%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.090 Acc 97.184%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.091 Acc 97.169%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.092 Acc 97.176%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.189 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.173 Acc 95.637%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.173 Acc 95.682%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.081 Acc 97.517%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.085 Acc 97.442%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.087 Acc 97.368%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.089 Acc 97.263%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.179 Acc 95.530%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.079 Acc 97.478%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.084 Acc 97.376%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.086 Acc 97.397%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.086 Acc 97.389%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.087 Acc 97.341%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.185 Acc 96.094%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.183 Acc 95.405%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.182 Acc 95.355%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.079 Acc 97.672%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.083 Acc 97.439%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.084 Acc 97.368%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.084 Acc 97.374%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.085 Acc 97.360%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.483%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.180 Acc 95.522%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.082 Acc 97.471%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.084 Acc 97.417%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.086 Acc 97.395%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.086 Acc 97.383%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.232 Acc 94.431%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.227 Acc 94.465%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.083 Acc 97.386%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.084 Acc 97.428%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.084 Acc 97.422%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.085 Acc 97.376%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.176 Acc 95.545%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.173 Acc 95.678%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.080 Acc 97.463%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.077 Acc 97.520%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.078 Acc 97.511%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.079 Acc 97.502%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.082 Acc 97.436%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.180 Acc 95.503%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.071 Acc 97.757%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.077 Acc 97.579%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.080 Acc 97.475%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.179 Acc 95.537%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.177 Acc 95.398%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.071 Acc 97.679%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.075 Acc 97.700%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.077 Acc 97.643%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.078 Acc 97.616%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.184 Acc 95.367%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.182 Acc 95.324%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.077 Acc 97.494%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.078 Acc 97.532%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.078 Acc 97.545%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.078 Acc 97.528%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.080 Acc 97.482%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.175 Acc 95.637%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.172 Acc 95.604%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.074 Acc 97.676%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.076 Acc 97.591%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.079 Acc 97.495%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.079 Acc 97.471%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.188 Acc 95.157%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.059 Acc 99.219%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.069 Acc 97.788%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.075 Acc 97.568%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.076 Acc 97.598%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.076 Acc 97.603%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.176 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.187 Acc 95.250%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.074 Acc 97.509%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.074 Acc 97.563%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.076 Acc 97.534%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.077 Acc 97.525%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.194 Acc 95.297%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.191 Acc 95.344%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.073 Acc 97.741%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.074 Acc 97.680%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.072 Acc 97.739%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.074 Acc 97.680%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.075 Acc 97.645%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.196 Acc 95.390%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.192 Acc 95.460%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.070 Acc 97.881%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.068 Acc 97.963%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.070 Acc 97.882%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.072 Acc 97.773%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.074 Acc 97.681%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.498%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.177 Acc 95.585%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.071 Acc 97.703%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.072 Acc 97.652%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.072 Acc 97.664%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.074 Acc 97.602%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.177 Acc 96.875%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.190 Acc 95.575%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 95.507%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.071 Acc 97.679%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.073 Acc 97.680%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.071 Acc 97.713%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.074 Acc 97.631%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.184 Acc 95.251%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.183 Acc 95.278%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.065 Acc 97.865%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.069 Acc 97.761%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.070 Acc 97.763%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.070 Acc 97.758%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.071 Acc 97.748%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.184 Acc 95.467%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.185 Acc 95.239%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.072 Acc 97.571%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.068 Acc 97.722%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.066 Acc 97.815%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.069 Acc 97.783%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.071 Acc 97.744%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.184 Acc 95.320%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.180 Acc 95.394%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.092 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.069 Acc 97.734%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.069 Acc 97.700%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.072 Acc 97.631%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.071 Acc 97.678%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.198 Acc 95.235%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.196 Acc 95.289%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.064 Acc 97.950%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.067 Acc 97.882%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.070 Acc 97.711%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.070 Acc 97.700%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.193 Acc 95.552%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.189 Acc 95.526%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.065 Acc 97.819%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.067 Acc 97.816%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.064 Acc 97.882%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.065 Acc 97.839%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.069 Acc 97.775%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.174 Acc 95.753%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.028 Acc 100.000%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.068 Acc 97.819%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.065 Acc 97.866%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.068 Acc 97.789%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.069 Acc 97.806%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.068 Acc 97.798%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.174 Acc 95.777%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.172 Acc 95.763%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.122 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.063 Acc 97.888%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.064 Acc 97.940%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.063 Acc 97.981%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.064 Acc 97.933%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.065 Acc 97.885%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.206 Acc 95.057%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.199 Acc 95.130%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.061 Acc 98.136%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.064 Acc 97.994%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.068 Acc 97.859%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.067 Acc 97.871%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.067 Acc 97.859%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.181 Acc 95.777%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.180 Acc 95.612%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.060 Acc 98.074%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.064 Acc 97.866%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.064 Acc 97.864%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.065 Acc 97.871%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.067 Acc 97.829%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.199 Acc 95.421%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.195 Acc 95.402%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.076 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.064 Acc 98.113%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.064 Acc 97.987%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.062 Acc 98.007%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.061 Acc 98.042%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.063 Acc 97.990%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.195 Acc 95.173%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.195 Acc 95.270%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.061 Acc 98.053%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.063 Acc 97.931%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.065 Acc 97.893%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.201 Acc 94.972%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.201 Acc 94.943%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.062 Acc 97.909%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.065 Acc 97.832%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.187 Acc 95.231%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.063 Acc 97.811%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.063 Acc 97.866%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.065 Acc 97.835%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.064 Acc 97.880%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.064 Acc 97.865%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.191 Acc 95.374%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.191 Acc 95.336%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.061 Acc 98.012%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.062 Acc 97.948%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.062 Acc 97.957%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.061 Acc 97.976%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.063 Acc 97.910%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.192 Acc 95.266%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.188 Acc 95.274%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.061 Acc 97.741%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.061 Acc 97.889%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.063 Acc 97.882%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.063 Acc 97.907%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.199 Acc 94.872%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.196 Acc 94.974%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.058 Acc 98.120%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.060 Acc 98.107%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.058 Acc 98.116%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.060 Acc 98.011%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.062 Acc 97.926%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.195 Acc 95.560%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.190 Acc 95.550%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.022 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.056 Acc 98.260%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.058 Acc 98.165%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.058 Acc 98.129%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.059 Acc 98.056%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.060 Acc 98.046%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.200 Acc 95.196%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.194 Acc 95.219%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.056 Acc 98.221%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.055 Acc 98.212%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.057 Acc 98.147%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.057 Acc 98.137%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.059 Acc 98.055%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.196 Acc 95.127%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.191 Acc 95.328%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.053 Acc 98.182%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.054 Acc 98.181%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.058 Acc 98.110%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.059 Acc 98.091%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.060 Acc 98.035%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.189 Acc 95.444%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.186 Acc 95.456%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.053 Acc 98.283%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.052 Acc 98.317%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.055 Acc 98.178%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.057 Acc 98.116%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.059 Acc 98.041%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.196 Acc 95.297%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.192 Acc 95.243%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.057 Acc 98.066%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.057 Acc 98.053%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.059 Acc 97.983%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.059 Acc 98.007%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.058 Acc 98.029%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.201 Acc 95.266%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.199 Acc 95.258%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.049 Acc 98.275%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.052 Acc 98.228%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.055 Acc 98.162%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.058 Acc 98.093%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.058 Acc 98.034%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.169 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.205 Acc 95.057%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.203 Acc 95.103%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.011 Acc 100.000%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.054 Acc 98.175%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.055 Acc 98.146%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.056 Acc 98.113%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.057 Acc 98.073%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.056 Acc 98.094%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.203 Acc 95.343%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.200 Acc 95.417%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.051 Acc 98.314%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.052 Acc 98.263%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.055 Acc 98.139%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.056 Acc 98.126%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.056 Acc 98.118%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.191 Acc 95.676%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.189 Acc 95.585%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.052 Acc 98.182%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.054 Acc 98.134%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.055 Acc 98.113%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.054 Acc 98.176%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.056 Acc 98.141%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.209 Acc 95.034%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.205 Acc 95.005%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.111 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.051 Acc 98.182%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.053 Acc 98.189%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.054 Acc 98.199%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.054 Acc 98.196%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.055 Acc 98.163%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.194 Acc 95.436%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.190 Acc 95.569%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.052 Acc 98.144%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.052 Acc 98.189%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.052 Acc 98.206%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.053 Acc 98.206%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.055 Acc 98.177%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.148 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.210 Acc 95.421%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.204 Acc 95.464%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.047 Acc 98.291%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.054 Acc 98.092%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.054 Acc 98.108%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.054 Acc 98.106%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.054 Acc 98.115%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.206 Acc 94.957%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.204 Acc 95.056%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.051 Acc 98.283%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.051 Acc 98.259%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.052 Acc 98.235%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.053 Acc 98.184%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.053 Acc 98.210%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.205 Acc 95.034%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.056 Acc 98.151%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.053 Acc 98.286%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.055 Acc 98.222%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.054 Acc 98.249%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.052 Acc 98.302%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.214 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.199 Acc 95.166%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.195 Acc 95.258%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.046 Acc 98.407%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.048 Acc 98.422%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.050 Acc 98.331%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.051 Acc 98.289%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.053 Acc 98.250%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.200 Acc 95.459%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.197 Acc 95.491%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.051 Acc 98.190%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.054 Acc 98.099%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.054 Acc 98.149%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.054 Acc 98.151%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.198 Acc 95.459%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.196 Acc 95.402%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.049 Acc 98.290%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.050 Acc 98.301%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.050 Acc 98.307%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.133 Acc 96.875%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.198 Acc 95.204%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.196 Acc 95.223%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.049 Acc 98.314%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.052 Acc 98.200%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.053 Acc 98.194%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.053 Acc 98.221%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.054 Acc 98.172%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.186 Acc 95.452%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.185 Acc 95.417%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.045 Acc 98.507%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.049 Acc 98.418%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.048 Acc 98.380%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.051 Acc 98.258%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.202 Acc 95.483%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.198 Acc 95.414%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.044 Acc 98.468%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.052 Acc 98.296%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.197 Acc 95.467%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.190 Acc 95.503%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.048 Acc 98.340%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.049 Acc 98.282%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.049 Acc 98.280%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.051 Acc 98.261%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.208 Acc 95.606%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.202 Acc 95.546%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.049 Acc 98.399%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.050 Acc 98.371%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.051 Acc 98.284%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.052 Acc 98.278%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.051 Acc 98.302%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.197 Acc 95.251%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.191 Acc 95.305%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.048 Acc 98.391%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.046 Acc 98.403%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.049 Acc 98.339%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.049 Acc 98.334%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.049 Acc 98.303%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.201 Acc 95.073%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.197 Acc 95.033%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.044 Acc 98.538%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.045 Acc 98.484%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.047 Acc 98.432%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.049 Acc 98.348%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.049 Acc 98.364%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.197 Acc 95.637%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.196 Acc 95.522%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.047 Acc 98.484%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.047 Acc 98.426%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.046 Acc 98.399%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.048 Acc 98.356%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.049 Acc 98.321%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.208 Acc 95.173%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.206 Acc 95.161%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.045 Acc 98.468%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.046 Acc 98.472%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.048 Acc 98.380%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.048 Acc 98.371%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.048 Acc 98.375%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.216 Acc 94.531%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.205 Acc 95.606%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.200 Acc 95.612%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.046 Acc 98.484%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.047 Acc 98.465%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.049 Acc 98.401%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.048 Acc 98.461%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.048 Acc 98.428%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.207 Acc 95.429%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.043 Acc 98.484%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.046 Acc 98.399%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.048 Acc 98.383%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.049 Acc 98.328%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.049 Acc 98.328%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.201 Acc 95.251%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.199 Acc 95.285%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.039 Acc 98.670%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.042 Acc 98.593%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.045 Acc 98.489%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.046 Acc 98.459%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.047 Acc 98.425%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.193 Acc 95.514%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.193 Acc 95.476%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.047 Acc 98.360%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.045 Acc 98.356%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.048 Acc 98.323%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.048 Acc 98.317%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.048 Acc 98.317%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.233 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.218 Acc 95.266%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.212 Acc 95.243%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.047 Acc 98.445%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.048 Acc 98.472%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.047 Acc 98.432%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.047 Acc 98.453%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.047 Acc 98.442%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.222 Acc 95.212%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.221 Acc 95.091%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.044 Acc 98.561%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.044 Acc 98.488%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.045 Acc 98.500%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.045 Acc 98.482%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.048 Acc 98.403%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.219 Acc 94.779%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.215 Acc 94.803%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.042 Acc 98.530%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.045 Acc 98.465%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.045 Acc 98.430%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.044 Acc 98.451%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.045 Acc 98.423%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.120 Acc 97.656%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.211 Acc 95.367%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.208 Acc 95.386%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.043 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.040 Acc 98.623%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.041 Acc 98.624%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.043 Acc 98.518%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.045 Acc 98.478%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.046 Acc 98.462%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.208 Acc 95.212%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.205 Acc 95.173%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.046 Acc 98.538%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.043 Acc 98.593%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.044 Acc 98.523%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.045 Acc 98.465%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.046 Acc 98.450%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.216 Acc 94.717%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.211 Acc 94.881%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.040 Acc 98.639%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.041 Acc 98.612%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.042 Acc 98.583%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.045 Acc 98.506%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.045 Acc 98.483%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.212 Acc 95.158%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.212 Acc 95.013%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.047 Acc 98.314%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.048 Acc 98.313%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.048 Acc 98.339%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.047 Acc 98.340%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.047 Acc 98.358%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.226 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.227 Acc 95.173%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.225 Acc 95.079%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.041 Acc 98.584%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.042 Acc 98.577%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.043 Acc 98.526%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.044 Acc 98.447%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.045 Acc 98.420%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.194 Acc 95.730%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.191 Acc 95.616%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.012 Acc 99.219%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.038 Acc 98.662%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.039 Acc 98.682%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.041 Acc 98.609%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.041 Acc 98.589%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.043 Acc 98.545%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.214 Acc 95.080%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.210 Acc 95.106%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.040 Acc 98.693%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.039 Acc 98.655%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.041 Acc 98.567%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.043 Acc 98.562%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.044 Acc 98.492%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.199 Acc 95.630%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.195 Acc 95.612%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.037 Acc 98.741%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.040 Acc 98.637%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.043 Acc 98.537%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.043 Acc 98.509%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.224 Acc 94.756%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [200/204] Loss: 0.219 Acc 94.710%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.042 Acc 98.468%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.041 Acc 98.554%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.043 Acc 98.484%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.042 Acc 98.531%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.043 Acc 98.500%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.204 Acc 95.475%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.204 Acc 95.359%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.041 Acc 98.608%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.043 Acc 98.504%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.043 Acc 98.531%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.044 Acc 98.519%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.045 Acc 98.480%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.198 Acc 95.243%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.197 Acc 95.274%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.044 Acc 98.484%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.044 Acc 98.515%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.043 Acc 98.535%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.043 Acc 98.519%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.218 Acc 95.065%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.214 Acc 95.106%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.036 Acc 98.778%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.039 Acc 98.644%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.041 Acc 98.627%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.042 Acc 98.617%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.043 Acc 98.570%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.203 Acc 95.552%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.202 Acc 95.565%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.032 Acc 98.863%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.037 Acc 98.752%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.039 Acc 98.707%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.040 Acc 98.677%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.042 Acc 98.637%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.227 Acc 95.220%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.226 Acc 95.215%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.038 Acc 98.639%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.039 Acc 98.616%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.039 Acc 98.643%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.041 Acc 98.572%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.041 Acc 98.553%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.221 Acc 95.274%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.214 Acc 95.336%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.090 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.041 Acc 98.700%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.042 Acc 98.636%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.041 Acc 98.609%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.041 Acc 98.605%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.042 Acc 98.600%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.210 Acc 94.980%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.205 Acc 94.955%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.038 Acc 98.770%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.037 Acc 98.756%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.040 Acc 98.643%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.040 Acc 98.644%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.041 Acc 98.617%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.227 Acc 95.111%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.224 Acc 95.040%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.044 Acc 98.507%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.044 Acc 98.504%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.044 Acc 98.487%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.045 Acc 98.482%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.044 Acc 98.484%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.222 Acc 95.088%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.221 Acc 94.998%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.025 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.042 Acc 98.654%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.040 Acc 98.651%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.040 Acc 98.676%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.040 Acc 98.638%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.041 Acc 98.612%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.219 Acc 95.390%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.214 Acc 95.468%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.041 Acc 98.530%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.041 Acc 98.531%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.041 Acc 98.552%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.041 Acc 98.570%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.041 Acc 98.562%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.207 Acc 95.011%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.204 Acc 94.982%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.038 Acc 98.693%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.039 Acc 98.690%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.040 Acc 98.617%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.040 Acc 98.628%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.040 Acc 98.622%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.205 Acc 95.204%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.198 Acc 95.196%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.038 Acc 98.685%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.037 Acc 98.682%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.039 Acc 98.635%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.041 Acc 98.586%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.041 Acc 98.572%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.230 Acc 95.034%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.225 Acc 95.134%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.038 Acc 98.793%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.039 Acc 98.733%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.040 Acc 98.645%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.041 Acc 98.607%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.041 Acc 98.572%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.552%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.208 Acc 95.647%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.038 Acc 98.741%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.038 Acc 98.715%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.039 Acc 98.679%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.039 Acc 98.695%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.206 Acc 95.382%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.205 Acc 95.340%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.042 Acc 98.592%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.041 Acc 98.574%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.041 Acc 98.583%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.040 Acc 98.599%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.040 Acc 98.607%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.190 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.218 Acc 95.158%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.214 Acc 95.079%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.039 Acc 98.615%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.038 Acc 98.612%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.039 Acc 98.614%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.040 Acc 98.589%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.041 Acc 98.567%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.222 Acc 95.421%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.214 Acc 95.476%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.035 Acc 98.755%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.038 Acc 98.682%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.038 Acc 98.666%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.039 Acc 98.630%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.039 Acc 98.659%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.215 Acc 95.591%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.209 Acc 95.666%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.027 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.035 Acc 98.760%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.037 Acc 98.689%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.038 Acc 98.699%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.038 Acc 98.676%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.292 Acc 92.969%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.223 Acc 95.398%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.219 Acc 95.425%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.034 Acc 98.894%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.036 Acc 98.853%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.037 Acc 98.772%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.037 Acc 98.763%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.039 Acc 98.695%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.228 Acc 95.258%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.224 Acc 95.153%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.036 Acc 98.840%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.034 Acc 98.888%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.037 Acc 98.757%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.038 Acc 98.701%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.038 Acc 98.689%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.229 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.237 Acc 94.701%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.230 Acc 94.900%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.038 Acc 98.662%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.036 Acc 98.776%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.036 Acc 98.759%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.037 Acc 98.741%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.037 Acc 98.718%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.196 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.227 Acc 95.220%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.222 Acc 95.246%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.034 Acc 98.846%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.033 Acc 98.845%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.035 Acc 98.767%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.036 Acc 98.729%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.203 Acc 95.359%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.200 Acc 95.231%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.034 Acc 98.824%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.036 Acc 98.795%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.035 Acc 98.840%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.035 Acc 98.835%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.036 Acc 98.773%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.213 Acc 95.359%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.207 Acc 95.410%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.040 Acc 98.615%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.037 Acc 98.690%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.037 Acc 98.728%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.038 Acc 98.673%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.039 Acc 98.615%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.209 Acc 95.622%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.204 Acc 95.530%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.028 Acc 99.025%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.033 Acc 98.869%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.038 Acc 98.665%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.038 Acc 98.664%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.195 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.211 Acc 95.305%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.208 Acc 95.258%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.033 Acc 98.786%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.033 Acc 98.884%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.033 Acc 98.902%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.034 Acc 98.858%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.035 Acc 98.802%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.214 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.209 Acc 95.614%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.205 Acc 95.581%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.035 Acc 98.817%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.035 Acc 98.873%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.034 Acc 98.879%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.036 Acc 98.831%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.036 Acc 98.806%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.202 Acc 95.475%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.200 Acc 95.472%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.035 Acc 98.871%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.037 Acc 98.783%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.039 Acc 98.661%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.038 Acc 98.673%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.037 Acc 98.720%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.222 Acc 95.374%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.218 Acc 95.336%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.039 Acc 98.700%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.038 Acc 98.772%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.036 Acc 98.796%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.037 Acc 98.778%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.037 Acc 98.777%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.233 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.219 Acc 95.282%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [165/200]Batch [200/204] Loss: 0.218 Acc 95.363%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.039 Acc 98.608%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.038 Acc 98.706%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.038 Acc 98.665%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.038 Acc 98.665%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.193 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.222 Acc 95.088%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.217 Acc 95.052%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.038 Acc 98.708%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.037 Acc 98.768%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.038 Acc 98.731%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.038 Acc 98.730%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.037 Acc 98.726%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.211 Acc 95.026%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.211 Acc 95.044%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.032 Acc 98.832%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.033 Acc 98.826%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.033 Acc 98.816%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.034 Acc 98.800%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.035 Acc 98.751%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.214 Acc 95.467%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.212 Acc 95.476%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.031 Acc 98.847%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.031 Acc 98.846%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.033 Acc 98.772%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.034 Acc 98.773%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.036 Acc 98.710%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.234 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.202 Acc 95.220%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.202 Acc 95.126%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.032 Acc 98.948%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.032 Acc 98.923%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.032 Acc 98.918%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.033 Acc 98.874%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.034 Acc 98.844%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.206 Acc 95.336%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.202 Acc 95.367%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.034 Acc 98.770%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.035 Acc 98.791%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.036 Acc 98.757%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.036 Acc 98.739%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.037 Acc 98.695%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.237 Acc 95.173%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.231 Acc 95.188%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.032 Acc 98.871%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.034 Acc 98.865%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.034 Acc 98.855%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.034 Acc 98.808%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.035 Acc 98.757%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.211 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.214 Acc 95.166%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.214 Acc 95.227%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.037 Acc 98.755%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.036 Acc 98.702%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.035 Acc 98.752%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.034 Acc 98.776%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.036 Acc 98.735%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.215 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.224 Acc 95.243%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.223 Acc 95.239%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.034 Acc 98.847%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.036 Acc 98.780%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.036 Acc 98.778%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.037 Acc 98.728%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.038 Acc 98.706%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.227 Acc 95.575%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.227 Acc 95.553%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.032 Acc 98.824%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.034 Acc 98.776%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.035 Acc 98.798%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.035 Acc 98.814%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.035 Acc 98.815%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.238 Acc 95.135%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.235 Acc 95.176%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.033 Acc 98.886%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.034 Acc 98.803%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.033 Acc 98.863%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.033 Acc 98.847%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.034 Acc 98.837%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.228 Acc 94.926%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.227 Acc 94.998%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.031 Acc 98.948%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.031 Acc 98.892%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.032 Acc 98.900%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.033 Acc 98.882%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.034 Acc 98.829%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.242 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.232 Acc 95.111%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.232 Acc 95.072%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.036 Acc 98.855%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.034 Acc 98.857%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.035 Acc 98.829%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.035 Acc 98.796%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.035 Acc 98.820%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.214 Acc 95.336%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.211 Acc 95.398%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.031 Acc 98.863%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.031 Acc 98.818%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.032 Acc 98.842%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.033 Acc 98.843%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.034 Acc 98.834%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.212 Acc 95.490%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.213 Acc 95.382%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.030 Acc 99.002%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.031 Acc 98.947%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.032 Acc 98.874%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.032 Acc 98.860%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.033 Acc 98.834%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.223 Acc 94.825%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [180/200]Batch [200/204] Loss: 0.220 Acc 94.994%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.034 Acc 98.809%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.034 Acc 98.846%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.033 Acc 98.845%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.034 Acc 98.815%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.035 Acc 98.781%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.202 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.204 Acc 95.266%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.204 Acc 95.332%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.030 Acc 99.080%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.030 Acc 99.032%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.032 Acc 98.912%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.033 Acc 98.915%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.033 Acc 98.904%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.225 Acc 95.212%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.224 Acc 95.188%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.032 Acc 99.010%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.031 Acc 98.967%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.033 Acc 98.917%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.032 Acc 98.922%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.209 Acc 96.875%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.222 Acc 95.166%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.222 Acc 95.138%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.034 Acc 98.809%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.033 Acc 98.850%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.035 Acc 98.811%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.035 Acc 98.780%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.036 Acc 98.762%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.221 Acc 95.158%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.219 Acc 95.270%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.033 Acc 99.010%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.033 Acc 98.939%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.034 Acc 98.907%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.034 Acc 98.934%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.034 Acc 98.888%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.221 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.220 Acc 95.514%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.215 Acc 95.596%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.027 Acc 99.049%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.030 Acc 98.978%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.032 Acc 98.933%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.032 Acc 98.889%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.033 Acc 98.840%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.190 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.228 Acc 95.351%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.221 Acc 95.410%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.031 Acc 98.963%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.030 Acc 98.954%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.031 Acc 98.931%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.031 Acc 98.944%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.206 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.232 Acc 95.374%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.226 Acc 95.309%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.033 Acc 98.987%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.033 Acc 98.904%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.033 Acc 98.855%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.033 Acc 98.823%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.034 Acc 98.818%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.273 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.241 Acc 95.003%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.235 Acc 95.157%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.030 Acc 98.956%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.033 Acc 98.902%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.033 Acc 98.876%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.033 Acc 98.868%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.229 Acc 95.374%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.222 Acc 95.347%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.026 Acc 99.072%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.029 Acc 99.021%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.030 Acc 98.977%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.031 Acc 98.944%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.032 Acc 98.933%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.219 Acc 95.498%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.216 Acc 95.522%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.026 Acc 99.165%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.031 Acc 98.977%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.032 Acc 98.903%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.034 Acc 98.862%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.235 Acc 95.328%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.227 Acc 95.363%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.031 Acc 98.847%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.031 Acc 98.830%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.032 Acc 98.845%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.031 Acc 98.872%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.032 Acc 98.852%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.278 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.224 Acc 95.282%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.220 Acc 95.289%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.028 Acc 99.080%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.029 Acc 98.974%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.031 Acc 98.928%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.032 Acc 98.891%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.231 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.220 Acc 95.483%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.217 Acc 95.456%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.031 Acc 99.025%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.030 Acc 99.071%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.030 Acc 99.027%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.031 Acc 98.983%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.032 Acc 98.930%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.253 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.225 Acc 95.173%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.220 Acc 95.239%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.034 Acc 98.762%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.033 Acc 98.818%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.032 Acc 98.907%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.032 Acc 98.903%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.032 Acc 98.912%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.233 Acc 95.444%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [195/200]Batch [200/204] Loss: 0.227 Acc 95.375%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.039 Acc 97.656%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.031 Acc 99.033%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.033 Acc 98.951%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.032 Acc 98.941%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.034 Acc 98.876%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.222 Acc 95.413%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.220 Acc 95.324%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.033 Acc 98.871%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.031 Acc 98.877%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.032 Acc 98.845%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.032 Acc 98.829%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.033 Acc 98.824%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.134 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.220 Acc 94.957%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.221 Acc 94.998%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.029 Acc 99.002%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.030 Acc 98.958%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.032 Acc 98.887%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.032 Acc 98.886%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.032 Acc 98.899%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.220 Acc 95.645%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.221 Acc 95.686%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.029 Acc 98.925%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.028 Acc 98.989%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.029 Acc 98.985%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.031 Acc 98.938%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.031 Acc 98.930%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.206 Acc 95.599%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.206 Acc 95.410%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fb6ca5819447aebd82c31b799f0d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.324 Acc 10.938%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.191 Acc 21.248%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 1.849 Acc 34.558%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.530 Acc 46.699%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.315 Acc 54.781%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.158 Acc 60.474%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.597 Acc 79.688%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.482 Acc 85.118%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.472 Acc 85.432%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.409 Acc 89.062%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.450 Acc 86.077%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.438 Acc 86.431%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.423 Acc 86.921%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.414 Acc 87.243%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.409 Acc 87.498%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.307 Acc 87.500%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.342 Acc 89.411%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.332 Acc 89.875%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.216 Acc 93.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.361 Acc 89.001%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.348 Acc 89.432%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.342 Acc 89.525%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.336 Acc 89.778%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.331 Acc 89.880%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.325 Acc 85.938%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.306 Acc 91.197%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.300 Acc 91.227%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.262 Acc 92.188%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.308 Acc 90.339%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.301 Acc 90.664%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.301 Acc 90.721%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.298 Acc 90.925%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.296 Acc 90.990%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.277 Acc 91.955%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.269 Acc 92.013%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.283 Acc 91.870%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.278 Acc 91.861%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.279 Acc 91.785%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.274 Acc 91.973%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.272 Acc 92.011%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.227 Acc 92.188%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.257 Acc 92.721%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.252 Acc 92.829%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.358 Acc 92.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.255 Acc 92.427%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.256 Acc 92.475%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.251 Acc 92.644%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.254 Acc 92.560%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.203 Acc 91.406%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.224 Acc 93.742%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.219 Acc 93.816%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.157 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.226 Acc 93.425%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.236 Acc 93.097%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.238 Acc 92.974%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.238 Acc 92.945%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.240 Acc 93.005%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.256 Acc 92.188%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.246 Acc 92.837%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.241 Acc 93.050%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.230 Acc 93.309%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.230 Acc 93.311%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.233 Acc 93.143%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.232 Acc 93.218%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.232 Acc 93.257%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.280 Acc 87.500%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.285 Acc 91.731%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.278 Acc 91.989%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.263 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.214 Acc 93.765%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.219 Acc 93.719%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.218 Acc 93.732%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.223 Acc 93.569%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.225 Acc 93.472%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.203 Acc 94.199%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.198 Acc 94.531%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.208 Acc 93.912%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.209 Acc 93.855%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.208 Acc 93.908%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.210 Acc 93.853%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.214 Acc 93.792%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.217 Acc 94.059%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.211 Acc 94.003%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.205 Acc 96.094%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.199 Acc 93.905%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.200 Acc 93.948%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.206 Acc 93.986%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.207 Acc 94.029%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.206 Acc 94.046%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.363 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.287 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.283 Acc 92.965%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.269 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.202 Acc 94.083%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.200 Acc 94.143%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.199 Acc 94.150%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.200 Acc 94.202%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.199 Acc 94.269%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.224 Acc 94.075%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.220 Acc 93.898%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.242 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.191 Acc 94.640%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.193 Acc 94.555%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.198 Acc 94.344%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.195 Acc 94.410%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.195 Acc 94.400%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.209 Acc 94.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.205 Acc 94.516%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.189 Acc 94.694%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.182 Acc 94.792%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.184 Acc 94.692%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.183 Acc 94.703%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.185 Acc 94.715%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.195 Acc 94.964%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.190 Acc 95.044%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.218 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.175 Acc 94.903%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.178 Acc 94.932%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.184 Acc 94.684%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.182 Acc 94.734%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.181 Acc 94.775%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.200 Acc 94.732%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.195 Acc 94.850%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.231 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.172 Acc 95.104%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.177 Acc 94.978%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.179 Acc 94.884%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.179 Acc 94.890%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.179 Acc 94.898%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.195 Acc 94.900%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.237 Acc 93.750%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.157 Acc 95.529%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.169 Acc 95.192%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.173 Acc 95.053%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.173 Acc 95.024%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.176 Acc 94.927%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.190 Acc 94.995%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.185 Acc 95.106%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.193 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.165 Acc 95.289%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.168 Acc 95.285%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.172 Acc 95.198%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.170 Acc 95.172%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.169 Acc 95.224%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.197 Acc 94.609%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.193 Acc 94.792%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.214 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.167 Acc 95.243%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.162 Acc 95.394%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.167 Acc 95.297%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.166 Acc 95.303%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.165 Acc 95.311%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.210 Acc 94.833%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.206 Acc 94.986%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.167 Acc 95.158%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.161 Acc 95.371%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.161 Acc 95.411%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.162 Acc 95.412%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.164 Acc 95.359%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.184 Acc 95.227%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.180 Acc 95.266%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.157 Acc 95.676%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.162 Acc 95.631%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.159 Acc 95.580%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.160 Acc 95.513%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.160 Acc 95.507%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.195 Acc 94.872%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.190 Acc 94.858%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.160 Acc 95.499%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.155 Acc 95.601%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.153 Acc 95.671%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.156 Acc 95.603%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.193 Acc 94.887%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.186 Acc 94.990%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.144 Acc 95.854%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.147 Acc 95.841%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.150 Acc 95.772%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.150 Acc 95.702%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.152 Acc 95.645%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.155 Acc 97.656%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.192 Acc 95.158%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.187 Acc 95.149%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.155 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.139 Acc 96.040%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.145 Acc 95.748%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.145 Acc 95.803%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.148 Acc 95.782%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.179 Acc 95.343%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.176 Acc 95.379%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.127 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.144 Acc 95.908%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.148 Acc 95.810%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.144 Acc 95.912%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.144 Acc 95.903%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.146 Acc 95.874%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.128 Acc 98.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.193 Acc 95.034%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.187 Acc 95.165%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.190 Acc 94.531%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.139 Acc 95.907%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.143 Acc 95.834%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.142 Acc 95.874%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.144 Acc 95.866%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.180 Acc 95.142%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.173 Acc 95.231%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.129 Acc 96.403%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.130 Acc 96.238%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.134 Acc 96.120%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.137 Acc 96.068%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.138 Acc 96.033%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.191 Acc 95.073%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.183 Acc 95.227%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.132 Acc 96.334%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.133 Acc 96.253%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.136 Acc 96.166%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.137 Acc 96.148%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.137 Acc 96.180%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.175 Acc 95.285%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.124 Acc 96.450%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.127 Acc 96.315%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.129 Acc 96.268%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.131 Acc 96.265%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.131 Acc 96.234%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.194 Acc 95.003%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.189 Acc 95.192%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.121 Acc 96.527%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.127 Acc 96.447%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.129 Acc 96.426%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.131 Acc 96.302%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.132 Acc 96.304%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.174 Acc 95.421%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.170 Acc 95.522%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.124 Acc 96.442%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.126 Acc 96.366%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.128 Acc 96.301%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.127 Acc 96.347%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.128 Acc 96.284%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.187 Acc 94.748%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.181 Acc 94.963%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.122 Acc 96.542%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.124 Acc 96.393%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.124 Acc 96.475%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.122 Acc 96.481%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.124 Acc 96.440%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.130 Acc 97.656%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.177 Acc 95.359%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.170 Acc 95.484%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.064 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.120 Acc 96.388%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.119 Acc 96.451%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.121 Acc 96.436%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.123 Acc 96.487%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.124 Acc 96.441%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.173 Acc 95.537%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.113 Acc 96.836%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.113 Acc 96.758%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.115 Acc 96.670%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.117 Acc 96.659%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.119 Acc 96.597%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.191 Acc 95.096%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.186 Acc 95.258%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.108 Acc 96.643%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.111 Acc 96.731%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.114 Acc 96.688%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.115 Acc 96.698%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.118 Acc 96.675%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.184 Acc 95.104%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.179 Acc 95.266%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.113 Acc 96.708%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.111 Acc 96.779%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.115 Acc 96.694%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.115 Acc 96.668%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.156 Acc 96.875%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.203 Acc 94.493%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.197 Acc 94.597%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.112 Acc 96.705%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.112 Acc 96.642%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.115 Acc 96.669%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.186 Acc 95.150%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.180 Acc 95.270%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.100 Acc 96.860%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.103 Acc 96.929%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.107 Acc 96.870%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.109 Acc 96.815%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.110 Acc 96.791%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.146 Acc 96.875%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.189 Acc 95.135%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.183 Acc 95.320%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.101 Acc 97.042%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.102 Acc 97.041%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.106 Acc 96.902%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.108 Acc 96.863%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.162 Acc 96.875%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.174 Acc 95.537%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.168 Acc 95.709%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.100 Acc 97.076%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.102 Acc 97.003%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.106 Acc 96.942%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.105 Acc 96.906%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.107 Acc 96.850%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.170 Acc 95.599%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.166 Acc 95.674%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.081 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.101 Acc 97.006%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.098 Acc 97.030%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.098 Acc 96.981%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.101 Acc 96.942%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.177 Acc 95.599%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.172 Acc 95.608%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.095 Acc 97.254%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.097 Acc 97.163%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.098 Acc 97.168%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.100 Acc 97.062%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.103 Acc 97.031%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.118 Acc 97.656%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.173 Acc 95.487%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.061 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.102 Acc 96.995%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.102 Acc 96.992%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.101 Acc 97.025%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.102 Acc 97.017%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.202 Acc 94.933%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.195 Acc 95.083%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.088 Acc 97.401%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.093 Acc 97.240%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.095 Acc 97.184%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.098 Acc 97.087%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.099 Acc 97.065%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.190 Acc 94.833%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.183 Acc 95.068%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.090 Acc 97.231%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.093 Acc 97.173%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.095 Acc 97.120%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.180 Acc 95.483%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.088 Acc 97.393%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.088 Acc 97.353%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.093 Acc 97.282%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.094 Acc 97.214%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.094 Acc 97.199%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.178 Acc 95.464%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.090 Acc 97.339%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.088 Acc 97.341%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.089 Acc 97.303%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.089 Acc 97.290%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.091 Acc 97.224%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.186 Acc 95.135%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.180 Acc 95.262%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.086 Acc 97.393%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.085 Acc 97.415%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.085 Acc 97.410%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.088 Acc 97.335%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.090 Acc 97.290%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.184 Acc 95.266%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.176 Acc 95.402%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.174 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.088 Acc 97.378%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.087 Acc 97.330%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.089 Acc 97.225%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.088 Acc 97.245%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.089 Acc 97.227%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.112 Acc 97.656%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.195 Acc 94.817%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.189 Acc 95.002%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.084 Acc 97.345%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.086 Acc 97.267%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.087 Acc 97.230%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.089 Acc 97.199%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.191 Acc 95.080%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.184 Acc 95.316%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.121 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.072 Acc 97.695%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.077 Acc 97.551%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.081 Acc 97.485%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.084 Acc 97.444%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.085 Acc 97.429%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.122 Acc 96.875%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.183 Acc 95.382%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.177 Acc 95.503%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.079 Acc 97.625%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.080 Acc 97.571%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.081 Acc 97.519%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.081 Acc 97.498%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.084 Acc 97.419%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.089 Acc 96.875%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.183 Acc 95.196%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.178 Acc 95.320%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.077 Acc 97.602%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.077 Acc 97.497%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.079 Acc 97.534%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.082 Acc 97.483%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.084 Acc 97.415%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.182 Acc 95.653%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.075 Acc 97.648%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.078 Acc 97.568%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.079 Acc 97.543%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.081 Acc 97.466%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.109 Acc 97.656%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.180 Acc 95.490%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.173 Acc 95.581%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.076 Acc 97.471%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.075 Acc 97.629%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.079 Acc 97.576%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.079 Acc 97.561%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.080 Acc 97.508%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.185 Acc 95.189%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.180 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.076 Acc 97.803%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.074 Acc 97.827%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.075 Acc 97.724%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.077 Acc 97.666%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.078 Acc 97.638%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.184 Acc 95.150%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.177 Acc 95.289%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.078 Acc 97.618%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.078 Acc 97.625%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.078 Acc 97.580%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.080 Acc 97.525%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.191 Acc 95.382%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.185 Acc 95.495%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.077 Acc 97.803%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.075 Acc 97.668%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.075 Acc 97.677%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.076 Acc 97.619%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.125 Acc 97.656%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.192 Acc 95.064%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.073 Acc 97.695%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.074 Acc 97.594%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.074 Acc 97.597%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.074 Acc 97.637%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.075 Acc 97.633%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.188 Acc 95.289%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.180 Acc 95.515%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.071 Acc 97.672%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.073 Acc 97.661%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.074 Acc 97.604%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.075 Acc 97.555%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.207 Acc 94.856%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.197 Acc 95.013%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.066 Acc 97.811%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.067 Acc 97.909%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.070 Acc 97.794%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.072 Acc 97.779%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.073 Acc 97.742%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.194 Acc 94.995%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.190 Acc 95.087%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.064 Acc 97.896%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.067 Acc 97.862%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.067 Acc 97.887%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.069 Acc 97.843%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.070 Acc 97.817%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.172 Acc 96.875%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.205 Acc 95.019%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.194 Acc 95.243%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.071 Acc 97.873%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.070 Acc 97.781%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.071 Acc 97.748%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.070 Acc 97.750%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.194 Acc 95.065%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.186 Acc 95.239%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.064 Acc 98.028%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.064 Acc 98.014%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.068 Acc 97.838%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.070 Acc 97.795%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.072 Acc 97.730%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.189%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.177 Acc 95.355%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.065 Acc 97.913%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.066 Acc 97.908%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.066 Acc 97.925%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.068 Acc 97.846%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.211 Acc 94.670%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.201 Acc 94.881%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.058 Acc 98.175%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.062 Acc 97.998%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.063 Acc 97.991%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.064 Acc 97.941%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.065 Acc 97.926%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.118 Acc 96.875%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.193 Acc 95.367%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.184 Acc 95.550%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.059 Acc 98.082%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.061 Acc 98.033%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.063 Acc 97.970%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.066 Acc 97.901%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.210 Acc 94.817%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.198 Acc 95.083%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.065 Acc 97.896%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.065 Acc 97.998%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.065 Acc 97.944%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.066 Acc 97.865%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.196 Acc 95.080%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.189 Acc 95.204%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.068 Acc 99.219%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.058 Acc 98.229%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.060 Acc 98.092%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.061 Acc 97.999%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.062 Acc 97.938%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.209 Acc 94.841%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.195 Acc 95.064%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.056 Acc 98.229%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.059 Acc 98.123%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.061 Acc 98.074%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.061 Acc 98.024%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.063 Acc 97.993%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.193 Acc 95.119%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.186 Acc 95.309%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.053 Acc 98.221%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.057 Acc 98.146%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.060 Acc 98.040%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.060 Acc 98.021%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.061 Acc 97.995%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.200 Acc 94.872%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.188 Acc 95.161%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.052 Acc 98.260%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.053 Acc 98.266%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.057 Acc 98.129%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.059 Acc 98.058%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.060 Acc 98.029%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.195 Acc 95.196%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.184 Acc 95.394%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.031 Acc 97.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.060 Acc 97.950%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.058 Acc 98.072%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.059 Acc 98.064%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.060 Acc 98.038%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.060 Acc 98.012%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.149 Acc 97.656%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.193 Acc 95.266%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.183 Acc 95.390%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.052 Acc 98.283%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.056 Acc 98.189%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.059 Acc 98.091%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.060 Acc 98.084%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.210 Acc 94.771%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.201 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.057 Acc 98.198%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.057 Acc 98.169%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.057 Acc 98.162%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.059 Acc 98.073%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.059 Acc 98.054%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.216 Acc 94.848%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.206 Acc 94.982%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.051 Acc 98.376%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.052 Acc 98.321%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.055 Acc 98.174%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.057 Acc 98.121%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.170 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.215 Acc 94.895%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.206 Acc 95.072%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.049 Acc 98.329%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.054 Acc 98.162%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.055 Acc 98.136%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.055 Acc 98.143%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.056 Acc 98.105%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.215 Acc 94.854%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.058 Acc 96.875%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.048 Acc 98.430%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.050 Acc 98.336%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.052 Acc 98.292%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.054 Acc 98.208%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.055 Acc 98.169%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.209 Acc 94.972%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.198 Acc 95.173%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.050 Acc 98.283%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.051 Acc 98.270%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.053 Acc 98.199%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.054 Acc 98.180%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.057 Acc 98.096%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.212 Acc 94.879%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.206 Acc 94.943%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.053 Acc 98.298%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.053 Acc 98.255%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.053 Acc 98.269%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.054 Acc 98.194%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.055 Acc 98.146%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.052 Acc 98.275%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.053 Acc 98.255%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.054 Acc 98.287%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.055 Acc 98.215%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.056 Acc 98.155%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.204 Acc 95.297%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.195 Acc 95.410%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.047 Acc 98.345%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.052 Acc 98.270%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.053 Acc 98.230%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.051 Acc 98.299%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.054 Acc 98.213%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.207 Acc 95.111%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.049 Acc 98.345%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.052 Acc 98.204%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.051 Acc 98.301%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.053 Acc 98.238%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.217 Acc 95.011%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.210 Acc 95.095%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.053 Acc 98.175%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.051 Acc 98.247%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.051 Acc 98.247%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.051 Acc 98.271%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.205 Acc 94.438%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.193 Acc 94.803%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.049 Acc 98.368%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.050 Acc 98.321%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.052 Acc 98.300%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.051 Acc 98.301%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.051 Acc 98.311%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.211 Acc 94.833%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.201 Acc 94.986%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.046 Acc 98.480%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.047 Acc 98.409%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.049 Acc 98.375%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.051 Acc 98.344%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.099 Acc 96.875%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.217 Acc 94.903%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.206 Acc 95.106%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.052 Acc 98.260%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.055 Acc 98.216%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.052 Acc 98.284%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.054 Acc 98.200%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.054 Acc 98.194%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.223 Acc 94.841%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.210 Acc 95.040%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.047 Acc 98.314%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.046 Acc 98.379%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.048 Acc 98.339%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.048 Acc 98.367%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.050 Acc 98.353%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.211 Acc 94.926%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.202 Acc 95.145%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.038 Acc 96.875%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.042 Acc 98.631%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.047 Acc 98.403%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.048 Acc 98.373%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.049 Acc 98.379%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.048 Acc 98.369%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.231 Acc 94.748%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.219 Acc 94.932%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.048 Acc 98.348%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.047 Acc 98.409%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.048 Acc 98.387%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.049 Acc 98.392%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.218 Acc 95.243%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.208 Acc 95.305%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.064 Acc 96.094%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.047 Acc 98.445%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.044 Acc 98.574%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.045 Acc 98.549%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.045 Acc 98.525%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.046 Acc 98.466%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.218 Acc 94.787%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.205 Acc 94.928%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.047 Acc 98.461%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.049 Acc 98.406%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.048 Acc 98.430%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.049 Acc 98.384%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.205 Acc 95.367%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.045 Acc 98.492%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.046 Acc 98.440%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.047 Acc 98.420%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.048 Acc 98.395%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.195 Acc 95.282%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.188 Acc 95.421%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.042 Acc 98.600%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.045 Acc 98.418%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.045 Acc 98.430%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.047 Acc 98.389%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.047 Acc 98.391%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.170 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.211 Acc 95.189%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.202 Acc 95.328%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.047 Acc 98.407%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.045 Acc 98.488%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.046 Acc 98.448%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.046 Acc 98.432%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.048 Acc 98.378%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.235 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.221 Acc 95.034%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.214 Acc 95.114%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.042 Acc 98.577%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.045 Acc 98.480%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.045 Acc 98.492%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.046 Acc 98.420%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.046 Acc 98.433%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.193 Acc 95.374%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.187 Acc 95.414%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.034 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.038 Acc 98.631%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.041 Acc 98.562%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.042 Acc 98.567%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.043 Acc 98.537%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.044 Acc 98.489%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.223 Acc 94.593%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.215 Acc 94.761%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.043 Acc 98.523%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.043 Acc 98.570%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.043 Acc 98.559%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.042 Acc 98.582%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.044 Acc 98.520%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.205 Acc 95.119%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.195 Acc 95.281%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.034 Acc 97.656%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.045 Acc 98.399%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.042 Acc 98.550%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.042 Acc 98.580%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.043 Acc 98.589%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.044 Acc 98.544%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.216 Acc 95.127%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.043 Acc 98.561%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.041 Acc 98.597%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.041 Acc 98.603%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.042 Acc 98.545%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.262 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.234 Acc 95.042%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.224 Acc 94.998%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.039 Acc 98.646%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.042 Acc 98.566%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.043 Acc 98.575%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.044 Acc 98.484%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.044 Acc 98.523%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.209 Acc 95.019%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.201 Acc 95.215%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.039 Acc 98.677%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.039 Acc 98.612%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.040 Acc 98.614%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.041 Acc 98.588%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.042 Acc 98.572%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.144 Acc 96.875%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.205 Acc 95.166%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.197 Acc 95.417%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.043 Acc 98.461%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.042 Acc 98.588%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.043 Acc 98.535%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.044 Acc 98.522%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.187 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.219 Acc 95.150%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.206 Acc 95.386%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.045 Acc 98.443%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.044 Acc 98.482%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.044 Acc 98.480%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.212 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.221 Acc 95.042%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.213 Acc 95.048%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.041 Acc 98.600%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.042 Acc 98.570%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.043 Acc 98.534%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.044 Acc 98.523%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.044 Acc 98.486%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.225 Acc 95.258%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.211 Acc 95.425%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.035 Acc 98.793%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.040 Acc 98.659%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.041 Acc 98.635%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.042 Acc 98.632%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.041 Acc 98.639%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.234 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.223 Acc 95.019%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.212 Acc 95.138%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.035 Acc 98.855%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.042 Acc 98.557%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.041 Acc 98.566%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.041 Acc 98.570%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.218 Acc 94.872%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.210 Acc 94.974%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.037 Acc 98.801%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.040 Acc 98.630%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.040 Acc 98.621%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.040 Acc 98.629%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.214 Acc 96.094%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.244 Acc 94.547%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.232 Acc 94.780%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.034 Acc 98.855%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.040 Acc 98.659%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.043 Acc 98.531%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.044 Acc 98.496%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.043 Acc 98.525%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.215 Acc 94.980%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.203 Acc 95.118%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.035 Acc 98.811%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.037 Acc 98.788%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.037 Acc 98.753%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.038 Acc 98.712%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.217 Acc 95.088%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.205 Acc 95.243%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.071 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.044 Acc 98.708%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.042 Acc 98.678%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.041 Acc 98.648%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.040 Acc 98.662%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.040 Acc 98.643%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.221 Acc 94.910%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.207 Acc 95.262%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.039 Acc 98.677%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.041 Acc 98.647%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.039 Acc 98.705%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.041 Acc 98.650%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.042 Acc 98.590%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.231 Acc 94.964%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.217 Acc 95.208%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.037 Acc 98.832%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.037 Acc 98.826%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.037 Acc 98.816%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.037 Acc 98.775%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.039 Acc 98.687%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.218 Acc 95.367%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.205 Acc 95.534%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.031 Acc 98.909%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.033 Acc 98.811%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.035 Acc 98.759%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.036 Acc 98.714%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.038 Acc 98.653%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.234 Acc 94.833%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.222 Acc 95.106%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.038 Acc 98.677%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.038 Acc 98.705%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.038 Acc 98.699%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.038 Acc 98.701%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.224 Acc 95.196%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.213 Acc 95.425%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.035 Acc 98.747%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.034 Acc 98.752%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.036 Acc 98.723%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.037 Acc 98.708%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.037 Acc 98.717%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.234 Acc 95.266%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.222 Acc 95.472%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.038 Acc 98.631%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.038 Acc 98.725%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.037 Acc 98.733%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.038 Acc 98.718%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.038 Acc 98.729%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.255 Acc 94.709%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.242 Acc 94.807%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.041 Acc 98.608%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.038 Acc 98.682%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.038 Acc 98.700%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.038 Acc 98.728%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.039 Acc 98.687%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.210 Acc 95.011%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.199 Acc 95.188%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.037 Acc 98.670%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.037 Acc 98.694%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.036 Acc 98.744%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.036 Acc 98.714%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.240 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.223 Acc 95.220%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.209 Acc 95.476%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.038 Acc 98.739%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.037 Acc 98.787%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.037 Acc 98.762%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.038 Acc 98.716%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.038 Acc 98.720%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.240 Acc 94.794%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.224 Acc 95.072%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.041 Acc 98.592%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.037 Acc 98.748%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.037 Acc 98.707%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.037 Acc 98.704%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.037 Acc 98.717%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [100/204] Loss: 0.232 Acc 94.462%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.218 Acc 94.807%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.036 Acc 98.764%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.037 Acc 98.736%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.038 Acc 98.706%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.038 Acc 98.706%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.214 Acc 95.026%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.203 Acc 95.301%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.027 Acc 99.064%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.030 Acc 99.028%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.033 Acc 98.910%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.035 Acc 98.810%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.036 Acc 98.779%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.279 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.224 Acc 94.949%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.212 Acc 95.176%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.029 Acc 98.994%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.033 Acc 98.869%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.032 Acc 98.905%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.033 Acc 98.858%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.034 Acc 98.835%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.228 Acc 94.980%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.214 Acc 95.270%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.035 Acc 98.793%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.033 Acc 98.853%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.036 Acc 98.754%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.037 Acc 98.734%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.036 Acc 98.751%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.226 Acc 95.096%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.215 Acc 95.289%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.027 Acc 99.080%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.031 Acc 98.951%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.031 Acc 98.957%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.031 Acc 98.958%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.034 Acc 98.873%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.217 Acc 94.980%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.206 Acc 95.184%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.029 Acc 99.072%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.032 Acc 98.902%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.032 Acc 98.917%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.033 Acc 98.873%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.212 Acc 95.127%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.204 Acc 95.278%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.033 Acc 98.824%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.033 Acc 98.850%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.034 Acc 98.822%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.034 Acc 98.835%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.035 Acc 98.820%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.226 Acc 95.119%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.214 Acc 95.340%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.031 Acc 98.931%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.032 Acc 98.871%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.033 Acc 98.812%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.035 Acc 98.787%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.216 Acc 94.640%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.208 Acc 94.900%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.033 Acc 98.925%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.034 Acc 98.861%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.034 Acc 98.845%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.035 Acc 98.833%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.035 Acc 98.832%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.286 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.229 Acc 94.554%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.219 Acc 94.838%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.031 Acc 98.878%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.031 Acc 98.935%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.031 Acc 98.923%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.032 Acc 98.895%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.032 Acc 98.857%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.251 Acc 94.848%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.238 Acc 95.204%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.036 Acc 98.764%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.034 Acc 98.819%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.034 Acc 98.815%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.034 Acc 98.818%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.232 Acc 94.616%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.218 Acc 94.799%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.031 Acc 98.900%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.032 Acc 98.855%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.033 Acc 98.847%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.033 Acc 98.849%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.235 Acc 94.995%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.220 Acc 95.157%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.029 Acc 98.979%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.032 Acc 98.954%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.033 Acc 98.876%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.033 Acc 98.915%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.033 Acc 98.910%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.228 Acc 94.763%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.215 Acc 95.083%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.032 Acc 98.786%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.029 Acc 98.888%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.031 Acc 98.879%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.031 Acc 98.880%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.032 Acc 98.857%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.228 Acc 95.196%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.213 Acc 95.468%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.030 Acc 98.971%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.032 Acc 98.896%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.031 Acc 98.946%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.032 Acc 98.907%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.032 Acc 98.902%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.305 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.223 Acc 95.359%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.211 Acc 95.460%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.028 Acc 99.080%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.033 Acc 98.923%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.033 Acc 98.889%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.033 Acc 98.870%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.033 Acc 98.888%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.222 Acc 94.941%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.209 Acc 95.211%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.031 Acc 98.878%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.030 Acc 98.904%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.031 Acc 98.920%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.031 Acc 98.911%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.031 Acc 98.885%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.222 Acc 95.150%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.208 Acc 95.359%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.033 Acc 98.933%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.033 Acc 98.919%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.033 Acc 98.897%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.033 Acc 98.886%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.032 Acc 98.912%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.244 Acc 94.964%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.229 Acc 95.075%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.030 Acc 98.909%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.033 Acc 98.896%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.031 Acc 98.951%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.031 Acc 98.950%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.032 Acc 98.907%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.227 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.231 Acc 95.088%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.220 Acc 95.192%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.025 Acc 99.141%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.027 Acc 99.001%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.027 Acc 98.993%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.029 Acc 98.950%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.030 Acc 98.921%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.242 Acc 94.547%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.226 Acc 94.784%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.029 Acc 98.909%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.031 Acc 98.877%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.031 Acc 98.897%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.032 Acc 98.878%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.032 Acc 98.865%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.237 Acc 94.957%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.226 Acc 95.227%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.028 Acc 98.987%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.030 Acc 98.978%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.030 Acc 98.975%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.030 Acc 98.936%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.031 Acc 98.926%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.230 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.226 Acc 94.926%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.212 Acc 95.141%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.026 Acc 99.103%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.029 Acc 99.014%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.030 Acc 98.991%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.030 Acc 98.960%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.257 Acc 94.833%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.240 Acc 95.037%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.029 Acc 99.080%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.030 Acc 99.017%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.030 Acc 98.975%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.030 Acc 98.965%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.031 Acc 98.954%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.279 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.236 Acc 94.980%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.226 Acc 95.188%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.032 Acc 98.909%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.030 Acc 98.916%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.031 Acc 98.871%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.032 Acc 98.843%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.032 Acc 98.865%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.224 Acc 95.135%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.212 Acc 95.332%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.025 Acc 98.438%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.033 Acc 99.002%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.030 Acc 98.982%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.031 Acc 98.909%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.031 Acc 98.937%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.364 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.253 Acc 94.794%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.235 Acc 95.033%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.032 Acc 98.863%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.030 Acc 98.958%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.030 Acc 98.925%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.029 Acc 98.979%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.029 Acc 98.986%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.219 Acc 95.359%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.208 Acc 95.553%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.026 Acc 99.018%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.027 Acc 99.052%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.028 Acc 99.021%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.029 Acc 99.001%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.029 Acc 98.983%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.266 Acc 95.312%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.227 Acc 94.972%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.217 Acc 95.196%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.056 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.027 Acc 99.110%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.026 Acc 99.067%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.027 Acc 99.058%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.027 Acc 99.073%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.028 Acc 99.013%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.282 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.256 Acc 94.864%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.245 Acc 94.932%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.027 Acc 99.080%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.029 Acc 99.001%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.031 Acc 98.967%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.030 Acc 98.954%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.030 Acc 98.991%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [100/204] Loss: 0.215 Acc 94.910%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.200 Acc 95.274%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.028 Acc 99.018%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.027 Acc 99.040%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.028 Acc 99.022%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.029 Acc 98.972%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.254 Acc 94.825%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.241 Acc 94.970%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.030 Acc 98.925%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.030 Acc 98.912%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.030 Acc 98.907%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.031 Acc 98.913%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.031 Acc 98.904%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.223 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.233 Acc 94.964%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.220 Acc 95.165%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.027 Acc 99.103%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.029 Acc 99.032%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.030 Acc 98.998%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.030 Acc 98.987%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.030 Acc 98.983%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.236 Acc 95.189%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.219 Acc 95.507%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.031 Acc 98.948%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.030 Acc 99.005%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.030 Acc 99.019%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.030 Acc 99.006%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.030 Acc 98.968%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.190 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.232 Acc 94.988%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.220 Acc 95.161%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.012 Acc 99.219%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.026 Acc 99.103%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.026 Acc 99.106%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.026 Acc 99.114%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.027 Acc 99.074%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.230 Acc 95.166%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.218 Acc 95.258%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.029 Acc 98.987%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.030 Acc 99.009%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.028 Acc 99.037%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.028 Acc 99.059%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.028 Acc 99.036%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.216 Acc 95.212%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.202 Acc 95.515%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.013 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.022 Acc 99.203%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.025 Acc 99.172%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.025 Acc 99.169%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.025 Acc 99.158%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.027 Acc 99.113%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.192 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.242 Acc 95.026%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.228 Acc 95.169%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.019 Acc 99.319%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.024 Acc 99.122%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.026 Acc 99.076%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.026 Acc 99.078%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.027 Acc 99.066%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.224 Acc 96.094%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.235 Acc 95.498%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.223 Acc 95.666%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.025 Acc 99.049%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.028 Acc 98.989%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.029 Acc 98.957%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.029 Acc 98.975%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.028 Acc 99.029%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.204 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.232 Acc 95.096%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.222 Acc 95.250%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.030 Acc 99.118%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.030 Acc 99.040%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.028 Acc 99.118%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.028 Acc 99.069%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.028 Acc 99.055%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.245 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.254 Acc 94.895%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.241 Acc 95.060%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.023 Acc 99.226%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.029 Acc 98.985%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.029 Acc 99.004%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.029 Acc 98.996%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.229 Acc 95.050%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.213 Acc 95.417%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.025 Acc 99.226%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.026 Acc 99.114%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.027 Acc 99.092%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.027 Acc 99.060%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.234 Acc 94.848%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.220 Acc 95.138%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.027 Acc 99.134%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.028 Acc 99.044%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.027 Acc 99.040%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.026 Acc 99.049%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.027 Acc 99.010%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.254 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.249 Acc 94.756%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.232 Acc 95.114%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.031 Acc 98.987%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.027 Acc 99.075%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.030 Acc 98.980%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.029 Acc 99.006%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.029 Acc 98.988%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.230 Acc 94.995%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.216 Acc 95.320%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.026 Acc 99.145%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.026 Acc 99.154%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.026 Acc 99.133%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.027 Acc 99.102%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [165/200]Batch [100/204] Loss: 0.242 Acc 95.297%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.226 Acc 95.390%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.023 Acc 99.157%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.024 Acc 99.106%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.025 Acc 99.136%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.026 Acc 99.082%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.027 Acc 99.071%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.241 Acc 94.918%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.224 Acc 95.145%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.024 Acc 99.141%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.026 Acc 99.102%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.027 Acc 99.082%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.027 Acc 99.082%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.242 Acc 94.361%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.226 Acc 94.652%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.027 Acc 99.087%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.027 Acc 99.063%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.028 Acc 99.045%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.028 Acc 99.041%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.232 Acc 94.957%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.218 Acc 95.200%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.024 Acc 99.103%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.025 Acc 99.145%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.024 Acc 99.214%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.025 Acc 99.186%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.027 Acc 99.121%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.286 Acc 92.188%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.249 Acc 95.019%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.232 Acc 95.281%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.029 Acc 99.087%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.026 Acc 99.122%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.027 Acc 99.089%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.028 Acc 99.050%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.225 Acc 95.220%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.209 Acc 95.332%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.028 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.025 Acc 99.172%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.023 Acc 99.199%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.024 Acc 99.193%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.024 Acc 99.170%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.024 Acc 99.159%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.255 Acc 94.802%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.240 Acc 95.075%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.028 Acc 99.013%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.028 Acc 99.014%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.029 Acc 99.020%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.028 Acc 99.049%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.237 Acc 95.135%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.220 Acc 95.382%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.007 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.020 Acc 99.404%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.022 Acc 99.312%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.024 Acc 99.224%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.024 Acc 99.170%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.026 Acc 99.097%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.216 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.230 Acc 94.941%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.215 Acc 95.184%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.021 Acc 99.226%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.024 Acc 99.153%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.025 Acc 99.123%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.026 Acc 99.123%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.027 Acc 99.091%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.201 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.254 Acc 94.756%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.241 Acc 94.893%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.027 Acc 99.072%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.024 Acc 99.188%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.024 Acc 99.193%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.024 Acc 99.191%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.025 Acc 99.139%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.250 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.242 Acc 95.057%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.226 Acc 95.239%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.024 Acc 99.118%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.025 Acc 99.156%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.025 Acc 99.143%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.025 Acc 99.122%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.248 Acc 95.343%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.229 Acc 95.476%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.025 Acc 99.056%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.023 Acc 99.168%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.024 Acc 99.159%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.025 Acc 99.156%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.025 Acc 99.164%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.243 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.245 Acc 95.003%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.228 Acc 95.278%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.011 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.026 Acc 99.141%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.024 Acc 99.203%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.024 Acc 99.185%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.025 Acc 99.154%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.025 Acc 99.124%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.241 Acc 94.980%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.227 Acc 95.227%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.025 Acc 99.141%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.025 Acc 99.180%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.025 Acc 99.168%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.025 Acc 99.161%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.248 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.245 Acc 94.972%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.229 Acc 95.204%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.025 Acc 99.118%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.024 Acc 99.203%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.025 Acc 99.203%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.025 Acc 99.168%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.025 Acc 99.147%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [180/200]Batch [100/204] Loss: 0.230 Acc 95.127%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.213 Acc 95.336%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.023 Acc 99.265%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.022 Acc 99.300%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.022 Acc 99.278%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.023 Acc 99.267%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.024 Acc 99.248%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.231 Acc 95.135%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.217 Acc 95.320%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.022 Acc 99.250%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.023 Acc 99.223%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.024 Acc 99.172%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.024 Acc 99.178%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.025 Acc 99.156%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.256 Acc 96.094%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.249 Acc 94.903%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.235 Acc 95.044%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.023 Acc 99.103%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.024 Acc 99.141%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.024 Acc 99.167%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.025 Acc 99.136%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.225 Acc 94.864%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.213 Acc 95.180%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.023 Acc 99.172%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.025 Acc 99.122%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.026 Acc 99.102%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.027 Acc 99.094%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.026 Acc 99.127%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.212 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.253 Acc 95.235%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.237 Acc 95.429%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.022 Acc 99.157%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.023 Acc 99.137%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.025 Acc 99.102%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.026 Acc 99.092%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.025 Acc 99.105%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.246 Acc 95.104%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.233 Acc 95.363%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.017 Acc 99.366%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.021 Acc 99.246%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.024 Acc 99.136%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.025 Acc 99.119%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.024 Acc 99.153%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.291 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.249 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.233 Acc 95.573%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.024 Acc 99.180%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.026 Acc 99.106%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.027 Acc 99.092%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.026 Acc 99.121%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.026 Acc 99.131%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.322 Acc 93.750%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.251 Acc 95.034%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.237 Acc 95.223%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.020 Acc 99.265%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.020 Acc 99.331%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.022 Acc 99.252%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.023 Acc 99.223%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.023 Acc 99.198%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.238 Acc 94.949%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.225 Acc 95.176%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.020 Acc 99.319%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.020 Acc 99.285%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.021 Acc 99.276%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.023 Acc 99.234%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.025 Acc 99.161%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.250 Acc 95.374%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.234 Acc 95.468%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.020 Acc 99.288%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.021 Acc 99.246%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.023 Acc 99.172%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.023 Acc 99.184%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.024 Acc 99.169%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.271 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.235 Acc 95.196%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.221 Acc 95.460%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.024 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.020 Acc 99.428%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.021 Acc 99.308%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.021 Acc 99.291%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.022 Acc 99.227%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.023 Acc 99.183%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.302 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.243 Acc 95.073%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.229 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.024 Acc 99.126%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.024 Acc 99.157%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.023 Acc 99.188%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.024 Acc 99.176%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.025 Acc 99.141%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.237 Acc 95.282%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.227 Acc 95.367%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.021 Acc 99.335%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.023 Acc 99.260%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.023 Acc 99.222%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.245 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.254 Acc 94.740%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.235 Acc 95.103%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.021 Acc 99.335%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.022 Acc 99.268%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.022 Acc 99.254%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.023 Acc 99.227%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.246 Acc 96.094%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.251 Acc 94.910%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.238 Acc 95.219%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.024 Acc 99.257%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.022 Acc 99.281%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.021 Acc 99.284%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.021 Acc 99.275%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.021 Acc 99.245%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [195/200]Batch [100/204] Loss: 0.246 Acc 94.957%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.232 Acc 95.239%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.026 Acc 99.172%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.025 Acc 99.149%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.025 Acc 99.145%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.024 Acc 99.163%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.236 Acc 95.235%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.224 Acc 95.495%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.023 Acc 99.234%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.023 Acc 99.246%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.022 Acc 99.265%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.022 Acc 99.266%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.023 Acc 99.251%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.264 Acc 95.088%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.248 Acc 95.165%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.026 Acc 99.141%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.023 Acc 99.211%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.024 Acc 99.169%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.024 Acc 99.190%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.023 Acc 99.214%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.267 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.259 Acc 94.964%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.243 Acc 95.208%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.017 Acc 99.474%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.020 Acc 99.355%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.020 Acc 99.369%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.021 Acc 99.328%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.021 Acc 99.315%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.262 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.293 Acc 93.920%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.270 Acc 94.290%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba61029e3b8f4f579817542977b908d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2024ee24a84ae4bd7c9144d41029f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.303 Acc 11.719%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 8.025 Acc 15.401%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 5.146 Acc 17.339%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 4.179 Acc 17.953%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 3.695 Acc 18.214%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 3.404 Acc 18.318%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.255 Acc 17.969%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.236 Acc 18.843%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.234 Acc 19.049%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.235 Acc 19.025%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 18.939%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 18.862%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.230 Acc 15.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.237 Acc 19.067%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.235 Acc 19.080%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.235 Acc 19.093%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.315 Acc 10.938%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.235 Acc 19.640%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 19.174%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.212 Acc 21.094%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.240 Acc 18.727%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.239 Acc 18.862%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.239 Acc 18.857%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.238 Acc 18.900%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.222 Acc 17.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.230 Acc 19.276%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.234 Acc 19.080%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.235 Acc 19.007%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.169 Acc 29.688%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.242 Acc 18.487%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.241 Acc 18.404%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.238 Acc 18.690%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.238 Acc 18.732%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.204 Acc 25.781%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.239 Acc 16.406%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.242 Acc 18.533%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.236 Acc 18.854%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.238 Acc 18.851%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.254 Acc 15.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.241 Acc 18.673%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.239 Acc 19.049%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.237 Acc 19.072%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.225 Acc 19.562%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.174 Acc 26.562%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 6213550647.636 Acc 17.164%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 37551639969.051 Acc 13.402%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 25104879750.669 Acc 12.129%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 18855689582.073 Acc 11.415%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 15094789924.211 Acc 11.185%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 7.187 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 7.676 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 7.696 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 6041380.000 Acc 10.156%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 5473234.931 Acc 11.231%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 4976875.229 Acc 11.497%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 4544429.591 Acc 11.734%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 4206809.904 Acc 11.822%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 3938327.651 Acc 11.948%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 11.669 Acc 9.375%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 12.234 Acc 11.108%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 12.264 Acc 11.093%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2507511.750 Acc 10.938%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2311833.406 Acc 13.436%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2187310.575 Acc 13.623%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2092788.024 Acc 13.647%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2018538.674 Acc 13.714%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 1942253.055 Acc 13.864%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 17.163 Acc 9.375%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 17.601 Acc 11.108%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 17.640 Acc 11.093%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 1888615.250 Acc 12.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 1459795.185 Acc 14.070%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 1393741.603 Acc 14.109%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 1340408.878 Acc 14.210%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 1313410.556 Acc 14.238%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 1260194.836 Acc 14.203%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 22.430 Acc 9.375%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 22.853 Acc 11.108%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 22.899 Acc 11.093%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 908454.750 Acc 12.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 956601.303 Acc 14.202%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 930840.723 Acc 14.265%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 901913.691 Acc 14.314%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 875672.090 Acc 14.288%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 844684.134 Acc 14.310%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 27.390 Acc 9.375%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 27.907 Acc 11.108%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 27.959 Acc 11.093%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 526005.688 Acc 17.969%\n",
      "Train Epoch [ 15/200]Batch [100/573] Loss: 612044.314 Acc 14.356%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 600380.545 Acc 14.152%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 577658.191 Acc 14.091%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 563275.872 Acc 14.105%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 543114.875 Acc 14.014%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 32.159 Acc 9.375%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 32.872 Acc 11.108%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 32.929 Acc 11.093%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 447300.031 Acc 13.281%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 407633.550 Acc 14.016%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 395274.217 Acc 13.724%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 386481.198 Acc 13.652%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 373672.679 Acc 13.636%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 358889.282 Acc 13.585%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 36.693 Acc 9.375%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 37.637 Acc 11.108%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 37.699 Acc 11.093%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 292437.875 Acc 10.156%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 253033.740 Acc 13.622%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 241545.837 Acc 13.717%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 232323.333 Acc 13.806%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 222294.857 Acc 13.741%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 216782.666 Acc 13.772%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 41.517 Acc 9.375%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 42.568 Acc 11.108%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 42.636 Acc 11.093%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 160903.500 Acc 12.500%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 161151.500 Acc 13.784%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 164359.385 Acc 13.577%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 153657.264 Acc 13.632%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 156148.302 Acc 13.418%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 149851.187 Acc 13.341%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 45.191 Acc 9.375%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 46.436 Acc 11.108%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 46.506 Acc 11.093%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 63205.645 Acc 17.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 94403.536 Acc 13.390%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 88352.827 Acc 13.371%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 90885.111 Acc 13.294%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 86646.933 Acc 13.285%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 83086.624 Acc 13.217%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 46.909 Acc 9.375%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 48.046 Acc 11.108%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 48.111 Acc 11.093%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 45848.961 Acc 10.938%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 70149.331 Acc 12.972%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 61051.910 Acc 12.955%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 53685.090 Acc 12.848%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 55921.962 Acc 12.808%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 51164.849 Acc 12.782%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 44.300 Acc 9.375%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 45.207 Acc 11.108%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 45.251 Acc 11.093%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 18917.396 Acc 18.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 35828.784 Acc 12.693%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 30236.849 Acc 12.484%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 30473.959 Acc 12.453%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 29109.716 Acc 12.387%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 27399.590 Acc 12.321%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 39.009 Acc 9.375%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 39.796 Acc 11.108%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 39.818 Acc 11.093%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 11112.469 Acc 15.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 18974.805 Acc 11.974%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 20543.330 Acc 11.917%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 19506.000 Acc 12.009%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 18980.794 Acc 11.986%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 17907.474 Acc 11.981%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 32.365 Acc 9.375%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 33.266 Acc 11.108%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 33.257 Acc 11.093%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 6967.160 Acc 10.156%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 9300.033 Acc 11.603%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 8596.181 Acc 11.855%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 8409.276 Acc 12.043%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 8291.172 Acc 11.867%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 9299.169 Acc 11.911%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 25.181 Acc 9.375%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 26.245 Acc 11.108%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 26.205 Acc 11.093%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 3703.797 Acc 14.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 7592.864 Acc 12.005%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 7847.532 Acc 11.758%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 7758.796 Acc 11.760%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 12206.384 Acc 11.746%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 11231.750 Acc 11.719%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 19.585 Acc 9.375%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 20.732 Acc 11.108%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 20.670 Acc 11.093%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 1433.439 Acc 13.281%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 4798.989 Acc 11.858%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 4252.188 Acc 11.835%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 4642.637 Acc 11.724%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 4589.142 Acc 11.699%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 4551.210 Acc 11.737%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 14.822 Acc 9.375%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 15.905 Acc 11.108%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 15.842 Acc 11.093%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2972.569 Acc 12.500%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 4132.033 Acc 11.255%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 4028.600 Acc 11.544%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 3535.654 Acc 11.490%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 3507.258 Acc 11.584%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 3769.963 Acc 11.638%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 9.964 Acc 9.375%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 10.976 Acc 11.108%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 10.913 Acc 11.093%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2050.243 Acc 12.500%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 1782.913 Acc 12.028%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2166.118 Acc 11.929%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2018.950 Acc 13.427%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 1912.508 Acc 14.838%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 1785.121 Acc 15.533%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 8.076 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 8.969 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 8.913 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2006.777 Acc 18.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 1798.753 Acc 18.735%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 1725.513 Acc 18.847%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 1608.431 Acc 18.836%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 1537.532 Acc 18.756%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 1564.648 Acc 18.725%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 7.050 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 7.792 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 7.745 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 389.863 Acc 18.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2761.735 Acc 18.796%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 1745.843 Acc 18.672%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 1553.086 Acc 18.763%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 1545.196 Acc 18.649%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 1349.591 Acc 18.697%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 5.983 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 6.571 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 6.534 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 473.417 Acc 18.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 605.824 Acc 18.719%\n",
      "Train Epoch [ 30/200]Batch [200/573] Loss: 648.914 Acc 18.633%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 914.802 Acc 18.779%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 1035.822 Acc 18.768%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 970.848 Acc 18.655%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 4.877 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 5.303 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 5.276 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 22.792 Acc 21.094%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 957.913 Acc 18.464%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 1108.719 Acc 18.552%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 932.388 Acc 18.675%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 825.785 Acc 18.701%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 731.564 Acc 18.783%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 3.778 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 4.045 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 4.029 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 213.059 Acc 14.062%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 540.039 Acc 19.075%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 470.664 Acc 19.166%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 437.730 Acc 18.937%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 378.047 Acc 18.912%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 348.678 Acc 18.794%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.610 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.704 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.699 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 67.964 Acc 21.094%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 297.568 Acc 19.021%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 306.675 Acc 19.282%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 294.340 Acc 19.129%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 384.530 Acc 19.089%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 334.494 Acc 18.869%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 552.268 Acc 13.281%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 168.669 Acc 18.835%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 409.513 Acc 19.123%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 323.366 Acc 18.903%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 459.588 Acc 18.859%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 405.835 Acc 18.971%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.241 Acc 16.406%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 77.093 Acc 18.711%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 89.257 Acc 18.661%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 80.736 Acc 18.921%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 73.796 Acc 18.990%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 106.043 Acc 18.897%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.274 Acc 14.844%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 137.352 Acc 18.742%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 112.779 Acc 18.917%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 101.378 Acc 19.093%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 90.553 Acc 19.085%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 1202.635 Acc 18.931%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.223 Acc 20.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 292.400 Acc 18.866%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 276.161 Acc 18.991%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 239.156 Acc 19.059%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 243.641 Acc 19.042%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 217.404 Acc 19.021%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 431.644 Acc 15.625%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 79.793 Acc 18.541%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 54.305 Acc 18.789%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 50.986 Acc 18.677%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 53.645 Acc 18.842%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 52.200 Acc 18.876%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.272 Acc 20.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 35.276 Acc 18.557%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 28.471 Acc 18.855%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 22.003 Acc 18.971%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 34.963 Acc 19.064%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 37.115 Acc 19.015%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.241 Acc 17.188%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 53.433 Acc 19.230%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 43.128 Acc 19.131%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 10003096496.770 Acc 17.940%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 7536548727.768 Acc 16.180%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 6032569618.667 Acc 15.173%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.317 Acc 14.062%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.331 Acc 16.120%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.335 Acc 15.986%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 569269.500 Acc 5.469%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 579362.330 Acc 11.231%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 643076.310 Acc 11.692%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 526277.091 Acc 12.124%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 481483.459 Acc 12.186%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 435967.312 Acc 12.389%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.255 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.276 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.279 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 64445.195 Acc 16.406%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 149227.716 Acc 14.356%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 162712.317 Acc 14.358%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 148853.404 Acc 14.569%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 135026.937 Acc 14.807%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 129305.400 Acc 14.802%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 162876.094 Acc 17.188%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 82774.223 Acc 15.934%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 80779.525 Acc 15.909%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 81335.672 Acc 16.079%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 73378.340 Acc 16.231%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 66883.069 Acc 16.481%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 55375.816 Acc 19.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 63703.041 Acc 16.530%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 50863.328 Acc 16.768%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 48562.225 Acc 16.936%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 51873.907 Acc 17.164%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 49557.751 Acc 17.145%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 5269.593 Acc 13.281%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 184730.553 Acc 17.737%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 110343.663 Acc 17.887%\n",
      "Train Epoch [ 45/200]Batch [300/573] Loss: 84608.275 Acc 17.958%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 70553.611 Acc 18.014%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 77614.448 Acc 18.129%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 614.554 Acc 20.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 22879.371 Acc 18.533%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 24199.475 Acc 18.280%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 21720.314 Acc 18.394%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 18364.042 Acc 18.317%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 18364.888 Acc 18.373%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 16937.070 Acc 14.844%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 9163.843 Acc 18.270%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 12376.207 Acc 18.396%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 12386.037 Acc 18.387%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 14070.509 Acc 18.430%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 13757.779 Acc 18.454%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 844.195 Acc 25.781%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 11278.502 Acc 18.665%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 12148.474 Acc 18.563%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 12554.099 Acc 18.540%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 12026.046 Acc 18.635%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 10750.558 Acc 18.583%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 138.299 Acc 23.438%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 7370.496 Acc 18.843%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 7857.298 Acc 19.185%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 7251.319 Acc 18.945%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 6661.829 Acc 18.929%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 6775.552 Acc 18.806%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2710.559 Acc 15.625%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 11205.681 Acc 18.487%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 8512.851 Acc 18.509%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 6558.431 Acc 18.745%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 5883.780 Acc 18.775%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 6326.969 Acc 18.830%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 3028.367 Acc 21.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 4226.843 Acc 18.696%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 3221.334 Acc 18.614%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2778.574 Acc 18.760%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 3063.038 Acc 18.791%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2835.049 Acc 18.844%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 16252.369 Acc 16.406%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2951.769 Acc 18.843%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2902.062 Acc 18.563%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 3313.646 Acc 18.711%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2957.822 Acc 18.758%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 3180.259 Acc 18.842%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.250 Acc 15.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 5956.408 Acc 18.649%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 3933.581 Acc 19.174%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 3413.799 Acc 18.984%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 3387.115 Acc 19.029%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 3093.462 Acc 18.943%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.261 Acc 17.188%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 610.716 Acc 19.554%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 1228.969 Acc 19.310%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 1564.979 Acc 18.937%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 1476.887 Acc 18.974%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 1366.051 Acc 18.971%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.172 Acc 22.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 1317.795 Acc 19.175%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 1261.057 Acc 18.917%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 1080.701 Acc 18.823%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 1297.026 Acc 18.892%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 1262.169 Acc 18.928%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 26588.791 Acc 19.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 728.036 Acc 19.036%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 769.429 Acc 19.049%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 609.208 Acc 18.784%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 808.209 Acc 18.779%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 662.029 Acc 18.811%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 225.114 Acc 19.052%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 287.306 Acc 18.983%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 558.531 Acc 18.779%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 504.395 Acc 18.738%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 534.971 Acc 18.834%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.262 Acc 17.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 998.951 Acc 18.943%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 1092.295 Acc 18.890%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 58/200]Batch [300/573] Loss: 927.867 Acc 18.784%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 765.131 Acc 18.900%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 648.897 Acc 18.854%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2196.799 Acc 16.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 4488.168 Acc 19.694%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2384.479 Acc 18.929%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 1645.912 Acc 19.015%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 1317.479 Acc 18.824%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 1150.323 Acc 18.918%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.278 Acc 20.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 952.202 Acc 18.649%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 1113.443 Acc 18.711%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 1490.714 Acc 18.965%\n",
      "Train Epoch [ 60/200]Batch [400/573] Loss: 1189.772 Acc 18.980%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 966.603 Acc 19.034%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 799797.549 Acc 18.835%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 403273.636 Acc 19.030%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 269365.957 Acc 18.869%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 202506.780 Acc 18.925%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 167984.569 Acc 18.878%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.223 Acc 17.188%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 5.043 Acc 18.866%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 32.773 Acc 18.762%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 26.656 Acc 18.823%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 51.914 Acc 18.918%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 42.235 Acc 18.922%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.225 Acc 19.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.239 Acc 18.588%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.237 Acc 18.989%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 10.731 Acc 18.847%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 9.036 Acc 18.879%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.239 Acc 18.642%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.238 Acc 18.731%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.906 Acc 18.963%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 12.178 Acc 18.898%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 19.594 Acc 18.872%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.193 Acc 21.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.234 Acc 19.044%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.236 Acc 18.649%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.236 Acc 18.926%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.236 Acc 18.943%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 297.967 Acc 19.407%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 150.840 Acc 19.119%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 101.471 Acc 19.015%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 76.724 Acc 18.951%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 61.856 Acc 19.001%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.281 Acc 16.406%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.238 Acc 18.742%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.238 Acc 18.777%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.284 Acc 11.719%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.241 Acc 18.572%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.240 Acc 18.785%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.239 Acc 19.004%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.238 Acc 18.975%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.255 Acc 20.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.241 Acc 18.804%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.240 Acc 18.626%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 146.738 Acc 18.859%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 117.896 Acc 18.833%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.274 Acc 15.625%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.239 Acc 18.929%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.199 Acc 24.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.234 Acc 19.059%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.237 Acc 18.738%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.238 Acc 18.734%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.234 Acc 22.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.236 Acc 18.929%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.238 Acc 18.736%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.237 Acc 18.878%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.225 Acc 21.875%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.234 Acc 19.214%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.233 Acc 19.034%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 4.269 Acc 19.019%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 3.864 Acc 18.954%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.208 Acc 21.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.236 Acc 19.268%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.238 Acc 18.856%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.234 Acc 19.154%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.235 Acc 19.028%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.237 Acc 18.975%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.205 Acc 24.219%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.236 Acc 18.893%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.236 Acc 18.921%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.234 Acc 14.062%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 61.817 Acc 19.114%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 32.174 Acc 19.228%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 22.228 Acc 19.064%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 17.244 Acc 18.986%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 14.248 Acc 18.989%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.238 Acc 17.188%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.236 Acc 18.952%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.237 Acc 18.955%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.277 Acc 14.062%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.239 Acc 18.789%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.239 Acc 18.797%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.239 Acc 18.770%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.212 Acc 23.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.987%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.238 Acc 19.034%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.188 Acc 27.344%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.235 Acc 18.448%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 18.806%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.185 Acc 22.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.235 Acc 19.251%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.238 Acc 18.906%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.893%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.195 Acc 22.656%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.243 Acc 18.727%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.240 Acc 18.703%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.238 Acc 18.867%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.270 Acc 17.188%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.230 Acc 19.779%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.233 Acc 19.481%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 17.491 Acc 19.048%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 17.530 Acc 18.993%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.251 Acc 17.188%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.240 Acc 18.619%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.237 Acc 18.956%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.237 Acc 18.971%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.290 Acc 20.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.240 Acc 18.827%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.238 Acc 19.127%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.238 Acc 19.100%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.238 Acc 18.982%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.238 Acc 18.932%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.305 Acc 17.188%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 1012774983.521 Acc 19.206%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 508906833.984 Acc 18.937%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 339834796.860 Acc 18.802%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 255087965.283 Acc 18.888%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 204172712.573 Acc 18.953%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.259 Acc 18.750%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.237 Acc 18.881%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.239 Acc 18.688%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.239 Acc 18.742%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 519.081 Acc 18.961%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.161 Acc 25.000%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.242 Acc 18.835%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.238 Acc 18.972%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 849.208 Acc 18.965%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 637.994 Acc 18.881%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 511.095 Acc 18.957%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.237 Acc 18.719%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.237 Acc 18.859%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.237 Acc 18.810%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.251 Acc 14.844%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.236 Acc 18.982%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.236 Acc 19.014%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.235 Acc 18.893%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.305 Acc 15.625%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.237 Acc 19.014%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.237 Acc 19.056%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.219 Acc 21.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.240 Acc 18.781%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.237 Acc 18.799%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.270 Acc 17.969%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.240 Acc 18.889%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.238 Acc 18.952%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.238 Acc 18.879%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.219 Acc 21.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.236 Acc 18.766%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.237 Acc 18.789%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.259 Acc 13.281%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.239 Acc 18.851%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 217.008 Acc 18.830%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 163.449 Acc 18.908%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 131.272 Acc 18.851%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.269 Acc 18.750%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.246 Acc 18.317%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.241 Acc 18.766%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.240 Acc 18.906%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.238 Acc 19.005%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.213 Acc 20.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.241 Acc 18.719%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.238 Acc 19.014%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.237 Acc 18.805%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.250 Acc 14.062%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.231 Acc 19.531%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 365.787 Acc 19.500%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 245.005 Acc 19.202%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 184.466 Acc 19.050%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 148.094 Acc 18.864%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.246 Acc 21.875%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.237 Acc 18.781%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.235 Acc 18.960%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.237 Acc 18.807%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.834%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.213 Acc 25.000%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.236 Acc 18.889%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.235 Acc 19.004%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.236 Acc 18.919%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.845%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.230 Acc 12.500%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.236 Acc 18.862%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.236 Acc 18.916%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.236 Acc 19.000%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.214 Acc 21.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.240 Acc 18.588%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [103/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.236 Acc 18.962%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.236 Acc 18.934%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.203 Acc 26.562%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.240 Acc 18.502%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.239 Acc 18.812%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.237 Acc 18.727%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.236 Acc 18.956%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.237 Acc 19.005%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.277 Acc 9.375%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.236 Acc 19.175%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.234 Acc 19.259%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.238 Acc 18.872%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.243 Acc 14.844%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.240 Acc 18.824%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.238 Acc 18.900%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.282 Acc 16.406%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.236 Acc 19.174%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.237 Acc 18.964%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.242 Acc 18.557%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.238 Acc 18.794%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.237 Acc 18.806%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.210 Acc 17.969%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 109777.650 Acc 18.905%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 55163.013 Acc 19.080%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 36837.175 Acc 18.973%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 27651.406 Acc 18.836%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 22132.610 Acc 18.876%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.231 Acc 21.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.237 Acc 18.928%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.237 Acc 18.777%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.217 Acc 24.219%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.233 Acc 19.361%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.237 Acc 19.061%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.237 Acc 18.792%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.288 Acc 14.844%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.237 Acc 18.603%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.236 Acc 19.158%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.236 Acc 19.054%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.243 Acc 19.531%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.237 Acc 18.704%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.238 Acc 18.763%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.190 Acc 25.781%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.242 Acc 18.851%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.237 Acc 19.069%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.237 Acc 19.093%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 18.976%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.292 Acc 18.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.236 Acc 18.987%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.237 Acc 18.857%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.883%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.223 Acc 19.531%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.240 Acc 18.851%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.239 Acc 18.828%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.238 Acc 18.884%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.238 Acc 18.950%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.213 Acc 22.656%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.234 Acc 19.183%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [118/200]Batch [200/573] Loss: 2.235 Acc 19.209%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.234 Acc 19.160%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.241 Acc 12.500%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.238 Acc 18.796%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.244%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.238 Acc 18.880%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.238 Acc 18.820%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.236 Acc 19.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.237 Acc 18.747%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.236 Acc 19.014%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.242 Acc 19.531%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.235 Acc 18.951%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.238 Acc 18.975%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.250 Acc 17.969%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.237 Acc 19.170%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.236 Acc 19.077%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.255 Acc 19.531%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.240 Acc 18.738%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.239 Acc 18.799%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.239 Acc 18.721%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.239 Acc 18.822%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.253 Acc 18.750%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.236 Acc 18.975%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.237 Acc 18.872%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.216 Acc 17.188%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.234 Acc 19.036%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.237 Acc 18.857%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.237 Acc 18.830%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.230 Acc 17.188%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.234 Acc 19.369%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.238 Acc 18.948%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.235 Acc 19.082%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 18.917%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.234 Acc 22.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.215 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.210 Acc 21.094%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.236 Acc 19.013%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.237 Acc 19.127%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.236 Acc 19.111%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.224 Acc 17.188%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.235 Acc 19.291%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.236 Acc 19.111%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.237 Acc 18.978%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.286 Acc 17.969%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.237 Acc 19.098%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.238 Acc 18.997%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.825%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.298 Acc 15.625%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.234 Acc 18.998%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.707%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.238 Acc 18.768%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.238 Acc 18.738%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.918%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.173 Acc 25.000%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.233 Acc 19.423%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.236 Acc 19.162%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [133/200]Batch [300/573] Loss: 2.235 Acc 19.186%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.209 Acc 25.781%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.235 Acc 19.276%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.235 Acc 18.983%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.238 Acc 18.881%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.296 Acc 14.844%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.236 Acc 19.199%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.237 Acc 19.209%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.237 Acc 19.080%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.238 Acc 18.834%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.237 Acc 18.869%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.228 Acc 20.312%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.238 Acc 18.645%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.239 Acc 18.817%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.238 Acc 18.869%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.249 Acc 22.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.234 Acc 18.943%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.236 Acc 18.808%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.238 Acc 18.794%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.266 Acc 17.969%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.240 Acc 18.332%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.239 Acc 18.657%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.236 Acc 19.041%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.236 Acc 18.953%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.237 Acc 18.859%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.189 Acc 19.531%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.241 Acc 18.448%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.240 Acc 18.424%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.240 Acc 18.628%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.237 Acc 18.916%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.965%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.161 Acc 25.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.240 Acc 18.363%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.237 Acc 18.832%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.243 Acc 21.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.237 Acc 19.237%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.235 Acc 19.286%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.234 Acc 19.209%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.236 Acc 18.980%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.248 Acc 16.406%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.240 Acc 18.936%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.240 Acc 18.832%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.239 Acc 18.871%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.238 Acc 18.831%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.258 Acc 15.625%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.237 Acc 18.804%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.236 Acc 18.976%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.254 Acc 18.750%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.241 Acc 18.781%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.238 Acc 18.807%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.237 Acc 18.992%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.243 Acc 18.711%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.239 Acc 18.723%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.194 Acc 19.531%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.235 Acc 19.059%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.237 Acc 18.699%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.755%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.795%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.283 Acc 17.188%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.836%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.267 Acc 17.969%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.239 Acc 18.711%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [148/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.188 Acc 24.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.234 Acc 19.732%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.235 Acc 19.341%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.235 Acc 19.202%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.236 Acc 19.173%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.239 Acc 17.969%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.235 Acc 19.446%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.238 Acc 19.045%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.238 Acc 18.855%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.238 Acc 18.914%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.159 Acc 28.906%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.237 Acc 19.069%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.196 Acc 23.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.238 Acc 18.974%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.240 Acc 18.769%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.239 Acc 18.777%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.238 Acc 18.914%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.227 Acc 24.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.241 Acc 18.680%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.260 Acc 17.969%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.241 Acc 18.560%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.241 Acc 18.644%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.239 Acc 18.787%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.290 Acc 14.844%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.239 Acc 18.858%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.235 Acc 19.166%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.234 Acc 18.967%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.235 Acc 19.095%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.236 Acc 19.095%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.237 Acc 19.032%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.213 Acc 17.188%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.235 Acc 18.943%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.236 Acc 18.863%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.235 Acc 18.914%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.260 Acc 15.625%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.237 Acc 19.106%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.238 Acc 18.662%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.238 Acc 18.752%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.238 Acc 18.858%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.269 Acc 14.062%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.234 Acc 18.680%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.235 Acc 18.773%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.238 Acc 18.649%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.237 Acc 18.818%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.237 Acc 18.884%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.256 Acc 17.969%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.239 Acc 18.827%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.237 Acc 19.061%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.237 Acc 18.849%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.236 Acc 18.971%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.238 Acc 18.680%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.239 Acc 18.805%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.265 Acc 15.625%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.240 Acc 18.905%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.237 Acc 18.983%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.971%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.237 Acc 18.935%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.191 Acc 21.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.234 Acc 19.144%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.235 Acc 19.061%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.237 Acc 18.971%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.236 Acc 19.071%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [163/200]Batch [500/573] Loss: 2.237 Acc 19.003%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.189 Acc 26.562%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.239 Acc 18.905%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.236 Acc 18.983%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.236 Acc 19.020%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.236 Acc 19.021%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.242 Acc 17.188%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.239 Acc 18.619%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.240 Acc 18.528%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.238 Acc 18.792%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.237 Acc 18.871%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.216 Acc 17.969%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.233 Acc 18.866%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.872%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.262 Acc 20.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.240 Acc 18.781%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.839%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.236 Acc 18.957%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.237 Acc 19.001%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.239 Acc 18.738%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.238 Acc 18.937%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.238 Acc 18.842%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.233 Acc 17.969%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.236 Acc 19.206%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.238 Acc 19.026%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.238 Acc 19.020%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.220 Acc 16.406%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.235 Acc 19.018%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.237 Acc 18.993%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.204 Acc 21.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.236 Acc 18.518%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.237 Acc 18.637%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.237 Acc 18.768%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.236 Acc 18.934%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.196 Acc 20.312%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.244 Acc 17.946%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.240 Acc 18.595%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.238 Acc 18.854%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.237 Acc 19.059%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.233 Acc 19.399%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.235 Acc 19.194%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.200 Acc 22.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.238 Acc 19.059%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.237 Acc 19.127%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.276 Acc 14.844%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.243 Acc 18.294%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.237 Acc 19.046%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.238 Acc 18.886%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.236 Acc 18.869%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.237 Acc 18.981%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.257 Acc 17.188%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.237 Acc 19.284%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.235 Acc 19.232%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.238 Acc 18.955%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.877%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.238 Acc 18.926%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.204 Acc 20.312%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.235 Acc 19.315%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.239 Acc 18.929%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.238 Acc 18.952%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.238 Acc 18.832%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.247 Acc 17.969%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.242 Acc 18.533%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.241 Acc 18.738%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.240 Acc 18.869%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.238 Acc 18.873%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.235 Acc 17.969%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.239 Acc 18.796%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.236 Acc 18.886%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.222 Acc 21.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.236 Acc 19.245%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.238 Acc 18.984%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.223 Acc 16.406%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.232 Acc 19.168%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.234 Acc 18.991%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.236 Acc 18.911%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.235 Acc 18.968%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.235 Acc 18.995%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.298 Acc 14.062%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.238 Acc 19.005%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.239 Acc 18.846%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.230 Acc 15.625%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.239 Acc 18.588%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.239 Acc 21.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.239 Acc 18.552%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.238 Acc 18.579%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.238 Acc 18.701%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.238 Acc 18.839%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.245 Acc 19.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.236 Acc 19.010%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.245 Acc 17.969%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.923%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.235 Acc 22.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.238 Acc 19.137%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.236 Acc 19.294%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.237 Acc 19.064%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.196 Acc 21.875%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.236 Acc 18.936%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.239 Acc 18.769%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.237 Acc 19.000%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.176 Acc 21.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 18.777%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.237 Acc 18.907%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.229 Acc 17.188%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.230 Acc 19.624%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.237 Acc 19.100%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.235 Acc 19.173%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.235 Acc 19.091%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.236 Acc 19.035%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.272 Acc 21.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.233 Acc 19.516%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.232 Acc 19.469%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.234 Acc 19.254%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.236 Acc 19.004%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.278 Acc 12.500%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.236 Acc 19.353%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.235 Acc 19.022%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.237 Acc 18.854%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [193/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.298 Acc 11.719%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.235 Acc 19.508%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.235 Acc 19.426%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.237 Acc 19.194%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.237 Acc 19.021%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.238 Acc 18.897%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.279 Acc 15.625%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.232 Acc 19.717%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.234 Acc 19.220%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 19.243%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.237 Acc 18.856%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.272 Acc 19.531%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.237 Acc 18.835%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.236 Acc 18.878%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.237 Acc 18.911%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.343 Acc 10.938%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.239 Acc 18.603%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.239 Acc 18.684%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.238 Acc 18.871%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.237 Acc 18.967%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.248 Acc 17.188%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.238 Acc 18.804%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.237 Acc 18.987%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.223 Acc 20.312%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.238 Acc 18.895%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1759680e0042e3a502d2a7b97c3753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.326 Acc 11.719%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.245 Acc 18.077%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.244 Acc 18.447%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.233 Acc 18.906%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.184 Acc 20.852%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.076 Acc 24.880%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.586 Acc 47.656%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.498 Acc 50.534%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.496 Acc 50.389%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.369 Acc 50.781%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.109 Acc 62.856%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.979 Acc 67.868%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.874 Acc 71.732%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.800 Acc 74.232%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.744 Acc 76.084%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.484 Acc 84.375%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.564 Acc 82.163%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.555 Acc 82.533%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.568 Acc 79.688%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.452 Acc 86.363%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.451 Acc 86.178%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.436 Acc 86.597%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.429 Acc 86.836%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.421 Acc 87.088%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.469 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.410 Acc 87.508%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.409 Acc 87.376%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.468 Acc 86.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.385 Acc 88.397%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.370 Acc 88.748%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.364 Acc 89.065%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.364 Acc 89.016%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.362 Acc 89.083%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.264 Acc 91.406%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.297 Acc 91.414%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.293 Acc 91.414%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.219 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.333 Acc 90.053%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.333 Acc 90.073%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.330 Acc 90.108%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.328 Acc 90.087%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.325 Acc 90.187%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.323 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.295 Acc 91.545%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.289 Acc 91.814%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.238 Acc 92.969%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.317 Acc 90.780%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.310 Acc 90.749%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.310 Acc 90.804%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.306 Acc 90.839%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.306 Acc 90.848%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.257 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.277 Acc 91.847%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.270 Acc 92.184%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.296 Acc 92.969%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.279 Acc 91.460%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.287 Acc 91.212%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.284 Acc 91.287%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.286 Acc 91.241%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.289 Acc 91.275%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.258 Acc 90.625%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.292 Acc 91.592%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.287 Acc 91.682%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.285 Acc 89.062%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.281 Acc 91.716%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.275 Acc 91.760%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.279 Acc 91.679%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.283 Acc 91.628%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.280 Acc 91.676%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.279 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.260 Acc 92.760%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.255 Acc 92.926%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.254 Acc 89.844%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.268 Acc 92.273%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.276 Acc 92.044%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.273 Acc 91.897%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.272 Acc 91.952%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.269 Acc 92.105%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.315 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.294 Acc 91.576%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.292 Acc 91.604%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.283 Acc 91.406%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.271 Acc 92.002%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.270 Acc 92.016%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.267 Acc 92.071%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.266 Acc 92.115%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.264 Acc 92.191%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.223 Acc 94.013%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.221 Acc 94.065%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.258 Acc 92.497%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.258 Acc 92.347%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.253 Acc 92.515%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.255 Acc 92.512%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.257 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.253 Acc 92.891%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.251 Acc 93.035%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.154 Acc 96.094%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.229 Acc 93.255%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.241 Acc 92.868%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.244 Acc 92.795%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.245 Acc 92.752%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.246 Acc 92.716%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.223 Acc 93.943%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.218 Acc 93.948%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.294 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.229 Acc 93.270%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.235 Acc 93.089%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.238 Acc 93.052%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.239 Acc 92.926%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.239 Acc 92.938%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.238 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.227 Acc 93.998%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.224 Acc 93.956%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.331 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.238 Acc 93.062%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.235 Acc 93.190%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.238 Acc 93.112%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.238 Acc 93.056%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.237 Acc 93.089%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.200 Acc 92.188%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.223 Acc 93.967%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.219 Acc 94.088%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.264 Acc 96.875%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.241 Acc 93.356%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.240 Acc 93.171%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.239 Acc 93.158%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.236 Acc 93.169%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.237 Acc 93.182%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.271 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.207 Acc 94.415%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.202 Acc 94.496%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.235 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.234 Acc 93.294%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.233 Acc 93.256%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.233 Acc 93.189%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.233 Acc 93.204%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.231 Acc 93.245%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.301 Acc 91.406%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.223 Acc 93.912%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.220 Acc 93.902%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.346 Acc 90.625%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.226 Acc 93.611%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.226 Acc 93.525%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.225 Acc 93.467%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.224 Acc 93.475%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.226 Acc 93.373%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.205 Acc 94.415%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.200 Acc 94.516%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.223 Acc 92.969%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.222 Acc 93.495%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.216 Acc 93.509%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.218 Acc 93.418%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.220 Acc 93.440%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.222 Acc 93.396%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.264 Acc 89.844%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.239 Acc 93.541%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.232 Acc 93.703%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.183 Acc 96.094%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.211 Acc 93.588%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.216 Acc 93.513%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.219 Acc 93.483%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.219 Acc 93.493%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.220 Acc 93.507%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.275 Acc 91.406%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.232 Acc 93.595%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.229 Acc 93.680%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.251 Acc 92.188%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.211 Acc 93.874%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.216 Acc 93.766%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.215 Acc 93.807%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.216 Acc 93.760%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.216 Acc 93.703%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.247 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.199 Acc 94.632%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.196 Acc 94.753%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.367 Acc 90.625%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.210 Acc 93.998%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.212 Acc 93.707%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.211 Acc 93.727%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.210 Acc 93.748%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.213 Acc 93.636%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.194 Acc 95.042%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.191 Acc 95.087%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.102 Acc 97.656%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.213 Acc 93.564%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.211 Acc 93.758%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.213 Acc 93.719%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.213 Acc 93.717%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.213 Acc 93.753%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.235 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.202 Acc 94.763%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.194 Acc 94.873%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.205 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.197 Acc 94.346%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.202 Acc 94.220%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.203 Acc 94.178%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.205 Acc 94.120%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.206 Acc 94.101%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.187 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.200 Acc 94.763%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.196 Acc 94.866%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.197 Acc 94.485%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.196 Acc 94.407%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.203 Acc 94.222%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.202 Acc 94.223%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.205 Acc 94.127%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.200 Acc 94.493%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.193 Acc 94.796%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.194 Acc 94.284%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.200 Acc 94.127%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.204 Acc 94.025%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.204 Acc 94.071%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.202 Acc 94.070%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.195 Acc 94.941%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.192 Acc 94.967%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.190 Acc 94.338%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.192 Acc 94.372%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.194 Acc 94.326%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.196 Acc 94.292%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.199 Acc 94.274%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.195 Acc 94.678%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.188 Acc 94.799%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.192 Acc 94.531%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.193 Acc 94.485%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.195 Acc 94.407%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.197 Acc 94.316%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.199 Acc 94.223%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.201 Acc 94.177%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.211 Acc 94.291%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.207 Acc 94.469%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.314 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.187 Acc 94.678%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.195 Acc 94.339%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.194 Acc 94.393%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.194 Acc 94.389%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.197 Acc 94.779%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.192 Acc 94.920%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.185 Acc 94.616%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.188 Acc 94.426%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.192 Acc 94.329%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.194 Acc 94.370%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.195 Acc 94.346%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.217 Acc 94.315%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.213 Acc 94.356%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.214 Acc 94.531%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.185 Acc 94.825%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.190 Acc 94.566%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.190 Acc 94.549%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.189 Acc 94.596%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.191 Acc 94.503%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.259 Acc 92.188%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.199 Acc 94.562%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.194 Acc 94.706%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.185 Acc 94.485%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.187 Acc 94.543%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.192 Acc 94.485%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.190 Acc 94.496%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.188 Acc 94.562%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.189 Acc 95.088%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.184 Acc 95.204%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.286 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.181 Acc 94.810%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.900%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.185 Acc 94.757%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.185 Acc 94.705%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.187 Acc 94.634%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.247 Acc 92.188%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.206 Acc 94.570%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.202 Acc 94.694%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.173 Acc 95.173%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.180 Acc 94.963%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.184 Acc 94.741%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.184 Acc 94.751%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.186 Acc 94.653%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.190 Acc 94.972%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.183 Acc 95.138%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.170 Acc 94.910%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.177 Acc 94.757%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.177 Acc 94.848%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.179 Acc 94.812%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.184 Acc 94.661%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.207 Acc 92.188%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.678%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.196 Acc 94.741%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.179 Acc 94.725%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.181 Acc 94.710%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.762%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.183 Acc 94.714%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.183 Acc 94.664%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.191 Acc 95.042%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.189 Acc 95.029%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.177 Acc 94.957%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.170 Acc 94.982%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.175 Acc 94.934%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.177 Acc 94.942%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.179 Acc 94.901%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.181 Acc 95.258%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.180 Acc 95.332%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.237 Acc 92.969%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.179 Acc 94.624%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.177 Acc 94.788%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.176 Acc 94.967%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.179 Acc 94.864%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.178 Acc 94.867%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.181 Acc 95.483%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.581%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.175 Acc 94.933%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.172 Acc 94.978%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.175 Acc 94.921%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.177 Acc 94.909%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.179 Acc 94.860%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.185 Acc 95.235%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.179 Acc 95.301%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.168 Acc 95.111%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.174 Acc 94.963%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.172 Acc 94.988%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.176 Acc 94.929%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.177 Acc 94.842%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.187 Acc 94.964%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.182 Acc 95.246%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.160 Acc 95.475%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.240%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.172 Acc 95.125%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.173 Acc 95.027%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.545%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.171 Acc 95.639%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.162 Acc 95.390%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.166 Acc 95.173%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.172 Acc 95.066%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.171 Acc 95.005%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.172 Acc 95.012%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.196 Acc 94.972%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.194 Acc 94.955%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.173 Acc 95.189%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.168 Acc 95.254%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.165 Acc 95.198%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.167 Acc 95.168%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.169 Acc 95.127%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.190 Acc 90.625%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.192 Acc 94.887%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.184 Acc 95.196%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.174 Acc 94.787%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.169 Acc 95.064%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.170 Acc 95.053%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.171 Acc 95.026%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.171 Acc 95.018%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.189 Acc 95.235%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.185 Acc 95.340%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.154 Acc 95.575%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.163 Acc 95.359%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.161 Acc 95.367%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.164 Acc 95.254%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.166 Acc 95.239%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.193 Acc 91.406%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.186 Acc 95.227%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.182 Acc 95.274%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.164 Acc 95.390%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.164 Acc 95.250%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.164 Acc 95.284%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.167 Acc 95.194%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.166 Acc 95.214%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.187 Acc 95.158%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.239%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.158 Acc 95.529%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.162 Acc 95.344%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.164 Acc 95.328%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.165 Acc 95.248%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.167 Acc 95.178%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.184 Acc 95.204%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.182 Acc 92.969%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.155 Acc 95.614%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.160 Acc 95.437%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.162 Acc 95.357%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.163 Acc 95.311%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.164 Acc 95.250%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.197 Acc 95.181%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.191 Acc 95.153%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.150 Acc 95.552%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.155 Acc 95.588%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.577%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.160 Acc 95.416%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.162 Acc 95.339%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.209 Acc 94.756%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.206 Acc 94.694%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.163 Acc 95.192%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.164 Acc 95.162%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.163 Acc 95.235%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.162 Acc 95.208%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.194 Acc 94.949%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.189 Acc 95.002%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.168 Acc 95.034%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.161 Acc 95.173%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.159 Acc 95.253%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.160 Acc 95.268%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.163 Acc 95.270%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.233 Acc 92.188%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.196 Acc 95.088%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.191 Acc 95.208%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.161 Acc 95.490%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.162 Acc 95.262%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.160 Acc 95.336%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.160 Acc 95.314%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.160 Acc 95.330%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.173 Acc 95.561%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.160 Acc 95.305%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.160 Acc 95.367%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.157 Acc 95.460%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.157 Acc 95.463%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.158 Acc 95.464%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.184 Acc 95.359%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.179 Acc 95.452%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.152 Acc 92.969%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.159 Acc 95.475%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.159 Acc 95.281%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.158 Acc 95.336%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.158 Acc 95.350%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.157 Acc 95.384%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.129 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.186 Acc 95.429%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.180 Acc 95.585%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.214 Acc 92.969%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.163 Acc 95.196%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.163 Acc 95.367%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.160 Acc 95.419%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.160 Acc 95.435%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.157 Acc 95.521%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.195 Acc 95.019%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.191 Acc 95.141%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.156 Acc 95.429%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.154 Acc 95.476%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.155 Acc 95.418%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.156 Acc 95.426%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.180 Acc 95.498%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.174 Acc 95.526%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.131 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.152 Acc 95.684%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.152 Acc 95.596%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.156 Acc 95.427%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.155 Acc 95.451%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.156 Acc 95.484%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.173 Acc 95.715%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.169 Acc 95.697%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.152 Acc 95.575%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.153 Acc 95.631%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.151 Acc 95.645%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.154 Acc 95.611%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.156 Acc 95.548%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.179 Acc 95.472%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.204 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.137 Acc 96.016%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.142 Acc 95.876%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.148 Acc 95.691%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.149 Acc 95.687%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.152 Acc 95.640%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.194 Acc 94.910%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.188 Acc 95.044%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.153 Acc 95.429%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.150 Acc 95.604%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.151 Acc 95.533%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.154 Acc 95.468%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.153 Acc 95.493%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.176 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.183 Acc 95.614%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.178 Acc 95.635%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.145 Acc 95.939%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.151 Acc 95.713%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.151 Acc 95.655%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.151 Acc 95.592%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.188 Acc 95.274%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.183 Acc 95.332%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.149 Acc 95.753%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.148 Acc 95.791%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.152 Acc 95.634%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.152 Acc 95.650%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.152 Acc 95.590%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.521%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.177 Acc 95.546%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.203 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.769%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.149 Acc 95.713%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.148 Acc 95.746%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.146 Acc 95.761%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.149 Acc 95.702%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.199 Acc 94.918%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.195 Acc 94.893%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.145 Acc 95.483%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.142 Acc 95.686%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.146 Acc 95.572%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.147 Acc 95.628%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.147 Acc 95.613%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.195 Acc 94.895%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.190 Acc 94.970%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.231 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.137 Acc 95.846%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.144 Acc 95.690%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.145 Acc 95.733%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.147 Acc 95.659%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.148 Acc 95.704%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.188 Acc 95.196%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.184%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.144 Acc 95.692%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.146 Acc 95.829%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.145 Acc 95.821%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.147 Acc 95.800%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.147 Acc 95.787%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.210 Acc 92.188%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.206 Acc 94.655%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.204 Acc 94.714%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.143 Acc 95.831%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.143 Acc 95.725%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.146 Acc 95.741%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.148 Acc 95.715%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.175 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.212%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.180 Acc 95.398%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.142 Acc 95.846%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.144 Acc 95.748%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.142 Acc 95.874%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.143 Acc 95.824%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.180 Acc 95.545%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.175 Acc 95.670%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.133 Acc 96.279%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.136 Acc 96.191%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.138 Acc 96.037%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.141 Acc 95.915%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.142 Acc 95.886%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.168 Acc 95.908%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.163 Acc 95.962%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.096 Acc 95.312%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.130 Acc 96.202%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.137 Acc 96.090%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.141 Acc 95.879%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.144 Acc 95.819%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.190 Acc 95.367%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.187 Acc 95.375%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.134 Acc 96.086%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.138 Acc 96.024%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.139 Acc 95.926%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.141 Acc 95.894%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.201 Acc 94.771%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.199 Acc 94.831%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.206 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.127 Acc 96.233%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.136 Acc 96.012%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.140 Acc 95.904%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.141 Acc 95.915%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.141 Acc 95.885%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.199 Acc 95.104%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.193 Acc 95.200%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.131 Acc 96.016%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.139 Acc 95.841%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.138 Acc 95.894%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.139 Acc 95.858%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.141 Acc 95.841%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.192 Acc 95.367%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.186 Acc 95.363%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.178 Acc 92.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.138 Acc 95.978%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.137 Acc 96.004%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.140 Acc 96.018%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.140 Acc 95.957%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.140 Acc 95.985%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.181 Acc 95.359%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.176 Acc 95.394%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.128 Acc 96.171%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.135 Acc 95.927%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.135 Acc 95.998%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.138 Acc 95.981%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.140 Acc 95.919%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.192 Acc 95.196%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.188 Acc 95.215%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.126 Acc 96.086%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.134 Acc 95.981%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.135 Acc 96.013%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.139 Acc 95.928%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.139 Acc 95.886%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.188 Acc 95.351%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.181 Acc 95.472%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.138 Acc 95.753%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.138 Acc 95.958%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.135 Acc 96.104%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.136 Acc 96.047%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.137 Acc 96.025%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.189 Acc 95.235%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.184 Acc 95.320%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.130 Acc 96.101%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.132 Acc 96.016%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.136 Acc 95.938%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.136 Acc 95.965%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.136 Acc 95.964%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.139 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.784%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.174 Acc 95.802%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.127 Acc 96.140%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.131 Acc 96.000%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.134 Acc 95.954%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.136 Acc 95.918%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.138 Acc 95.899%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.188 Acc 95.413%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.185 Acc 95.437%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.125 Acc 96.303%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.135 Acc 95.993%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.136 Acc 96.018%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.136 Acc 96.020%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.136 Acc 96.020%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.186 Acc 95.243%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.181 Acc 95.402%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.132 Acc 96.127%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.133 Acc 96.088%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.134 Acc 96.078%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.282%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.096 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.131 Acc 96.364%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.127 Acc 96.358%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.127 Acc 96.309%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.131 Acc 96.174%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.133 Acc 96.125%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.189 Acc 95.343%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.183 Acc 95.363%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.127 Acc 96.372%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.132 Acc 96.125%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.130 Acc 96.159%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.133 Acc 96.070%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.132 Acc 96.103%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.183 Acc 95.498%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.178 Acc 95.530%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.130 Acc 96.129%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.129 Acc 96.169%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.130 Acc 96.130%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.180 Acc 95.452%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.174 Acc 95.585%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.128 Acc 96.241%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.128 Acc 96.339%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.132 Acc 96.146%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.132 Acc 96.109%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.135 Acc 96.020%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.202 Acc 94.879%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.201 Acc 94.904%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.176 Acc 92.969%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.133 Acc 95.985%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.131 Acc 96.070%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.133 Acc 96.000%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.134 Acc 95.961%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.134 Acc 95.961%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.160 Acc 92.969%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.186 Acc 95.320%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.183 Acc 95.379%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.128 Acc 96.210%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.126 Acc 96.284%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.129 Acc 96.249%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.129 Acc 96.211%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.131 Acc 96.142%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.190 Acc 95.119%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.187 Acc 95.262%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.126 Acc 96.148%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.130 Acc 96.144%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.129 Acc 96.182%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.127 Acc 96.238%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.130 Acc 96.175%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.180 Acc 95.692%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.175 Acc 95.682%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.258 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.126 Acc 96.296%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.130 Acc 96.178%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.199 Acc 95.212%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.191 Acc 95.297%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.116 Acc 96.767%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.123 Acc 96.467%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.126 Acc 96.382%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.128 Acc 96.296%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.130 Acc 96.236%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.191 Acc 95.220%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.184 Acc 95.386%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.169 Acc 94.531%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.127 Acc 96.303%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.126 Acc 96.245%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.125 Acc 96.172%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.127 Acc 96.213%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.128 Acc 96.178%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.204 Acc 94.918%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.198 Acc 94.963%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.123 Acc 96.296%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.127 Acc 96.179%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.127 Acc 96.209%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.128 Acc 96.223%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.198 Acc 95.080%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.193 Acc 95.169%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.120 Acc 96.364%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.120 Acc 96.447%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.123 Acc 96.333%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.125 Acc 96.201%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.127 Acc 96.178%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.265 Acc 92.188%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.191 Acc 95.351%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.188 Acc 95.215%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.127 Acc 96.334%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.124 Acc 96.416%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.124 Acc 96.343%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.126 Acc 96.304%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.436%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.181 Acc 95.476%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.146 Acc 94.531%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.131 Acc 96.109%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.130 Acc 96.105%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.129 Acc 96.159%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.127 Acc 96.238%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.126 Acc 96.268%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.201 Acc 92.188%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.189 Acc 95.343%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.188 Acc 95.262%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.112 Acc 96.651%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.122 Acc 96.369%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.124 Acc 96.326%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.201 Acc 94.771%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.200 Acc 94.788%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.122 Acc 96.171%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.129 Acc 96.082%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.128 Acc 96.159%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.127 Acc 96.158%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.127 Acc 96.220%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.189 Acc 95.374%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.186 Acc 95.359%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.129 Acc 96.133%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.123 Acc 96.278%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.123 Acc 96.263%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.124 Acc 96.247%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.183 Acc 95.429%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.179 Acc 95.519%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.134 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.125 Acc 96.241%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.121 Acc 96.479%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.123 Acc 96.395%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.123 Acc 96.402%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.123 Acc 96.395%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.183 Acc 95.599%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.178 Acc 95.631%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.139 Acc 92.969%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.120 Acc 96.457%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.119 Acc 96.498%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.122 Acc 96.447%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.125 Acc 96.345%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.125 Acc 96.276%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.180 Acc 95.792%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.174 Acc 95.868%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.120 Acc 96.697%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.118 Acc 96.568%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.118 Acc 96.540%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.118 Acc 96.571%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.121 Acc 96.449%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.194 Acc 95.142%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.190 Acc 95.219%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.119 Acc 96.620%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.117 Acc 96.560%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.120 Acc 96.501%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.121 Acc 96.454%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.121 Acc 96.452%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.176 Acc 95.692%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.172 Acc 95.822%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.118 Acc 96.542%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.118 Acc 96.510%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.119 Acc 96.473%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.122 Acc 96.433%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.121 Acc 96.429%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.125 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.201 Acc 95.011%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.195 Acc 95.204%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.180 Acc 92.969%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.116 Acc 96.525%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.119 Acc 96.417%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.122 Acc 96.306%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.194 Acc 95.158%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.188 Acc 95.227%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.118 Acc 96.529%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.120 Acc 96.441%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.170 Acc 92.188%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.191 Acc 95.599%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.186 Acc 95.585%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.154 Acc 94.531%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.112 Acc 96.658%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.114 Acc 96.502%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.118 Acc 96.400%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.117 Acc 96.433%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.118 Acc 96.432%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.188 Acc 95.367%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.183 Acc 95.526%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.269 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.124 Acc 96.233%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.124 Acc 96.253%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.123 Acc 96.239%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.120 Acc 96.376%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.121 Acc 96.356%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.182 Acc 95.552%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.178 Acc 95.577%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.116 Acc 96.542%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.112 Acc 96.700%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.116 Acc 96.527%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.118 Acc 96.439%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.117 Acc 96.434%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.172 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.202 Acc 95.382%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.195 Acc 95.417%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.108 Acc 96.581%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.115 Acc 96.459%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.119 Acc 96.418%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.116 Acc 96.485%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.119 Acc 96.448%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.193 Acc 95.359%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.187 Acc 95.515%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.113 Acc 96.457%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.117 Acc 96.409%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.117 Acc 96.429%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.116 Acc 96.452%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.116 Acc 96.459%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.199 Acc 95.034%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.194 Acc 95.114%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.111 Acc 96.581%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.111 Acc 96.599%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.113 Acc 96.587%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.117 Acc 96.495%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.117 Acc 96.496%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.182 Acc 95.676%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.178 Acc 95.647%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.109 Acc 96.527%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.112 Acc 96.521%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.115 Acc 96.444%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.116 Acc 96.421%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.116 Acc 96.429%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.117 Acc 93.750%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.186 Acc 95.390%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.181 Acc 95.515%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.114 Acc 96.529%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.115 Acc 96.567%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.116 Acc 96.574%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.184 Acc 95.483%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.177 Acc 95.449%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.117 Acc 96.581%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.118 Acc 96.498%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.113 Acc 96.569%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.114 Acc 96.505%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.114 Acc 96.485%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.189 Acc 95.436%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.180 Acc 95.643%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.115 Acc 96.488%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.109 Acc 96.801%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.115 Acc 96.618%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.117 Acc 96.528%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.118 Acc 96.501%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.194 Acc 95.243%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.187 Acc 95.336%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.125 Acc 93.750%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.108 Acc 96.597%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.109 Acc 96.556%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.110 Acc 96.639%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.112 Acc 96.561%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.114 Acc 96.538%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.198 Acc 95.336%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.192 Acc 95.437%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.108 Acc 96.682%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.110 Acc 96.646%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.111 Acc 96.662%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.113 Acc 96.612%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.114 Acc 96.562%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.193 Acc 95.475%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.189 Acc 95.445%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.117 Acc 96.535%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.115 Acc 96.723%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.113 Acc 96.670%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.115 Acc 96.554%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.117 Acc 96.485%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.199 Acc 92.969%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.201 Acc 94.794%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.200 Acc 94.772%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.110 Acc 96.732%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.112 Acc 96.596%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.112 Acc 96.619%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.179 Acc 95.475%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.175 Acc 95.530%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.151 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.109 Acc 96.720%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.104 Acc 96.848%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.108 Acc 96.693%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.109 Acc 96.674%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.111 Acc 96.652%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.195 Acc 95.282%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.190 Acc 95.289%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.131 Acc 93.750%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.114 Acc 96.488%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.112 Acc 96.595%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.113 Acc 96.545%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.115 Acc 96.444%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.115 Acc 96.466%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.184 Acc 95.444%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.178 Acc 95.561%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.113 Acc 96.545%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.111 Acc 96.569%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.112 Acc 96.612%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.112 Acc 96.605%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.169 Acc 92.969%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.206 Acc 95.065%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.112 Acc 96.357%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.108 Acc 96.599%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.110 Acc 96.571%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.110 Acc 96.618%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.112 Acc 96.580%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.180 Acc 95.684%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.176 Acc 95.655%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.100 Acc 96.991%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.104 Acc 96.739%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.109 Acc 96.566%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.111 Acc 96.517%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.111 Acc 96.519%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.193 Acc 95.498%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.191 Acc 95.472%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.110 Acc 96.658%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.113 Acc 96.549%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.111 Acc 96.608%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.110 Acc 96.657%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.111 Acc 96.607%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.191 Acc 95.514%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.187 Acc 95.507%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.112 Acc 96.496%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.111 Acc 96.583%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.111 Acc 96.597%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.111 Acc 96.612%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.111 Acc 96.605%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.206 Acc 94.779%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.205 Acc 94.862%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.105 Acc 96.767%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.107 Acc 96.603%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.111 Acc 96.488%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.110 Acc 96.563%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.109 Acc 96.627%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.188 Acc 95.441%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.101 Acc 96.798%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.102 Acc 96.817%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.106 Acc 96.753%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.108 Acc 96.655%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.107 Acc 96.666%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.197 Acc 95.196%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.194 Acc 95.215%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.112 Acc 96.558%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.108 Acc 96.665%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.111 Acc 96.577%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.109 Acc 96.641%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.110 Acc 96.625%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.195 Acc 95.328%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.188 Acc 95.487%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.124 Acc 93.750%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.118 Acc 96.488%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.110 Acc 96.739%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.109 Acc 96.709%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.110 Acc 96.661%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.111 Acc 96.636%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.140 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.193 Acc 95.521%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.188 Acc 95.569%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.103 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.108 Acc 96.689%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.106 Acc 96.762%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.108 Acc 96.714%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.108 Acc 96.735%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.109 Acc 96.722%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.182 Acc 95.467%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.538%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.104 Acc 96.821%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.109 Acc 96.675%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.109 Acc 96.709%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.108 Acc 96.713%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.179 Acc 95.721%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.098 Acc 97.014%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.101 Acc 96.844%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.103 Acc 96.797%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.105 Acc 96.743%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.106 Acc 96.702%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.177 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.195 Acc 95.343%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.192 Acc 95.375%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.111 Acc 96.665%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.108 Acc 96.680%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.108 Acc 96.743%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.108 Acc 96.755%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.199 Acc 94.995%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.194 Acc 95.087%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.094 Acc 97.130%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.103 Acc 96.857%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.108 Acc 96.700%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.108 Acc 96.696%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.195 Acc 95.475%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.190 Acc 95.534%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.130 Acc 99.219%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.095 Acc 96.983%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.104 Acc 96.769%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.105 Acc 96.793%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.104 Acc 96.799%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.206 Acc 95.142%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.203 Acc 95.110%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.100 Acc 97.030%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.103 Acc 96.867%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.105 Acc 96.826%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.106 Acc 96.811%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.091 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.169 Acc 95.903%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.097 Acc 96.821%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.096 Acc 96.953%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.100 Acc 96.872%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.104 Acc 96.776%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.103 Acc 96.780%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.187 Acc 95.599%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.182 Acc 95.647%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.101 Acc 96.798%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.101 Acc 96.894%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.104 Acc 96.826%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.105 Acc 96.771%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.104 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.180 Acc 95.862%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.175 Acc 95.818%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.095 Acc 96.798%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.101 Acc 96.770%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.103 Acc 96.771%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.105 Acc 96.741%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.105 Acc 96.730%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.182 Acc 95.452%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.177 Acc 95.596%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.096 Acc 97.146%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.098 Acc 96.988%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.100 Acc 96.950%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.103 Acc 96.863%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.104 Acc 96.841%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.198 Acc 95.336%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.194 Acc 95.289%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.080 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.097 Acc 96.952%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.097 Acc 97.108%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.099 Acc 97.009%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.101 Acc 96.937%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.206 Acc 95.003%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.204 Acc 95.052%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.105 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.103 Acc 96.766%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.102 Acc 96.846%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.103 Acc 96.794%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.194 Acc 95.498%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.192 Acc 95.464%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.100 Acc 96.844%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.101 Acc 96.844%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.103 Acc 96.841%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.105 Acc 96.786%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.189 Acc 95.421%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.183 Acc 95.468%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.102 Acc 96.798%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.099 Acc 96.879%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.102 Acc 96.802%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.103 Acc 96.797%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.104 Acc 96.777%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.207 Acc 95.080%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.203 Acc 95.083%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.106 Acc 96.770%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.106 Acc 96.723%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.105 Acc 96.761%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.192 Acc 95.367%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.189 Acc 95.355%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.103 Acc 96.921%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.098 Acc 96.995%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.100 Acc 96.924%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.100 Acc 96.939%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.101 Acc 96.845%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.158 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.192 Acc 95.386%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.127 Acc 94.531%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.095 Acc 96.995%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.099 Acc 96.857%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.101 Acc 96.807%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.101 Acc 96.794%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.206 Acc 95.196%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.201 Acc 95.285%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.100 Acc 96.952%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.099 Acc 96.871%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.100 Acc 96.805%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.102 Acc 96.801%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.102 Acc 96.819%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.217 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.204 Acc 95.127%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.200 Acc 95.157%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.100 Acc 96.774%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.098 Acc 96.879%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.098 Acc 96.849%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.100 Acc 96.822%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.102 Acc 96.806%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.192 Acc 95.398%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.098 Acc 97.037%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.098 Acc 97.003%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.098 Acc 96.998%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.098 Acc 96.990%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.191 Acc 92.188%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.211 Acc 95.142%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.093 Acc 97.130%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.093 Acc 97.034%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.101 Acc 96.856%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.101 Acc 96.863%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.203 Acc 95.080%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.196 Acc 95.281%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.098 Acc 96.929%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.096 Acc 96.972%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.099 Acc 96.937%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.099 Acc 96.928%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.100 Acc 96.931%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.187 Acc 95.630%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.178 Acc 95.787%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.101 Acc 97.068%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.100 Acc 97.059%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.100 Acc 96.996%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.189 Acc 95.784%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.183 Acc 95.845%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.093 Acc 97.006%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.093 Acc 97.027%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.091 Acc 97.080%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.094 Acc 96.992%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.095 Acc 96.984%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.200 Acc 95.328%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.194 Acc 95.355%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.089 Acc 97.208%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.091 Acc 97.209%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.097 Acc 96.941%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.100 Acc 96.894%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.197 Acc 95.343%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.187 Acc 95.530%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.093 Acc 97.023%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.097 Acc 96.930%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.095 Acc 97.004%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.098 Acc 96.950%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 95.413%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.184 Acc 95.503%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.099 Acc 96.805%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.101 Acc 96.821%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.098 Acc 96.958%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.098 Acc 96.970%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.097 Acc 96.997%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.207 Acc 94.918%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.202 Acc 95.056%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.139 Acc 93.750%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.094 Acc 97.092%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.090 Acc 97.093%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.095 Acc 97.049%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.097 Acc 96.939%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.247 Acc 91.406%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.213 Acc 94.740%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.209 Acc 94.955%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.089 Acc 97.169%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.093 Acc 97.120%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.093 Acc 97.059%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.096 Acc 97.002%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.098 Acc 96.922%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.200 Acc 95.289%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.193 Acc 95.425%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.127 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.086 Acc 97.378%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.095 Acc 97.065%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.097 Acc 96.989%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.096 Acc 97.025%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.096 Acc 97.023%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.195 Acc 95.390%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.187 Acc 95.534%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.092 Acc 97.108%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.095 Acc 97.039%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.097 Acc 96.959%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.098 Acc 96.920%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.192 Acc 95.421%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.135 Acc 94.531%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.088 Acc 97.200%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.092 Acc 97.089%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.095 Acc 97.026%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.095 Acc 97.043%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.095 Acc 97.022%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.160 Acc 92.188%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.192 Acc 95.405%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.185 Acc 95.550%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.094 Acc 97.053%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.093 Acc 97.067%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.095 Acc 97.035%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.095 Acc 97.034%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.194 Acc 95.390%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.189 Acc 95.452%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.088 Acc 97.208%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.088 Acc 97.213%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.092 Acc 97.083%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.093 Acc 97.050%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.095 Acc 97.028%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.209 Acc 95.026%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.204 Acc 95.149%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.175 Acc 93.750%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.088 Acc 97.030%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.091 Acc 97.065%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.095 Acc 96.994%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.096 Acc 96.996%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.095 Acc 97.053%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.198 Acc 95.343%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.191 Acc 95.503%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.082 Acc 97.393%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.088 Acc 97.155%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.092 Acc 97.106%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.095 Acc 97.002%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.094 Acc 97.048%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.157 Acc 93.750%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.206 Acc 95.173%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.203 Acc 95.332%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.092 Acc 97.014%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.095 Acc 97.038%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.093 Acc 97.101%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.095 Acc 97.041%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.095 Acc 97.011%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.204 Acc 95.150%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.200 Acc 95.285%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.089 Acc 97.285%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.091 Acc 97.145%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.093 Acc 97.109%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.093 Acc 97.096%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.152 Acc 92.969%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.204 Acc 95.220%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.199 Acc 95.293%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.083 Acc 97.293%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.091 Acc 97.011%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.094 Acc 96.930%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.092 Acc 96.996%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.093 Acc 96.961%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.188 Acc 95.552%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.185 Acc 95.503%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.092 Acc 97.331%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.093 Acc 97.279%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.093 Acc 97.197%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.094 Acc 97.132%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.095 Acc 97.062%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.196 Acc 95.429%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.191 Acc 95.585%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.095 Acc 96.968%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.096 Acc 96.980%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.092 Acc 97.070%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.092 Acc 97.101%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.091 Acc 97.106%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.186 Acc 95.436%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.178 Acc 95.635%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.087 Acc 97.184%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.087 Acc 97.252%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.091 Acc 97.140%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.094 Acc 97.068%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.202 Acc 95.026%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.195 Acc 95.258%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.084 Acc 97.277%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.092 Acc 97.108%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.092 Acc 97.097%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.092 Acc 97.117%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.202 Acc 95.336%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.194 Acc 95.519%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.082 Acc 97.478%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.088 Acc 97.213%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.089 Acc 97.179%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.092 Acc 97.073%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.191 Acc 95.583%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.187 Acc 95.713%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.095 Acc 96.898%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.091 Acc 97.151%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.092 Acc 97.064%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.091 Acc 97.097%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.092 Acc 97.103%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.190 Acc 95.730%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.179 Acc 95.829%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.085 Acc 97.300%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.086 Acc 97.310%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.089 Acc 97.176%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.090 Acc 97.175%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.089 Acc 97.185%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.201 Acc 95.421%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.194 Acc 95.522%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.087 Acc 97.215%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.089 Acc 97.201%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.088 Acc 97.231%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.090 Acc 97.175%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.090 Acc 97.179%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.201 Acc 95.080%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.193 Acc 95.258%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.084 Acc 97.324%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.086 Acc 97.283%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.087 Acc 97.238%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.088 Acc 97.177%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.090 Acc 97.148%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.199 Acc 95.088%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.192 Acc 95.270%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.090 Acc 97.077%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.091 Acc 97.088%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.090 Acc 97.144%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.090 Acc 97.151%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.200 Acc 95.212%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.193 Acc 95.332%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.086 Acc 97.192%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.085 Acc 97.353%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.088 Acc 97.262%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.089 Acc 97.232%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.089 Acc 97.196%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.231 Acc 94.779%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.224 Acc 94.881%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.091 Acc 96.937%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.089 Acc 97.042%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.086 Acc 97.173%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.085 Acc 97.198%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.089 Acc 97.118%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.206 Acc 95.382%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.202 Acc 95.336%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.085 Acc 97.246%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.086 Acc 97.268%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.089 Acc 97.173%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.090 Acc 97.152%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.091 Acc 97.149%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.190 Acc 95.560%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.188 Acc 95.592%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.088 Acc 97.386%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.087 Acc 97.287%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.087 Acc 97.298%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.088 Acc 97.237%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.088 Acc 97.209%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.198 Acc 95.583%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.189 Acc 95.721%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.087 Acc 97.300%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.086 Acc 97.407%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.087 Acc 97.324%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.089 Acc 97.253%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.088 Acc 97.263%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.220 Acc 95.235%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.212 Acc 95.421%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.082 Acc 97.239%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.085 Acc 97.288%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.086 Acc 97.265%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.088 Acc 97.185%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.219 Acc 94.957%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.215 Acc 95.029%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.085 Acc 97.386%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.085 Acc 97.252%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.090 Acc 97.142%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.206 Acc 95.282%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.202 Acc 95.246%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.084 Acc 97.401%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.086 Acc 97.194%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.088 Acc 97.202%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.087 Acc 97.217%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.359%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.406%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.061 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.084 Acc 97.393%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.086 Acc 97.341%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.087 Acc 97.288%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.088 Acc 97.284%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.088 Acc 97.255%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.208 Acc 95.537%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.202 Acc 95.557%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.080 Acc 97.393%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.083 Acc 97.353%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.085 Acc 97.392%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.085 Acc 97.364%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.087 Acc 97.337%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.205 Acc 95.336%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.199 Acc 95.460%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.081 Acc 97.347%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.085 Acc 97.330%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.089 Acc 97.212%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.089 Acc 97.185%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.088 Acc 97.215%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.214 Acc 95.003%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.209 Acc 95.239%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.253 Acc 93.750%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.091 Acc 97.324%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.087 Acc 97.373%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.085 Acc 97.324%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.086 Acc 97.286%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.086 Acc 97.255%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.215 Acc 94.918%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.212 Acc 95.013%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.087 Acc 97.260%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.086 Acc 97.207%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.088 Acc 97.183%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.091 Acc 97.100%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.269 Acc 93.750%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.225 Acc 94.926%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.216 Acc 95.017%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.082 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.086 Acc 97.169%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.086 Acc 97.147%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.087 Acc 97.145%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.085 Acc 97.212%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.087 Acc 97.184%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.405%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.191 Acc 95.546%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.086 Acc 97.123%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.086 Acc 97.143%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.084 Acc 97.272%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.083 Acc 97.339%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.084 Acc 97.305%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.211 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.211 Acc 95.196%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.202 Acc 95.367%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.080 Acc 97.370%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.084 Acc 97.279%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.088 Acc 97.202%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.087 Acc 97.235%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.086 Acc 97.270%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.211 Acc 95.181%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.205 Acc 95.258%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.079 Acc 97.424%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.083 Acc 97.376%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.084 Acc 97.335%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.084 Acc 97.299%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.199 Acc 95.490%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.193 Acc 95.588%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.082 Acc 97.401%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.085 Acc 97.221%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.084 Acc 97.257%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.085 Acc 97.241%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.086 Acc 97.215%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.192 Acc 95.459%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.185 Acc 95.666%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.083 Acc 97.386%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.082 Acc 97.396%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.082 Acc 97.340%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.082 Acc 97.337%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.083 Acc 97.305%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.206 Acc 95.150%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.200 Acc 95.305%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.083 Acc 97.401%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.085 Acc 97.415%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.085 Acc 97.345%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.085 Acc 97.327%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.195 Acc 95.390%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.189 Acc 95.573%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.082 Acc 97.392%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.084 Acc 97.350%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.086 Acc 97.343%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.087 Acc 97.301%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.211 Acc 95.336%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.205 Acc 95.359%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c34f402dcd4576b71fc37be7f33b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.363 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 3.402 Acc 17.976%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.826 Acc 18.151%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.631 Acc 18.452%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.533 Acc 18.538%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.474 Acc 18.700%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.226 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.230 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.231 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.185 Acc 27.344%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.239 Acc 18.982%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.236 Acc 18.781%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 18.965%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.238 Acc 18.906%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.221 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.295 Acc 17.188%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.235 Acc 18.920%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.235 Acc 18.929%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.237 Acc 18.802%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.315 Acc 11.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 19.022%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 19.027%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.271 Acc 15.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.231 Acc 19.647%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.237 Acc 18.896%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.261 Acc 16.406%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.243 Acc 18.325%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.201 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.269 Acc 15.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.233 Acc 19.562%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.234 Acc 19.345%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.236 Acc 19.134%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.248 Acc 17.969%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.237 Acc 18.897%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.240 Acc 18.649%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.238 Acc 18.776%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.235 Acc 19.052%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.236 Acc 18.913%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.236 Acc 18.950%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.234 Acc 19.066%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.234 Acc 18.981%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.220 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.221 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.189 Acc 25.781%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.234 Acc 18.998%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.234 Acc 18.940%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.234 Acc 18.859%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.234 Acc 18.805%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.233 Acc 18.920%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.222 Acc 21.094%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 2.234 Acc 18.905%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 2.232 Acc 18.921%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 2.230 Acc 19.196%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 2.230 Acc 18.974%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 2.232 Acc 18.985%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 2.217 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 2.216 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 2.218 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 2.221 Acc 18.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 2.225 Acc 18.835%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 2.222 Acc 19.154%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 2.232 Acc 18.924%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 2.234 Acc 18.822%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 2.234 Acc 18.879%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2.213 Acc 21.875%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2.235 Acc 19.578%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2.238 Acc 18.940%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2.237 Acc 18.856%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 2.238 Acc 18.828%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 2.272 Acc 14.062%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 2.234 Acc 19.346%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 2.235 Acc 19.076%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 2.237 Acc 18.926%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 2.261 Acc 17.969%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 2.239 Acc 18.777%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 2.239 Acc 18.879%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 2.238 Acc 18.895%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 2.163 Acc 28.125%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 2.240 Acc 19.137%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 2.238 Acc 19.111%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 2.236 Acc 19.098%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 2.238 Acc 18.953%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 2.283 Acc 14.062%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 2.237 Acc 18.719%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 2.236 Acc 18.952%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 2.237 Acc 18.766%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 2.238 Acc 18.865%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 2.244 Acc 17.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 2.234 Acc 18.611%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 2.234 Acc 18.874%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 2.265 Acc 11.719%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 2.241 Acc 18.827%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 2.239 Acc 18.622%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 2.239 Acc 18.625%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 2.238 Acc 18.865%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 2.283 Acc 14.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 2.235 Acc 19.067%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 2.238 Acc 18.637%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 2.238 Acc 18.711%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 2.238 Acc 18.723%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 2.238 Acc 18.865%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 2.279 Acc 15.625%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 2.497 Acc 19.160%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 2.367 Acc 19.162%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 2.324 Acc 19.074%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 2.303 Acc 18.968%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 2.290 Acc 18.884%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 2.207 Acc 22.656%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 2.235 Acc 19.021%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 2.236 Acc 19.088%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 2.219 Acc 18.750%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 2.237 Acc 19.034%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 2.256 Acc 20.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 2.234 Acc 19.261%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 2.232 Acc 14.062%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 2.237 Acc 19.139%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2.205 Acc 24.219%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 2.235 Acc 19.512%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 2.236 Acc 19.272%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 2.236 Acc 19.077%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 2.236 Acc 18.987%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2.230 Acc 19.531%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 2.234 Acc 19.245%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 2.236 Acc 18.922%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2.249 Acc 19.531%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 2.239 Acc 18.673%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 2.239 Acc 18.747%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 2.237 Acc 19.014%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 2.211 Acc 18.750%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2.233 Acc 19.129%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 2.236 Acc 18.914%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 2.237 Acc 18.842%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 2.283 Acc 16.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 2.240 Acc 18.394%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 2.237 Acc 18.902%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 2.237 Acc 18.907%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 2.209 Acc 24.219%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 2.235 Acc 18.928%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 2.235 Acc 18.933%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 2.248 Acc 25.000%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 2.239 Acc 18.824%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 2.238 Acc 18.779%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 2.265 Acc 16.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 2.239 Acc 19.108%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 2.236 Acc 19.225%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 2.237 Acc 19.124%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 2.238 Acc 18.950%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 2.287 Acc 11.719%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 2.238 Acc 19.052%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 2.238 Acc 19.038%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 2.237 Acc 18.978%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 2.238 Acc 18.896%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.201 Acc 22.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 2.239 Acc 18.908%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.251 Acc 15.625%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 2.237 Acc 18.580%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 2.236 Acc 18.933%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 2.236 Acc 18.953%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.204 Acc 20.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 2.241 Acc 18.557%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 2.238 Acc 19.090%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 2.237 Acc 18.962%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 2.284 Acc 18.750%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 2.233 Acc 19.230%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 2.238 Acc 18.786%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 2.237 Acc 19.005%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.233 Acc 22.656%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 2.239 Acc 18.676%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 2.237 Acc 18.797%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.294 Acc 14.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 2.236 Acc 18.940%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 2.238 Acc 18.854%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 2.238 Acc 18.806%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 2.161 Acc 22.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 2.240 Acc 18.920%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 2.236 Acc 19.279%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 2.243 Acc 20.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 2.238 Acc 19.067%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 2.237 Acc 19.255%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 2.238 Acc 19.007%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 2.236 Acc 19.040%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 2.170 Acc 30.469%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 2.236 Acc 19.129%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 2.236 Acc 19.236%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 2.237 Acc 19.168%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 2.238 Acc 18.937%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 2.221 Acc 19.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 2.237 Acc 18.684%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 2.238 Acc 18.911%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 2.238 Acc 18.869%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 2.234 Acc 20.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 2.234 Acc 19.446%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 2.235 Acc 19.181%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 2.236 Acc 18.872%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 2.217 Acc 17.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 2.241 Acc 18.758%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 2.244 Acc 19.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 2.240 Acc 18.626%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 2.240 Acc 18.591%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 2.202 Acc 17.969%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 2.229 Acc 19.624%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 2.235 Acc 18.960%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 2.235 Acc 18.924%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 2.236 Acc 18.912%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2.260 Acc 17.969%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 2.239 Acc 18.951%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 2.224 Acc 17.188%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 2.234 Acc 19.647%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 2.239 Acc 18.972%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 2.236 Acc 19.056%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 2.194 Acc 18.750%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2.234 Acc 19.021%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 2.238 Acc 18.825%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2.237 Acc 18.853%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.253 Acc 15.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 2.234 Acc 19.237%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 2.235 Acc 19.224%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 2.237 Acc 18.953%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.225 Acc 17.969%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 2.238 Acc 18.711%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 2.237 Acc 18.950%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 2.237 Acc 18.904%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 2.238 Acc 18.883%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.242 Acc 18.750%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 2.234 Acc 19.361%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 2.235 Acc 19.290%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 2.237 Acc 18.881%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 2.236 Acc 19.006%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 2.298 Acc 13.281%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 2.239 Acc 18.441%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 2.238 Acc 18.680%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 2.236 Acc 18.851%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.227 Acc 17.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 2.231 Acc 19.144%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 2.237 Acc 18.856%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.235 Acc 18.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 2.238 Acc 18.657%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 2.239 Acc 18.707%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 2.237 Acc 18.975%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2.231 Acc 15.625%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 2.235 Acc 18.897%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2.237 Acc 18.777%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.295 Acc 14.062%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 2.232 Acc 19.407%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 2.235 Acc 19.061%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 2.237 Acc 18.923%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 2.238 Acc 18.864%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.212 Acc 21.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.273 Acc 16.406%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 2.240 Acc 18.951%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 2.236 Acc 19.110%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.256 Acc 20.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.233 Acc 18.982%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.235 Acc 18.870%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.236 Acc 18.854%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.234 Acc 19.106%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.234 Acc 19.213%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.235 Acc 19.173%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 2.236 Acc 18.997%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.241 Acc 22.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.240 Acc 18.858%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.182 Acc 24.219%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 2.238 Acc 18.878%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 2.238 Acc 18.893%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 2.237 Acc 18.964%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.234 Acc 18.858%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.235 Acc 18.859%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.236 Acc 18.864%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.237 Acc 18.840%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.219 Acc 19.531%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.235 Acc 19.183%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.236 Acc 18.895%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.217 Acc 17.188%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.238 Acc 18.472%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.239 Acc 18.707%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.238 Acc 18.755%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.249 Acc 18.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.234 Acc 18.765%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.237 Acc 18.668%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.238 Acc 18.620%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.237 Acc 18.768%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.187 Acc 23.438%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.232 Acc 19.152%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.235 Acc 19.049%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.235 Acc 19.215%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.236 Acc 19.054%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.211 Acc 17.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.236 Acc 18.765%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 19.084%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.237 Acc 18.871%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.267 Acc 18.750%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.229 Acc 19.624%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.234 Acc 19.100%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 2.237 Acc 18.861%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 2.237 Acc 18.876%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.214 Acc 20.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.238 Acc 18.692%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.204 Acc 21.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.241 Acc 18.742%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.239 Acc 18.867%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.238 Acc 18.886%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.264 Acc 17.969%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.239 Acc 18.912%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.237 Acc 18.750%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.236 Acc 18.830%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.238 Acc 18.756%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.837%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.179 Acc 25.000%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 2.243 Acc 18.533%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 2.238 Acc 18.746%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 2.237 Acc 18.923%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.235 Acc 21.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.236 Acc 18.991%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.227 Acc 20.312%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.241 Acc 18.564%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.240 Acc 18.614%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.239 Acc 18.864%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.236 Acc 18.984%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.239 Acc 18.595%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.238 Acc 18.784%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.237 Acc 18.828%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.238 Acc 18.844%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.221 Acc 23.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.236 Acc 19.284%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.240 Acc 18.890%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.236 Acc 19.013%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.273 Acc 14.844%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.242 Acc 18.394%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.239 Acc 18.864%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.848%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.234 Acc 15.625%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.238 Acc 18.371%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.236 Acc 18.908%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.237 Acc 18.982%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.228 Acc 21.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.239 Acc 19.137%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.235 Acc 19.158%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 2.236 Acc 19.068%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 2.237 Acc 18.965%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.271 Acc 16.406%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.239 Acc 18.645%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.239 Acc 18.724%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.238 Acc 18.845%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.262 Acc 19.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.237 Acc 18.975%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.248 Acc 18.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 2.239 Acc 18.672%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 2.237 Acc 18.858%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.199 Acc 20.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.238 Acc 18.699%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.239 Acc 18.675%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.791%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.218 Acc 20.312%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.242 Acc 18.626%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.237 Acc 18.944%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 2.238 Acc 18.892%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 2.238 Acc 18.923%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.241 Acc 18.750%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.235 Acc 18.773%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.235 Acc 19.076%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.239 Acc 18.629%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.238 Acc 18.792%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.249 Acc 15.625%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.236 Acc 19.144%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.236 Acc 19.123%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.238 Acc 18.881%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.217 Acc 18.750%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.234 Acc 19.307%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.236 Acc 19.056%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.196 Acc 26.562%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.237 Acc 18.942%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.236 Acc 19.079%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.887%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.184 Acc 19.531%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.237 Acc 19.098%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.238 Acc 18.817%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.239 Acc 18.692%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.834%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.222 Acc 19.531%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.241 Acc 18.781%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.240 Acc 18.816%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.239 Acc 18.779%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.254 Acc 17.969%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.242 Acc 18.216%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.239 Acc 18.490%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 2.238 Acc 18.768%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 2.237 Acc 18.848%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.209 Acc 26.562%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.233 Acc 19.137%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.235 Acc 18.758%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.237 Acc 18.714%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.237 Acc 18.832%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.884%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.241 Acc 16.406%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.233 Acc 19.446%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.235 Acc 19.092%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.238 Acc 18.854%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.237 Acc 18.844%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.229 Acc 16.406%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.241 Acc 18.858%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 2.239 Acc 19.038%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.244 Acc 17.188%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.242 Acc 18.278%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.240 Acc 18.610%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.243 Acc 20.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.240 Acc 18.765%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.235 Acc 19.057%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.236 Acc 19.004%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.186 Acc 26.562%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.237 Acc 19.009%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.198 Acc 23.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.243 Acc 18.835%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 2.242 Acc 18.637%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.239 Acc 18.771%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.246 Acc 17.188%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.241 Acc 18.699%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.204 Acc 23.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.239 Acc 18.464%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.241 Acc 18.233%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.239 Acc 18.490%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.252 Acc 20.312%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.235 Acc 18.991%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.236 Acc 18.941%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.251 Acc 17.188%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.234 Acc 19.400%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.234 Acc 19.442%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.236 Acc 19.155%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.273 Acc 17.969%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.238 Acc 18.984%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.238 Acc 18.828%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.206 Acc 23.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.233 Acc 19.516%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.235 Acc 19.263%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.236 Acc 19.072%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.232 Acc 20.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 2.235 Acc 19.044%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 2.238 Acc 18.995%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 2.237 Acc 18.976%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 2.238 Acc 18.941%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 2.237 Acc 18.981%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.190 Acc 24.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.232 Acc 19.717%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.236 Acc 19.286%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 19.142%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.236 Acc 19.116%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.215 Acc 18.750%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.237 Acc 19.090%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.238 Acc 18.975%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.238 Acc 18.950%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.254 Acc 17.969%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.235 Acc 19.044%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.236 Acc 18.766%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.237 Acc 18.708%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 18.785%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.240 Acc 15.625%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.232 Acc 19.663%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.236 Acc 19.317%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.236 Acc 19.017%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.269 Acc 16.406%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.237 Acc 18.834%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 18.859%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.256 Acc 18.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.240 Acc 18.758%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.229 Acc 21.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.238 Acc 18.964%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.238 Acc 18.815%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.238 Acc 18.805%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 2.235 Acc 19.178%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.237 Acc 18.957%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.286 Acc 13.281%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.235 Acc 18.866%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.018%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.243 Acc 19.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.239 Acc 18.750%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.238 Acc 18.913%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.237 Acc 19.004%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 19.091%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.236 Acc 19.071%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.283 Acc 17.188%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.240 Acc 18.820%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.238 Acc 18.890%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.236 Acc 18.990%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.195 Acc 16.406%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.235 Acc 19.261%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.236 Acc 19.135%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.236 Acc 19.243%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.238 Acc 19.036%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.237 Acc 18.978%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.254 Acc 21.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.240 Acc 18.448%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.239 Acc 18.633%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.238 Acc 18.953%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.246 Acc 17.969%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.238 Acc 19.106%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.238 Acc 18.797%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.238 Acc 18.858%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.220 Acc 17.188%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.235 Acc 19.154%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.235 Acc 19.222%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.235 Acc 19.192%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.236 Acc 19.001%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.243 Acc 18.750%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.234 Acc 19.106%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.235 Acc 18.991%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.236 Acc 18.895%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.231 Acc 18.750%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.238 Acc 18.998%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 19.018%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.240 Acc 16.406%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.240 Acc 18.680%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.238 Acc 18.836%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.238 Acc 18.879%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.238 Acc 18.920%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.213 Acc 21.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.240 Acc 18.688%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.240 Acc 18.692%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.239 Acc 18.768%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.239 Acc 18.758%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.278 Acc 17.969%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.239 Acc 18.882%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.238 Acc 18.931%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.224 Acc 18.750%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 18.939%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.833%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.240 Acc 17.969%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.909%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.239 Acc 18.779%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.177 Acc 23.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.232 Acc 19.129%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.235 Acc 19.010%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 2.235 Acc 19.056%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.235 Acc 18.955%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.238 Acc 19.531%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.232 Acc 19.330%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.234 Acc 19.216%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.235 Acc 19.120%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.236 Acc 19.035%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.235 Acc 19.202%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.236 Acc 19.027%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.210 Acc 19.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.235 Acc 19.018%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.238 Acc 18.876%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.222 Acc 17.188%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.237 Acc 18.750%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.238 Acc 18.792%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.263 Acc 16.406%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.237 Acc 18.882%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.237 Acc 18.841%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.237 Acc 18.861%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.238 Acc 18.850%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.228 Acc 18.750%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.238 Acc 18.549%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.195 Acc 25.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.235 Acc 19.349%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.237 Acc 19.121%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.276 Acc 17.188%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.241 Acc 18.456%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.238 Acc 18.847%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.236 Acc 19.082%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.222 Acc 15.625%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.239 Acc 18.874%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.239 Acc 18.773%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.238 Acc 18.917%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.214 Acc 21.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.234 Acc 19.199%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.234 Acc 19.127%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.235 Acc 19.043%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.271 Acc 14.844%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.769%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.238 Acc 18.762%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.238 Acc 18.792%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.208 Acc 21.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.234 Acc 19.284%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.236 Acc 19.080%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.235 Acc 19.189%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.237 Acc 19.058%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.247 Acc 20.312%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.244 Acc 18.263%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.995%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.222 Acc 20.312%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.233 Acc 19.191%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.235 Acc 18.972%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.237 Acc 18.727%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.237 Acc 18.920%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.238 Acc 18.963%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 2.238 Acc 18.890%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.216 Acc 23.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.241 Acc 18.704%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.236 Acc 18.847%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.236 Acc 18.932%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.237 Acc 18.855%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.186 Acc 24.219%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.233 Acc 19.114%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.237 Acc 18.968%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.292 Acc 13.281%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 2.235 Acc 18.881%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.238 Acc 19.061%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.236 Acc 19.126%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.222 Acc 18.750%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.244 Acc 18.564%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.241 Acc 18.664%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.239 Acc 18.750%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.238 Acc 18.861%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.240 Acc 21.094%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.237 Acc 18.665%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.236 Acc 18.851%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.236 Acc 18.901%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.238 Acc 18.862%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.267 Acc 14.062%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.240 Acc 18.742%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.236 Acc 18.967%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.251 Acc 14.062%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.234 Acc 19.237%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.236 Acc 19.131%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.236 Acc 19.121%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.237 Acc 19.095%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.237 Acc 18.957%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.188 Acc 18.750%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.240 Acc 18.448%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.236 Acc 18.762%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.235 Acc 19.041%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.247 Acc 15.625%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.240 Acc 18.711%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.239 Acc 18.785%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.236 Acc 18.910%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.255 Acc 20.312%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.234 Acc 19.267%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.237 Acc 19.051%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.227 Acc 23.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.238 Acc 18.936%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.237 Acc 19.049%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.236 Acc 18.946%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.211 Acc 25.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.241 Acc 18.509%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.241 Acc 18.623%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.238 Acc 18.826%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.259 Acc 18.750%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.240 Acc 19.052%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.239 Acc 18.952%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.942%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.238 Acc 18.951%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.198 Acc 20.312%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.237 Acc 19.253%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.239 Acc 18.937%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.239 Acc 18.763%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 2.238 Acc 18.839%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.255 Acc 15.625%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.237 Acc 18.917%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.992%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.226 Acc 21.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.243 Acc 18.572%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.239 Acc 18.653%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.174 Acc 21.875%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.237 Acc 18.967%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.911%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.236 Acc 18.943%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.215 Acc 16.406%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.917%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.235 Acc 19.033%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.236 Acc 19.018%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.229 Acc 17.188%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.242 Acc 18.673%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.238 Acc 19.003%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.235 Acc 19.083%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.236 Acc 19.015%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.276 Acc 18.750%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.234 Acc 19.624%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.235 Acc 19.236%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.236 Acc 19.019%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.214 Acc 24.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.237 Acc 19.144%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.236 Acc 19.033%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.221 Acc 20.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.241 Acc 18.256%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.240 Acc 18.576%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.239 Acc 18.697%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.242 Acc 15.625%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.235 Acc 18.976%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.939%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.250 Acc 15.625%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.239 Acc 18.711%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.237 Acc 19.073%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.237 Acc 18.991%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.238 Acc 18.886%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.191 Acc 22.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.235 Acc 19.052%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.234 Acc 19.306%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.235 Acc 19.272%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.235 Acc 19.149%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.236 Acc 19.006%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.279 Acc 19.531%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.233 Acc 19.462%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.234 Acc 19.251%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.238 Acc 18.893%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.281 Acc 14.062%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.233 Acc 19.377%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.235 Acc 19.119%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.237 Acc 18.968%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.250 Acc 17.188%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.239 Acc 18.595%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.239 Acc 18.638%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.738%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.294 Acc 13.281%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.236 Acc 19.100%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.223 Acc 17.969%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.236 Acc 19.237%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.233 Acc 19.399%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.236 Acc 19.155%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.249 Acc 17.188%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.241 Acc 18.536%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.237 Acc 18.885%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.259 Acc 20.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.240 Acc 18.611%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.237 Acc 18.797%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.281 Acc 16.406%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.237 Acc 18.936%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.236 Acc 19.248%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.237 Acc 19.121%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.237 Acc 18.957%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.226 Acc 17.188%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.238 Acc 18.897%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.895%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.237 Acc 18.786%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.238 Acc 18.658%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.231 Acc 19.531%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.235 Acc 18.959%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.235 Acc 19.088%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.235 Acc 19.082%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.237 Acc 18.926%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.283 Acc 19.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.233 Acc 19.384%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.236 Acc 19.216%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.237 Acc 19.147%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.237 Acc 19.042%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.236 Acc 14.062%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.005%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.237 Acc 18.723%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.237 Acc 18.952%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.273 Acc 14.062%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.242 Acc 18.448%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.241 Acc 18.870%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.238 Acc 18.906%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.226 Acc 23.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.240 Acc 18.526%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.235 Acc 19.057%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.237 Acc 18.838%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.231 Acc 17.969%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 18.917%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.236 Acc 18.970%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.233 Acc 17.188%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.235 Acc 19.245%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.236 Acc 19.053%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.239 Acc 18.890%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.263 Acc 19.531%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.238 Acc 18.913%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.236 Acc 18.963%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.182 Acc 22.656%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.232 Acc 18.912%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.236 Acc 18.987%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.236 Acc 18.815%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.760%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.236 Acc 19.162%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.236 Acc 18.997%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.253 Acc 18.750%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.234 Acc 19.083%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.234 Acc 18.952%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 18.916%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.294 Acc 14.062%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.235 Acc 18.843%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.239 Acc 18.684%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.239 Acc 18.908%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 2.239 Acc 18.867%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.245 Acc 21.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.240 Acc 18.715%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.239 Acc 18.877%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.238 Acc 18.887%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.236 Acc 14.062%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.234 Acc 17.969%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.236 Acc 18.979%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.236 Acc 19.074%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf8a61684ab45849204ce483e439362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.316 Acc 8.594%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 4.569 Acc 16.793%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 3.410 Acc 18.066%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 3.022 Acc 18.285%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.826 Acc 18.317%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.709 Acc 18.443%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.228 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.225 Acc 20.266%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.233 Acc 19.356%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 19.069%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 19.070%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 19.007%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.259 Acc 15.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.235 Acc 18.704%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.236 Acc 18.874%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.235 Acc 18.978%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.273 Acc 15.625%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.238 Acc 18.796%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.239 Acc 18.762%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 19.040%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.948%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.260 Acc 14.844%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.235 Acc 18.889%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.236 Acc 18.587%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.236 Acc 18.690%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.236 Acc 18.816%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.235 Acc 18.744%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.196 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.214 Acc 19.531%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.238 Acc 18.363%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.232 Acc 18.913%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.234 Acc 18.929%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.233 Acc 18.869%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.233 Acc 18.948%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.191 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.218 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.219 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.221 Acc 20.312%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.223 Acc 19.438%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.226 Acc 19.007%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.226 Acc 18.914%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.223 Acc 18.958%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.214 Acc 19.431%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 1.984 Acc 38.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.006 Acc 31.405%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.011 Acc 31.110%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.061 Acc 32.031%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.009 Acc 29.308%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 1.903 Acc 34.161%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 1.782 Acc 38.800%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 1.644 Acc 43.990%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 1.514 Acc 48.728%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.747 Acc 77.344%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.795 Acc 75.472%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.792 Acc 75.649%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.725 Acc 74.219%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.726 Acc 77.027%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.686 Acc 78.327%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.651 Acc 79.384%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.628 Acc 80.243%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.607 Acc 80.930%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.495 Acc 82.031%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.497 Acc 85.063%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.497 Acc 85.005%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.477 Acc 85.938%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.493 Acc 84.855%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.470 Acc 85.588%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.462 Acc 85.930%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.457 Acc 86.105%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.448 Acc 86.391%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.477 Acc 87.500%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.479 Acc 86.703%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.476 Acc 86.633%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.297 Acc 88.281%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.403 Acc 87.670%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.394 Acc 88.099%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.393 Acc 88.164%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.392 Acc 88.186%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.393 Acc 88.138%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.388 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.371 Acc 88.869%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.367 Acc 88.977%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.413 Acc 88.281%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.363 Acc 89.032%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.363 Acc 89.117%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.364 Acc 89.140%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.362 Acc 89.135%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.363 Acc 89.089%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.362 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.371 Acc 89.565%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.361 Acc 89.754%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.268 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.345 Acc 89.581%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.351 Acc 89.443%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.351 Acc 89.519%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.349 Acc 89.555%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.347 Acc 89.594%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.319 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.350 Acc 89.689%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.344 Acc 89.879%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.218 Acc 92.969%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.327 Acc 89.991%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.321 Acc 90.170%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.328 Acc 90.072%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.330 Acc 90.062%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.332 Acc 90.043%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.287 Acc 89.844%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.297 Acc 91.793%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.288 Acc 91.939%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.344 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.330 Acc 89.937%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.327 Acc 90.034%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.324 Acc 90.207%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.321 Acc 90.327%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.321 Acc 90.360%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.355 Acc 88.281%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.314 Acc 91.677%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.310 Acc 91.756%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.348 Acc 89.844%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.303 Acc 90.865%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.306 Acc 90.897%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.317 Acc 90.677%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.318 Acc 90.522%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.317 Acc 90.570%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.304 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.276 Acc 91.932%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.267 Acc 92.067%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.289 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.294 Acc 91.275%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.297 Acc 91.157%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.300 Acc 91.030%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.301 Acc 90.991%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.301 Acc 90.991%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.312 Acc 93.750%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.275 Acc 92.280%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.265 Acc 92.413%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.259 Acc 92.188%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.283 Acc 91.414%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.301 Acc 91.018%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.296 Acc 91.274%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.296 Acc 91.307%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.296 Acc 91.336%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.311 Acc 89.844%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.254 Acc 93.031%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.246 Acc 93.124%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.211 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.286 Acc 91.267%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.284 Acc 91.449%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.294 Acc 91.206%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.297 Acc 91.174%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.297 Acc 91.208%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.285 Acc 88.281%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.246 Acc 93.023%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.240 Acc 93.276%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.173 Acc 92.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.268 Acc 91.940%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.280 Acc 91.589%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.282 Acc 91.596%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.285 Acc 91.613%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.284 Acc 91.614%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.247 Acc 92.984%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.239 Acc 93.206%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.159 Acc 96.875%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.286 Acc 92.048%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.280 Acc 91.912%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.285 Acc 91.707%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.283 Acc 91.771%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.281 Acc 91.798%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.279 Acc 89.844%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.248 Acc 93.301%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.240 Acc 93.319%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.249 Acc 90.625%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.270 Acc 92.296%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.268 Acc 92.343%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.273 Acc 92.055%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.274 Acc 92.045%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.273 Acc 92.060%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.331 Acc 90.625%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.262 Acc 92.884%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.251 Acc 93.132%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.244 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.265 Acc 92.443%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.267 Acc 92.292%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.270 Acc 92.265%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.270 Acc 92.262%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.273 Acc 92.177%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.248 Acc 93.201%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.242 Acc 93.233%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.257 Acc 92.242%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.260 Acc 92.425%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.269 Acc 92.307%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.266 Acc 92.373%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.265 Acc 92.414%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.245 Acc 93.038%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.241 Acc 93.155%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.266 Acc 92.188%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.264 Acc 92.351%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.266 Acc 92.312%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.266 Acc 92.242%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.265 Acc 92.309%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.219 Acc 94.230%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.211 Acc 94.372%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.244 Acc 91.406%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.263 Acc 92.497%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.268 Acc 92.222%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.264 Acc 92.419%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.263 Acc 92.464%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.263 Acc 92.484%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.332 Acc 89.844%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.227 Acc 93.719%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.222 Acc 94.045%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.252 Acc 92.946%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.256 Acc 92.712%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.257 Acc 92.595%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.258 Acc 92.571%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.260 Acc 92.517%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.184 Acc 91.406%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.207 Acc 94.407%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.201 Acc 94.566%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.221 Acc 91.406%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.245 Acc 92.822%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.245 Acc 92.852%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.248 Acc 92.771%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.249 Acc 92.749%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.249 Acc 92.705%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.216 Acc 94.330%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.206 Acc 94.457%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.230 Acc 92.969%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.247 Acc 92.891%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.252 Acc 92.724%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.246 Acc 92.896%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.248 Acc 92.836%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.248 Acc 92.833%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.220 Acc 94.075%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.211 Acc 94.263%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.338 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.243 Acc 93.093%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.242 Acc 93.109%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.244 Acc 93.021%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.248 Acc 92.963%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.250 Acc 92.833%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.344 Acc 90.625%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.230 Acc 94.377%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.224 Acc 94.450%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.235 Acc 93.123%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.243 Acc 92.918%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.241 Acc 93.041%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.241 Acc 93.064%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.242 Acc 93.081%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.230 Acc 93.657%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.221 Acc 93.886%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.231 Acc 93.209%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.234 Acc 93.237%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.236 Acc 93.200%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.234 Acc 93.154%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.238 Acc 93.050%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.234 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.227 Acc 93.839%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.161 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.228 Acc 93.603%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.235 Acc 93.291%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.234 Acc 93.231%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.236 Acc 93.230%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.234 Acc 93.232%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.326 Acc 90.625%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.217 Acc 94.307%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.208 Acc 94.422%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.344 Acc 91.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.228 Acc 93.139%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.229 Acc 93.218%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.231 Acc 93.233%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.229 Acc 93.325%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.229 Acc 93.370%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.240 Acc 93.595%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.229 Acc 93.894%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.255 Acc 94.531%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.234 Acc 93.178%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.236 Acc 93.167%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.236 Acc 93.182%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.237 Acc 93.210%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.235 Acc 93.262%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.234 Acc 92.188%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.187 Acc 95.003%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.180 Acc 95.204%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.150 Acc 94.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.217 Acc 93.881%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.226 Acc 93.521%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.228 Acc 93.343%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.230 Acc 93.339%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.230 Acc 93.337%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.252 Acc 93.116%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.244 Acc 93.249%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.223 Acc 93.588%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.227 Acc 93.400%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.223 Acc 93.553%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.229 Acc 93.397%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.228 Acc 93.455%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.198 Acc 94.694%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.189 Acc 94.998%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.242 Acc 92.188%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.229 Acc 93.170%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.226 Acc 93.505%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.225 Acc 93.532%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.226 Acc 93.520%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.228 Acc 93.479%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.234 Acc 94.028%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.229 Acc 94.111%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.213 Acc 93.704%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.213 Acc 93.762%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.217 Acc 93.638%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.217 Acc 93.752%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.218 Acc 93.706%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.211 Acc 94.392%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.205 Acc 94.504%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.222 Acc 93.735%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.219 Acc 93.633%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.218 Acc 93.662%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.225 Acc 93.551%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.222 Acc 93.647%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.255 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.201 Acc 94.933%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.192 Acc 95.048%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.210 Acc 94.044%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.214 Acc 93.886%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.214 Acc 93.893%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.215 Acc 93.828%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.219 Acc 93.720%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.283 Acc 92.188%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.223 Acc 94.067%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.215 Acc 94.232%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.280 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.196 Acc 94.222%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.207 Acc 94.030%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.213 Acc 93.867%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.217 Acc 93.793%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.217 Acc 93.758%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.199 Acc 94.524%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.191 Acc 94.912%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.204 Acc 94.524%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.211 Acc 94.119%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.212 Acc 94.030%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.214 Acc 93.964%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.213 Acc 93.971%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.182 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.192 Acc 94.841%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.186 Acc 94.970%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.194 Acc 94.338%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.213 Acc 93.933%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.213 Acc 93.869%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.214 Acc 93.857%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.214 Acc 93.900%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.217 Acc 94.763%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.209 Acc 94.943%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.225 Acc 93.696%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.219 Acc 93.812%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.218 Acc 93.856%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.218 Acc 93.867%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.215 Acc 93.914%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.280 Acc 90.625%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.231 Acc 93.425%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.224 Acc 93.680%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.203 Acc 94.160%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.204 Acc 94.146%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.209 Acc 93.994%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.211 Acc 93.994%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.214 Acc 93.842%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.193 Acc 95.173%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.185 Acc 95.320%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.202 Acc 92.188%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.216 Acc 93.634%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.218 Acc 93.723%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.217 Acc 93.797%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.216 Acc 93.814%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.214 Acc 93.839%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.218 Acc 94.531%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.213 Acc 94.558%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.202 Acc 92.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.217 Acc 93.974%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.209 Acc 93.968%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.212 Acc 93.994%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.209 Acc 94.009%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.208 Acc 94.048%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.208 Acc 94.779%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.203 Acc 94.827%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.165 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.199 Acc 94.315%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.196 Acc 94.508%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.196 Acc 94.435%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.203 Acc 94.186%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.206 Acc 94.098%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.200 Acc 94.794%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.194 Acc 95.021%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.200 Acc 94.315%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.204 Acc 94.111%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.208 Acc 94.017%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.206 Acc 94.179%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.205 Acc 94.085%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.197 Acc 94.972%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.188 Acc 95.235%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.199 Acc 94.338%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.203 Acc 94.127%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.203 Acc 94.121%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.205 Acc 94.122%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.207 Acc 94.095%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.198 Acc 95.119%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.192 Acc 95.169%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.192 Acc 94.732%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.197 Acc 94.446%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.203 Acc 94.326%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.199 Acc 94.401%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.198 Acc 94.375%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 95.057%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 95.114%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.206 Acc 93.765%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.211 Acc 93.781%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.207 Acc 93.901%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.207 Acc 93.976%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.206 Acc 94.024%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.195 Acc 95.127%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.187 Acc 95.188%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.201 Acc 94.044%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.201 Acc 94.069%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.199 Acc 94.207%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.203 Acc 94.159%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.203 Acc 94.162%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.192 Acc 95.034%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.138%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.201 Acc 94.694%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.203 Acc 94.426%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.200 Acc 94.461%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.200 Acc 94.403%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.198 Acc 94.371%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.196 Acc 94.640%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.193 Acc 94.768%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.185 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.208 Acc 94.183%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.208 Acc 94.135%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.201 Acc 94.334%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.201 Acc 94.270%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.203 Acc 94.196%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.164 Acc 92.188%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.203 Acc 94.717%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.197 Acc 94.904%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.186 Acc 94.655%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.186 Acc 94.621%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.191 Acc 94.573%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.192 Acc 94.525%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.194 Acc 94.452%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.187 Acc 95.490%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.180 Acc 95.565%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.148 Acc 94.531%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.194 Acc 94.330%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.196 Acc 94.271%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.200 Acc 94.103%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.199 Acc 94.159%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.198 Acc 94.169%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.259 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.213 Acc 94.508%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.206 Acc 94.729%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.179 Acc 92.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.188 Acc 94.485%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.192 Acc 94.329%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.197 Acc 94.298%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.197 Acc 94.327%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.196 Acc 94.361%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.199 Acc 95.080%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.192 Acc 95.075%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.195 Acc 91.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.190 Acc 94.230%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.192 Acc 94.240%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.196 Acc 94.163%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.195 Acc 94.227%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.195 Acc 94.254%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.202 Acc 94.910%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.196 Acc 95.114%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.377 Acc 90.625%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.192 Acc 94.205%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.194 Acc 94.220%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.192 Acc 94.307%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.194 Acc 94.263%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.190 Acc 95.173%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.184 Acc 95.301%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.153 Acc 95.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.181 Acc 94.810%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.186 Acc 94.784%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.187 Acc 94.653%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.187 Acc 94.642%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.188 Acc 94.591%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.195 Acc 94.972%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.190 Acc 95.029%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.134 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.188 Acc 94.632%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.189 Acc 94.504%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.193 Acc 94.456%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.195 Acc 94.380%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.197 Acc 94.841%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.190 Acc 94.974%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.183 Acc 94.732%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.181 Acc 94.749%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.185 Acc 94.661%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.186 Acc 94.656%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.190 Acc 94.558%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.227%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.173%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.179 Acc 94.856%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.182 Acc 94.900%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.181 Acc 94.869%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.738%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.188 Acc 94.711%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.187 Acc 95.406%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.197 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.181 Acc 94.771%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.183 Acc 94.648%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.183 Acc 94.643%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.184 Acc 94.596%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.188 Acc 94.545%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.188 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.189 Acc 95.104%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.183 Acc 95.262%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.177 Acc 94.949%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.181 Acc 94.726%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.188 Acc 94.565%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.186 Acc 94.644%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.188 Acc 94.595%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.173 Acc 95.588%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.178 Acc 94.841%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.691%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.186 Acc 94.721%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.189 Acc 94.545%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.125 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.193 Acc 95.421%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.189 Acc 95.402%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.221 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.178 Acc 94.787%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.186 Acc 94.617%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.189 Acc 94.536%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.193 Acc 94.539%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.190 Acc 94.573%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.188 Acc 95.305%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.184 Acc 95.441%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.165 Acc 92.969%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.190 Acc 94.500%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.178 Acc 94.838%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.179 Acc 94.840%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.183 Acc 94.732%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.183 Acc 94.767%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.179 Acc 95.622%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.175 Acc 95.670%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.187 Acc 94.709%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.181 Acc 94.858%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.183 Acc 94.793%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.185 Acc 94.722%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.187 Acc 94.633%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.183 Acc 95.382%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.178 Acc 95.484%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.342 Acc 92.188%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.172 Acc 94.879%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.178 Acc 94.656%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.185 Acc 94.521%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.188 Acc 94.442%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.185 Acc 94.544%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.182 Acc 95.444%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.179 Acc 95.515%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.166 Acc 95.127%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.180 Acc 94.768%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.182 Acc 94.791%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.182 Acc 94.833%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.181 Acc 94.838%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.186 Acc 95.483%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.184 Acc 95.437%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.283 Acc 94.531%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.182 Acc 94.647%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.182 Acc 94.803%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.180 Acc 94.858%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.182 Acc 94.742%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.184 Acc 94.667%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.178 Acc 95.800%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.173 Acc 95.775%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.173 Acc 95.050%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.174 Acc 94.974%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.181 Acc 94.868%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.180 Acc 94.865%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.211 Acc 94.701%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.208 Acc 94.667%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.172 Acc 95.065%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.176 Acc 95.029%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.179 Acc 94.936%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.180 Acc 94.915%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.181 Acc 94.877%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.530%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.183 Acc 93.750%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.166 Acc 94.964%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.172 Acc 94.866%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.178 Acc 94.773%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.180 Acc 94.751%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.182 Acc 94.737%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.202 Acc 95.251%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.188 Acc 95.460%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.171 Acc 94.910%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.178 Acc 94.885%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.178 Acc 94.892%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.176 Acc 94.880%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.177 Acc 94.860%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.179 Acc 95.449%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.203 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.172 Acc 94.972%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.173 Acc 94.947%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.178 Acc 94.830%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.181 Acc 94.790%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.180 Acc 94.796%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.178 Acc 95.645%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.224 Acc 92.969%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.175 Acc 95.065%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.172 Acc 95.040%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.174 Acc 95.037%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.175 Acc 94.927%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.175 Acc 94.951%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.233 Acc 92.969%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.202 Acc 95.343%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.194 Acc 95.421%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.243 Acc 92.969%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.169 Acc 95.266%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.172 Acc 95.083%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.173 Acc 95.056%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.173 Acc 95.067%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.175 Acc 95.015%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.188 Acc 95.405%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.185 Acc 95.468%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.173 Acc 95.065%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.170 Acc 95.029%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.173 Acc 95.032%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.176 Acc 94.968%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.177 Acc 94.901%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.213 Acc 94.446%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.204 Acc 94.648%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.178 Acc 94.787%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.175 Acc 94.908%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.173 Acc 94.949%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.173 Acc 95.020%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.173 Acc 95.060%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.190 Acc 95.405%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.184 Acc 95.456%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.173 Acc 94.887%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.175 Acc 94.694%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.178 Acc 94.687%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.177 Acc 94.777%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.176 Acc 94.876%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.197 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.186 Acc 95.583%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.184 Acc 95.655%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.178 Acc 94.903%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.174 Acc 94.924%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.172 Acc 94.936%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.173 Acc 94.931%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.173 Acc 94.930%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.209 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.189 Acc 95.382%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.186 Acc 95.484%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.171 Acc 95.065%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.166 Acc 95.204%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.172 Acc 95.087%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.172 Acc 95.024%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.171 Acc 95.030%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.110 Acc 95.312%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.176 Acc 95.838%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.173 Acc 95.903%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.191 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.181 Acc 94.825%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.173 Acc 94.963%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.174 Acc 94.970%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.172 Acc 94.995%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.171 Acc 95.019%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.203 Acc 94.995%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.197 Acc 95.130%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.095 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.169 Acc 94.670%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.166 Acc 94.963%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.166 Acc 95.061%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.168 Acc 95.049%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.171 Acc 95.005%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.224 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.211 Acc 94.980%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.175 Acc 94.794%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.176 Acc 94.846%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.177 Acc 94.879%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.177 Acc 94.866%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.177 Acc 94.863%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.175 Acc 92.188%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.184 Acc 95.529%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.181 Acc 95.550%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.359%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.166 Acc 95.184%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.172 Acc 95.048%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.173 Acc 94.975%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.175 Acc 94.913%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.676%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.173 Acc 95.662%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.160 Acc 95.413%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.166 Acc 95.239%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.169 Acc 95.178%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.172 Acc 95.133%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.172 Acc 95.052%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.250 Acc 91.406%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.204 Acc 94.941%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.200 Acc 94.974%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.164 Acc 95.135%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.166 Acc 95.270%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.168 Acc 95.188%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.169 Acc 95.139%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.168 Acc 95.167%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.190 Acc 95.220%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.187 Acc 95.270%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.211 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.149 Acc 95.568%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.163 Acc 95.320%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.165 Acc 95.224%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.166 Acc 95.190%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.168 Acc 95.111%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.092 Acc 97.656%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.173 Acc 95.506%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.169 Acc 95.709%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.159 Acc 92.188%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.167 Acc 94.903%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.167 Acc 95.021%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.164 Acc 95.100%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.165 Acc 95.092%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.167 Acc 95.079%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.177 Acc 95.885%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.127 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.157 Acc 95.429%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.166 Acc 95.118%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.169 Acc 95.001%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.170 Acc 94.964%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.170 Acc 94.971%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.191 Acc 95.630%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.186 Acc 95.728%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.165 Acc 95.212%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.165 Acc 95.122%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.166 Acc 95.110%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.168 Acc 95.118%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.168 Acc 95.033%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.117 Acc 96.875%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.205 Acc 94.872%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.199 Acc 94.939%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.166 Acc 95.150%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.166 Acc 95.122%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.167 Acc 95.185%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.169 Acc 95.125%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.168 Acc 95.124%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.188 Acc 95.498%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.185 Acc 95.414%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.259 Acc 92.188%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.155 Acc 95.367%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.160 Acc 95.208%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.164 Acc 95.203%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.164 Acc 95.170%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.166 Acc 95.105%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.192 Acc 95.429%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.190 Acc 95.394%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.090 Acc 98.438%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.166 Acc 95.266%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.167 Acc 95.122%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.161 Acc 95.287%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.165 Acc 95.211%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.167 Acc 95.079%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.209 Acc 93.750%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.204 Acc 95.158%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.199 Acc 95.274%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.157 Acc 95.490%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.161 Acc 95.433%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.160 Acc 95.429%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.164 Acc 95.262%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.165 Acc 95.255%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.185 Acc 95.568%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.184 Acc 95.565%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.398%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.160 Acc 95.309%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.164 Acc 95.271%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.163 Acc 95.274%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.164 Acc 95.255%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.211 Acc 94.895%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.208 Acc 95.149%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.250 Acc 91.406%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.172 Acc 94.848%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.165 Acc 95.075%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.163 Acc 95.227%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.163 Acc 95.229%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.164 Acc 95.219%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.190 Acc 95.421%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.186 Acc 95.480%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.159 Acc 95.421%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.157 Acc 95.476%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.163 Acc 95.162%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.164 Acc 95.149%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.164 Acc 95.155%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.202 Acc 95.282%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.198 Acc 95.309%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.160 Acc 95.382%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.160 Acc 95.464%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.159 Acc 95.424%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.162 Acc 95.357%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.163 Acc 95.292%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.225 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.206 Acc 95.034%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.200 Acc 95.169%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.149 Acc 95.545%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.159 Acc 95.219%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.162 Acc 95.188%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.160 Acc 95.274%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.162 Acc 95.241%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.188 Acc 95.606%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.168 Acc 95.073%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.164 Acc 95.122%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.161 Acc 95.248%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.163 Acc 95.237%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.161 Acc 95.292%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.182 Acc 95.552%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.174 Acc 95.635%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.160 Acc 95.328%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.161 Acc 95.367%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.161 Acc 95.341%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.160 Acc 95.340%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.160 Acc 95.350%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.187 Acc 95.367%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.185 Acc 95.355%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.161 Acc 95.343%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.159 Acc 95.379%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.158 Acc 95.375%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.157 Acc 95.455%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.160 Acc 95.364%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.213 Acc 95.413%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.208 Acc 95.309%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.213 Acc 95.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.164 Acc 95.127%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.159 Acc 95.347%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.160 Acc 95.367%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.158 Acc 95.394%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.160 Acc 95.337%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.214 Acc 94.732%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.212 Acc 94.799%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.221 Acc 95.312%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.152 Acc 95.220%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.159 Acc 95.188%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.159 Acc 95.263%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.156 Acc 95.355%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.157 Acc 95.376%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.172 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.199 Acc 95.467%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.188 Acc 95.557%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.148 Acc 95.614%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.153 Acc 95.445%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.158 Acc 95.310%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.160 Acc 95.248%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.163 Acc 95.247%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.202 Acc 91.406%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.176 Acc 95.441%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.152 Acc 95.413%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.155 Acc 95.398%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.157 Acc 95.333%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.159 Acc 95.340%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.159 Acc 95.341%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.191 Acc 95.614%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.187 Acc 95.686%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.165 Acc 95.073%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.158 Acc 95.293%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.158 Acc 95.232%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.159 Acc 95.311%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.161 Acc 95.252%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.191 Acc 95.405%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.187 Acc 95.515%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.145 Acc 95.637%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.155 Acc 95.600%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.154 Acc 95.614%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.154 Acc 95.527%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.158 Acc 95.414%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.189 Acc 95.475%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.185 Acc 95.491%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.143 Acc 95.924%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.143 Acc 95.903%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.149 Acc 95.767%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.153 Acc 95.622%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.155 Acc 95.548%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.203 Acc 95.483%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.197 Acc 95.515%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.183 Acc 92.969%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.149 Acc 95.483%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.154 Acc 95.437%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.155 Acc 95.468%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.159 Acc 95.404%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.158 Acc 95.414%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.248 Acc 93.750%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.231 Acc 94.183%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.224 Acc 94.282%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.160 Acc 95.173%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.152 Acc 95.472%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.154 Acc 95.460%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.154 Acc 95.496%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.155 Acc 95.448%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.176 Acc 95.676%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.171 Acc 95.763%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.188 Acc 91.406%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.157 Acc 95.227%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.153 Acc 95.437%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.154 Acc 95.411%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.157 Acc 95.340%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.158 Acc 95.309%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.170 Acc 96.875%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.196 Acc 95.158%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.193 Acc 95.188%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.156 Acc 95.429%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.150 Acc 95.421%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.151 Acc 95.450%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.154 Acc 95.390%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.157 Acc 95.317%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.174 Acc 95.763%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.150 Acc 95.701%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.152 Acc 95.632%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.152 Acc 95.566%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.155 Acc 95.481%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.228 Acc 94.957%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.226 Acc 94.862%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.160 Acc 95.104%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.157 Acc 95.157%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.156 Acc 95.328%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.159 Acc 95.309%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.161 Acc 95.298%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.185 Acc 95.487%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.160 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.144 Acc 95.614%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.151 Acc 95.538%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.153 Acc 95.536%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.154 Acc 95.501%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.157 Acc 95.394%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.191 Acc 95.344%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.128 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.142 Acc 95.908%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.150 Acc 95.569%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.150 Acc 95.629%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.150 Acc 95.620%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.152 Acc 95.542%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.156 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.211 Acc 95.057%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.207 Acc 95.239%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.162 Acc 95.235%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.150 Acc 95.592%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.150 Acc 95.588%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.152 Acc 95.544%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.154 Acc 95.504%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.191 Acc 95.413%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.186 Acc 95.484%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.144 Acc 95.606%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.150 Acc 95.429%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.151 Acc 95.424%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.154 Acc 95.369%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.154 Acc 95.381%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.195 Acc 95.003%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.188 Acc 95.188%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.154 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.152 Acc 95.475%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.157 Acc 95.476%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.154 Acc 95.489%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.153 Acc 95.527%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.153 Acc 95.529%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.184 Acc 95.568%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.179 Acc 95.647%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.307 Acc 91.406%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.148 Acc 95.552%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.151 Acc 95.484%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.152 Acc 95.486%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.152 Acc 95.455%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.154 Acc 95.392%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.184 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.193 Acc 95.761%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.186 Acc 95.767%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.158 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.146 Acc 95.869%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.151 Acc 95.732%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.151 Acc 95.621%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.151 Acc 95.564%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.152 Acc 95.518%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.192 Acc 95.436%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.184 Acc 95.581%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.136 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.157 Acc 95.441%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.156 Acc 95.481%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.158 Acc 95.379%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.157 Acc 95.383%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.181 Acc 95.258%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.182 Acc 95.359%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.144 Acc 93.750%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.150 Acc 95.436%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.147 Acc 95.612%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.147 Acc 95.645%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.150 Acc 95.578%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.191 Acc 95.150%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.186 Acc 95.359%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.145 Acc 95.662%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.149 Acc 95.549%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.154 Acc 95.449%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.154 Acc 95.429%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.177 Acc 95.814%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.129 Acc 96.101%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.137 Acc 96.012%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.145 Acc 95.704%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.150 Acc 95.599%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.147 Acc 95.621%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.179 Acc 96.094%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.196 Acc 95.351%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.194 Acc 95.386%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.150 Acc 95.537%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.152 Acc 95.491%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.152 Acc 95.453%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.154 Acc 95.427%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.153 Acc 95.473%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.188 Acc 95.476%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.156 Acc 95.475%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.150 Acc 95.569%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.151 Acc 95.519%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.152 Acc 95.518%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.307 Acc 93.750%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.216 Acc 95.220%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.207 Acc 95.309%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.147 Acc 95.560%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.151 Acc 95.592%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.148 Acc 95.559%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.147 Acc 95.620%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.150 Acc 95.576%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.128 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.188 Acc 95.692%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.180 Acc 95.748%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.136 Acc 95.924%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.143 Acc 95.658%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.143 Acc 95.671%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.147 Acc 95.576%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.148 Acc 95.557%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.215 Acc 95.142%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.211 Acc 95.169%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.157 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.135 Acc 96.086%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.137 Acc 95.965%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.142 Acc 95.894%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.144 Acc 95.825%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.147 Acc 95.737%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.213 Acc 95.034%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.207 Acc 95.118%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.203 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.128 Acc 96.086%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.139 Acc 95.736%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.144 Acc 95.723%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.145 Acc 95.661%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.147 Acc 95.595%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.199 Acc 95.243%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.194 Acc 95.390%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.144 Acc 95.815%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.144 Acc 95.709%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.147 Acc 95.632%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.147 Acc 95.649%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.201 Acc 95.166%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.199 Acc 95.285%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.146 Acc 95.529%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.146 Acc 95.612%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.144 Acc 95.665%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.145 Acc 95.630%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.148 Acc 95.574%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.202 Acc 95.537%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.196 Acc 95.635%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.141 Acc 95.599%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.144 Acc 95.655%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.150 Acc 95.494%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.151 Acc 95.406%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.153 Acc 95.381%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.210 Acc 94.864%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.204 Acc 95.013%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.147 Acc 95.777%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.144 Acc 95.767%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.146 Acc 95.637%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.146 Acc 95.646%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.146 Acc 95.693%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.206 Acc 95.483%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.202 Acc 95.484%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.142 Acc 95.568%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.141 Acc 95.577%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.142 Acc 95.678%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.145 Acc 95.620%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.148 Acc 95.546%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.203 Acc 95.073%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.192 Acc 95.246%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.155 Acc 95.444%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.149 Acc 95.631%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.149 Acc 95.569%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.148 Acc 95.577%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.148 Acc 95.571%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.188 Acc 96.875%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.193 Acc 95.552%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.189 Acc 95.542%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.169 Acc 94.531%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.142 Acc 95.769%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.147 Acc 95.581%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.147 Acc 95.541%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.146 Acc 95.548%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.147 Acc 95.531%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.205 Acc 95.452%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.203 Acc 95.534%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.182 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.142 Acc 95.869%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.145 Acc 95.806%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.144 Acc 95.839%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.144 Acc 95.784%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.144 Acc 95.751%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.176 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.178 Acc 95.616%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.141 Acc 95.715%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.145 Acc 95.635%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.145 Acc 95.614%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.146 Acc 95.603%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.147 Acc 95.574%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.199 Acc 95.390%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.197 Acc 95.351%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.156 Acc 95.498%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.152 Acc 95.515%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.150 Acc 95.588%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.148 Acc 95.630%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.147 Acc 95.624%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.185 Acc 95.692%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.185 Acc 95.794%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.137 Acc 95.614%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.140 Acc 95.705%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.142 Acc 95.647%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.145 Acc 95.562%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.146 Acc 95.554%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.221 Acc 94.833%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.217 Acc 94.967%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.222 Acc 91.406%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.150 Acc 95.459%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.143 Acc 95.709%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.142 Acc 95.746%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.144 Acc 95.696%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.145 Acc 95.670%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.212 Acc 95.645%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.204 Acc 95.709%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.135 Acc 95.831%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.137 Acc 95.802%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.143 Acc 95.697%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.145 Acc 95.663%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.146 Acc 95.635%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.194 Acc 95.614%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.189 Acc 95.658%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.132 Acc 96.109%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.141 Acc 95.849%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.141 Acc 95.967%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.143 Acc 95.885%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.145 Acc 95.766%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.201 Acc 95.119%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.197 Acc 95.095%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.335 Acc 92.969%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.143 Acc 95.738%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.147 Acc 95.647%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.147 Acc 95.694%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.145 Acc 95.716%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.146 Acc 95.690%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.197 Acc 95.606%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.191 Acc 95.573%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.172 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.136 Acc 95.908%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.139 Acc 95.864%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.144 Acc 95.723%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.145 Acc 95.700%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.148 Acc 95.645%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.202 Acc 95.111%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.195 Acc 95.145%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.145 Acc 95.583%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.143 Acc 95.616%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.146 Acc 95.551%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.147 Acc 95.566%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.149 Acc 95.550%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.217 Acc 95.181%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.208 Acc 95.250%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.140 Acc 95.823%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.136 Acc 95.934%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.145 Acc 95.720%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.146 Acc 95.727%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.146 Acc 95.696%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.207 Acc 95.382%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.205 Acc 95.429%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.130 Acc 96.210%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.136 Acc 96.032%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.138 Acc 95.941%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.138 Acc 95.942%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.140 Acc 95.893%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.203 Acc 95.243%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.199 Acc 95.239%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.129 Acc 95.962%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.135 Acc 95.969%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.141 Acc 95.839%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.141 Acc 95.849%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.192 Acc 95.599%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.185 Acc 95.728%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.147 Acc 95.537%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.138 Acc 95.845%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.139 Acc 95.800%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.141 Acc 95.766%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.143 Acc 95.727%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.212 Acc 94.794%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.203 Acc 94.967%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.147 Acc 95.744%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.145 Acc 95.764%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.144 Acc 95.726%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.144 Acc 95.735%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.203 Acc 95.715%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.195 Acc 95.759%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.131 Acc 96.264%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.137 Acc 96.047%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.140 Acc 95.933%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.142 Acc 95.800%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.140 Acc 95.819%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.193 Acc 95.498%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.187 Acc 95.569%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.124 Acc 96.171%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.126 Acc 96.168%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.129 Acc 96.148%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.134 Acc 96.082%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.134 Acc 96.047%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.207 Acc 95.490%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.200 Acc 95.627%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.140 Acc 95.761%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.139 Acc 95.814%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.142 Acc 95.694%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.141 Acc 95.710%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.146 Acc 95.601%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.277 Acc 92.969%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.223 Acc 95.220%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.216 Acc 95.390%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.139 Acc 95.815%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.140 Acc 95.791%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.144 Acc 95.738%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.144 Acc 95.724%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.144 Acc 95.705%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.276 Acc 92.188%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.210 Acc 95.490%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.573%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.141 Acc 95.919%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.143 Acc 95.816%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.143 Acc 95.757%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.143 Acc 95.715%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.257 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.223 Acc 95.173%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.218 Acc 95.208%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.134 Acc 95.970%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.137 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.139 Acc 95.852%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.142 Acc 95.745%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.141 Acc 95.782%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.246 Acc 92.188%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.214 Acc 95.320%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.204 Acc 95.371%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.274 Acc 92.969%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.132 Acc 96.047%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.135 Acc 96.050%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.138 Acc 95.965%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.140 Acc 95.913%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.203 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.218 Acc 95.498%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.213 Acc 95.476%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.179 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.139 Acc 95.831%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.142 Acc 95.826%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.137 Acc 95.915%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.140 Acc 95.868%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.141 Acc 95.838%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.260 Acc 91.406%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.198 Acc 95.189%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.138 Acc 95.939%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.139 Acc 95.896%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.141 Acc 95.720%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.140 Acc 95.729%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.140 Acc 95.746%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.382%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.191 Acc 95.390%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.138 Acc 95.800%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.136 Acc 95.958%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.139 Acc 95.909%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.140 Acc 95.825%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.140 Acc 95.807%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.193 Acc 95.475%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.191 Acc 95.484%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.134 Acc 96.024%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.138 Acc 95.920%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.140 Acc 95.846%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.140 Acc 95.846%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.188 Acc 95.792%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.181 Acc 95.841%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.203 Acc 95.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.122 Acc 96.558%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.132 Acc 96.107%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.134 Acc 96.049%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.135 Acc 96.020%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.186 Acc 95.693%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.140 Acc 95.893%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.138 Acc 95.892%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.136 Acc 95.917%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.138 Acc 95.876%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.138 Acc 95.907%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.198 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.187 Acc 95.846%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.184 Acc 95.818%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.131 Acc 95.970%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.137 Acc 95.903%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.140 Acc 95.764%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.138 Acc 95.848%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.141 Acc 95.771%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.239 Acc 92.188%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.190 Acc 95.707%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.185 Acc 95.814%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.128 Acc 96.032%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.131 Acc 95.985%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.133 Acc 95.993%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.137 Acc 95.881%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.136 Acc 95.847%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.214 Acc 95.367%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.208 Acc 95.324%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.108 Acc 93.750%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.134 Acc 96.086%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.135 Acc 96.063%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.134 Acc 95.990%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.135 Acc 95.998%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.136 Acc 95.899%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.199 Acc 95.506%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.194 Acc 95.530%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.173 Acc 92.969%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.132 Acc 96.194%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.137 Acc 95.973%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.137 Acc 95.951%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.137 Acc 95.952%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.138 Acc 95.952%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.192 Acc 95.498%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.188 Acc 95.670%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.127 Acc 96.202%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.139 Acc 95.829%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.137 Acc 95.865%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.135 Acc 95.963%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.135 Acc 95.980%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.201 Acc 95.312%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.211 Acc 95.305%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.205 Acc 95.414%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.149 Acc 95.483%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.141 Acc 95.616%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.137 Acc 95.728%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.138 Acc 95.747%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.140 Acc 95.734%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.215 Acc 95.297%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.204 Acc 95.456%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.134 Acc 94.531%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.130 Acc 96.105%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.132 Acc 96.013%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.135 Acc 95.909%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.138 Acc 95.829%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.224 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.201 Acc 95.452%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.193 Acc 95.503%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.123 Acc 96.303%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.131 Acc 96.016%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.134 Acc 95.934%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.134 Acc 95.963%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.220 Acc 94.887%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.208 Acc 95.072%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.140 Acc 94.531%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.136 Acc 95.846%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.142 Acc 95.752%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.139 Acc 95.852%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.137 Acc 95.920%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.137 Acc 95.904%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.219 Acc 95.026%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.215 Acc 95.106%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.131 Acc 96.040%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.136 Acc 95.931%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.135 Acc 95.922%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.136 Acc 95.848%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.139 Acc 95.841%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.205 Acc 95.506%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.198 Acc 95.612%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.131 Acc 96.086%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.135 Acc 95.938%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.135 Acc 95.974%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.137 Acc 95.965%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.135 Acc 95.974%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.198 Acc 95.831%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.193 Acc 95.864%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.124 Acc 96.326%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.130 Acc 96.191%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.134 Acc 96.034%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.133 Acc 96.022%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.132 Acc 96.003%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.286 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.214 Acc 95.398%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.210 Acc 95.421%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.130 Acc 95.838%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.132 Acc 95.896%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.136 Acc 95.808%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.139 Acc 95.790%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.138 Acc 95.818%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.235 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.217 Acc 95.699%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.211 Acc 95.728%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.130 Acc 96.098%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.135 Acc 95.967%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.135 Acc 95.957%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.135 Acc 95.986%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.699%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.195 Acc 95.861%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.135 Acc 95.959%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.133 Acc 95.990%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.134 Acc 95.941%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.257 Acc 94.640%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.245 Acc 94.834%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.259 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.131 Acc 95.955%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.133 Acc 95.958%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.132 Acc 96.016%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.134 Acc 95.940%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.135 Acc 95.904%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.200 Acc 95.490%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.195 Acc 95.542%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.202 Acc 91.406%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.130 Acc 95.800%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.129 Acc 96.067%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.132 Acc 96.031%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.134 Acc 95.979%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.134 Acc 95.975%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.246 Acc 94.601%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.240 Acc 94.698%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.129 Acc 96.016%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.133 Acc 95.958%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.133 Acc 95.972%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.135 Acc 95.961%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.135 Acc 95.955%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.210 Acc 95.792%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.208 Acc 95.713%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.135 Acc 95.861%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.133 Acc 95.956%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.136 Acc 95.961%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.136 Acc 95.971%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.165 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.188 Acc 95.784%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.183 Acc 95.740%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.133 Acc 96.031%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.135 Acc 95.973%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.135 Acc 95.952%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.163 Acc 96.875%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.205 Acc 95.614%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.198 Acc 95.643%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.139 Acc 95.779%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.141 Acc 95.751%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.137 Acc 95.840%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.137 Acc 95.838%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.203 Acc 95.459%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.195 Acc 95.616%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.123 Acc 96.334%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.127 Acc 96.273%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.126 Acc 96.320%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.127 Acc 96.267%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.127 Acc 96.259%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.214 Acc 95.282%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.210 Acc 95.293%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.181 Acc 93.750%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.131 Acc 95.931%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.130 Acc 96.024%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.132 Acc 96.018%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.134 Acc 96.006%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.136 Acc 95.946%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.213 Acc 95.552%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.209 Acc 95.616%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.126 Acc 96.303%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.128 Acc 96.102%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.128 Acc 96.195%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.130 Acc 96.137%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.129 Acc 96.091%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.223 Acc 95.297%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.212 Acc 95.445%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.168 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.126 Acc 96.156%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.129 Acc 96.067%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.130 Acc 96.063%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.132 Acc 96.024%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.131 Acc 96.070%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.193 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.218 Acc 95.351%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.215 Acc 95.414%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.168 Acc 92.188%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.140 Acc 95.761%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.131 Acc 96.024%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.130 Acc 96.050%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.129 Acc 96.068%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.132 Acc 95.991%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.112 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.201 Acc 95.575%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.193 Acc 95.651%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.067 Acc 95.312%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.121 Acc 96.419%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.125 Acc 96.276%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.129 Acc 96.115%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.130 Acc 95.990%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.132 Acc 95.977%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.223 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.224 Acc 95.351%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.218 Acc 95.414%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad4f8d2f1d7456492633adccc45219f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.305 Acc 13.281%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.249 Acc 18.758%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.246 Acc 18.598%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.242 Acc 18.805%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.241 Acc 18.805%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.240 Acc 18.854%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.228 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.253 Acc 22.656%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.239 Acc 18.897%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.235 Acc 19.022%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.236 Acc 18.940%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.220 Acc 17.969%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.240 Acc 18.580%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.238 Acc 18.738%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.235 Acc 18.934%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.896%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.236 Acc 18.903%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.218 Acc 21.875%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.236 Acc 18.906%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 18.916%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.973%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.247 Acc 20.312%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.239 Acc 18.502%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.238 Acc 18.839%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.180 Acc 21.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.240 Acc 18.912%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.238 Acc 19.111%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.237 Acc 19.064%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.217 Acc 18.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.246 Acc 18.325%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.240 Acc 18.734%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.237 Acc 19.030%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.236 Acc 19.132%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.219 Acc 20.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.238 Acc 19.098%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.239 Acc 18.793%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.239 Acc 18.802%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.239 Acc 18.840%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.238 Acc 18.890%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.235 Acc 18.959%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.238 Acc 18.903%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.239 Acc 18.764%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.238 Acc 18.831%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.266 Acc 19.531%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.241 Acc 18.765%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.238 Acc 18.731%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.239 Acc 18.768%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.237 Acc 18.957%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.273 Acc 11.719%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 2.234 Acc 19.168%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 2.236 Acc 19.014%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 2.236 Acc 19.051%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 2.297 Acc 14.844%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 2.237 Acc 19.199%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 2.235 Acc 19.143%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 2.238 Acc 18.900%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2.233 Acc 20.312%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2.236 Acc 19.214%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2.237 Acc 19.123%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2.237 Acc 18.991%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 2.256 Acc 18.750%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 2.235 Acc 18.870%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 2.235 Acc 18.888%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 2.236 Acc 18.937%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 2.246 Acc 18.750%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 2.233 Acc 19.361%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 2.234 Acc 19.080%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 2.236 Acc 18.940%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 2.256 Acc 17.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 2.240 Acc 18.704%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 2.236 Acc 19.103%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 2.236 Acc 19.058%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 2.236 Acc 19.085%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 2.234 Acc 19.407%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 2.235 Acc 19.127%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 2.234 Acc 19.150%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 2.236 Acc 18.958%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 2.246 Acc 17.188%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 2.234 Acc 19.052%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 2.234 Acc 19.069%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 2.235 Acc 19.048%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 2.267 Acc 14.062%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 2.241 Acc 18.533%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 2.240 Acc 18.738%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 2.238 Acc 18.863%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 2.211 Acc 23.438%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 2.233 Acc 19.021%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 2.238 Acc 18.746%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 2.238 Acc 18.867%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 2.237 Acc 14.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 2.236 Acc 19.019%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 2.234 Acc 16.406%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 2.238 Acc 18.456%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 2.238 Acc 18.618%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 2.238 Acc 18.628%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 2.238 Acc 18.754%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 2.238 Acc 18.862%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 2.246 Acc 15.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 2.239 Acc 18.715%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 2.239 Acc 18.859%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 2.194 Acc 21.875%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 2.238 Acc 18.619%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 2.236 Acc 19.018%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 2.236 Acc 18.991%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 2.278 Acc 14.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 2.240 Acc 18.889%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 2.238 Acc 19.045%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 2.238 Acc 18.949%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 2.238 Acc 18.959%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 2.244 Acc 17.969%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 2.240 Acc 18.572%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 2.238 Acc 18.937%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 2.236 Acc 19.330%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 2.236 Acc 19.174%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2.275 Acc 15.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 2.234 Acc 18.881%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 2.238 Acc 18.781%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2.258 Acc 14.844%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 2.240 Acc 18.937%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 2.238 Acc 18.960%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 2.237 Acc 18.883%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 2.294 Acc 14.062%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2.241 Acc 18.858%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 2.239 Acc 18.902%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 2.239 Acc 18.810%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 2.239 Acc 18.816%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 2.210 Acc 21.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 2.237 Acc 18.805%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 2.237 Acc 18.838%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 2.276 Acc 13.281%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 2.240 Acc 18.982%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 2.239 Acc 18.740%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 2.237 Acc 18.995%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 2.236 Acc 17.188%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 2.236 Acc 19.137%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 2.236 Acc 18.855%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 2.237 Acc 18.854%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 2.237 Acc 18.855%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 2.238 Acc 18.879%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 2.184 Acc 23.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 2.233 Acc 19.245%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 2.236 Acc 19.022%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 2.236 Acc 18.908%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 2.242 Acc 17.188%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 2.235 Acc 18.881%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 2.234 Acc 19.007%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 2.235 Acc 18.999%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 2.236 Acc 19.032%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.212 Acc 19.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 2.230 Acc 19.423%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 2.234 Acc 19.216%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 2.236 Acc 19.001%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 2.238 Acc 18.879%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.264 Acc 17.969%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 2.237 Acc 18.878%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.230 Acc 21.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 2.237 Acc 19.076%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 2.239 Acc 17.188%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 2.235 Acc 19.346%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 2.239 Acc 18.785%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 2.235 Acc 19.157%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 2.236 Acc 19.057%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.257 Acc 17.188%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 2.244 Acc 18.255%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 2.241 Acc 18.567%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 2.240 Acc 18.644%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 2.238 Acc 18.918%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 2.238 Acc 18.943%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.260 Acc 14.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 2.236 Acc 19.129%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 2.237 Acc 19.135%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 2.237 Acc 19.103%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 2.213 Acc 24.219%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 2.232 Acc 19.369%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 2.236 Acc 19.116%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 2.238 Acc 18.941%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 2.225 Acc 23.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 2.232 Acc 19.570%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 2.235 Acc 19.263%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 2.238 Acc 19.007%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 2.237 Acc 19.068%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 2.241 Acc 18.970%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 2.187 Acc 18.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 2.238 Acc 19.160%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 2.239 Acc 19.003%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 2.238 Acc 18.825%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 2.227 Acc 22.656%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 2.256 Acc 16.406%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 2.243 Acc 18.611%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 2.241 Acc 18.785%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 2.239 Acc 18.984%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 2.237 Acc 19.056%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 2.251 Acc 15.625%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 2.238 Acc 18.742%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 2.235 Acc 19.088%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 2.238 Acc 18.889%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 2.265 Acc 17.188%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 2.236 Acc 18.898%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 2.238 Acc 18.784%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 2.238 Acc 18.873%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 2.234 Acc 17.188%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 2.237 Acc 19.013%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 2.235 Acc 19.185%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 2.236 Acc 19.046%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 2.214 Acc 17.188%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 2.236 Acc 18.996%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2.238 Acc 14.844%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 2.235 Acc 19.067%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 2.233 Acc 19.170%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 2.235 Acc 19.087%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 2.236 Acc 19.021%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 2.206 Acc 19.531%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 2.237 Acc 18.595%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 2.237 Acc 18.676%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2.237 Acc 18.810%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 2.274 Acc 14.844%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2.237 Acc 19.014%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 2.236 Acc 19.186%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2.235 Acc 19.157%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 2.235 Acc 19.191%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 2.236 Acc 19.045%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 2.237 Acc 19.080%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 2.236 Acc 19.132%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.257 Acc 10.938%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 2.237 Acc 19.129%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 2.235 Acc 19.115%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 2.234 Acc 19.212%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.253 Acc 15.625%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 2.241 Acc 18.727%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 2.237 Acc 19.043%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 2.236 Acc 19.058%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 2.306 Acc 14.844%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 2.240 Acc 18.765%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 2.240 Acc 18.657%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 2.239 Acc 18.667%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 2.238 Acc 18.690%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 2.237 Acc 18.872%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.214 Acc 20.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 2.241 Acc 18.394%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 2.239 Acc 18.715%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 2.240 Acc 18.755%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 2.238 Acc 18.842%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 2.238 Acc 18.945%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.227 Acc 17.188%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 2.240 Acc 18.502%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 2.237 Acc 19.162%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2.227 Acc 16.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 2.237 Acc 19.299%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 2.238 Acc 18.766%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 2.238 Acc 18.857%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 2.238 Acc 18.942%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.191 Acc 25.000%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 2.232 Acc 19.508%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 2.236 Acc 19.076%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 2.236 Acc 19.038%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 2.236 Acc 18.995%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.278 Acc 16.406%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 2.238 Acc 18.776%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 2.238 Acc 18.844%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 2.237 Acc 18.945%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.227 Acc 21.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.333 Acc 6.250%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.239 Acc 18.696%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.236 Acc 18.839%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.238 Acc 18.779%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.229 Acc 21.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.234 Acc 19.191%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.235 Acc 19.038%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.234 Acc 19.017%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.191 Acc 21.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.236 Acc 19.049%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.185 Acc 25.781%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 2.234 Acc 19.407%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 2.233 Acc 19.411%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 2.234 Acc 19.168%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 2.235 Acc 19.130%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.313 Acc 13.281%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.241 Acc 19.307%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.242 Acc 18.874%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.239 Acc 18.797%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.264 Acc 14.844%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.236 Acc 19.392%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.236 Acc 19.178%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.237 Acc 19.087%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.313 Acc 13.281%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.240 Acc 18.665%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.238 Acc 19.003%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.239 Acc 18.810%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.279 Acc 17.188%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.235 Acc 19.524%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.239 Acc 18.856%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.255 Acc 17.188%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.241 Acc 18.464%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.239 Acc 18.653%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.238 Acc 18.886%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.235 Acc 18.920%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.238 Acc 18.849%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.236 Acc 18.959%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.206 Acc 20.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.234 Acc 19.384%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.237 Acc 19.073%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.238 Acc 18.934%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 2.237 Acc 18.799%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.264 Acc 16.406%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.238 Acc 18.765%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.235 Acc 19.049%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.238 Acc 18.865%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.236 Acc 17.969%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.235 Acc 19.384%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.236 Acc 19.088%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.238 Acc 18.862%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.239 Acc 18.857%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.238 Acc 18.925%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.263 Acc 14.062%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.238 Acc 18.456%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.237 Acc 18.633%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.237 Acc 18.680%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.185 Acc 25.000%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 2.235 Acc 19.259%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 2.236 Acc 19.046%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.181 Acc 27.344%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.239 Acc 18.754%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.237 Acc 18.880%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.238 Acc 18.847%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.192 Acc 17.188%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.231 Acc 19.322%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.236 Acc 18.916%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.236 Acc 18.980%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.244 Acc 20.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.240 Acc 19.152%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.238 Acc 18.916%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.238 Acc 18.840%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.202 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.190 Acc 25.000%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.236 Acc 18.967%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.236 Acc 19.205%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 19.017%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.271 Acc 17.188%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.234 Acc 19.206%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.238 Acc 18.911%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.237 Acc 18.904%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.270 Acc 15.625%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.233 Acc 19.462%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.234 Acc 19.181%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.236 Acc 18.882%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.236 Acc 18.992%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.204 Acc 21.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.236 Acc 18.936%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.239 Acc 18.664%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.237 Acc 18.901%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.276 Acc 15.625%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.237 Acc 18.510%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.238 Acc 18.637%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.239 Acc 18.786%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.232 Acc 14.844%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.241 Acc 18.549%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.238 Acc 19.018%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.239 Acc 18.911%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.261 Acc 21.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 2.238 Acc 18.541%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 2.236 Acc 18.727%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 2.235 Acc 18.939%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 2.235 Acc 18.939%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.229 Acc 14.844%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.240 Acc 18.974%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.240 Acc 18.913%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.240 Acc 18.841%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.237 Acc 19.175%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.236 Acc 19.119%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 2.236 Acc 19.072%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.244 Acc 15.625%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.238 Acc 19.059%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.239 Acc 18.869%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.239 Acc 18.845%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.201 Acc 21.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.241 Acc 19.044%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.239 Acc 19.076%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.237 Acc 18.989%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.238 Acc 18.927%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.238 Acc 18.915%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.233 Acc 19.299%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.235 Acc 19.092%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.236 Acc 19.080%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.205 Acc 21.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.238 Acc 18.665%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.236 Acc 18.892%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.239 Acc 18.672%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.236 Acc 18.976%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.236 Acc 18.992%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.261 Acc 16.406%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.240 Acc 18.510%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.240 Acc 18.509%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.239 Acc 18.618%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.238 Acc 18.783%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.233 Acc 17.188%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.235 Acc 19.152%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.237 Acc 18.653%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 2.236 Acc 18.750%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 2.237 Acc 18.717%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 2.236 Acc 18.878%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.203 Acc 20.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.235 Acc 19.021%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.234 Acc 19.185%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.235 Acc 19.126%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.236 Acc 19.050%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.208 Acc 18.750%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.239 Acc 18.664%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.238 Acc 18.802%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.228 Acc 18.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.237 Acc 19.052%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 2.235 Acc 19.158%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 2.236 Acc 18.939%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.233 Acc 19.245%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.236 Acc 18.870%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.951%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.231 Acc 20.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.237 Acc 19.106%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.236 Acc 19.128%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.192 Acc 22.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.235 Acc 18.858%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.237 Acc 18.941%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.247 Acc 18.750%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.238 Acc 19.067%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.238 Acc 18.915%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.238 Acc 21.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.236 Acc 19.183%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.240 Acc 18.793%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.212 Acc 23.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.238 Acc 18.611%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.212 Acc 21.094%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.237 Acc 18.897%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.238 Acc 18.806%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.227 Acc 25.000%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.233 Acc 19.222%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.233 Acc 19.213%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.235 Acc 19.183%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.236 Acc 19.050%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.200 Acc 20.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.238 Acc 18.866%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.240 Acc 18.820%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.238 Acc 18.923%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.237 Acc 18.918%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.267 Acc 18.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.239 Acc 18.633%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.238 Acc 18.783%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.257 Acc 21.094%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 2.237 Acc 18.812%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 2.237 Acc 18.864%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.143 Acc 21.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.238 Acc 19.088%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.231 Acc 21.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.241 Acc 18.611%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.238 Acc 18.785%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.236 Acc 18.893%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.237 Acc 18.849%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.236 Acc 18.950%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.215 Acc 17.188%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.233 Acc 19.090%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.219 Acc 21.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.234 Acc 19.267%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.236 Acc 19.285%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.236 Acc 19.147%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.236 Acc 19.048%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.212 Acc 21.875%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.236 Acc 19.095%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 19.009%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.152 Acc 26.562%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.233 Acc 18.912%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.235 Acc 19.135%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.234 Acc 19.007%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.236 Acc 18.847%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.236 Acc 21.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.232 Acc 19.446%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.232 Acc 19.376%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.234 Acc 19.129%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.236 Acc 19.052%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.237 Acc 19.034%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.228 Acc 17.188%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.236 Acc 19.031%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.225 Acc 21.094%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.236 Acc 19.137%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.150%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.236 Acc 19.217%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.237 Acc 19.101%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.228 Acc 21.094%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.236 Acc 19.361%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.238 Acc 18.916%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.262 Acc 14.062%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.242 Acc 18.642%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.237 Acc 18.976%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.237 Acc 18.879%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.261 Acc 17.969%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.238 Acc 19.098%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.236 Acc 19.185%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.237 Acc 18.926%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.238 Acc 18.873%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.280 Acc 15.625%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.239 Acc 18.789%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.238 Acc 19.038%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.237 Acc 18.941%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.254 Acc 19.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.234 Acc 19.083%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.248 Acc 19.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.237 Acc 18.955%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.252 Acc 20.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.240 Acc 18.433%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.238 Acc 18.602%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.165 Acc 25.000%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.235 Acc 19.485%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 18.995%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.238 Acc 19.004%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.236 Acc 19.068%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.227 Acc 18.750%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.241 Acc 18.680%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.238 Acc 19.069%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.238 Acc 19.011%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.238 Acc 18.920%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.241 Acc 25.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.233 Acc 19.670%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.239 Acc 18.817%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.238 Acc 18.849%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.238 Acc 18.864%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.214 Acc 24.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.237 Acc 18.944%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.236 Acc 19.012%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.236 Acc 18.921%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.236 Acc 19.012%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.248 Acc 15.625%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.232 Acc 19.469%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.234 Acc 19.329%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.237 Acc 19.002%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 18.873%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.848%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.228 Acc 21.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.886%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.252 Acc 15.625%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.234 Acc 19.438%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.236 Acc 19.209%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.237 Acc 18.935%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.298 Acc 13.281%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.233 Acc 19.061%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.236 Acc 18.856%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.247 Acc 18.750%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.240 Acc 18.619%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.238 Acc 18.752%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.238 Acc 18.803%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.252 Acc 18.750%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.240 Acc 18.526%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.307 Acc 14.844%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.235 Acc 18.987%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.237 Acc 18.973%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.199 Acc 23.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.238 Acc 18.869%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.238 Acc 18.872%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.256 Acc 14.844%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.236 Acc 18.881%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.236 Acc 18.906%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.236 Acc 18.877%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.268 Acc 17.969%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.236 Acc 19.245%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.234 Acc 19.213%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.236 Acc 19.060%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.236 Acc 19.020%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.248 Acc 18.750%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.241 Acc 18.943%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.238 Acc 18.940%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.237 Acc 18.885%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.237 Acc 18.976%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.251 Acc 16.406%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.243 Acc 18.472%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.240 Acc 18.777%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.240 Acc 18.683%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.236 Acc 18.959%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.201 Acc 23.438%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.235 Acc 19.276%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.239 Acc 18.802%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.237 Acc 18.881%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.236 Acc 18.970%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.194 Acc 22.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.243 Acc 18.588%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.239 Acc 18.937%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.239 Acc 18.911%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.238 Acc 18.949%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.238 Acc 18.895%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.277 Acc 15.625%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.239 Acc 18.881%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.239 Acc 18.645%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.875%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.200 Acc 21.875%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.236 Acc 18.696%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.236 Acc 18.962%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.267 Acc 16.406%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.238 Acc 18.735%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.237 Acc 18.688%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.238 Acc 18.638%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.243 Acc 21.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.237 Acc 18.889%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.236 Acc 19.139%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 19.017%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.246 Acc 18.750%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.242 Acc 18.649%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.238 Acc 18.714%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.236 Acc 18.939%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.235 Acc 19.139%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.236 Acc 19.048%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.237 Acc 19.052%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.210 Acc 23.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.236 Acc 18.932%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.237 Acc 18.882%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.237 Acc 18.926%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.261 Acc 15.625%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.236 Acc 18.827%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.236 Acc 18.933%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.238 Acc 18.740%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.238 Acc 18.845%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.238 Acc 18.873%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.273 Acc 15.625%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.240 Acc 18.789%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.239 Acc 18.849%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.195 Acc 18.750%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.236 Acc 19.299%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.237 Acc 19.146%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.236 Acc 19.024%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.265 Acc 16.406%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.241 Acc 18.564%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.240 Acc 18.972%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.239 Acc 19.033%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.220 Acc 20.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.239 Acc 18.874%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.238 Acc 18.979%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.179 Acc 24.219%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.240 Acc 18.824%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.238 Acc 18.990%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.238 Acc 18.981%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.249 Acc 17.969%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.245 Acc 18.239%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.243 Acc 18.416%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.240 Acc 18.540%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.239 Acc 18.651%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.238 Acc 18.803%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.264 Acc 18.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.237 Acc 18.580%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.236 Acc 18.960%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.189 Acc 21.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.239 Acc 19.152%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.238 Acc 18.926%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.236 Acc 19.073%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.236 Acc 19.038%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.239 Acc 20.312%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.242 Acc 18.680%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.239 Acc 18.882%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.206 Acc 22.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.236 Acc 18.696%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.235 Acc 19.064%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.287 Acc 14.062%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.233 Acc 19.415%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.235 Acc 19.132%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.263 Acc 14.844%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.239 Acc 18.533%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.236 Acc 18.948%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.237 Acc 19.046%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.236 Acc 18.929%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.210 Acc 18.750%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.241 Acc 18.796%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 2.239 Acc 18.863%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.817%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.238 Acc 18.881%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.239 Acc 18.936%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.874%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.161 Acc 22.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.235 Acc 18.936%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.237 Acc 18.816%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.236 Acc 18.937%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.220 Acc 20.312%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.238 Acc 18.990%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.237 Acc 19.065%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.237 Acc 19.009%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.236 Acc 18.957%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.255 Acc 17.188%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.239 Acc 18.665%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.237 Acc 18.901%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.238 Acc 18.830%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.223 Acc 14.844%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.237 Acc 18.673%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.235 Acc 18.981%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.235 Acc 19.013%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.208 Acc 20.312%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.239 Acc 18.773%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.239 Acc 18.792%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.195 Acc 23.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.241 Acc 18.588%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.236 Acc 18.750%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.239 Acc 18.557%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.237 Acc 18.754%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.237 Acc 18.685%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.237 Acc 18.844%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.182 Acc 25.000%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.231 Acc 19.090%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.234 Acc 18.909%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.237 Acc 18.784%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.291 Acc 12.500%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.240 Acc 18.758%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.241 Acc 18.587%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.240 Acc 18.792%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.238 Acc 18.962%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.263 Acc 17.969%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.237 Acc 18.804%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.239 Acc 18.737%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.879%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.238 Acc 18.929%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.213 Acc 17.188%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.237 Acc 19.075%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.238 Acc 18.804%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.236 Acc 18.924%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.293 Acc 11.719%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.234 Acc 19.049%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.234 Acc 19.090%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.235 Acc 19.058%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.247 Acc 17.969%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.232 Acc 19.369%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.236 Acc 19.142%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 19.054%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.202 Acc 22.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.240 Acc 18.557%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.236 Acc 19.042%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 2.238 Acc 18.981%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.236 Acc 18.992%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.188 Acc 20.312%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.238 Acc 18.832%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.237 Acc 18.924%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.237 Acc 18.927%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.236 Acc 18.939%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.207 Acc 21.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.235 Acc 18.912%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.238 Acc 18.707%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.238 Acc 18.649%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.240 Acc 18.490%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.240 Acc 18.594%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.239 Acc 18.682%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.238 Acc 18.738%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.270 Acc 17.969%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.236 Acc 18.965%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.305 Acc 10.938%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.241 Acc 18.758%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.240 Acc 18.847%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.239 Acc 18.822%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.243 Acc 17.969%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.655%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.234 Acc 19.380%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.237 Acc 19.025%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.238 Acc 18.896%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.202 Acc 22.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.234 Acc 19.454%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.236 Acc 19.092%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.237 Acc 19.030%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.237 Acc 19.070%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.184 Acc 23.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.240 Acc 18.139%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.238 Acc 18.839%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.238 Acc 18.836%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.243 Acc 18.750%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.238 Acc 18.893%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.812%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.234 Acc 19.160%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.251 Acc 14.844%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.240 Acc 18.634%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.240 Acc 18.754%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.239 Acc 18.688%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.238 Acc 18.927%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.296 Acc 15.625%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.236 Acc 18.797%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.237 Acc 18.729%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.850%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.243 Acc 17.969%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.234 Acc 19.183%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.235 Acc 19.178%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.264 Acc 17.188%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.235 Acc 19.205%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 19.207%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.235 Acc 19.124%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.236 Acc 19.017%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.189 Acc 19.531%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.241 Acc 18.348%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.238 Acc 18.692%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.238 Acc 18.830%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 2.239 Acc 18.816%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.197 Acc 22.656%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.240 Acc 18.513%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.237 Acc 18.737%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.238 Acc 18.851%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.251 Acc 20.312%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.240 Acc 18.602%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.239 Acc 18.807%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.238 Acc 18.823%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.151 Acc 26.562%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.237 Acc 19.531%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.237 Acc 18.873%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e5de7d6634418e9223fe21922c8340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.309 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.246 Acc 18.843%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.244 Acc 18.874%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.240 Acc 18.916%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.234 Acc 19.065%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.941 Acc 25.000%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.934 Acc 25.681%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.937 Acc 25.342%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.772 Acc 37.500%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.450 Acc 50.487%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.210 Acc 59.624%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.033 Acc 66.022%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.914 Acc 70.122%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.837 Acc 72.873%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.897 Acc 80.469%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.850 Acc 81.946%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.852 Acc 81.810%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.494 Acc 85.938%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.433 Acc 87.044%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.433 Acc 87.088%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.424 Acc 87.370%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.413 Acc 87.568%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.409 Acc 87.725%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.540 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.543 Acc 88.072%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.539 Acc 88.134%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.320 Acc 88.281%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.350 Acc 89.488%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.351 Acc 89.478%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.351 Acc 89.428%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.350 Acc 89.468%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.347 Acc 89.566%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.611 Acc 89.844%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.615 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.611 Acc 89.327%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.210 Acc 93.750%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.320 Acc 90.300%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.324 Acc 90.365%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.322 Acc 90.443%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.320 Acc 90.506%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.318 Acc 90.570%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.316 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.332 Acc 91.553%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.324 Acc 91.764%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.198 Acc 92.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.296 Acc 91.414%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.294 Acc 91.418%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.296 Acc 91.282%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.296 Acc 91.338%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.294 Acc 91.356%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.309 Acc 92.969%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.359 Acc 91.491%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.353 Acc 91.655%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.274 Acc 91.855%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.274 Acc 91.822%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.279 Acc 91.705%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.277 Acc 91.827%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.280 Acc 91.801%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.310 Acc 93.750%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.348 Acc 92.149%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.343 Acc 92.289%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.267 Acc 92.188%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.284 Acc 91.669%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.271 Acc 91.923%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.272 Acc 91.886%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.272 Acc 91.960%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.272 Acc 91.982%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.601 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.552 Acc 90.524%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.551 Acc 90.582%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.337 Acc 89.062%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.243 Acc 92.744%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.259 Acc 92.428%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.256 Acc 92.616%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.258 Acc 92.544%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.260 Acc 92.448%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.368 Acc 91.406%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.342 Acc 93.131%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.336 Acc 93.284%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.270 Acc 92.188%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.247 Acc 92.969%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.238 Acc 93.039%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.245 Acc 92.862%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.250 Acc 92.776%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.252 Acc 92.708%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.291 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.310 Acc 92.984%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.307 Acc 93.089%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.246 Acc 92.984%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.244 Acc 92.840%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.240 Acc 92.901%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.243 Acc 92.877%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.242 Acc 92.920%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.359 Acc 93.750%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.395 Acc 93.549%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.391 Acc 93.661%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.215 Acc 93.518%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.227 Acc 93.350%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.234 Acc 93.210%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.233 Acc 93.218%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.235 Acc 93.242%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.336 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.338 Acc 92.226%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.334 Acc 92.292%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.235 Acc 93.456%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.229 Acc 93.622%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.224 Acc 93.553%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.228 Acc 93.425%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.229 Acc 93.437%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.358 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.381 Acc 92.528%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.376 Acc 92.704%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.395 Acc 89.062%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.223 Acc 93.402%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.220 Acc 93.447%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.227 Acc 93.358%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.228 Acc 93.388%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.228 Acc 93.357%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.355 Acc 93.750%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.373 Acc 92.860%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.367 Acc 93.050%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.236 Acc 93.750%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.203 Acc 94.121%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.215 Acc 93.649%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.217 Acc 93.654%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.215 Acc 93.731%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.217 Acc 93.700%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.486 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.508 Acc 91.538%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.503 Acc 91.682%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.310 Acc 91.406%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.220 Acc 93.533%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.221 Acc 93.653%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.215 Acc 93.823%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.217 Acc 93.781%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.216 Acc 93.830%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.353 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.364 Acc 93.990%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.359 Acc 94.170%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.354 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.203 Acc 94.168%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.203 Acc 94.104%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.209 Acc 94.025%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.209 Acc 94.040%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.209 Acc 94.054%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.348 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.372 Acc 92.938%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.367 Acc 93.046%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.213 Acc 93.750%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.201 Acc 94.106%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.204 Acc 94.007%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.211 Acc 93.867%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.206 Acc 93.958%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.206 Acc 94.040%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.289 Acc 93.796%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.284 Acc 93.560%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.260 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.198 Acc 94.214%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.201 Acc 94.158%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.203 Acc 94.119%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.204 Acc 94.140%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.207 Acc 94.053%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.288 Acc 92.907%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.282 Acc 92.992%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.121 Acc 95.312%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.184 Acc 94.562%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.188 Acc 94.617%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.194 Acc 94.412%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.196 Acc 94.323%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.197 Acc 94.336%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.306 Acc 95.312%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.362 Acc 93.758%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.358 Acc 93.762%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.187 Acc 94.624%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.186 Acc 94.632%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.191 Acc 94.521%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.197 Acc 94.338%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.198 Acc 94.389%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.263 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.300 Acc 93.232%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.294 Acc 93.377%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.427 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.196 Acc 94.392%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.194 Acc 94.407%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.190 Acc 94.562%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.193 Acc 94.436%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.193 Acc 94.427%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.286 Acc 94.531%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.324 Acc 92.752%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.317 Acc 92.938%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.198 Acc 93.750%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.194 Acc 94.315%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.190 Acc 94.450%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.189 Acc 94.485%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.192 Acc 94.418%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.191 Acc 94.433%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.397 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.424 Acc 92.102%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.418 Acc 92.335%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.309 Acc 92.969%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.170 Acc 95.196%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.184 Acc 94.757%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.182 Acc 94.799%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.184 Acc 94.742%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.182 Acc 94.798%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.319 Acc 92.188%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.346 Acc 93.054%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.339 Acc 93.295%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.190 Acc 92.969%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.180 Acc 94.879%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.184 Acc 94.593%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.189 Acc 94.500%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.186 Acc 94.520%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.204 Acc 96.094%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.272 Acc 94.160%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.267 Acc 94.080%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.176 Acc 94.988%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.181 Acc 94.978%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.182 Acc 94.830%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.182 Acc 94.816%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.181 Acc 94.813%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.349 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.395 Acc 93.224%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.390 Acc 93.354%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.165 Acc 95.243%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.173 Acc 95.044%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.176 Acc 94.931%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.177 Acc 94.905%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.180 Acc 94.824%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.293 Acc 94.075%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.288 Acc 94.181%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.172 Acc 95.080%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.169 Acc 95.130%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.173 Acc 94.983%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.173 Acc 94.991%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.174 Acc 94.965%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.298 Acc 93.859%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.170 Acc 94.817%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.166 Acc 95.087%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.171 Acc 94.960%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.169 Acc 95.022%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.172 Acc 94.999%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.312 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.339 Acc 93.085%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.332 Acc 93.295%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.235 Acc 93.750%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.162 Acc 95.243%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.166 Acc 95.130%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.169 Acc 95.084%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.173 Acc 95.020%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.174 Acc 94.955%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.283 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.316 Acc 93.727%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.312 Acc 93.839%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.167 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.169 Acc 95.498%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.166 Acc 95.328%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.166 Acc 95.227%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.165 Acc 95.266%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.165 Acc 95.258%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.416 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.412 Acc 92.327%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.409 Acc 92.265%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.160 Acc 95.266%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.163 Acc 95.239%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.166 Acc 95.167%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.166 Acc 95.147%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.167 Acc 95.133%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.295 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.330 Acc 93.688%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.327 Acc 93.657%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.154 Acc 95.490%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.158 Acc 95.386%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.161 Acc 95.255%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.160 Acc 95.293%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.163 Acc 95.224%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.347 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.351 Acc 93.123%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.348 Acc 92.984%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.165 Acc 95.158%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.158 Acc 95.332%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.162 Acc 95.248%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.213%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.165 Acc 95.220%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.310 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.355 Acc 93.417%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.352 Acc 93.408%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.146 Acc 95.560%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.152 Acc 95.476%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.154 Acc 95.510%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.157 Acc 95.523%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.159 Acc 95.459%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.381 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.446 Acc 91.832%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.442 Acc 91.970%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.160 Acc 95.452%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.159 Acc 95.424%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.159 Acc 95.427%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.159 Acc 95.380%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.283 Acc 95.312%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.300 Acc 94.175%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.298 Acc 94.080%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.151 Acc 95.398%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.157 Acc 95.262%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.157 Acc 95.315%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.158 Acc 95.303%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.158 Acc 95.390%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.508 Acc 90.625%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.529 Acc 91.027%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.525 Acc 91.021%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.199 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.150 Acc 95.722%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.152 Acc 95.600%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.154 Acc 95.531%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.152 Acc 95.566%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.154 Acc 95.578%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.343 Acc 93.185%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.340 Acc 93.159%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.143 Acc 95.854%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.145 Acc 95.713%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.149 Acc 95.636%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.152 Acc 95.542%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.250 Acc 96.094%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.299 Acc 93.348%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.297 Acc 93.326%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.151 Acc 95.746%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.144 Acc 95.837%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.147 Acc 95.663%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.151 Acc 95.579%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.151 Acc 95.560%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.378 Acc 91.406%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.401 Acc 92.257%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.394 Acc 92.479%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.136 Acc 95.955%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.142 Acc 95.872%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.144 Acc 95.790%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.149 Acc 95.581%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.150 Acc 95.554%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.277 Acc 94.299%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.274 Acc 94.368%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.134 Acc 96.264%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.143 Acc 96.004%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.144 Acc 95.912%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.147 Acc 95.809%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.147 Acc 95.787%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.247 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.268 Acc 93.959%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.262 Acc 94.022%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.143 Acc 95.506%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.144 Acc 95.612%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.143 Acc 95.676%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.142 Acc 95.743%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.147 Acc 95.648%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.278 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.292 Acc 93.688%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.287 Acc 93.828%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.139 Acc 95.792%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.138 Acc 95.763%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.137 Acc 95.824%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.142 Acc 95.794%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.280 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.295 Acc 93.735%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.293 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.118 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.141 Acc 95.862%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.137 Acc 95.973%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.143 Acc 95.816%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.141 Acc 95.868%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.143 Acc 95.780%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.332 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.360 Acc 93.386%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.356 Acc 93.412%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.181 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.132 Acc 95.908%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.138 Acc 95.822%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.142 Acc 95.793%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.141 Acc 95.837%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.142 Acc 95.821%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.523 Acc 90.625%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.520 Acc 90.555%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.517 Acc 90.683%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.144 Acc 95.730%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.142 Acc 95.810%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.140 Acc 95.847%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.141 Acc 95.864%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.142 Acc 95.854%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.362 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.377 Acc 92.683%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.372 Acc 92.736%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.136 Acc 95.877%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.137 Acc 95.923%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.138 Acc 95.930%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.138 Acc 95.938%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.138 Acc 95.924%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.489 Acc 91.406%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.488 Acc 91.584%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.482 Acc 91.772%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.130 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.142 Acc 95.676%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.139 Acc 95.783%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.138 Acc 95.790%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.135 Acc 95.879%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.136 Acc 95.880%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.303 Acc 93.510%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.302 Acc 93.490%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.133 Acc 95.973%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.137 Acc 95.912%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.138 Acc 95.895%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.137 Acc 95.879%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.299 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.315 Acc 93.642%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.313 Acc 93.618%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.128 Acc 95.931%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.130 Acc 95.985%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.136 Acc 95.839%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.136 Acc 95.852%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.138 Acc 95.804%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.281 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.322 Acc 93.325%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.315 Acc 93.490%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.129 Acc 96.117%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.129 Acc 96.125%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.137 Acc 95.955%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.136 Acc 95.946%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.375 Acc 92.188%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.358 Acc 93.209%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.354 Acc 93.315%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.144 Acc 92.969%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.134 Acc 95.862%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.129 Acc 96.059%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.132 Acc 95.933%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.131 Acc 95.989%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.132 Acc 95.996%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.324 Acc 93.139%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.318 Acc 93.140%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.120 Acc 96.380%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.125 Acc 96.245%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.125 Acc 96.229%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.128 Acc 96.176%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.129 Acc 96.097%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.323 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.335 Acc 93.642%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.331 Acc 93.703%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.252 Acc 96.094%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.137 Acc 96.063%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.135 Acc 96.024%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.134 Acc 96.065%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.132 Acc 96.041%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.134 Acc 96.053%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.285 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.311 Acc 93.193%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.307 Acc 93.319%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.209 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.114 Acc 96.364%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.123 Acc 96.175%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.123 Acc 96.187%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.123 Acc 96.242%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.123 Acc 96.253%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.403 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.374 Acc 93.023%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.366 Acc 93.175%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.126 Acc 96.117%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.128 Acc 96.078%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.128 Acc 96.115%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.130 Acc 96.151%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.320 Acc 90.625%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.313 Acc 93.270%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.309 Acc 93.330%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.125 Acc 96.256%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.122 Acc 96.319%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.122 Acc 96.275%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.125 Acc 96.193%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.127 Acc 96.142%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.321 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.361 Acc 92.737%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.355 Acc 92.879%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.115 Acc 96.426%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.123 Acc 96.288%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.121 Acc 96.314%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.123 Acc 96.298%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.124 Acc 96.286%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.282 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.286 Acc 93.773%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.282 Acc 93.839%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.122 Acc 96.238%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.122 Acc 96.249%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.123 Acc 96.271%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.124 Acc 96.270%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.343 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.356 Acc 93.077%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.350 Acc 93.186%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.256 Acc 92.188%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.109 Acc 96.689%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.116 Acc 96.436%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.117 Acc 96.356%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.120 Acc 96.304%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.123 Acc 96.226%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.352 Acc 92.969%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.337 Acc 93.247%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.331 Acc 93.357%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.116 Acc 96.558%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.117 Acc 96.545%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.120 Acc 96.351%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.122 Acc 96.341%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.123 Acc 96.300%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.286 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.318 Acc 92.752%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.311 Acc 93.008%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.118 Acc 96.426%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.119 Acc 96.374%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.119 Acc 96.372%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.119 Acc 96.359%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.513 Acc 91.406%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.542 Acc 89.735%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.539 Acc 89.941%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.136 Acc 97.656%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.115 Acc 96.511%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.116 Acc 96.424%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.118 Acc 96.447%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.120 Acc 96.390%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.406 Acc 92.969%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.418 Acc 91.429%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.412 Acc 91.682%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.117 Acc 96.388%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.111 Acc 96.498%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.119 Acc 96.377%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.118 Acc 96.404%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.118 Acc 96.393%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.340 Acc 92.969%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.380 Acc 92.342%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.374 Acc 92.440%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.112 Acc 96.566%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.116 Acc 96.529%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.114 Acc 96.496%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.116 Acc 96.448%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.119 Acc 96.396%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.413 Acc 91.406%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.403 Acc 91.747%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.397 Acc 91.764%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.104 Acc 96.759%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.108 Acc 96.587%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.116 Acc 96.397%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.117 Acc 96.361%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.118 Acc 96.321%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.271 Acc 92.969%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.318 Acc 92.613%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.313 Acc 92.747%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.121 Acc 96.395%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.117 Acc 96.432%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.122 Acc 96.252%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.122 Acc 96.281%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.120 Acc 96.281%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.308 Acc 91.406%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.320 Acc 92.876%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.314 Acc 93.081%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.141 Acc 93.750%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.119 Acc 96.349%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.121 Acc 96.362%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.121 Acc 96.397%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.120 Acc 96.409%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.120 Acc 96.384%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.353 Acc 92.188%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.366 Acc 92.265%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.357 Acc 92.545%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.111 Acc 96.701%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.112 Acc 96.610%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.113 Acc 96.538%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.321 Acc 92.188%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.326 Acc 92.976%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.322 Acc 93.132%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.100 Acc 96.945%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.111 Acc 96.605%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.110 Acc 96.604%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.111 Acc 96.625%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.286 Acc 93.023%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.279 Acc 93.334%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.066 Acc 96.875%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.097 Acc 96.999%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.105 Acc 96.755%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.108 Acc 96.608%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.108 Acc 96.602%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.110 Acc 96.587%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.385 Acc 92.188%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.410 Acc 91.136%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.404 Acc 91.181%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.109 Acc 96.558%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.107 Acc 96.642%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.108 Acc 96.602%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.109 Acc 96.614%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.110 Acc 96.571%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.456 Acc 89.062%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.415 Acc 92.033%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.409 Acc 91.993%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.105 Acc 96.728%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.106 Acc 96.751%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.108 Acc 96.676%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.109 Acc 96.646%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.415 Acc 90.625%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.456 Acc 90.749%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.450 Acc 90.897%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.107 Acc 96.635%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.112 Acc 96.556%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.112 Acc 96.582%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.111 Acc 96.593%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.112 Acc 96.537%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.398 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.377 Acc 92.520%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.370 Acc 92.549%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.103 Acc 96.450%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.105 Acc 96.611%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.107 Acc 96.613%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.109 Acc 96.554%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.110 Acc 96.551%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.394 Acc 89.062%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.391 Acc 92.249%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.386 Acc 92.421%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.092 Acc 96.960%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.100 Acc 96.817%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.100 Acc 96.808%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.104 Acc 96.725%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.106 Acc 96.643%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.302 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.316 Acc 92.690%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.310 Acc 92.926%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.105 Acc 96.767%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.106 Acc 96.743%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.109 Acc 96.662%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.109 Acc 96.647%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.109 Acc 96.574%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.322 Acc 92.489%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.317 Acc 92.506%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.100 Acc 96.821%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.104 Acc 96.599%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.110 Acc 96.429%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.110 Acc 96.483%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.110 Acc 96.513%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.433 Acc 91.406%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.373 Acc 92.543%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.366 Acc 92.864%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.106 Acc 96.767%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.105 Acc 96.700%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.105 Acc 96.711%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.105 Acc 96.700%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.107 Acc 96.644%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.415 Acc 91.406%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.407 Acc 91.863%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.402 Acc 92.044%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.098 Acc 96.774%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.102 Acc 96.774%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.102 Acc 96.792%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.103 Acc 96.793%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.105 Acc 96.738%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.387 Acc 89.844%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.356 Acc 91.917%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.348 Acc 92.094%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.107 Acc 96.589%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.104 Acc 96.696%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.109 Acc 96.592%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.107 Acc 96.649%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.107 Acc 96.664%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.419 Acc 90.625%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.333 Acc 92.946%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.329 Acc 93.054%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.094 Acc 97.146%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.095 Acc 97.057%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.098 Acc 96.974%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.100 Acc 96.911%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.271 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.305 Acc 93.131%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.299 Acc 93.171%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.100 Acc 96.929%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.105 Acc 96.820%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.105 Acc 96.809%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.104 Acc 96.805%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.384 Acc 92.188%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.367 Acc 92.667%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.361 Acc 92.774%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.110 Acc 96.465%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.104 Acc 96.688%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.103 Acc 96.717%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.103 Acc 96.715%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.103 Acc 96.750%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.387 Acc 91.406%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.374 Acc 91.375%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.369 Acc 91.531%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.097 Acc 97.045%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.097 Acc 97.023%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.099 Acc 97.026%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.101 Acc 96.895%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.417 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.387 Acc 91.646%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.382 Acc 91.857%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.097 Acc 96.968%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.095 Acc 97.108%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.098 Acc 96.992%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.099 Acc 96.972%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.100 Acc 96.937%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.329 Acc 92.969%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.358 Acc 92.311%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.353 Acc 92.541%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.100 Acc 96.805%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.102 Acc 96.739%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.104 Acc 96.701%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.105 Acc 96.694%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.105 Acc 96.688%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.515 Acc 89.062%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.452 Acc 90.726%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.448 Acc 90.745%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.097 Acc 96.929%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.099 Acc 96.854%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.098 Acc 96.895%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.379 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.332 Acc 92.288%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.327 Acc 92.463%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.094 Acc 96.929%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.099 Acc 96.805%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.098 Acc 96.898%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.098 Acc 96.893%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.100 Acc 96.799%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.385 Acc 92.188%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.374 Acc 91.940%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.371 Acc 91.939%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.101 Acc 96.860%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.099 Acc 96.918%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.098 Acc 96.927%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.100 Acc 96.869%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.099 Acc 96.897%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.382 Acc 90.625%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.358 Acc 91.847%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.355 Acc 91.760%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.090 Acc 97.084%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.091 Acc 97.077%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.095 Acc 97.023%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.097 Acc 96.912%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.097 Acc 96.902%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.318 Acc 91.406%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.315 Acc 92.791%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.311 Acc 92.891%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.090 Acc 97.006%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.091 Acc 97.054%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.098 Acc 96.880%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.102 Acc 96.746%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.101 Acc 96.767%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.290 Acc 91.406%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.308 Acc 93.069%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.303 Acc 93.144%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.090 Acc 97.092%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.096 Acc 96.957%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.097 Acc 96.880%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.099 Acc 96.865%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.101 Acc 96.805%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.376 Acc 92.188%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.364 Acc 92.574%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.363 Acc 92.452%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.085 Acc 97.200%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.090 Acc 97.151%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.089 Acc 97.148%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.094 Acc 97.062%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.326 Acc 92.296%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.321 Acc 92.397%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.092 Acc 96.999%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.092 Acc 97.019%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.093 Acc 96.989%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.095 Acc 96.961%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.097 Acc 96.922%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.491 Acc 92.188%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.499 Acc 90.602%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.495 Acc 90.726%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.114 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.094 Acc 97.061%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.097 Acc 97.003%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.098 Acc 96.968%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.098 Acc 96.943%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.098 Acc 96.955%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.378 Acc 91.406%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.375 Acc 91.824%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.370 Acc 92.048%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.086 Acc 97.254%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.087 Acc 97.209%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.086 Acc 97.218%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.089 Acc 97.152%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.091 Acc 97.092%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.327 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.322 Acc 92.613%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.316 Acc 92.825%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.110 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.082 Acc 97.300%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.091 Acc 97.054%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.091 Acc 97.062%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.094 Acc 96.986%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.094 Acc 96.978%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.321 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.315 Acc 92.837%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.310 Acc 93.062%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.088 Acc 96.983%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.090 Acc 97.073%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.092 Acc 97.018%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.093 Acc 96.998%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.094 Acc 96.959%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.581 Acc 87.500%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.526 Acc 89.101%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.521 Acc 89.303%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.099 Acc 96.813%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.095 Acc 96.972%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.096 Acc 96.950%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.368 Acc 92.188%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.352 Acc 91.878%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.346 Acc 92.051%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.082 Acc 97.362%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.083 Acc 97.264%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.089 Acc 97.155%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.090 Acc 97.134%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.381 Acc 90.625%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.383 Acc 91.298%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.377 Acc 91.461%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.091 Acc 97.155%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.093 Acc 97.127%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.093 Acc 97.078%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.093 Acc 97.057%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.339 Acc 92.188%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.356 Acc 92.288%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.352 Acc 92.425%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.088 Acc 97.178%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.090 Acc 97.116%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.090 Acc 97.120%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.090 Acc 97.103%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.437 Acc 89.844%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.473 Acc 88.885%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.465 Acc 89.082%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.087 Acc 97.233%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.088 Acc 97.199%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.087 Acc 97.165%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.089 Acc 97.096%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.411 Acc 92.188%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.387 Acc 91.530%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.384 Acc 91.569%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.087 Acc 97.213%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.091 Acc 97.111%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.091 Acc 97.107%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.092 Acc 97.076%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.383 Acc 90.903%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.379 Acc 91.134%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.087 Acc 97.192%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.083 Acc 97.244%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.088 Acc 97.127%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.088 Acc 97.161%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.088 Acc 97.139%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.323 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.323 Acc 92.644%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.320 Acc 92.743%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.134 Acc 94.531%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.078 Acc 97.362%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.081 Acc 97.295%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.086 Acc 97.119%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.086 Acc 97.132%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.088 Acc 97.081%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.391 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.397 Acc 90.664%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.390 Acc 90.691%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.084 Acc 97.262%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.084 Acc 97.265%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.086 Acc 97.209%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.317 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.332 Acc 92.845%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.328 Acc 92.903%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.086 Acc 97.138%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.084 Acc 97.271%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.088 Acc 97.171%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.089 Acc 97.128%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.090 Acc 97.118%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.507 Acc 89.062%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.524 Acc 88.730%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.521 Acc 88.950%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.086 Acc 97.068%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.088 Acc 97.170%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.089 Acc 97.098%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.089 Acc 97.074%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.091 Acc 97.020%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.349 Acc 92.969%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.370 Acc 91.600%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.365 Acc 91.869%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.086 Acc 97.285%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.086 Acc 97.283%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.089 Acc 97.202%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.088 Acc 97.228%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.088 Acc 97.213%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.382 Acc 90.625%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.357 Acc 91.855%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.351 Acc 91.958%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.094 Acc 96.960%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.086 Acc 97.174%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.085 Acc 97.155%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.085 Acc 97.173%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.086 Acc 97.140%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.361 Acc 91.406%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.320 Acc 92.551%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.318 Acc 92.724%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.086 Acc 97.306%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.085 Acc 97.316%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.087 Acc 97.255%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.086 Acc 97.299%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.387 Acc 92.188%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.381 Acc 91.832%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.376 Acc 91.896%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.077 Acc 97.401%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.080 Acc 97.404%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.083 Acc 97.334%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.086 Acc 97.224%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.088 Acc 97.148%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.330 Acc 90.625%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.362 Acc 91.979%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.351 Acc 92.230%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.081 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.084 Acc 97.231%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.085 Acc 97.236%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.085 Acc 97.225%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.085 Acc 97.243%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.088 Acc 97.196%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.461 Acc 90.625%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.523 Acc 87.353%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.520 Acc 87.247%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.082 Acc 97.316%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.085 Acc 97.236%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.085 Acc 97.207%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.088 Acc 97.120%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.088 Acc 97.095%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.354 Acc 91.406%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.360 Acc 92.079%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.356 Acc 91.954%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.077 Acc 97.517%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.081 Acc 97.392%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.079 Acc 97.423%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.079 Acc 97.440%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.083 Acc 97.344%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.266 Acc 92.188%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.286 Acc 93.549%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.284 Acc 93.416%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.079 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.079 Acc 97.432%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.083 Acc 97.295%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.084 Acc 97.280%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.083 Acc 97.309%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.084 Acc 97.284%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.441 Acc 87.500%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.418 Acc 90.300%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.411 Acc 90.559%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.076 Acc 97.432%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.080 Acc 97.419%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.084 Acc 97.306%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.086 Acc 97.245%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.086 Acc 97.251%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.346 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.396 Acc 90.733%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.391 Acc 90.913%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.077 Acc 97.396%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.080 Acc 97.355%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.084 Acc 97.261%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.085 Acc 97.266%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.477 Acc 90.625%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.412 Acc 90.277%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.411 Acc 90.454%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.082 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.083 Acc 97.308%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.085 Acc 97.244%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.086 Acc 97.210%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.087 Acc 97.191%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.086 Acc 97.190%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.290 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.303 Acc 92.992%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.301 Acc 92.961%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.080 Acc 97.509%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.080 Acc 97.470%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.078 Acc 97.480%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.079 Acc 97.450%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.081 Acc 97.427%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.388 Acc 89.844%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.358 Acc 92.110%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.353 Acc 92.020%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.070 Acc 97.757%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.077 Acc 97.520%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.081 Acc 97.374%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.082 Acc 97.358%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.360 Acc 91.406%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.366 Acc 91.399%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.361 Acc 91.709%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.085 Acc 97.208%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.080 Acc 97.369%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.083 Acc 97.343%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.083 Acc 97.321%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.409 Acc 92.969%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.376 Acc 90.811%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.368 Acc 91.099%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.079 Acc 97.308%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.077 Acc 97.349%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.082 Acc 97.295%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.083 Acc 97.300%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.084 Acc 97.255%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.417 Acc 91.406%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.364 Acc 92.025%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.360 Acc 92.067%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.081 Acc 97.416%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.079 Acc 97.458%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.080 Acc 97.443%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.084 Acc 97.313%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.084 Acc 97.340%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.311 Acc 90.625%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.329 Acc 91.855%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.326 Acc 91.985%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.081 Acc 97.369%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.083 Acc 97.257%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.085 Acc 97.257%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.084 Acc 97.293%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.417 Acc 92.188%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.395 Acc 91.236%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.391 Acc 91.367%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.079 Acc 97.462%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.078 Acc 97.532%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.080 Acc 97.430%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.081 Acc 97.380%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.356 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.378 Acc 91.692%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.372 Acc 91.869%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.078 Acc 97.316%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.077 Acc 97.427%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.077 Acc 97.438%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.078 Acc 97.399%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.079 Acc 97.358%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.389 Acc 92.188%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.430 Acc 89.496%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.424 Acc 89.871%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.067 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.072 Acc 97.741%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.076 Acc 97.571%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.082 Acc 97.368%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.082 Acc 97.399%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.082 Acc 97.366%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.391 Acc 90.625%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.366 Acc 91.894%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.363 Acc 91.970%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.077 Acc 97.486%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.079 Acc 97.462%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.081 Acc 97.433%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.082 Acc 97.407%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.085 Acc 97.319%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.385 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.389 Acc 91.553%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.385 Acc 91.725%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.077 Acc 97.516%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.076 Acc 97.522%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.078 Acc 97.457%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.285 Acc 93.750%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.311 Acc 92.907%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.307 Acc 93.070%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.075 Acc 97.548%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.078 Acc 97.442%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.080 Acc 97.402%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.080 Acc 97.395%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.081 Acc 97.371%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.379 Acc 91.406%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.389 Acc 91.515%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.384 Acc 91.632%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.080 Acc 96.094%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.074 Acc 97.447%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.077 Acc 97.388%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.077 Acc 97.410%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.079 Acc 97.372%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.079 Acc 97.424%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.298 Acc 92.188%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.320 Acc 92.064%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.313 Acc 92.238%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.078 Acc 97.370%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.080 Acc 97.306%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.082 Acc 97.363%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.081 Acc 97.377%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.572 Acc 85.156%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.530 Acc 88.498%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.523 Acc 88.526%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.078 Acc 97.331%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.079 Acc 97.380%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.078 Acc 97.449%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.079 Acc 97.421%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.079 Acc 97.427%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.365 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.368 Acc 91.778%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.365 Acc 91.803%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.076 Acc 97.509%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.075 Acc 97.450%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.078 Acc 97.373%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.076 Acc 97.421%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.078 Acc 97.402%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.467 Acc 89.062%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.447 Acc 90.331%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.445 Acc 90.590%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.076 Acc 97.618%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.079 Acc 97.498%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.079 Acc 97.483%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.079 Acc 97.461%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.328 Acc 92.450%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.326 Acc 92.456%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.075 Acc 97.587%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.080 Acc 97.361%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.078 Acc 97.358%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.081 Acc 97.345%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.080 Acc 97.355%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.354 Acc 90.625%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.415 Acc 89.813%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.410 Acc 89.960%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.077 Acc 97.567%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.079 Acc 97.485%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.078 Acc 97.504%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.078 Acc 97.458%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.385 Acc 91.406%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.422 Acc 90.478%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.420 Acc 90.516%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.078 Acc 97.393%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.078 Acc 97.458%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.079 Acc 97.428%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.080 Acc 97.383%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.398 Acc 89.844%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.405 Acc 90.617%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.400 Acc 90.691%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.077 Acc 97.497%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.078 Acc 97.454%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.077 Acc 97.461%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.077 Acc 97.460%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.290 Acc 92.188%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.317 Acc 92.427%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.314 Acc 92.428%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.078 Acc 97.454%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.077 Acc 97.449%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.080 Acc 97.415%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.081 Acc 97.358%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.392 Acc 89.844%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.400 Acc 91.043%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.398 Acc 91.192%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.077 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.066 Acc 97.780%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.071 Acc 97.672%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.072 Acc 97.613%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.075 Acc 97.544%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.342 Acc 92.528%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.338 Acc 92.440%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.068 Acc 97.687%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.074 Acc 97.512%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.072 Acc 97.555%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.072 Acc 97.588%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.073 Acc 97.594%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.380 Acc 90.625%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.354 Acc 92.141%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.348 Acc 92.281%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.079 Acc 97.455%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.075 Acc 97.645%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.074 Acc 97.638%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.075 Acc 97.600%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.077 Acc 97.561%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.362 Acc 91.406%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.367 Acc 91.128%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.361 Acc 91.367%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.084 Acc 97.246%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.081 Acc 97.427%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.080 Acc 97.506%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.078 Acc 97.520%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.078 Acc 97.505%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.306 Acc 92.930%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.301 Acc 92.926%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.079 Acc 97.494%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.076 Acc 97.551%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.075 Acc 97.588%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.075 Acc 97.535%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.329 Acc 92.188%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.327 Acc 92.574%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.325 Acc 92.607%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.075 Acc 97.610%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.075 Acc 97.563%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.078 Acc 97.506%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.079 Acc 97.463%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.330 Acc 93.750%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.340 Acc 92.489%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.336 Acc 92.460%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.076 Acc 97.525%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.074 Acc 97.586%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.077 Acc 97.529%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.079 Acc 97.438%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.078 Acc 97.472%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.344 Acc 90.625%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.323 Acc 92.458%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.319 Acc 92.428%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.028 Acc 97.656%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.073 Acc 97.749%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.073 Acc 97.612%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.075 Acc 97.532%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.075 Acc 97.503%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.300 Acc 92.969%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.297 Acc 92.512%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.289 Acc 92.693%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.069 Acc 97.888%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.072 Acc 97.785%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.073 Acc 97.698%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.074 Acc 97.666%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.362 Acc 89.844%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.309 Acc 92.528%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.306 Acc 92.491%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.074 Acc 97.563%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.073 Acc 97.664%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.076 Acc 97.547%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.075 Acc 97.570%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.343 Acc 90.625%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.379 Acc 91.004%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.373 Acc 91.181%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.070 Acc 97.633%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.070 Acc 97.695%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.071 Acc 97.668%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.072 Acc 97.661%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.380 Acc 89.844%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.389 Acc 90.911%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.382 Acc 91.025%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.080 Acc 97.347%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.083 Acc 97.271%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.079 Acc 97.415%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.078 Acc 97.426%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.077 Acc 97.446%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.420 Acc 91.406%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.416 Acc 90.950%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.413 Acc 90.874%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.063 Acc 97.989%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.062 Acc 97.944%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.067 Acc 97.835%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.070 Acc 97.736%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.438 Acc 90.625%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.402 Acc 90.563%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.397 Acc 90.676%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.072 Acc 97.679%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.075 Acc 97.582%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.073 Acc 97.620%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.073 Acc 97.639%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.073 Acc 97.631%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.341 Acc 92.969%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.314 Acc 92.868%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.312 Acc 92.755%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.072 Acc 97.587%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.067 Acc 97.691%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.070 Acc 97.612%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.071 Acc 97.586%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.072 Acc 97.603%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.494 Acc 89.062%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.479 Acc 88.181%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.476 Acc 88.305%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.069 Acc 97.788%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.075 Acc 97.516%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.077 Acc 97.450%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.076 Acc 97.471%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.297 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.299 Acc 92.412%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.298 Acc 92.514%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.076 Acc 97.409%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.074 Acc 97.547%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.075 Acc 97.552%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.076 Acc 97.535%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.076 Acc 97.513%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.358 Acc 92.969%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.358 Acc 91.453%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.356 Acc 91.558%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.070 Acc 97.772%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.070 Acc 97.668%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.072 Acc 97.597%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.073 Acc 97.555%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.073 Acc 97.567%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.370 Acc 89.062%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.398 Acc 90.517%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.395 Acc 90.555%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.074 Acc 97.455%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.070 Acc 97.660%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.074 Acc 97.547%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.076 Acc 97.489%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.075 Acc 97.483%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.477 Acc 89.062%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.478 Acc 88.722%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.469 Acc 88.981%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.059 Acc 97.888%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.065 Acc 97.905%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.065 Acc 97.903%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.069 Acc 97.703%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.071 Acc 97.673%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.433 Acc 88.281%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.410 Acc 90.439%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.404 Acc 90.470%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.069 Acc 97.755%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.070 Acc 97.738%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.070 Acc 97.728%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.335 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.343 Acc 91.855%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.338 Acc 91.935%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.057 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.070 Acc 97.556%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.068 Acc 97.648%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.070 Acc 97.643%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.071 Acc 97.606%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.072 Acc 97.597%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.424 Acc 91.406%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.427 Acc 90.316%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.422 Acc 90.435%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.065 Acc 97.834%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.066 Acc 97.800%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.068 Acc 97.690%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.071 Acc 97.584%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.072 Acc 97.580%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.345 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.403 Acc 90.710%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.400 Acc 90.777%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.070 Acc 97.757%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.067 Acc 97.718%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.069 Acc 97.633%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.069 Acc 97.647%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.069 Acc 97.661%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.249 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.291 Acc 92.984%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.288 Acc 93.050%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.064 Acc 97.757%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.066 Acc 97.742%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.069 Acc 97.625%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.071 Acc 97.563%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.073 Acc 97.539%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.355 Acc 90.625%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.368 Acc 91.174%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.365 Acc 91.492%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.079 Acc 97.355%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.073 Acc 97.565%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.073 Acc 97.578%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.073 Acc 97.600%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.386 Acc 91.406%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.359 Acc 91.917%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.353 Acc 91.915%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.069 Acc 97.834%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.073 Acc 97.641%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.072 Acc 97.646%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.069 Acc 97.730%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.070 Acc 97.658%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.518 Acc 87.500%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.492 Acc 89.279%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.491 Acc 89.144%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.072 Acc 97.660%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.073 Acc 97.633%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.073 Acc 97.596%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.073 Acc 97.645%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.373 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.320 Acc 92.721%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.314 Acc 92.786%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.070 Acc 97.800%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.069 Acc 97.825%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.072 Acc 97.700%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.298 Acc 93.363%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.291 Acc 93.342%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.061 Acc 97.904%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.061 Acc 97.967%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.063 Acc 97.898%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.065 Acc 97.851%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.065 Acc 97.843%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.460 Acc 89.844%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.431 Acc 90.989%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.427 Acc 91.080%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.072 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.068 Acc 97.808%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.068 Acc 97.830%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.067 Acc 97.818%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.069 Acc 97.723%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.439 Acc 89.062%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.392 Acc 91.321%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.389 Acc 91.383%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.076 Acc 97.424%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.073 Acc 97.637%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.075 Acc 97.617%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.073 Acc 97.639%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.073 Acc 97.617%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.422 Acc 91.406%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.391 Acc 91.190%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.388 Acc 91.165%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.064 Acc 97.795%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.066 Acc 97.726%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.068 Acc 97.659%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.068 Acc 97.687%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.069 Acc 97.658%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.419 Acc 90.625%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.392 Acc 91.197%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.390 Acc 91.185%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.065 Acc 97.803%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.065 Acc 97.870%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.068 Acc 97.778%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.068 Acc 97.756%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.068 Acc 97.781%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.336 Acc 91.406%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.353 Acc 92.087%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.346 Acc 92.215%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.068 Acc 97.726%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.069 Acc 97.737%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.070 Acc 97.680%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.070 Acc 97.681%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.363 Acc 90.625%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.377 Acc 91.174%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.373 Acc 91.274%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.061 Acc 97.942%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.062 Acc 97.983%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.064 Acc 97.913%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.067 Acc 97.845%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.337 Acc 92.188%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.348 Acc 92.041%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.346 Acc 91.985%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.063 Acc 98.113%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.069 Acc 97.831%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.069 Acc 97.787%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.070 Acc 97.736%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.355 Acc 93.750%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.396 Acc 91.499%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.390 Acc 91.597%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.070 Acc 97.668%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.070 Acc 97.682%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.070 Acc 97.691%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.070 Acc 97.697%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.365 Acc 89.062%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.387 Acc 91.298%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.382 Acc 91.519%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.068 Acc 97.788%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.070 Acc 97.648%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.070 Acc 97.620%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.070 Acc 97.662%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.070 Acc 97.672%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.335 Acc 89.844%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.351 Acc 91.932%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.342 Acc 91.888%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.062 Acc 98.058%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.068 Acc 97.750%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.070 Acc 97.680%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.071 Acc 97.662%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.475 Acc 87.500%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.482 Acc 89.101%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.481 Acc 89.257%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.061 Acc 97.896%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.065 Acc 97.843%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.067 Acc 97.781%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.067 Acc 97.798%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.066 Acc 97.806%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.356 Acc 91.538%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.350 Acc 91.651%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.063 Acc 98.012%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.066 Acc 97.843%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.065 Acc 97.843%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.065 Acc 97.845%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.066 Acc 97.831%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.419 Acc 89.062%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.421 Acc 90.138%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.414 Acc 90.431%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.059 Acc 98.028%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.058 Acc 98.099%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.061 Acc 97.988%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.064 Acc 97.933%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.064 Acc 97.907%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.343 Acc 92.188%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.353 Acc 92.273%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.349 Acc 92.230%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.064 Acc 98.035%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.065 Acc 97.936%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.066 Acc 97.877%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.067 Acc 97.867%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.068 Acc 97.801%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.371 Acc 90.625%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.405 Acc 90.463%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.400 Acc 90.714%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.061 Acc 97.850%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.060 Acc 97.952%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.062 Acc 97.937%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.061 Acc 97.978%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.064 Acc 97.923%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.424 Acc 90.625%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.363 Acc 91.592%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.359 Acc 91.807%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.213 Acc 94.531%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.066 Acc 97.927%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.068 Acc 97.812%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.066 Acc 97.848%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.068 Acc 97.763%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.068 Acc 97.769%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.424 Acc 90.625%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.349 Acc 91.832%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.346 Acc 91.877%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.066 Acc 97.950%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.068 Acc 97.886%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.067 Acc 97.841%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.068 Acc 97.808%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.067 Acc 97.820%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.403 Acc 90.625%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.420 Acc 89.921%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.415 Acc 89.964%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.063 Acc 97.912%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.068 Acc 97.816%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.067 Acc 97.830%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.066 Acc 97.839%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.067 Acc 97.787%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.393 Acc 88.281%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.391 Acc 90.068%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.383 Acc 90.427%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.069 Acc 97.703%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.064 Acc 97.892%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.066 Acc 97.878%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.065 Acc 97.882%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.430 Acc 89.062%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.340 Acc 91.754%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.334 Acc 91.904%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.159 Acc 96.094%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.067 Acc 97.718%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.064 Acc 97.874%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.065 Acc 97.864%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.065 Acc 97.830%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.064 Acc 97.900%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.427 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.395 Acc 90.718%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.390 Acc 90.808%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.066 Acc 97.772%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.069 Acc 97.827%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.067 Acc 97.916%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.068 Acc 97.834%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.070 Acc 97.770%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.349 Acc 90.625%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.362 Acc 91.615%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.352 Acc 91.795%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.059 Acc 98.060%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.064 Acc 97.884%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.066 Acc 97.825%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.419 Acc 92.188%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.358 Acc 92.002%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.350 Acc 91.954%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.064 Acc 97.834%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.061 Acc 97.975%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.064 Acc 97.952%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.065 Acc 97.917%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.064 Acc 97.921%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.343 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.330 Acc 92.536%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.324 Acc 92.720%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.051%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.062 Acc 97.936%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.063 Acc 97.916%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.062 Acc 97.906%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.063 Acc 97.885%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.298 Acc 92.969%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.372 Acc 90.981%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.366 Acc 91.220%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.065 Acc 97.935%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.063 Acc 97.998%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.063 Acc 97.963%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.064 Acc 97.941%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.065 Acc 97.893%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.468 Acc 87.500%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.459 Acc 90.207%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.448 Acc 90.345%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.057 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.065 Acc 97.857%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.062 Acc 97.901%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.064 Acc 97.879%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.328 Acc 92.188%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.327 Acc 92.613%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.321 Acc 92.553%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7182ba086a1347cb8025eb0c928105cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.305 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 3.068 Acc 15.934%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.657 Acc 17.211%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.516 Acc 17.943%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.446 Acc 18.191%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.404 Acc 18.335%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.196 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.213 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.214 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.292 Acc 14.844%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.229 Acc 18.943%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.221 Acc 18.972%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.146 Acc 22.314%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.971 Acc 29.489%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.781 Acc 36.940%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.928 Acc 73.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.863 Acc 72.223%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.857 Acc 72.252%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.735 Acc 76.562%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.647 Acc 79.780%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.589 Acc 81.685%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.550 Acc 82.903%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.524 Acc 83.765%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.504 Acc 84.398%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.570 Acc 83.594%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.486 Acc 84.901%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.477 Acc 85.102%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.398 Acc 87.740%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.380 Acc 88.371%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.375 Acc 88.637%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.373 Acc 88.681%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.374 Acc 88.680%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.426 Acc 86.719%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.351 Acc 89.349%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.344 Acc 89.626%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.411 Acc 83.594%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.328 Acc 89.728%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.333 Acc 89.883%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.333 Acc 89.839%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.334 Acc 89.891%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.333 Acc 90.004%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.441 Acc 89.844%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.366 Acc 90.942%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.363 Acc 91.072%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.310 Acc 90.610%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.306 Acc 90.668%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.309 Acc 90.558%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.309 Acc 90.641%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.308 Acc 90.706%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.546 Acc 82.031%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.467 Acc 85.218%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.459 Acc 85.483%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.466 Acc 90.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.290 Acc 91.515%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.287 Acc 91.527%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.295 Acc 91.331%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.300 Acc 91.149%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.298 Acc 91.199%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.330 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.312 Acc 92.837%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.307 Acc 93.101%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.321 Acc 92.188%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.290 Acc 91.437%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.286 Acc 91.500%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.282 Acc 91.604%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.279 Acc 91.683%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.281 Acc 91.653%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.271 Acc 89.844%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.281 Acc 92.489%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.279 Acc 92.576%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.284 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.269 Acc 91.971%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.265 Acc 92.153%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.273 Acc 91.928%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.270 Acc 92.045%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.272 Acc 92.033%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.331 Acc 87.500%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.308 Acc 92.126%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.303 Acc 92.312%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.209 Acc 92.969%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.264 Acc 92.025%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.259 Acc 92.324%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.259 Acc 92.322%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.260 Acc 92.357%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.263 Acc 92.300%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.365 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.310 Acc 91.979%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.305 Acc 92.277%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.272 Acc 92.188%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.253 Acc 92.698%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.256 Acc 92.572%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.257 Acc 92.457%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.260 Acc 92.412%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.262 Acc 92.361%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.227 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.266 Acc 92.667%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.258 Acc 92.938%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.290 Acc 93.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.260 Acc 92.853%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.261 Acc 92.413%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.257 Acc 92.447%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.255 Acc 92.538%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.255 Acc 92.546%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.313 Acc 92.404%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.307 Acc 92.631%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.236 Acc 93.054%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.242 Acc 92.980%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.246 Acc 92.813%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.251 Acc 92.700%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.252 Acc 92.679%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.414 Acc 88.281%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.364 Acc 89.148%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.356 Acc 89.269%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.384 Acc 91.406%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.252 Acc 92.737%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.242 Acc 93.070%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.241 Acc 93.156%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.241 Acc 93.142%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.241 Acc 93.058%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.323 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.307 Acc 91.437%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.302 Acc 91.639%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.232 Acc 93.317%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.233 Acc 93.272%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.235 Acc 93.187%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.235 Acc 93.187%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.235 Acc 93.207%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.396 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.349 Acc 92.311%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.342 Acc 92.627%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.228 Acc 93.680%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.237 Acc 93.210%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.236 Acc 93.278%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.236 Acc 93.280%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.233 Acc 93.309%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.353 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.375 Acc 91.955%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.369 Acc 92.226%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.315 Acc 86.719%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.208 Acc 93.912%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.215 Acc 93.762%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.219 Acc 93.607%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.226 Acc 93.577%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.226 Acc 93.555%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.521 Acc 90.625%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.486 Acc 91.708%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.483 Acc 91.842%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.216 Acc 93.750%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.212 Acc 93.990%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.207 Acc 93.995%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.215 Acc 93.825%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.216 Acc 93.777%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.216 Acc 93.811%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.377 Acc 85.938%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.348 Acc 90.989%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.343 Acc 91.146%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.135 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.216 Acc 94.028%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.212 Acc 94.100%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.213 Acc 94.033%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.213 Acc 93.988%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.214 Acc 93.943%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.278 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.260 Acc 94.152%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.256 Acc 94.286%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.165 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.210 Acc 94.005%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.211 Acc 94.065%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.212 Acc 93.978%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.212 Acc 93.955%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.213 Acc 93.931%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.307 Acc 89.062%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.275 Acc 93.317%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.273 Acc 93.155%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.220 Acc 91.406%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.195 Acc 94.477%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.198 Acc 94.185%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.199 Acc 94.145%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.205 Acc 94.071%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.205 Acc 94.109%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.253 Acc 93.889%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.247 Acc 94.018%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.112 Acc 94.531%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.192 Acc 94.353%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.197 Acc 94.224%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.201 Acc 94.186%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.202 Acc 94.202%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.201 Acc 94.221%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.326 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.280 Acc 92.830%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.272 Acc 93.183%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.179 Acc 94.632%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.183 Acc 94.764%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.191 Acc 94.583%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.194 Acc 94.562%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.198 Acc 94.491%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.247 Acc 93.727%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.244 Acc 93.913%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.199 Acc 94.253%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.192 Acc 94.582%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.192 Acc 94.573%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.194 Acc 94.465%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.194 Acc 94.497%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.360 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.359 Acc 93.015%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.354 Acc 93.155%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.181 Acc 95.057%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.178 Acc 95.005%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.185 Acc 94.788%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.189 Acc 94.714%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.189 Acc 94.711%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.300 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.278 Acc 94.021%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.273 Acc 93.987%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.215 Acc 92.969%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.171 Acc 94.910%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.175 Acc 94.932%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.181 Acc 94.817%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.184 Acc 94.714%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.186 Acc 94.633%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.245 Acc 94.052%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.239 Acc 94.228%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.174 Acc 95.019%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.178 Acc 94.963%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.181 Acc 94.845%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.183 Acc 94.839%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.187 Acc 94.729%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.270 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.247 Acc 94.508%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.240 Acc 94.792%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.226 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.183 Acc 94.980%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.178 Acc 95.044%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.180 Acc 94.957%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.181 Acc 94.903%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.179 Acc 94.966%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.237 Acc 93.804%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.232 Acc 93.905%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.174 Acc 95.150%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.172 Acc 95.064%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.174 Acc 95.092%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.174 Acc 95.079%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.174 Acc 95.079%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.226 Acc 94.833%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.223 Acc 94.683%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.162 Acc 95.351%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.170 Acc 95.209%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.169 Acc 95.221%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.171 Acc 95.183%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.290 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.282 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.278 Acc 93.116%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.169 Acc 95.343%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.164 Acc 95.359%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.169 Acc 95.203%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.168 Acc 95.188%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.203 Acc 94.477%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.197 Acc 94.741%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.169 Acc 95.398%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.162 Acc 95.476%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.160 Acc 95.546%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.163 Acc 95.416%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.166 Acc 95.305%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.232 Acc 94.415%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.227 Acc 94.457%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.152 Acc 95.730%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.154 Acc 95.674%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.155 Acc 95.629%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.157 Acc 95.556%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.160 Acc 95.448%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.249 Acc 96.094%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.265 Acc 93.858%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.261 Acc 93.952%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.150 Acc 95.761%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.158 Acc 95.588%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.161 Acc 95.512%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.158 Acc 95.583%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.159 Acc 95.464%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.223 Acc 95.135%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.217 Acc 95.332%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.116 Acc 94.531%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.157 Acc 95.498%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.158 Acc 95.456%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.156 Acc 95.567%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.155 Acc 95.607%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.157 Acc 95.501%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.263 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.272 Acc 94.206%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.268 Acc 94.259%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.154 Acc 95.668%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.153 Acc 95.565%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.154 Acc 95.551%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.157 Acc 95.463%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.160 Acc 95.412%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.221 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.203 Acc 95.111%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.197 Acc 95.316%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.149 Acc 95.862%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.152 Acc 95.763%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.151 Acc 95.764%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.153 Acc 95.720%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.155 Acc 95.642%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.204 Acc 95.312%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.249 Acc 94.438%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.247 Acc 94.512%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.199 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.151 Acc 95.838%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.147 Acc 95.771%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.145 Acc 95.795%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.144 Acc 95.819%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.145 Acc 95.777%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.276 Acc 92.188%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.236 Acc 93.781%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.233 Acc 93.781%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.141 Acc 95.668%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.142 Acc 95.752%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.147 Acc 95.710%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.147 Acc 95.720%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.146 Acc 95.723%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.205 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.223 Acc 94.578%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.219 Acc 94.776%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.130 Acc 96.310%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.135 Acc 96.152%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.141 Acc 95.956%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.145 Acc 95.877%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.145 Acc 95.872%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.240 Acc 94.539%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.236 Acc 94.446%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.151 Acc 95.668%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.146 Acc 95.787%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.139 Acc 95.961%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.142 Acc 95.866%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.142 Acc 95.843%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.217 Acc 94.578%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.214 Acc 94.593%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.136 Acc 95.877%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.137 Acc 95.946%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.140 Acc 95.829%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.143 Acc 95.821%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.142 Acc 95.874%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.182 Acc 96.875%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.225 Acc 94.624%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.219 Acc 94.834%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.165 Acc 92.969%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.138 Acc 95.857%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.140 Acc 95.860%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.141 Acc 95.846%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.140 Acc 95.858%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.215 Acc 95.444%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.208 Acc 95.538%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.138 Acc 95.955%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.139 Acc 95.923%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.142 Acc 95.878%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.141 Acc 95.967%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.142 Acc 95.911%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.206 Acc 94.872%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.200 Acc 94.967%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.129 Acc 96.426%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.139 Acc 95.956%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.139 Acc 95.975%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.139 Acc 96.010%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.211 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.213 Acc 94.825%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.209 Acc 94.846%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.126 Acc 96.233%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.128 Acc 96.199%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.130 Acc 96.187%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.134 Acc 96.107%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.134 Acc 96.123%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.188 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.238 Acc 94.547%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.230 Acc 94.562%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.163 Acc 96.094%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.130 Acc 96.214%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.130 Acc 96.231%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.132 Acc 96.183%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.132 Acc 96.169%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.193 Acc 95.050%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.188 Acc 95.153%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.099 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.131 Acc 96.310%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.132 Acc 96.179%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.135 Acc 96.031%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.134 Acc 96.108%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.211 Acc 94.446%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.205 Acc 94.578%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.123 Acc 96.241%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.122 Acc 96.339%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.124 Acc 96.364%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.124 Acc 96.345%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.127 Acc 96.279%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.208 Acc 95.104%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.199 Acc 95.211%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.121 Acc 96.426%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.124 Acc 96.304%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.124 Acc 96.317%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.124 Acc 96.312%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.124 Acc 96.343%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.207 Acc 96.094%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.262 Acc 94.384%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.255 Acc 94.481%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.115 Acc 96.597%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.122 Acc 96.288%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.123 Acc 96.325%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.122 Acc 96.357%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.124 Acc 96.318%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.215 Acc 95.034%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.211 Acc 94.982%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.113 Acc 96.589%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.116 Acc 96.537%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.121 Acc 96.418%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.124 Acc 96.308%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.124 Acc 96.290%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.244 Acc 94.779%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.239 Acc 94.854%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.060 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.116 Acc 96.607%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.115 Acc 96.519%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.117 Acc 96.442%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.120 Acc 96.392%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.277 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.303 Acc 93.982%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.295 Acc 94.154%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.106 Acc 96.604%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.111 Acc 96.716%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.116 Acc 96.567%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.115 Acc 96.602%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.298 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.279 Acc 94.469%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.274 Acc 94.496%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.120 Acc 96.473%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.121 Acc 96.397%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.118 Acc 96.499%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.117 Acc 96.493%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.118 Acc 96.512%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.185 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.218 Acc 95.150%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.212 Acc 95.204%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.221 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.109 Acc 96.666%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.117 Acc 96.401%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.117 Acc 96.413%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.120 Acc 96.347%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.122 Acc 96.300%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.233 Acc 94.570%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.230 Acc 94.625%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.110 Acc 96.739%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.111 Acc 96.714%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.115 Acc 96.583%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.199 Acc 96.875%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.218 Acc 94.640%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.213 Acc 94.694%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.100 Acc 96.937%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.105 Acc 96.832%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.111 Acc 96.724%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.114 Acc 96.630%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.116 Acc 96.572%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.268 Acc 93.851%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.265 Acc 93.937%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.111 Acc 96.607%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.112 Acc 96.604%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.112 Acc 96.590%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.242 Acc 94.152%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.233 Acc 94.251%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.058 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.102 Acc 96.894%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.104 Acc 96.805%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.107 Acc 96.768%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.109 Acc 96.749%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.253 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.290 Acc 93.673%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.284 Acc 93.793%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.106 Acc 96.728%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.102 Acc 96.836%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.103 Acc 96.849%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.105 Acc 96.830%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.107 Acc 96.724%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.220 Acc 94.957%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.214 Acc 95.060%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.116 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.099 Acc 97.045%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.108 Acc 96.807%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.108 Acc 96.785%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.220 Acc 94.446%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.213 Acc 94.737%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.105 Acc 96.852%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.107 Acc 96.852%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.107 Acc 96.869%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.280 Acc 89.844%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.281 Acc 93.912%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.276 Acc 94.127%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.175 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.102 Acc 97.030%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.103 Acc 96.935%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.106 Acc 96.857%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.109 Acc 96.725%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.287 Acc 92.188%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.256 Acc 94.245%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.249 Acc 94.259%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.101 Acc 96.689%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.108 Acc 96.537%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.108 Acc 96.631%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.110 Acc 96.633%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.107 Acc 96.688%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.371 Acc 90.625%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.287 Acc 93.843%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.284 Acc 93.929%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.094 Acc 97.092%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.103 Acc 96.896%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.105 Acc 96.754%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.105 Acc 96.775%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.239 Acc 91.406%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.227 Acc 94.663%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.221 Acc 94.807%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.092 Acc 97.169%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.100 Acc 96.887%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.102 Acc 96.865%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.104 Acc 96.817%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.104 Acc 96.791%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.225 Acc 94.547%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.220 Acc 94.597%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.096 Acc 97.053%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.103 Acc 96.878%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.105 Acc 96.824%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.107 Acc 96.780%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.254 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.259 Acc 94.090%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.252 Acc 94.232%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.094 Acc 97.153%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.097 Acc 97.034%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.095 Acc 97.101%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.099 Acc 96.964%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.190 Acc 93.750%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.221 Acc 94.686%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.212 Acc 94.873%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.093 Acc 97.076%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.091 Acc 97.174%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.101 Acc 96.933%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.101 Acc 96.906%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.240 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.239 Acc 94.052%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.232 Acc 94.224%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.123 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.103 Acc 96.829%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.101 Acc 96.848%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.103 Acc 96.805%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.103 Acc 96.830%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.102 Acc 96.870%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.254 Acc 94.075%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.250 Acc 94.189%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.091 Acc 97.248%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.093 Acc 97.137%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.097 Acc 97.043%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.266 Acc 94.160%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.263 Acc 94.240%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.096 Acc 97.061%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.097 Acc 97.058%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.096 Acc 97.129%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.096 Acc 97.113%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.099 Acc 96.990%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.222 Acc 96.875%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.256 Acc 93.781%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.245 Acc 93.975%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.089 Acc 97.308%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.095 Acc 96.992%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.098 Acc 96.932%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.097 Acc 96.969%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.097 Acc 97.012%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.208 Acc 95.204%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.200 Acc 95.340%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.092 Acc 97.192%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.090 Acc 97.240%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.093 Acc 97.202%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.095 Acc 97.136%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.095 Acc 97.112%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.253 Acc 93.502%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.248 Acc 93.641%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.089 Acc 97.184%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.094 Acc 96.972%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.098 Acc 96.885%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.100 Acc 96.826%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.099 Acc 96.859%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.234 Acc 92.969%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.252 Acc 94.701%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.246 Acc 94.803%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.092 Acc 97.030%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.089 Acc 97.155%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.092 Acc 97.082%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.093 Acc 97.023%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.310 Acc 92.969%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.328 Acc 92.822%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.322 Acc 92.907%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.087 Acc 97.269%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.091 Acc 97.155%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.095 Acc 97.076%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.098 Acc 96.947%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.227 Acc 91.406%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.247 Acc 94.114%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.239 Acc 94.201%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.083 Acc 97.246%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.083 Acc 97.279%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.087 Acc 97.173%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.088 Acc 97.150%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.091 Acc 97.064%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.236 Acc 94.655%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.230 Acc 94.636%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.085 Acc 97.525%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.087 Acc 97.345%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.092 Acc 97.191%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.092 Acc 97.185%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.203 Acc 90.625%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.234 Acc 94.299%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.225 Acc 94.512%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.089 Acc 97.269%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.088 Acc 97.287%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.090 Acc 97.262%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.089 Acc 97.282%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.092 Acc 97.173%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.268 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.245 Acc 94.400%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.237 Acc 94.535%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.094 Acc 97.073%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.093 Acc 97.103%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.094 Acc 97.126%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.094 Acc 97.084%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.228 Acc 94.740%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.223 Acc 94.796%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.084 Acc 97.440%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.086 Acc 97.415%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.089 Acc 97.303%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.089 Acc 97.294%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.091 Acc 97.226%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.262 Acc 94.168%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.254 Acc 94.251%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.086 Acc 97.115%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.088 Acc 97.100%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.089 Acc 97.129%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.089 Acc 97.152%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.349 Acc 90.625%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.312 Acc 93.007%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.307 Acc 93.151%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.075 Acc 97.687%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.082 Acc 97.431%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.083 Acc 97.381%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.087 Acc 97.278%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.090 Acc 97.199%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.230 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.266 Acc 94.067%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.260 Acc 94.216%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.087 Acc 97.300%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.085 Acc 97.341%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.087 Acc 97.249%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.088 Acc 97.233%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.088 Acc 97.245%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.259 Acc 94.261%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.254 Acc 94.298%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.083 Acc 97.361%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.086 Acc 97.263%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.086 Acc 97.262%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.259 Acc 92.188%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.274 Acc 94.121%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.267 Acc 94.178%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.083 Acc 97.392%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.085 Acc 97.334%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.088 Acc 97.259%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.088 Acc 97.240%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.242 Acc 94.291%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.236 Acc 94.368%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.085 Acc 97.215%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.086 Acc 97.287%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.089 Acc 97.194%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.091 Acc 97.185%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.092 Acc 97.165%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.229 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.243 Acc 94.175%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.234 Acc 94.333%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.091 Acc 97.208%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.086 Acc 97.209%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.089 Acc 97.194%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.087 Acc 97.237%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.088 Acc 97.248%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.275 Acc 94.052%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.268 Acc 94.205%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.073 Acc 97.610%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.080 Acc 97.446%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.081 Acc 97.385%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.082 Acc 97.391%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.251 Acc 93.967%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.242 Acc 94.325%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.083 Acc 97.556%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.078 Acc 97.660%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.081 Acc 97.539%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.082 Acc 97.477%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.084 Acc 97.376%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.247 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.282 Acc 93.680%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.272 Acc 93.828%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.083 Acc 97.262%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.086 Acc 97.271%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.086 Acc 97.262%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.087 Acc 97.274%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.086 Acc 97.271%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.227 Acc 94.694%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.215 Acc 94.854%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.087 Acc 97.161%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.084 Acc 97.330%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.086 Acc 97.292%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.086 Acc 97.280%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.222 Acc 92.969%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.265 Acc 94.253%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.259 Acc 94.271%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.081 Acc 97.409%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.079 Acc 97.407%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.082 Acc 97.334%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.082 Acc 97.352%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.082 Acc 97.380%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.319 Acc 92.188%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.306 Acc 93.170%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.299 Acc 93.264%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.079 Acc 97.415%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.080 Acc 97.495%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.083 Acc 97.450%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.233 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.304 Acc 93.085%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.294 Acc 93.221%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.075 Acc 97.424%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.078 Acc 97.516%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.079 Acc 97.498%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.083 Acc 97.372%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.082 Acc 97.405%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.230 Acc 91.406%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.279 Acc 93.386%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.267 Acc 93.560%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.087 Acc 97.192%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.084 Acc 97.355%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.084 Acc 97.323%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.084 Acc 97.338%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.244 Acc 92.188%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.279 Acc 94.044%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.271 Acc 94.096%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.073 Acc 97.711%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.077 Acc 97.569%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.080 Acc 97.489%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.234 Acc 94.392%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.228 Acc 94.477%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.074 Acc 97.730%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.076 Acc 97.659%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.080 Acc 97.520%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.080 Acc 97.499%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.262 Acc 88.281%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.262 Acc 93.595%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.252 Acc 93.851%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.074 Acc 97.579%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.078 Acc 97.520%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.079 Acc 97.443%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.197 Acc 94.531%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.261 Acc 93.928%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.251 Acc 94.135%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.072 Acc 97.649%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.076 Acc 97.555%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.078 Acc 97.493%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.080 Acc 97.463%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.081 Acc 97.439%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.275 Acc 93.170%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.267 Acc 93.458%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.075 Acc 97.641%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.076 Acc 97.558%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.252 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.235 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.227 Acc 94.628%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.070 Acc 97.812%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.071 Acc 97.794%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.073 Acc 97.719%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.075 Acc 97.627%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.249 Acc 93.851%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.240 Acc 94.158%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.075 Acc 97.638%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.076 Acc 97.611%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.077 Acc 97.555%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.149 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.239 Acc 94.291%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.230 Acc 94.523%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.079 Acc 97.440%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.081 Acc 97.450%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.079 Acc 97.493%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.079 Acc 97.489%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.079 Acc 97.493%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.217 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.239 Acc 94.423%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.229 Acc 94.430%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.063 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.071 Acc 97.803%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.075 Acc 97.563%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.075 Acc 97.552%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.075 Acc 97.582%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.077 Acc 97.485%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.240 Acc 93.943%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.233 Acc 94.119%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.068 Acc 97.842%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.070 Acc 97.785%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.073 Acc 97.721%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.075 Acc 97.691%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.076 Acc 97.684%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.270 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.280 Acc 93.472%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.274 Acc 93.672%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.067 Acc 97.850%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.071 Acc 97.715%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.073 Acc 97.589%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.075 Acc 97.553%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.077 Acc 97.536%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.252 Acc 94.191%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.243 Acc 94.395%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.094 Acc 97.022%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.085 Acc 97.299%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.081 Acc 97.433%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.080 Acc 97.475%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.219 Acc 91.406%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.247 Acc 93.758%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.238 Acc 94.053%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.071 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.071 Acc 97.532%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.072 Acc 97.590%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.072 Acc 97.599%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.075 Acc 97.535%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.075 Acc 97.544%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.220 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.254 Acc 93.696%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.249 Acc 93.921%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.071 Acc 97.695%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.073 Acc 97.677%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.072 Acc 97.662%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.072 Acc 97.659%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.268 Acc 94.531%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.263 Acc 93.959%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.252 Acc 94.135%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.075 Acc 97.842%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.077 Acc 97.672%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.074 Acc 97.726%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.073 Acc 97.713%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.075 Acc 97.672%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.289 Acc 92.188%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.283 Acc 93.626%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.272 Acc 93.797%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.072 Acc 97.772%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.076 Acc 97.565%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.076 Acc 97.547%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.076 Acc 97.578%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.270 Acc 91.406%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.286 Acc 93.394%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.280 Acc 93.544%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.071 Acc 97.587%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.069 Acc 97.750%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.070 Acc 97.742%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.071 Acc 97.748%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.071 Acc 97.717%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.228 Acc 92.188%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.222 Acc 94.554%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.214 Acc 94.764%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.064 Acc 97.873%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.074 Acc 97.597%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.077 Acc 97.541%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.077 Acc 97.531%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.237 Acc 94.028%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.232 Acc 94.216%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.067 Acc 97.826%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.073 Acc 97.602%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.072 Acc 97.669%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.070 Acc 97.745%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.291 Acc 92.188%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.279 Acc 93.518%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.273 Acc 93.723%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.072 Acc 97.734%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.073 Acc 97.683%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.071 Acc 97.755%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.071 Acc 97.730%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.071 Acc 97.723%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.269 Acc 93.634%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.261 Acc 93.874%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.072 Acc 97.679%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.075 Acc 97.536%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.074 Acc 97.560%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.073 Acc 97.582%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.074 Acc 97.549%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.202 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.233 Acc 94.570%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.226 Acc 94.726%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.067 Acc 97.695%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.071 Acc 97.648%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.072 Acc 97.620%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.074 Acc 97.600%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.075 Acc 97.600%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.238 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.270 Acc 93.495%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.265 Acc 93.571%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.078 Acc 97.618%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.075 Acc 97.746%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.074 Acc 97.750%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.073 Acc 97.722%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.073 Acc 97.714%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.223 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.260 Acc 93.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.254 Acc 93.952%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.036 Acc 97.656%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.068 Acc 97.780%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.256 Acc 92.188%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.282 Acc 93.255%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.275 Acc 93.381%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.086 Acc 97.370%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.077 Acc 97.582%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.074 Acc 97.659%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.074 Acc 97.703%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.074 Acc 97.672%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.279 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.285 Acc 93.495%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.278 Acc 93.742%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.064 Acc 98.089%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.067 Acc 97.878%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.065 Acc 97.921%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.067 Acc 97.855%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.067 Acc 97.857%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.238 Acc 94.361%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.231 Acc 94.500%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.061 Acc 97.973%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.063 Acc 98.057%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.066 Acc 97.918%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.068 Acc 97.857%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.068 Acc 97.832%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.217 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.274 Acc 93.023%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.267 Acc 93.167%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.068 Acc 97.870%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.069 Acc 97.856%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.070 Acc 97.793%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.071 Acc 97.804%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.249 Acc 93.905%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.245 Acc 93.937%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.063 Acc 97.935%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.062 Acc 98.006%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.060 Acc 98.085%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.059 Acc 98.104%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.062 Acc 98.029%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.278 Acc 93.572%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.272 Acc 93.719%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.070 Acc 97.919%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.071 Acc 97.761%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.072 Acc 97.750%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.074 Acc 97.717%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.074 Acc 97.695%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.245 Acc 94.531%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.224 Acc 94.593%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.218 Acc 94.702%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.067 Acc 97.877%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.068 Acc 97.851%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.070 Acc 97.801%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.271 Acc 93.425%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.264 Acc 93.493%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.071 Acc 97.765%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.068 Acc 97.846%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.074 Acc 97.650%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.237 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.258 Acc 93.912%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.246 Acc 94.123%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.065 Acc 97.950%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.063 Acc 98.018%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.067 Acc 97.882%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.071 Acc 97.756%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.069 Acc 97.803%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.241 Acc 94.338%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.233 Acc 94.419%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.067 Acc 97.726%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.069 Acc 97.707%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.068 Acc 97.806%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.250 Acc 94.199%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.240 Acc 94.407%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.057 Acc 98.182%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.064 Acc 97.948%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.069 Acc 97.776%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.068 Acc 97.802%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.069 Acc 97.772%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.200 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.241 Acc 94.245%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.236 Acc 94.298%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.060 Acc 98.159%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.068 Acc 97.901%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.068 Acc 97.856%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.069 Acc 97.832%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.069 Acc 97.809%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.268 Acc 93.858%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.263 Acc 94.003%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.071 Acc 97.664%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.069 Acc 97.792%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.069 Acc 97.820%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.067 Acc 97.876%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.066 Acc 97.895%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.267 Acc 93.472%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.257 Acc 93.707%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.114 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.073 Acc 97.672%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.073 Acc 97.625%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.070 Acc 97.716%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.071 Acc 97.759%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.261 Acc 93.472%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.255 Acc 93.711%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.067 Acc 97.896%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.069 Acc 97.893%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.068 Acc 97.916%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.067 Acc 97.931%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.068 Acc 97.903%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.239 Acc 94.175%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.232 Acc 94.360%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.065 Acc 97.850%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.067 Acc 97.804%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.067 Acc 97.832%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.066 Acc 97.850%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.238 Acc 94.199%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.231 Acc 94.352%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.058 Acc 98.136%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.064 Acc 97.967%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.064 Acc 97.916%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.066 Acc 97.843%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.066 Acc 97.868%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.342 Acc 90.625%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.299 Acc 93.193%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.292 Acc 93.357%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.063 Acc 97.865%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.064 Acc 97.847%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.067 Acc 97.729%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.067 Acc 97.728%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.068 Acc 97.730%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.187 Acc 92.188%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.238 Acc 94.431%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.233 Acc 94.508%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.064 Acc 97.811%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.063 Acc 97.866%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.063 Acc 97.921%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.063 Acc 97.898%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.064 Acc 97.929%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.247 Acc 92.969%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.274 Acc 93.394%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.268 Acc 93.431%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.139 Acc 97.656%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.068 Acc 97.850%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.068 Acc 97.831%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.067 Acc 97.877%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.068 Acc 97.869%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.068 Acc 97.879%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.227 Acc 94.670%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.225 Acc 94.683%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.070 Acc 97.649%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.069 Acc 97.769%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.068 Acc 97.791%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.067 Acc 97.828%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.066 Acc 97.845%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.264 Acc 93.974%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.258 Acc 93.995%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.055 Acc 98.058%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.065 Acc 97.913%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.064 Acc 97.892%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.064 Acc 97.896%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.067 Acc 97.823%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.269 Acc 93.735%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.263 Acc 93.719%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.062 Acc 98.043%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.065 Acc 97.994%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.065 Acc 97.937%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.066 Acc 97.931%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.068 Acc 97.867%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.270 Acc 93.703%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.073 Acc 96.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.059 Acc 98.105%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.061 Acc 98.068%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.063 Acc 98.038%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.061 Acc 98.044%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.063 Acc 98.026%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.224 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.269 Acc 93.502%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.262 Acc 93.552%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.056 Acc 98.089%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.062 Acc 97.983%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.064 Acc 97.916%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.068 Acc 97.857%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.068 Acc 97.826%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.272 Acc 93.943%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.264 Acc 93.944%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.041 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.063 Acc 98.051%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.067 Acc 97.870%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.065 Acc 97.885%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.063 Acc 97.943%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.064 Acc 97.909%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.333 Acc 92.188%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.282 Acc 93.317%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.279 Acc 93.458%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.063 Acc 97.973%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.064 Acc 97.991%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.061 Acc 98.038%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.064 Acc 97.964%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.065 Acc 97.900%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.377 Acc 90.625%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.289 Acc 92.775%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.280 Acc 92.930%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.056 Acc 98.120%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.057 Acc 98.111%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.060 Acc 97.994%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.063 Acc 97.882%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.065 Acc 97.864%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.253 Acc 93.851%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.245 Acc 94.092%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.062 Acc 98.057%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.063 Acc 97.978%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.062 Acc 98.003%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.062 Acc 98.040%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.270 Acc 93.448%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.267 Acc 93.501%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.059 Acc 98.151%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.065 Acc 97.979%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.065 Acc 97.921%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.066 Acc 97.919%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.067 Acc 97.892%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.305 Acc 93.116%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.296 Acc 93.198%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.064 Acc 97.857%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.062 Acc 97.889%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.063 Acc 97.900%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.063 Acc 97.931%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.064 Acc 97.896%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.244 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.251 Acc 93.765%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.244 Acc 94.014%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.138 Acc 92.969%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.054 Acc 98.352%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.055 Acc 98.290%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.057 Acc 98.183%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.059 Acc 98.085%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.060 Acc 98.046%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.245 Acc 92.969%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.247 Acc 94.137%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.239 Acc 94.282%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.056 Acc 98.198%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.055 Acc 98.200%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.059 Acc 98.069%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.062 Acc 97.993%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.261 Acc 93.727%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.252 Acc 93.731%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.065 Acc 97.942%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.068 Acc 97.835%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.069 Acc 97.833%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.067 Acc 97.892%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.067 Acc 97.876%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.280 Acc 92.188%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.268 Acc 93.479%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.263 Acc 93.703%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.058 Acc 98.012%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.062 Acc 98.029%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.061 Acc 98.033%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.063 Acc 98.005%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.064 Acc 97.999%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.244 Acc 94.152%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.237 Acc 94.248%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.053 Acc 98.345%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.057 Acc 98.165%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.060 Acc 98.053%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.060 Acc 98.063%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.059 Acc 98.098%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.239 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.263 Acc 93.557%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.257 Acc 93.773%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.062 Acc 97.989%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.066 Acc 97.882%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.065 Acc 97.874%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.066 Acc 97.882%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.065 Acc 97.928%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.260 Acc 93.433%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.253 Acc 93.703%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.058 Acc 97.997%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.059 Acc 98.088%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.062 Acc 97.999%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.062 Acc 98.006%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.313 Acc 92.969%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.262 Acc 93.680%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.260 Acc 93.630%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.053 Acc 98.252%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.057 Acc 98.103%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.057 Acc 98.110%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.060 Acc 98.005%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.061 Acc 97.998%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.199 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.228 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.222 Acc 94.469%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.061 Acc 98.043%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.062 Acc 97.979%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.063 Acc 97.937%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.061 Acc 98.045%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.303 Acc 94.531%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.251 Acc 94.075%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.248 Acc 94.127%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.050 Acc 98.407%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.056 Acc 98.193%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.057 Acc 98.178%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.059 Acc 98.118%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.059 Acc 98.091%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.243 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.269 Acc 93.673%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.261 Acc 93.711%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.059 Acc 98.144%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.058 Acc 98.208%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.059 Acc 98.129%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.059 Acc 98.100%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.061 Acc 98.048%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.257 Acc 92.188%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.269 Acc 93.518%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.264 Acc 93.579%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.113 Acc 94.531%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.064 Acc 97.865%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.062 Acc 97.924%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.064 Acc 97.910%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.063 Acc 97.937%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.337 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.278 Acc 93.472%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.270 Acc 93.606%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.020 Acc 98.438%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.054 Acc 98.260%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.056 Acc 98.197%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.057 Acc 98.188%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.058 Acc 98.145%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.059 Acc 98.094%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.215 Acc 92.188%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.253 Acc 94.369%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.244 Acc 94.364%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [100/573] Loss: 0.062 Acc 98.012%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.061 Acc 98.014%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.060 Acc 97.986%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.061 Acc 97.986%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.062 Acc 97.992%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.249 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.249 Acc 94.268%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.238 Acc 94.446%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.056 Acc 98.105%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.060 Acc 98.018%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.062 Acc 97.955%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.063 Acc 97.956%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.062 Acc 97.953%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.252 Acc 92.188%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.276 Acc 93.680%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.269 Acc 93.707%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.064 Acc 97.989%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.061 Acc 98.041%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.061 Acc 98.069%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.059 Acc 98.149%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.059 Acc 98.119%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.258 Acc 93.967%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.253 Acc 93.921%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.057 Acc 98.136%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.055 Acc 98.173%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.060 Acc 98.048%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.061 Acc 98.030%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.060 Acc 98.049%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.285 Acc 91.406%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.301 Acc 93.193%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.289 Acc 93.291%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.062 Acc 98.097%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.059 Acc 98.146%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.062 Acc 98.072%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.061 Acc 98.102%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.062 Acc 98.073%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.245 Acc 94.361%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.238 Acc 94.368%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.058 Acc 98.267%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.057 Acc 98.165%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.057 Acc 98.170%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.057 Acc 98.190%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.056 Acc 98.236%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.233 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.224 Acc 94.694%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.064 Acc 97.927%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.061 Acc 98.010%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.060 Acc 98.100%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.061 Acc 98.052%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.248 Acc 92.969%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.245 Acc 94.121%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.239 Acc 94.166%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.056 Acc 98.244%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.057 Acc 98.158%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.057 Acc 98.183%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.058 Acc 98.128%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.059 Acc 98.088%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.205 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.253 Acc 93.588%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.247 Acc 93.614%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.062 Acc 98.151%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.060 Acc 98.103%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.059 Acc 98.110%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.060 Acc 98.087%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.060 Acc 98.069%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.249 Acc 92.969%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.297 Acc 93.054%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.293 Acc 93.120%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.056 Acc 98.205%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.060 Acc 98.057%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.058 Acc 98.149%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.059 Acc 98.188%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.059 Acc 98.158%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.262 Acc 93.680%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.256 Acc 93.793%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.059 Acc 98.035%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.060 Acc 98.025%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.061 Acc 97.968%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.061 Acc 98.011%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.062 Acc 97.965%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.245 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.261 Acc 93.472%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.256 Acc 93.672%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.060 Acc 98.028%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.058 Acc 98.130%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.057 Acc 98.139%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.057 Acc 98.147%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.058 Acc 98.101%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.199 Acc 92.969%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.235 Acc 94.268%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.233 Acc 94.267%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.054 Acc 98.430%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.056 Acc 98.301%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.057 Acc 98.238%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.056 Acc 98.241%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.056 Acc 98.224%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.292 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.303 Acc 92.853%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.297 Acc 92.965%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.069 Acc 97.966%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.067 Acc 98.033%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.067 Acc 97.965%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.065 Acc 98.032%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.064 Acc 98.079%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.258 Acc 93.998%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.253 Acc 93.983%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.056 Acc 98.173%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.055 Acc 98.206%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.057 Acc 98.159%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.058 Acc 98.127%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.243 Acc 94.183%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.235 Acc 94.360%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.058 Acc 98.314%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [200/573] Loss: 0.053 Acc 98.356%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.056 Acc 98.269%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.057 Acc 98.231%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.058 Acc 98.190%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.388 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.358 Acc 91.468%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.355 Acc 91.612%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.053 Acc 98.314%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.053 Acc 98.270%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.053 Acc 98.274%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.055 Acc 98.213%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.056 Acc 98.186%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.228 Acc 90.625%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.263 Acc 93.959%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.256 Acc 94.104%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.058 Acc 98.097%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.059 Acc 98.095%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.058 Acc 98.108%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.057 Acc 98.116%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.058 Acc 98.115%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.245 Acc 94.446%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.240 Acc 94.403%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.061 Acc 98.128%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.060 Acc 98.134%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.060 Acc 98.123%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.060 Acc 98.110%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.060 Acc 98.093%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.244 Acc 94.237%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.237 Acc 94.317%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.067 Acc 97.989%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.058 Acc 98.127%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.059 Acc 98.116%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.059 Acc 98.118%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.060 Acc 98.090%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.252 Acc 93.835%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.244 Acc 93.964%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.062 Acc 98.051%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.062 Acc 98.025%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.059 Acc 98.136%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.060 Acc 98.104%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.061 Acc 98.071%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.294 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.275 Acc 93.533%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.270 Acc 93.707%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.057 Acc 98.082%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.059 Acc 98.084%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.057 Acc 98.110%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.060 Acc 98.071%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.058 Acc 98.129%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.253 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.253 Acc 94.230%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.244 Acc 94.279%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.161 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.058 Acc 98.205%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.056 Acc 98.212%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.061 Acc 98.131%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.060 Acc 98.106%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.060 Acc 98.098%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.306 Acc 91.406%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.269 Acc 93.920%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.260 Acc 94.088%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.049 Acc 98.468%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.054 Acc 98.344%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.054 Acc 98.323%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.054 Acc 98.323%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.056 Acc 98.246%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.249 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.244 Acc 94.044%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.237 Acc 94.158%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.040 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.048 Acc 98.345%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.056 Acc 98.193%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.056 Acc 98.178%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.057 Acc 98.143%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.055 Acc 98.230%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.232 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.272 Acc 93.588%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.266 Acc 93.505%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.052 Acc 98.182%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.055 Acc 98.158%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.056 Acc 98.121%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.057 Acc 98.089%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.060 Acc 98.054%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.275 Acc 89.844%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.295 Acc 93.046%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.284 Acc 93.249%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.044 Acc 98.646%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.049 Acc 98.504%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.049 Acc 98.463%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.051 Acc 98.422%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.053 Acc 98.339%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.257 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.246 Acc 93.995%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.058 Acc 98.113%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.057 Acc 98.181%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.054 Acc 98.292%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.055 Acc 98.287%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.056 Acc 98.229%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.252 Acc 94.392%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.244 Acc 94.465%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.051 Acc 98.391%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.050 Acc 98.418%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.051 Acc 98.373%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.052 Acc 98.350%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.054 Acc 98.275%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.223 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.257 Acc 93.820%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.251 Acc 94.049%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.164 Acc 96.094%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.059 Acc 98.291%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.059 Acc 98.208%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.060 Acc 98.165%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.059 Acc 98.171%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.060 Acc 98.146%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.273 Acc 90.625%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.254 Acc 94.175%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.244 Acc 94.349%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.092 Acc 95.312%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.054 Acc 98.236%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.055 Acc 98.212%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [300/573] Loss: 0.058 Acc 98.142%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.059 Acc 98.102%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.058 Acc 98.129%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.363 Acc 92.188%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.367 Acc 91.136%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.357 Acc 91.585%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.052 Acc 98.321%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.051 Acc 98.356%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.052 Acc 98.295%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.051 Acc 98.336%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.052 Acc 98.319%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.289 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.260 Acc 94.013%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.252 Acc 94.181%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.051 Acc 98.391%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.053 Acc 98.329%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.053 Acc 98.308%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.053 Acc 98.297%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.053 Acc 98.325%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.276 Acc 92.969%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.246 Acc 94.593%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.238 Acc 94.613%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.049 Acc 98.422%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.049 Acc 98.476%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.052 Acc 98.365%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.053 Acc 98.344%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.054 Acc 98.294%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.227 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.262 Acc 93.773%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.257 Acc 93.898%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0 \n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "for lr in tqdm_notebook(LRS):\n",
    "    for norm in tqdm_notebook(NORMS):\n",
    "        net =  WideResNet(depth=16, num_classes=10, widen_factor=2,dropout_rate=0.3,norm=norm).cuda()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "        train_loss_log =[]\n",
    "        train_acc_log = []\n",
    "        test_loss_log =[]\n",
    "        test_acc_log =[]\n",
    "\n",
    "        for epoch in tqdm_notebook(range(NUM_EPOCH)):\n",
    "            train(epoch)\n",
    "            test(epoch)\n",
    "\n",
    "        np.save(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr), train_loss_log)  \n",
    "        np.save(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr), test_loss_log)    \n",
    "        np.save(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr), train_acc_log)    \n",
    "        np.save(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr), test_acc_log)   \n",
    "        del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5347194af230473ab5047a320eae2c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582b9f273a3f4b619577340fcc547b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8218f280d914aef97efa22e6844f64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "LRS = [0.0001, 0.001]\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook([None,'BN', 'SN', 'MSN'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "        \n",
    "        ax = plt.subplot(2,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "                \n",
    "        ax = plt.subplot(2,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Act_Norm_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200c5d0e97cb4d4eb9874664e2843dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676c3ccd71dc492e9ecc4af6ad0699a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866d600a39fc421baefc29dbbe4bcf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook(['WN', 'SN', 'MSN'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "        \n",
    "        ax = plt.subplot(2,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "                \n",
    "        ax = plt.subplot(2,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Weight_reparam_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b85374c18df4eaf92075fce6e1991bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe4c8a0399c4237b2a92f0f033e12cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cc175141a64443be296cab2578e2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook(['MSNTReLU', 'WNTReLU'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "\n",
    "        ax = plt.subplot(2,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Weight_reparam_act_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Weight_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa01599f2701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWideResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiden_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'WN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Anand/NeuralBlocks/models/wresnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, depth, num_classes, widen_factor, dropout_rate, norm)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/models/wresnet.py\u001b[0m in \u001b[0;36m_wideLayer\u001b[0;34m(self, out_planes, num_blocks, dropout_rate, stride)\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         \u001b[0mout_planes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                         \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                         stride=stride, padding=1, norm=self.norm, conv_last=True))\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_planes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_planes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/resblock.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, norm, kernel_size, stride, padding, reflection_pad, dropout_rate, conv_last)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodules\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         modules.append(ConvNormRelu(in_channels, out_channels, norm=norm, kernel_size=kernel_size,\n\u001b[0;32m---> 13\u001b[0;31m                              stride=1, padding=padding, conv_last=conv_last))\n\u001b[0m\u001b[1;32m     14\u001b[0m         modules.append(ConvNorm(out_channels, out_channels, norm=norm, kernel_size=kernel_size,\n\u001b[1;32m     15\u001b[0m                              stride=stride, padding=padding, conv_last= conv_last))\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/convnormrelu.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, norm, groups_size, conv_last, act)\u001b[0m\n\u001b[1;32m     46\u001b[0m             conv2d = WeightNormConv2d(in_channels, out_channels, kernel_size,\n\u001b[1;32m     47\u001b[0m                                           \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                                           bias, padding_mode)\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MWN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/weightnorm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeightNormConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         self.conv = Weight_norm(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n\u001b[0m\u001b[1;32m     11\u001b[0m                               \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                               bias=bias, padding_mode=padding_mode))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Weight_norm' is not defined"
     ]
    }
   ],
   "source": [
    "WideResNet(depth=16, num_classes=10, widen_factor=2,dropout_rate=0.3,norm='WN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
