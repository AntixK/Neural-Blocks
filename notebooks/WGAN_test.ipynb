{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm_notebook\n",
    "PATH = '/home/antixk/Anand/' #'/home/robot/Anand/' #'/home/antixk/Anand/' #\n",
    "sys.path.append(PATH)\n",
    "\n",
    "\n",
    "from NeuralBlocks.models.cyclegan import ResNetGenerator\n",
    "from NeuralBlocks.models.cyclegan import Discriminator\n",
    "from NeuralBlocks.trainers import GANTrainer\n",
    "from NeuralBlocks.trainers.ganloss import GANLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 200\n",
    "BATCH_SIZE = 2\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "NUM_CHANNELS = 3\n",
    "SAMPLE_INTERVAL = 100\n",
    "CHECKPOINT_INTERVAL = 10\n",
    "NUM_RESIDUAL_BLOCKS = 2\n",
    "LR = 0.0002\n",
    "NUM_WORKERS = 8\n",
    "IMG_SIZE = 32\n",
    "DATA_PATH = PATH+\"NeuralBlocks/data_utils/datasets/MNIST/\"\n",
    "SAVE_PATH = PATH+\"NeuralBlocks/experiments/MNIST/\"\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "NORM = 'MSN'\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "IMG_DIR = 'images_{}/'.format(NORM)\n",
    "SAVE_DIR = 'saved_models_{}/'.format(NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        \"../../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(IMG_SIZE), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = IMG_SIZE // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(128, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(1, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = IMG_SIZE // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity\n",
    "G = Generator()\n",
    "D =  Discriminator()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(G.parameters(), lr=LR, betas=(0.5,0.999))\n",
    "optimizer_D = torch.optim.Adam(D.parameters(), lr=LR, betas=(0.5,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_loss(GANLoss):\n",
    "    def __init__(self):\n",
    "        super(WGAN_loss, self).__init__()\n",
    "        self.adversarial_loss = torch.nn.BCELoss()\n",
    "        \n",
    "    def compute_loss(self, images, G_x, D_x, D_G_x):    \n",
    "        valid = torch.ones(images.shape[0], 1).cuda()\n",
    "        fake = torch.zeros(images.shape[0], 1).cuda()      \n",
    "\n",
    "\n",
    "        g_loss = self.adversarial_loss(D_G_x, valid)\n",
    "\n",
    "        real_loss = self.adversarial_loss(D_x, valid)\n",
    "        fake_loss = self.adversarial_loss(D_G_x.detach(), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        return g_loss, d_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-024646b30d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                      \u001b[0mG_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                      \u001b[0mD_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                      latent_dim = 128)\n\u001b[0m",
      "\u001b[0;32m~/Anand/NeuralBlocks/trainers/gan_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, G_model, D_model, dataloader, gan_loss, G_optimizer, D_optimizer, latent_dim, use_cuda)\u001b[0m\n\u001b[1;32m     15\u001b[0m                        \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                        use_cuda = True):\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGANTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/trainers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, use_cuda, metrics)\u001b[0m\n\u001b[1;32m     25\u001b[0m             raise Warning(\"CUDA is available on this machine. \"\n\u001b[1;32m     26\u001b[0m                           \"Set use_cuda = True for faster computation.\")\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'losses'"
     ]
    }
   ],
   "source": [
    "loss = WGAN_loss()\n",
    "\n",
    "trainer = GANTrainer(G_model=G, \n",
    "                     D_model=D, \n",
    "                     dataloader=dataloader,\n",
    "                     gan_loss = loss,\n",
    "                     G_optimizer=optimizer_G, \n",
    "                     D_optimizer=optimizer_D,\n",
    "                     latent_dim = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
