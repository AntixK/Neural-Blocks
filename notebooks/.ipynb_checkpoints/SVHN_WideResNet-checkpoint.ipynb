{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm_notebook\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "PATH = '/home/robot/Anand/'\n",
    "sys.path.append(PATH)\n",
    "\n",
    "from NeuralBlocks.models.wresnet import WideResNet\n",
    "# from NeuralBlocks.models.densenet import DenseNet\n",
    "\n",
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# net1 = DenseNet(3, 10, norm='BN')\n",
    "# net2 = WideResNet(depth=22, num_classes=10, widen_factor=5,dropout_rate=0.3,norm='BN')\n",
    "\n",
    "# print(count_parameters(net1), count_parameters(net2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2456)\n",
    "# cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "np.random.seed(2456)\n",
    "\n",
    "NUM_EPOCH = 200\n",
    "BATCH_SIZE = 128\n",
    "CHECKPOINT_INTERVAL = 100\n",
    "LRS = [0.0001, 0.001, 0.01]\n",
    "NORMS =[None,'BN', 'SN', 'WN', 'MWN', 'MSN', 'MSNTReLU', 'MWNTReLU']\n",
    "DATA_PATH = PATH+\"NeuralBlocks/data_utils/datasets/SVHN/\"\n",
    "SAVE_PATH = PATH+\"NeuralBlocks/experiments/SVHN/\"\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/robot-i9/Anand/NeuralBlocks/data_utils/datasets/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /home/robot-i9/Anand/NeuralBlocks/data_utils/datasets/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "trainset = torchvision.datasets.SVHN(root=DATA_PATH, download=True, transform=transform, split='train')\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.SVHN(root=DATA_PATH, download=True, transform=transform, split='test')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        train_loss_log.append(train_loss/(batch_idx+1))\n",
    "        train_acc_log.append( 100.*correct/total)\n",
    "        \n",
    "        if(batch_idx%CHECKPOINT_INTERVAL==0):\n",
    "             print(\"Train Epoch [{:3d}/{:3d}]Batch [{:3d}/{:3d}] Loss: {:.3f} Acc {:.3f}%\".format(epoch, NUM_EPOCH,batch_idx, len(trainloader),\n",
    "                train_loss/(batch_idx+1), 100.*correct/total))\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            test_loss_log.append(test_loss/(batch_idx+1))\n",
    "            test_acc_log.append( 100.*correct/total)\n",
    "        \n",
    "            if(batch_idx%CHECKPOINT_INTERVAL==0):\n",
    "                print(\"Test Epoch [{:3d}/{:3d}]Batch [{:3d}/{:3d}] Loss: {:.3f} Acc {:.3f}%\".format(epoch, NUM_EPOCH,batch_idx, len(testloader),\n",
    "                test_loss/(batch_idx+1), 100.*correct/total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(SAVE_PATH+'checkpoint'):\n",
    "            os.mkdir(SAVE_PATH+'checkpoint')\n",
    "        torch.save(state, SAVE_PATH+'checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e667392f59584e1089d7db22b3990b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2e4dc1fc9042fba664f8a127202f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9ce565b0c94430bb7913a692321138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.317 Acc 4.688%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.242 Acc 18.464%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.242 Acc 18.676%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.240 Acc 18.732%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.240 Acc 18.742%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.239 Acc 18.777%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Saving..\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.253 Acc 12.500%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.233 Acc 19.013%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.234 Acc 18.921%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.226 Acc 19.651%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.195 Acc 21.160%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.139 Acc 23.408%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.670 Acc 36.719%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.589 Acc 45.591%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.589 Acc 45.725%\n",
      "Saving..\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.674 Acc 43.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.609 Acc 45.042%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.553 Acc 47.054%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.513 Acc 48.572%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.467 Acc 50.251%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.429 Acc 51.608%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 1.143 Acc 61.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 1.065 Acc 64.635%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 1.062 Acc 64.681%\n",
      "Saving..\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.229 Acc 61.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 1.174 Acc 60.721%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 1.143 Acc 61.762%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 1.124 Acc 62.593%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 1.101 Acc 63.558%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 1.082 Acc 64.236%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.901 Acc 67.969%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.846 Acc 72.502%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.841 Acc 72.466%\n",
      "Saving..\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.988 Acc 67.188%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.929 Acc 69.802%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.909 Acc 70.557%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.892 Acc 71.229%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.879 Acc 71.735%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.868 Acc 72.165%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.812 Acc 75.781%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.739 Acc 76.145%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.731 Acc 76.073%\n",
      "Saving..\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.838 Acc 71.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.757 Acc 75.665%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.759 Acc 75.618%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.751 Acc 75.968%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.740 Acc 76.368%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.729 Acc 76.870%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.597 Acc 83.594%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.578 Acc 81.521%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.569 Acc 81.825%\n",
      "Saving..\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.667 Acc 80.469%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.661 Acc 79.069%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.659 Acc 79.275%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.654 Acc 79.376%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.648 Acc 79.584%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.643 Acc 79.753%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.547 Acc 82.812%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.516 Acc 83.888%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.509 Acc 84.021%\n",
      "Saving..\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.490 Acc 88.281%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.588 Acc 81.706%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.579 Acc 81.751%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.574 Acc 82.021%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.572 Acc 82.097%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.568 Acc 82.250%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.532 Acc 86.719%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.483 Acc 84.800%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.476 Acc 85.075%\n",
      "Saving..\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.719 Acc 78.906%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.543 Acc 83.060%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.540 Acc 83.069%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.536 Acc 83.303%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.527 Acc 83.607%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.523 Acc 83.795%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.437 Acc 88.281%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.417 Acc 87.167%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.411 Acc 87.212%\n",
      "Saving..\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.402 Acc 86.719%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.489 Acc 84.901%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.499 Acc 84.523%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.492 Acc 84.699%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.488 Acc 84.860%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.485 Acc 84.968%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.478 Acc 86.719%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.407 Acc 87.399%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.399 Acc 87.601%\n",
      "Saving..\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.558 Acc 83.594%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.464 Acc 85.504%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.455 Acc 85.961%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.455 Acc 85.932%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.452 Acc 85.941%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.451 Acc 86.036%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.399 Acc 89.062%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.367 Acc 88.800%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.360 Acc 88.899%\n",
      "Saving..\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.588 Acc 81.250%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.417 Acc 87.260%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.429 Acc 86.804%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.426 Acc 86.996%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.429 Acc 86.849%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.426 Acc 86.903%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.425 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.359 Acc 89.271%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.352 Acc 89.230%\n",
      "Saving..\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.292 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.428 Acc 86.649%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.419 Acc 86.952%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.419 Acc 87.041%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.413 Acc 87.188%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.409 Acc 87.330%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.410 Acc 89.062%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.345 Acc 89.681%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.337 Acc 89.817%\n",
      "Saving..\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.385 Acc 87.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.400 Acc 87.848%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.398 Acc 87.935%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.397 Acc 87.788%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.398 Acc 87.734%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.393 Acc 87.901%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.366 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.318 Acc 90.849%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.310 Acc 90.889%\n",
      "Saving..\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.540 Acc 85.938%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.384 Acc 88.513%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.382 Acc 88.398%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.381 Acc 88.416%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.377 Acc 88.517%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.376 Acc 88.464%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.389 Acc 92.188%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.318 Acc 90.803%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.311 Acc 90.711%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.339 Acc 90.625%\n",
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.364 Acc 88.869%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.364 Acc 88.740%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.366 Acc 88.777%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.363 Acc 88.862%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.363 Acc 88.882%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.415 Acc 89.062%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.316 Acc 91.027%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.308 Acc 91.107%\n",
      "Saving..\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.384 Acc 85.156%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.356 Acc 89.310%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.354 Acc 89.171%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.349 Acc 89.314%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.344 Acc 89.524%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.346 Acc 89.457%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.378 Acc 89.844%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.310 Acc 90.927%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.303 Acc 90.959%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.335 Acc 89.844%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.334 Acc 89.681%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.338 Acc 89.688%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.337 Acc 89.634%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.335 Acc 89.707%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.338 Acc 89.650%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.374 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.295 Acc 91.406%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.288 Acc 91.515%\n",
      "Saving..\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.370 Acc 86.719%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.334 Acc 89.790%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.327 Acc 90.042%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.328 Acc 90.028%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.332 Acc 89.877%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.329 Acc 89.972%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.339 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.276 Acc 92.087%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.268 Acc 92.230%\n",
      "Saving..\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.334 Acc 91.406%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.338 Acc 90.138%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.318 Acc 90.427%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.318 Acc 90.472%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.320 Acc 90.354%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.320 Acc 90.333%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.268 Acc 92.141%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.260 Acc 92.463%\n",
      "Saving..\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.409 Acc 88.281%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.310 Acc 90.370%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.309 Acc 90.505%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.312 Acc 90.503%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.308 Acc 90.607%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.313 Acc 90.461%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.321 Acc 92.188%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.271 Acc 92.443%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.262 Acc 92.522%\n",
      "Saving..\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.315 Acc 91.406%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.304 Acc 90.726%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.313 Acc 90.528%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.308 Acc 90.692%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.305 Acc 90.771%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.304 Acc 90.818%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.294 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.262 Acc 92.830%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.253 Acc 92.903%\n",
      "Saving..\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.311 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.283 Acc 91.213%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.290 Acc 91.282%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.294 Acc 91.149%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.297 Acc 91.007%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.298 Acc 91.001%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.341 Acc 90.625%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.257 Acc 92.675%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.251 Acc 92.763%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.303 Acc 89.844%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.284 Acc 91.615%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.292 Acc 91.262%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.291 Acc 91.310%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.288 Acc 91.381%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.291 Acc 91.349%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.305 Acc 92.188%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.252 Acc 93.000%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.242 Acc 93.206%\n",
      "Saving..\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.302 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.294 Acc 91.329%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.288 Acc 91.449%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.286 Acc 91.450%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.287 Acc 91.500%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.284 Acc 91.517%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.260 Acc 92.698%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.252 Acc 92.821%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.393 Acc 89.062%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.280 Acc 91.522%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.282 Acc 91.453%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.284 Acc 91.476%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.278 Acc 91.619%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.280 Acc 91.603%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.253 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.238 Acc 93.502%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.230 Acc 93.641%\n",
      "Saving..\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.277 Acc 91.638%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.282 Acc 91.651%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.277 Acc 91.772%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.276 Acc 91.833%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.274 Acc 91.893%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.249 Acc 92.915%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.243 Acc 93.050%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.369 Acc 89.844%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.272 Acc 92.102%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.268 Acc 92.199%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.270 Acc 92.060%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.270 Acc 92.018%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.271 Acc 91.949%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.311 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.239 Acc 93.379%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.234 Acc 93.560%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.265 Acc 90.625%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.268 Acc 91.754%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.269 Acc 91.869%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.269 Acc 91.962%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.269 Acc 91.924%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.268 Acc 91.991%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.303 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.242 Acc 93.680%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.234 Acc 93.692%\n",
      "Saving..\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.351 Acc 88.281%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.264 Acc 92.126%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.258 Acc 92.265%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.258 Acc 92.286%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.259 Acc 92.273%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.237 Acc 93.502%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.231 Acc 93.567%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.190 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.257 Acc 92.713%\n",
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.255 Acc 92.568%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.258 Acc 92.382%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.257 Acc 92.443%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.258 Acc 92.403%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.300 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.231 Acc 93.827%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.224 Acc 93.886%\n",
      "Saving..\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.285 Acc 91.406%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.262 Acc 92.396%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.253 Acc 92.483%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.255 Acc 92.416%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.256 Acc 92.441%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.256 Acc 92.398%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.230 Acc 92.188%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.217 Acc 94.199%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.210 Acc 94.209%\n",
      "Saving..\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.235 Acc 92.969%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.247 Acc 92.667%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.247 Acc 92.580%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.252 Acc 92.553%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.251 Acc 92.571%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.253 Acc 92.526%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.311 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.243 Acc 93.433%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.237 Acc 93.408%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.254 Acc 92.188%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.236 Acc 92.567%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.242 Acc 92.615%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.243 Acc 92.574%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.246 Acc 92.593%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.249 Acc 92.560%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.225 Acc 94.044%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.217 Acc 94.045%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.268 Acc 89.844%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.262 Acc 92.118%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.250 Acc 92.510%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.246 Acc 92.678%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.245 Acc 92.754%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.245 Acc 92.705%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.224 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.221 Acc 94.214%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.216 Acc 94.205%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.195 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.243 Acc 92.860%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.243 Acc 92.918%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.243 Acc 92.888%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.243 Acc 92.885%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.244 Acc 92.883%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.215 Acc 94.261%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.208 Acc 94.325%\n",
      "Saving..\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.238 Acc 93.100%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.241 Acc 92.895%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.239 Acc 92.979%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.238 Acc 92.957%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.238 Acc 92.997%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.235 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.224 Acc 93.851%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.219 Acc 93.812%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.227 Acc 93.154%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.240 Acc 92.868%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.240 Acc 92.886%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.237 Acc 93.006%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.237 Acc 93.000%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.212 Acc 94.570%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.205 Acc 94.547%\n",
      "Saving..\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.218 Acc 93.301%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.224 Acc 93.225%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.236%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.230 Acc 93.216%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.231 Acc 93.167%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.215 Acc 94.384%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.208 Acc 94.380%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.359 Acc 86.719%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.223 Acc 93.216%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.230 Acc 93.116%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.228 Acc 93.221%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.230 Acc 93.150%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.230 Acc 93.162%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.231 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.225 Acc 94.013%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.219 Acc 94.045%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.217 Acc 93.541%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.223 Acc 93.311%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.223 Acc 93.407%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.225 Acc 93.366%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.228 Acc 93.329%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.237 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.216 Acc 94.338%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.209 Acc 94.306%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.389 Acc 93.750%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.237 Acc 93.340%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.235 Acc 93.315%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.229 Acc 93.428%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.229 Acc 93.337%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.228 Acc 93.309%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.206 Acc 94.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.201 Acc 94.535%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.177 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.226 Acc 93.626%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.224 Acc 93.513%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.224 Acc 93.610%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.222 Acc 93.643%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.223 Acc 93.521%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.218 Acc 92.969%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.212 Acc 94.392%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.205 Acc 94.547%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.203 Acc 94.199%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.211 Acc 93.979%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.214 Acc 93.794%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.216 Acc 93.719%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.219 Acc 93.633%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.234 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.202 Acc 94.879%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.197 Acc 94.741%\n",
      "Saving..\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.278 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.220 Acc 93.209%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.219 Acc 93.373%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.219 Acc 93.511%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.222 Acc 93.534%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.220 Acc 93.536%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.195 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.208 Acc 94.609%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.203 Acc 94.632%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.292 Acc 90.625%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.222 Acc 93.464%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.219 Acc 93.711%\n",
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.216 Acc 93.758%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.214 Acc 93.748%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.216 Acc 93.703%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.266 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.208 Acc 94.616%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.203 Acc 94.590%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.205 Acc 94.144%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.212 Acc 93.902%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.210 Acc 93.908%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.212 Acc 93.869%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.214 Acc 93.873%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.198 Acc 94.732%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.194 Acc 94.796%\n",
      "Saving..\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.207 Acc 93.858%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.204 Acc 94.014%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.211 Acc 93.911%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.212 Acc 93.816%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.211 Acc 93.840%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.215 Acc 94.438%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.210 Acc 94.454%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.207 Acc 93.851%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.210 Acc 93.808%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.210 Acc 93.781%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.212 Acc 93.762%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.212 Acc 93.725%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.200 Acc 94.748%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.193 Acc 94.885%\n",
      "Saving..\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.203 Acc 94.090%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.206 Acc 93.917%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.208 Acc 93.926%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.208 Acc 93.859%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.199 Acc 94.887%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.193 Acc 94.939%\n",
      "Saving..\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.219 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.208 Acc 93.982%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.207 Acc 94.007%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.210 Acc 93.849%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.208 Acc 93.947%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.207 Acc 93.959%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.197 Acc 95.065%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.191 Acc 94.998%\n",
      "Saving..\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.285 Acc 91.406%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.207 Acc 93.967%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.208 Acc 93.863%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.208 Acc 93.836%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.207 Acc 93.857%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.206 Acc 93.948%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.195 Acc 94.879%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.189 Acc 94.873%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.194 Acc 94.230%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.198 Acc 94.139%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.200 Acc 94.121%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.202 Acc 94.130%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.202 Acc 94.074%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.200 Acc 94.833%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.195 Acc 94.885%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.197 Acc 94.431%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.210 Acc 94.061%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.204 Acc 94.126%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.205 Acc 94.145%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.205 Acc 94.134%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.240 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.206 Acc 94.957%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.200 Acc 95.064%\n",
      "Saving..\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.200 Acc 94.322%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.195 Acc 94.485%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.196 Acc 94.363%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.200 Acc 94.227%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.200 Acc 94.224%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.197 Acc 94.879%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.191 Acc 94.862%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.189 Acc 94.268%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.194 Acc 94.181%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.197 Acc 94.321%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.196 Acc 94.286%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.196 Acc 94.286%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.193 Acc 95.204%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.185 Acc 95.235%\n",
      "Saving..\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.191 Acc 94.601%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.195 Acc 94.376%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.198 Acc 94.326%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.197 Acc 94.344%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.196 Acc 94.360%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.199 Acc 95.011%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.191 Acc 95.095%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.169 Acc 91.406%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.189 Acc 94.570%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.192 Acc 94.562%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.192 Acc 94.529%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.194 Acc 94.479%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.195 Acc 94.405%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.237 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.206 Acc 95.011%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.200 Acc 95.017%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.192 Acc 94.493%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.191 Acc 94.625%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.191 Acc 94.612%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.193 Acc 94.535%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.194 Acc 94.455%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.241 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.191 Acc 95.220%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.185 Acc 95.235%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.300 Acc 90.625%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.192 Acc 94.431%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.191 Acc 94.438%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.191 Acc 94.498%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.191 Acc 94.442%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.191 Acc 94.453%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.195 Acc 95.119%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.190 Acc 95.211%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.280 Acc 89.844%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.180 Acc 94.856%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.180 Acc 94.920%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.184 Acc 94.767%\n",
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.188 Acc 94.631%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.189 Acc 94.592%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.211 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.186 Acc 95.289%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.179 Acc 95.386%\n",
      "Saving..\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.185 Acc 94.655%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.189 Acc 94.617%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.193 Acc 94.534%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.193 Acc 94.484%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.192 Acc 94.500%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.185 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.181 Acc 95.382%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.175 Acc 95.491%\n",
      "Saving..\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.182 Acc 94.678%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.178 Acc 94.893%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.184 Acc 94.801%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.185 Acc 94.761%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.186 Acc 94.712%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.225 Acc 93.750%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.195 Acc 95.019%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.189 Acc 95.099%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.269 Acc 91.406%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.191 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.189 Acc 94.605%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.187 Acc 94.651%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.188 Acc 94.598%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.191 Acc 95.243%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.320%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.191 Acc 94.593%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.186 Acc 94.718%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.633%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.185 Acc 94.658%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.229 Acc 93.750%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.181 Acc 95.464%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.176 Acc 96.094%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.185 Acc 94.779%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.185 Acc 94.803%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.186 Acc 94.684%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.184 Acc 94.771%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.184 Acc 94.753%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.193 Acc 95.104%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.187 Acc 95.219%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.266 Acc 92.969%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.178 Acc 94.933%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.176 Acc 94.951%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.181 Acc 94.778%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.184 Acc 94.734%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.182 Acc 94.803%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.259 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.211 Acc 94.879%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.202 Acc 94.939%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.175 Acc 95.026%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.176 Acc 94.951%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.179 Acc 94.879%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.179 Acc 94.851%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.181 Acc 94.771%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.183 Acc 95.394%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.175 Acc 94.632%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.180 Acc 94.710%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.181 Acc 94.773%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.181 Acc 94.812%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.181 Acc 94.813%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.227 Acc 92.969%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.200 Acc 95.042%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.193 Acc 95.095%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.179 Acc 94.957%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.178 Acc 94.916%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.173 Acc 95.027%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.174 Acc 95.016%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.177 Acc 94.940%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.186 Acc 95.266%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.180 Acc 95.355%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.212 Acc 93.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.176 Acc 94.578%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.173 Acc 94.819%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.172 Acc 94.980%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.172 Acc 94.960%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.173 Acc 94.971%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.182 Acc 95.475%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.176 Acc 95.534%\n",
      "Saving..\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.165 Acc 95.220%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.167 Acc 95.254%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.172 Acc 95.089%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.173 Acc 95.038%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.174 Acc 95.016%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.191 Acc 95.227%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.182 Acc 95.351%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.174 Acc 95.026%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.173 Acc 95.052%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.174 Acc 95.037%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.175 Acc 95.016%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.175 Acc 94.990%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.193 Acc 95.328%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.185 Acc 95.328%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.215 Acc 94.531%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.166 Acc 95.235%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.177 Acc 94.858%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.174 Acc 95.024%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.176 Acc 94.966%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.196 Acc 95.328%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.188 Acc 95.425%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.167 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.166 Acc 95.212%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.170 Acc 95.099%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 95.030%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.173 Acc 95.083%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.173 Acc 95.015%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.192 Acc 95.343%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.183 Acc 95.534%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.164 Acc 95.212%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.162 Acc 95.219%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.164 Acc 95.229%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.167 Acc 95.170%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.170 Acc 95.114%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.183 Acc 95.405%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.491%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.162 Acc 97.656%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.176 Acc 94.817%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.171 Acc 94.943%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.172 Acc 94.954%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.171 Acc 95.036%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.171 Acc 95.074%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.191 Acc 95.212%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.185 Acc 95.250%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.163 Acc 95.537%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.169 Acc 95.320%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.167 Acc 95.271%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.169 Acc 95.164%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.170 Acc 95.143%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.195 Acc 95.189%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 95.169%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.170 Acc 95.212%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.169 Acc 95.159%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.167 Acc 95.217%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.169 Acc 95.157%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.189 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.188 Acc 95.305%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.182 Acc 95.437%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.095 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.168 Acc 95.266%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.173%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.168 Acc 95.183%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.167 Acc 95.198%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.167 Acc 95.211%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.208 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.289%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.178 Acc 95.460%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.158 Acc 95.475%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.161 Acc 95.382%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.164 Acc 95.255%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.165 Acc 95.281%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.676%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Saving..\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.130 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.165 Acc 95.196%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.164 Acc 95.239%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.165 Acc 95.310%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.164 Acc 95.285%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.166 Acc 95.231%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.181 Acc 95.746%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.173 Acc 95.884%\n",
      "Saving..\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.171 Acc 95.282%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.164 Acc 95.301%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.164 Acc 95.341%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.163 Acc 95.299%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.163 Acc 95.317%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.231 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.193 Acc 95.382%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.185 Acc 95.437%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.111 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.164 Acc 95.065%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.161 Acc 95.254%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.164 Acc 95.165%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.165 Acc 95.198%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.165 Acc 95.241%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.222 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.188 Acc 95.398%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.180 Acc 95.546%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.179 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.153 Acc 95.561%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.157 Acc 95.414%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.159 Acc 95.412%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.161 Acc 95.327%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.177 Acc 95.421%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.171 Acc 95.546%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.169 Acc 95.297%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.167 Acc 95.223%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.161 Acc 95.333%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.159 Acc 95.390%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.158 Acc 95.423%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.189 Acc 95.444%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.181 Acc 95.561%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.183 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.163 Acc 95.297%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.160 Acc 95.464%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.157 Acc 95.531%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.159 Acc 95.482%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.161 Acc 95.425%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.187 Acc 95.599%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.181 Acc 95.600%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.154 Acc 95.514%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.156 Acc 95.565%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.156 Acc 95.569%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.157 Acc 95.568%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.157 Acc 95.512%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.174 Acc 95.746%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.167 Acc 95.814%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.154 Acc 95.552%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.156 Acc 95.577%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.156 Acc 95.458%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.157 Acc 95.420%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.158 Acc 95.394%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.197 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.183 Acc 95.568%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.175 Acc 95.627%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.196 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.152 Acc 95.738%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.152 Acc 95.627%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.157 Acc 95.536%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.155 Acc 95.591%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.157 Acc 95.511%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.186 Acc 95.568%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.179 Acc 95.534%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.115 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.152 Acc 95.676%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.155 Acc 95.487%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.156 Acc 95.531%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.154 Acc 95.560%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.156 Acc 95.482%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.174 Acc 95.653%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.168 Acc 95.705%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.147 Acc 95.606%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.150 Acc 95.620%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.154 Acc 95.546%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.155 Acc 95.538%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.155 Acc 95.560%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.189 Acc 95.645%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.181 Acc 95.756%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.200 Acc 92.188%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.152 Acc 95.583%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.153 Acc 95.604%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.155 Acc 95.528%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.155 Acc 95.540%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.154 Acc 95.579%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.193 Acc 95.529%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.186 Acc 95.515%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.184 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.153 Acc 95.568%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.151 Acc 95.569%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.152 Acc 95.554%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.154 Acc 95.581%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.154 Acc 95.579%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.177 Acc 95.717%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.154 Acc 95.552%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.147 Acc 95.690%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.150 Acc 95.684%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.149 Acc 95.690%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.151 Acc 95.620%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.183 Acc 95.506%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.177 Acc 95.662%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.144 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.157 Acc 95.444%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.635%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.149 Acc 95.686%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.150 Acc 95.706%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.151 Acc 95.679%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.187 Acc 95.684%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.179 Acc 95.767%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.157 Acc 95.429%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.152 Acc 95.655%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.156 Acc 95.567%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.155 Acc 95.607%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.153 Acc 95.610%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.191 Acc 95.645%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.183 Acc 95.725%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.160 Acc 95.475%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.153 Acc 95.697%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.153 Acc 95.629%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.153 Acc 95.589%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.150 Acc 95.681%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.180 Acc 95.838%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.171 Acc 95.899%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.123 Acc 93.750%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.140 Acc 95.915%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.148 Acc 95.702%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.149 Acc 95.699%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.185 Acc 95.606%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.176 Acc 95.728%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.143 Acc 95.823%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.150 Acc 95.647%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.148 Acc 95.621%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.149 Acc 95.650%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.149 Acc 95.648%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.199 Acc 95.367%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.191 Acc 95.511%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.140 Acc 96.032%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.148 Acc 95.794%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.148 Acc 95.767%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.147 Acc 95.768%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.148 Acc 95.740%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.178 Acc 95.483%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.170 Acc 95.686%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.141 Acc 96.001%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.140 Acc 95.981%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.141 Acc 95.943%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.142 Acc 95.915%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.146 Acc 95.821%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.190 Acc 95.653%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.181 Acc 95.826%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.194 Acc 97.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.143 Acc 95.846%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.151 Acc 95.709%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.148 Acc 95.738%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.148 Acc 95.749%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.146 Acc 95.765%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.183 Acc 95.668%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.175 Acc 95.841%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.218 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.139 Acc 95.885%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.137 Acc 95.977%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.142 Acc 95.894%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.144 Acc 95.844%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.146 Acc 95.796%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.179 Acc 95.808%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.172 Acc 95.907%\n",
      "Saving..\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.136 Acc 95.939%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.137 Acc 95.981%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.138 Acc 95.954%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.141 Acc 95.897%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.143 Acc 95.857%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.164 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.198 Acc 95.204%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.189 Acc 95.278%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.190 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.142 Acc 95.753%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.142 Acc 95.857%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.144 Acc 95.816%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.142 Acc 95.805%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.143 Acc 95.808%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.180 Acc 95.784%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.171 Acc 95.864%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.139 Acc 95.707%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.141 Acc 95.759%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.140 Acc 95.787%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.141 Acc 95.813%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.143 Acc 95.841%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.178 Acc 95.775%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.136 Acc 96.063%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.134 Acc 96.008%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.141 Acc 95.946%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.140 Acc 95.872%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.142 Acc 95.850%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.184 Acc 95.577%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.143 Acc 95.738%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.144 Acc 95.767%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.139 Acc 95.902%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.141 Acc 95.922%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.140 Acc 95.960%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.189 Acc 95.568%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.181 Acc 95.697%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.134 Acc 96.140%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.141 Acc 95.993%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.141 Acc 95.977%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.142 Acc 95.959%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.142 Acc 95.942%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.185 Acc 95.521%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.177 Acc 95.616%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.132 Acc 95.869%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.130 Acc 96.082%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.137 Acc 95.964%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.139 Acc 95.924%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.141 Acc 95.866%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.192 Acc 95.668%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.183 Acc 95.798%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.139 Acc 96.040%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.139 Acc 95.958%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.140 Acc 95.920%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.141 Acc 95.934%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.141 Acc 95.985%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.179 Acc 95.639%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.138 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.136 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.137 Acc 96.055%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.137 Acc 96.014%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.137 Acc 95.994%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.187 Acc 95.560%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.179 Acc 95.713%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.136 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.128 Acc 96.403%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.134 Acc 96.218%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.137 Acc 96.028%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.189 Acc 95.645%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.183 Acc 95.666%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.128 Acc 96.310%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.130 Acc 96.234%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.133 Acc 96.125%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.136 Acc 96.086%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.181 Acc 95.568%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.174 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.139 Acc 95.955%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.135 Acc 96.140%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.134 Acc 96.125%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.136 Acc 96.016%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.138 Acc 95.961%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.173 Acc 95.919%\n",
      "Saving..\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.137 Acc 96.047%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.134 Acc 95.969%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.133 Acc 96.127%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.134 Acc 96.084%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.134 Acc 96.097%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.188 Acc 95.722%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.181 Acc 95.787%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.130 Acc 96.349%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.134 Acc 96.195%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.134 Acc 96.120%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.138 Acc 96.043%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.137 Acc 96.091%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.179 Acc 95.947%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 96.012%\n",
      "Saving..\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.140 Acc 95.838%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.132 Acc 96.150%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.133 Acc 96.133%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.193 Acc 95.653%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.184 Acc 95.740%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.128 Acc 96.140%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.131 Acc 96.160%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.133 Acc 96.159%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.133 Acc 96.152%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.133 Acc 96.145%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.179 Acc 95.769%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.169 Acc 95.829%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.126 Acc 96.411%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.128 Acc 96.319%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.131 Acc 96.262%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.131 Acc 96.242%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.132 Acc 96.172%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.184 Acc 95.777%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.174 Acc 95.829%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.125 Acc 96.381%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.129 Acc 96.288%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.129 Acc 96.341%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.130 Acc 96.286%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.186 Acc 95.599%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.179 Acc 95.705%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.125 Acc 96.256%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.135 Acc 96.068%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.133 Acc 96.129%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.132 Acc 96.136%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.195 Acc 95.429%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.186 Acc 95.639%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.130 Acc 96.225%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.131 Acc 96.226%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.130 Acc 96.172%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.128 Acc 96.228%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.130 Acc 96.203%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.178 Acc 95.784%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.170 Acc 95.829%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.058 Acc 100.000%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.122 Acc 96.357%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.124 Acc 96.343%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.126 Acc 96.283%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.128 Acc 96.214%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.189 Acc 95.591%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.182 Acc 95.701%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.124 Acc 96.331%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.128 Acc 96.229%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.129 Acc 96.228%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.131 Acc 96.192%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.179 Acc 95.651%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.127 Acc 96.291%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.130 Acc 96.226%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.129 Acc 96.247%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.200 Acc 95.537%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.190 Acc 95.643%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.125 Acc 96.287%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.129 Acc 96.199%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.129 Acc 96.229%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.129 Acc 96.209%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.129 Acc 96.209%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.192 Acc 95.583%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.183 Acc 95.701%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.121 Acc 96.612%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.124 Acc 96.405%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.124 Acc 96.330%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.125 Acc 96.363%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.127 Acc 96.262%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.182 Acc 95.599%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.173 Acc 95.705%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.247 Acc 92.188%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.127 Acc 96.148%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.123 Acc 96.265%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.124 Acc 96.255%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.127 Acc 96.181%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.128 Acc 96.183%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.193 Acc 95.838%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.184 Acc 95.884%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.212 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.117 Acc 96.697%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.122 Acc 96.576%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.126 Acc 96.379%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.127 Acc 96.329%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.128 Acc 96.304%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.190 Acc 95.645%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.182 Acc 95.783%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.124 Acc 96.372%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.125 Acc 96.323%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.127 Acc 96.338%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.126 Acc 96.333%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.127 Acc 96.290%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.120 Acc 97.656%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.196 Acc 95.715%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.187 Acc 95.880%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.123 Acc 96.403%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.125 Acc 96.401%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.123 Acc 96.387%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.126 Acc 96.394%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.125 Acc 96.365%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.192 Acc 95.521%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.183 Acc 95.616%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.146 Acc 94.531%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.129 Acc 96.117%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.129 Acc 96.137%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.128 Acc 96.159%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.126 Acc 96.259%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.125 Acc 96.287%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.188 Acc 95.684%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.179 Acc 95.783%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.178 Acc 94.531%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.124 Acc 96.210%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.126 Acc 96.280%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.125 Acc 96.371%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.123 Acc 96.406%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [134/200]Batch [100/204] Loss: 0.194 Acc 95.537%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.186 Acc 95.627%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.119 Acc 96.457%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.121 Acc 96.354%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.120 Acc 96.408%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.121 Acc 96.396%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.123 Acc 96.325%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.189 Acc 95.514%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.178 Acc 95.690%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.123 Acc 96.419%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.123 Acc 96.331%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.122 Acc 96.333%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.123 Acc 96.287%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.123 Acc 96.304%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.203 Acc 95.622%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.193 Acc 95.725%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.072 Acc 96.094%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.128 Acc 96.234%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.124 Acc 96.325%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.122 Acc 96.363%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.122 Acc 96.395%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.201 Acc 95.568%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.193 Acc 95.643%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.119 Acc 96.364%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.122 Acc 96.276%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.123 Acc 96.270%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.121 Acc 96.351%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.121 Acc 96.384%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.185 Acc 95.815%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.177 Acc 95.892%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.094 Acc 95.312%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.114 Acc 96.481%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.124 Acc 96.405%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.122 Acc 96.506%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.121 Acc 96.509%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.120 Acc 96.533%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.190 Acc 95.800%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.182 Acc 95.798%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.113 Acc 96.651%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.116 Acc 96.533%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.119 Acc 96.447%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.118 Acc 96.458%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.120 Acc 96.452%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.186 Acc 95.637%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.177 Acc 95.864%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.065 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.118 Acc 96.504%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.119 Acc 96.501%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.120 Acc 96.493%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.121 Acc 96.445%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.175 Acc 95.312%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.195 Acc 95.614%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.186 Acc 95.631%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.241 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.118 Acc 96.635%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.120 Acc 96.638%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.119 Acc 96.636%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.117 Acc 96.672%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.119 Acc 96.563%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.189 Acc 95.684%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.177 Acc 95.837%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.116 Acc 96.650%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.119 Acc 96.553%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.119 Acc 96.521%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.186 Acc 95.722%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.118 Acc 96.511%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.116 Acc 96.514%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.116 Acc 96.558%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.184 Acc 95.529%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.174 Acc 95.736%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.110 Acc 96.705%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.112 Acc 96.692%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.112 Acc 96.597%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.114 Acc 96.571%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.116 Acc 96.529%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.194 Acc 95.722%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.185 Acc 95.810%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.115 Acc 96.634%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.113 Acc 96.657%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.114 Acc 96.621%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.190 Acc 95.808%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.180 Acc 95.977%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.115 Acc 96.388%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.116 Acc 96.482%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.115 Acc 96.512%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.114 Acc 96.598%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.115 Acc 96.568%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.191 Acc 95.328%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.184 Acc 95.491%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.106 Acc 96.720%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.112 Acc 96.642%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.113 Acc 96.654%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.117 Acc 96.562%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.194 Acc 95.746%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.185 Acc 95.876%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.061 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.117 Acc 96.720%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.116 Acc 96.599%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.117 Acc 96.587%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.116 Acc 96.622%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.115 Acc 96.574%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.203 Acc 95.622%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [149/200]Batch [200/204] Loss: 0.191 Acc 95.725%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.111 Acc 96.615%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.110 Acc 96.670%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.110 Acc 96.698%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.112 Acc 96.655%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.186 Acc 95.699%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.154 Acc 96.875%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.112 Acc 96.674%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.108 Acc 96.833%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.111 Acc 96.752%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.115 Acc 96.604%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.199 Acc 95.514%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.189 Acc 95.658%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.110 Acc 96.805%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.112 Acc 96.688%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.114 Acc 96.671%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.183 Acc 95.815%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.174 Acc 95.903%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.109 Acc 96.589%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.109 Acc 96.657%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.111 Acc 96.667%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.112 Acc 96.645%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.111 Acc 96.643%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.182 Acc 95.661%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.174 Acc 95.798%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.127 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.111 Acc 96.635%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.116 Acc 96.552%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.112 Acc 96.631%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.112 Acc 96.649%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.111 Acc 96.710%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.192 Acc 95.730%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.946%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.110 Acc 96.751%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.109 Acc 96.723%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.112 Acc 96.657%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.113 Acc 96.631%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.112 Acc 96.685%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 95.862%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.181 Acc 95.934%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.103 Acc 97.068%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.107 Acc 96.856%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.108 Acc 96.779%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.109 Acc 96.783%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.108 Acc 96.778%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.189 Acc 95.792%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.179 Acc 95.876%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.099 Acc 97.092%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.105 Acc 96.949%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.110 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.110 Acc 96.749%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.186 Acc 95.653%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.176 Acc 95.806%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.102 Acc 96.890%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.109 Acc 96.821%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.109 Acc 96.750%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.109 Acc 96.741%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.110 Acc 96.711%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.188 Acc 95.900%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.178 Acc 95.942%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.140 Acc 93.750%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.107 Acc 96.759%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.108 Acc 96.766%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.109 Acc 96.753%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.112 Acc 96.668%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.110 Acc 96.708%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.185 Acc 95.730%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.176 Acc 95.884%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.101 Acc 96.960%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.107 Acc 96.859%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.109 Acc 96.714%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.111 Acc 96.688%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.110 Acc 96.758%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.202 Acc 95.529%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.192 Acc 95.612%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.109 Acc 96.712%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.112 Acc 96.623%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.113 Acc 96.625%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.110 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.195 Acc 95.722%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.184 Acc 95.872%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.111 Acc 96.612%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.107 Acc 96.743%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.106 Acc 96.771%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.108 Acc 96.756%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.108 Acc 96.738%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.189 Acc 95.753%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.180 Acc 95.899%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.063 Acc 96.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.105 Acc 96.937%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.106 Acc 96.859%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.108 Acc 96.793%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.108 Acc 96.755%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.197 Acc 95.869%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.188 Acc 95.950%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.104 Acc 97.177%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.108 Acc 96.964%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.108 Acc 96.904%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.107 Acc 96.877%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.195 Acc 95.815%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.183 Acc 95.981%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.101 Acc 97.084%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.106 Acc 96.922%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.103 Acc 96.901%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.104 Acc 96.838%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.115 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.194 Acc 95.838%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.185 Acc 95.884%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.157 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.108 Acc 96.883%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.101 Acc 96.937%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.103 Acc 96.909%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.104 Acc 96.920%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.191 Acc 95.699%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.183 Acc 95.748%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.097 Acc 97.084%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.106 Acc 96.871%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.106 Acc 96.846%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.105 Acc 96.877%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.105 Acc 96.887%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.201 Acc 95.900%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.192 Acc 95.977%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.103 Acc 96.832%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.104 Acc 96.779%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.104 Acc 96.846%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.103 Acc 96.867%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.777%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.186 Acc 95.767%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.106 Acc 96.674%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.102 Acc 96.883%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.104 Acc 96.849%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.103 Acc 96.908%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.105 Acc 96.813%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.195 Acc 95.838%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.186 Acc 95.872%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.105 Acc 96.879%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.106 Acc 96.865%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.107 Acc 96.797%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.106 Acc 96.816%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.194 Acc 95.908%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.183 Acc 96.012%\n",
      "Saving..\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.102 Acc 97.022%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.104 Acc 96.953%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.105 Acc 96.803%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.105 Acc 96.769%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.211 Acc 95.514%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.201 Acc 95.674%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.097 Acc 97.014%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.103 Acc 96.836%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.102 Acc 96.880%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.103 Acc 96.893%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.104 Acc 96.883%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.205 Acc 95.761%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.195 Acc 95.763%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.102 Acc 97.022%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.102 Acc 96.953%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.102 Acc 96.935%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.103 Acc 96.898%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.191 Acc 95.676%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.181 Acc 95.853%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.175 Acc 93.750%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.102 Acc 96.991%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.102 Acc 96.871%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.103 Acc 96.820%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.104 Acc 96.826%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.104 Acc 96.839%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.202 Acc 95.614%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.191 Acc 95.678%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.097 Acc 97.068%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.101 Acc 97.007%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.099 Acc 97.058%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.100 Acc 97.045%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.183 Acc 95.896%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.094 Acc 97.045%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.096 Acc 97.042%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.097 Acc 97.000%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.102 Acc 96.877%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.102 Acc 96.900%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.208 Acc 95.583%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.198 Acc 95.705%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.091 Acc 97.362%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.094 Acc 97.221%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.095 Acc 97.186%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.096 Acc 97.159%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.098 Acc 97.075%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.201 Acc 95.722%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.189 Acc 95.818%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.039 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.103 Acc 96.790%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.095 Acc 96.937%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.097 Acc 96.987%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.099 Acc 96.912%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.100 Acc 96.914%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.190 Acc 95.761%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.180 Acc 95.880%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.099 Acc 96.926%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.100 Acc 96.939%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.100 Acc 96.953%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.203 Acc 95.537%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.190 Acc 95.655%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.095 Acc 97.030%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.100 Acc 96.896%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.100 Acc 96.887%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.101 Acc 96.905%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.203 Acc 95.854%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.193 Acc 95.899%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.098 Acc 97.107%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.099 Acc 97.046%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.100 Acc 96.994%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.101 Acc 96.949%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.100 Acc 96.955%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.216 Acc 95.606%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.203 Acc 95.775%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.092 Acc 97.409%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.100 Acc 97.081%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.099 Acc 97.057%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.099 Acc 97.027%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.100 Acc 97.020%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.212 Acc 95.583%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.201 Acc 95.701%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.218 Acc 92.188%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.092 Acc 97.107%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.095 Acc 97.059%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.096 Acc 97.039%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.097 Acc 97.059%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.197 Acc 95.583%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.187 Acc 95.721%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.093 Acc 97.153%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.097 Acc 97.077%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.097 Acc 97.072%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.096 Acc 97.066%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.096 Acc 97.075%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.206 Acc 95.645%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.194 Acc 95.833%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.095 Acc 97.208%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.092 Acc 97.256%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.094 Acc 97.129%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.097 Acc 97.070%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.099 Acc 97.020%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.196 Acc 95.746%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.186 Acc 95.868%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.101 Acc 97.053%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.099 Acc 97.093%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.098 Acc 97.101%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.096 Acc 97.109%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.201 Acc 95.661%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.814%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.178 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.092 Acc 97.161%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.096 Acc 97.108%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.096 Acc 97.096%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.096 Acc 97.064%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.201 Acc 95.784%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.192 Acc 95.849%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.188 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.096 Acc 97.208%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.096 Acc 97.128%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.095 Acc 97.155%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.098 Acc 97.032%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.203 Acc 95.769%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.190 Acc 95.907%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.095 Acc 97.132%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.095 Acc 97.111%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.096 Acc 97.086%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.198 Acc 95.661%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.187 Acc 95.787%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.095 Acc 97.184%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.092 Acc 97.209%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.094 Acc 97.179%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.095 Acc 97.113%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.095 Acc 97.109%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.222 Acc 95.537%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.209 Acc 95.647%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.099 Acc 97.107%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.093 Acc 97.264%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.092 Acc 97.249%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.094 Acc 97.237%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.096 Acc 97.135%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.203 Acc 95.684%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.191 Acc 95.756%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.093 Acc 97.221%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.094 Acc 97.155%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.095 Acc 97.083%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.096 Acc 97.087%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.661%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.186 Acc 95.822%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.092 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.098 Acc 97.053%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.096 Acc 97.132%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.096 Acc 97.083%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.096 Acc 97.089%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.207 Acc 95.838%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.195 Acc 95.954%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.097 Acc 97.050%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.096 Acc 97.106%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.096 Acc 97.083%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.096 Acc 97.064%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.208 Acc 95.637%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.196 Acc 95.763%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [195/200]Batch [100/573] Loss: 0.097 Acc 97.037%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.094 Acc 97.104%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.095 Acc 97.088%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.095 Acc 97.056%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.096 Acc 97.076%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.215 Acc 95.738%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.202 Acc 95.888%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.141 Acc 93.750%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.092 Acc 96.929%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.091 Acc 97.108%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.091 Acc 97.173%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.091 Acc 97.173%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.202 Acc 95.676%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.192 Acc 95.728%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.089 Acc 97.268%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.092 Acc 97.236%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.094 Acc 97.113%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.095 Acc 97.053%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.195 Acc 95.653%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.184 Acc 95.736%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.173 Acc 91.406%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.085 Acc 97.393%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.089 Acc 97.299%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.091 Acc 97.218%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.092 Acc 97.167%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.093 Acc 97.148%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.202 Acc 95.653%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.190 Acc 95.775%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.090 Acc 97.030%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.091 Acc 97.120%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.093 Acc 97.083%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.093 Acc 97.101%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.094 Acc 97.117%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.214 Acc 95.668%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.202 Acc 95.728%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c21fffee2d744ddb5bee0a3bfae6e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.337 Acc 9.375%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.309 Acc 8.988%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.266 Acc 15.683%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.215 Acc 19.721%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.164 Acc 22.695%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.117 Acc 24.975%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.655 Acc 41.406%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.703 Acc 39.550%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.704 Acc 39.657%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.838 Acc 35.156%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.781 Acc 38.459%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.732 Acc 40.668%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.683 Acc 42.951%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.635 Acc 45.355%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.592 Acc 47.452%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.155 Acc 57.812%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.172 Acc 61.912%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.169 Acc 61.870%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.294 Acc 61.719%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.276 Acc 61.100%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.243 Acc 62.345%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.216 Acc 63.442%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.187 Acc 64.596%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.158 Acc 65.703%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.833 Acc 71.094%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.847 Acc 73.940%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.847 Acc 73.993%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.051 Acc 73.438%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.956 Acc 74.095%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.931 Acc 75.101%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.912 Acc 75.867%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.886 Acc 76.757%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.863 Acc 77.660%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.547 Acc 84.375%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.567 Acc 84.777%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.569 Acc 84.608%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.738 Acc 84.375%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.695 Acc 83.470%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.685 Acc 83.633%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.668 Acc 84.105%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.651 Acc 84.467%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.637 Acc 84.685%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.424 Acc 88.281%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.429 Acc 87.771%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.430 Acc 87.675%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.466 Acc 89.062%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.543 Acc 86.595%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.528 Acc 86.851%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.522 Acc 87.033%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.509 Acc 87.276%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.500 Acc 87.422%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.327 Acc 89.844%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.358 Acc 89.952%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.359 Acc 89.785%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.412 Acc 90.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.443 Acc 88.274%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.445 Acc 88.235%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.435 Acc 88.603%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.429 Acc 88.762%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.424 Acc 88.838%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.299 Acc 90.625%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.307 Acc 91.066%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.308 Acc 90.905%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.409 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.398 Acc 89.016%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.388 Acc 89.424%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.382 Acc 89.610%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.378 Acc 89.668%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.375 Acc 89.710%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.271 Acc 90.625%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.279 Acc 91.785%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.277 Acc 91.877%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.425 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.342 Acc 90.586%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.340 Acc 90.501%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.344 Acc 90.389%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.344 Acc 90.329%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.342 Acc 90.332%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.230 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.256 Acc 92.420%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.258 Acc 92.246%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.349 Acc 90.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.315 Acc 91.143%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.321 Acc 90.948%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.322 Acc 90.929%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.321 Acc 91.009%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.320 Acc 90.965%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.253 Acc 88.281%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.244 Acc 93.023%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.243 Acc 92.922%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.271 Acc 92.188%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.304 Acc 91.190%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.306 Acc 91.212%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.308 Acc 91.154%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.306 Acc 91.241%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.304 Acc 91.286%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.232 Acc 90.625%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.244 Acc 92.891%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.243 Acc 92.728%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.243 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.288 Acc 91.723%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.291 Acc 91.554%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.286 Acc 91.715%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.286 Acc 91.689%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.287 Acc 91.668%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.275 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.238 Acc 93.108%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.237 Acc 92.988%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.452 Acc 85.938%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.277 Acc 92.157%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.274 Acc 92.188%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.277 Acc 92.040%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.276 Acc 91.963%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.275 Acc 91.950%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.239 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.237 Acc 93.309%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.236 Acc 93.210%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.394 Acc 89.844%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.279 Acc 91.847%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.273 Acc 92.071%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.268 Acc 92.245%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.269 Acc 92.168%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.266 Acc 92.242%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.229 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.229 Acc 93.317%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.229 Acc 93.350%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.257 Acc 92.683%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.259 Acc 92.526%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.257 Acc 92.525%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.259 Acc 92.451%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.259 Acc 92.462%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.210 Acc 92.188%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.216 Acc 93.796%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.215 Acc 93.723%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.240 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.247 Acc 93.054%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.254 Acc 92.782%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.249 Acc 92.893%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.250 Acc 92.803%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.251 Acc 92.730%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.282 Acc 89.844%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.223 Acc 93.626%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.221 Acc 93.544%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.379 Acc 91.406%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.247 Acc 92.845%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.249 Acc 92.763%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.248 Acc 92.761%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.248 Acc 92.768%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.246 Acc 92.827%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.185 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.209 Acc 94.067%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.208 Acc 94.014%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.302 Acc 89.062%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.248 Acc 92.744%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.234 Acc 93.148%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.237 Acc 93.073%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.240 Acc 92.971%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.241 Acc 92.920%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.185 Acc 91.406%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.204 Acc 94.369%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.201 Acc 94.232%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.306 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.236 Acc 93.139%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.233 Acc 93.280%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.233 Acc 93.223%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.235 Acc 93.156%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.236 Acc 93.101%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.232 Acc 89.844%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.204 Acc 94.322%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.203 Acc 94.263%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.281 Acc 89.062%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.234 Acc 93.185%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.230 Acc 93.276%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.233 Acc 93.184%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.231 Acc 93.265%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.232 Acc 93.207%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.237 Acc 91.406%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.201 Acc 94.384%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.199 Acc 94.434%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.101 Acc 98.438%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.230 Acc 93.216%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.223 Acc 93.513%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.226 Acc 93.501%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.227 Acc 93.423%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.228 Acc 93.398%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.199 Acc 94.454%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.199 Acc 94.298%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.215 Acc 92.188%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.215 Acc 93.665%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.220 Acc 93.544%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.224 Acc 93.457%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.224 Acc 93.442%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.228 Acc 93.318%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.138 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.203 Acc 94.462%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.201 Acc 94.446%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.291 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.214 Acc 93.533%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.217 Acc 93.614%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.217 Acc 93.633%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.217 Acc 93.635%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.220 Acc 93.588%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.194 Acc 94.701%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.191 Acc 94.601%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.152 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.215 Acc 93.758%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.217 Acc 93.653%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.214 Acc 93.758%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.214 Acc 93.771%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.215 Acc 93.744%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.191 Acc 94.686%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.188 Acc 94.694%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.206 Acc 93.858%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.208 Acc 93.925%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.210 Acc 93.919%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.211 Acc 93.886%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.211 Acc 93.881%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.193 Acc 91.406%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.193 Acc 94.524%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.191 Acc 94.652%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.299 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.207 Acc 93.874%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.204 Acc 94.115%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.207 Acc 94.010%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.208 Acc 93.945%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.208 Acc 93.950%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.187 Acc 94.895%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.185 Acc 94.943%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.207 Acc 93.998%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.207 Acc 94.022%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.206 Acc 94.038%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.207 Acc 93.968%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.207 Acc 93.957%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.187 Acc 95.011%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.186 Acc 95.005%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.169 Acc 92.969%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.192 Acc 94.330%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.196 Acc 94.279%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.196 Acc 94.233%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.201 Acc 94.130%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.203 Acc 94.095%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.194 Acc 94.593%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.195 Acc 94.543%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.199 Acc 93.959%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.201 Acc 94.042%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.202 Acc 94.059%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.203 Acc 94.031%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.202 Acc 94.059%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.192 Acc 94.640%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.191 Acc 94.675%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.291 Acc 90.625%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.194 Acc 94.454%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.199 Acc 94.263%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.198 Acc 94.251%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.201 Acc 94.177%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.202 Acc 94.163%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.221 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.181 Acc 95.158%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.179 Acc 95.126%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.191 Acc 94.578%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.196 Acc 94.286%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.196 Acc 94.295%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.197 Acc 94.221%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.196 Acc 94.261%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.183 Acc 95.227%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.181 Acc 95.122%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.248 Acc 93.750%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.201 Acc 94.183%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.194 Acc 94.380%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.197 Acc 94.347%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.197 Acc 94.362%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.196 Acc 94.343%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.185 Acc 94.926%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.185 Acc 94.908%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.142 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.191 Acc 94.462%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.197 Acc 94.395%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.193 Acc 94.381%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.194 Acc 94.319%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.195 Acc 94.288%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.178 Acc 95.212%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.176 Acc 95.231%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.300 Acc 90.625%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.182 Acc 94.779%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.187 Acc 94.621%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.188 Acc 94.625%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.189 Acc 94.601%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.191 Acc 94.495%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.179 Acc 95.282%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.189 Acc 94.640%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.191 Acc 94.500%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.186 Acc 94.609%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.186 Acc 94.629%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.199 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.189 Acc 95.050%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.186 Acc 95.040%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.280 Acc 93.750%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.189 Acc 94.601%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.187 Acc 94.656%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.184 Acc 94.658%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.187 Acc 94.558%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.173 Acc 95.459%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.171 Acc 95.530%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.180 Acc 94.941%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.186 Acc 94.745%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.186 Acc 94.682%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.187 Acc 94.621%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.186 Acc 94.581%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.174 Acc 95.367%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.172 Acc 95.359%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.207 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.179 Acc 94.856%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.182 Acc 94.788%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.181 Acc 94.884%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.183 Acc 94.765%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.184 Acc 94.717%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.177 Acc 95.328%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.172 Acc 95.433%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.204 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.179 Acc 94.879%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.178 Acc 94.842%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.179 Acc 94.825%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.180 Acc 94.779%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.180 Acc 94.782%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.178 Acc 95.243%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.174 Acc 95.278%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.181 Acc 92.969%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.185 Acc 94.701%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.179 Acc 94.819%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.178 Acc 94.858%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.179 Acc 94.818%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.179 Acc 94.812%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.107 Acc 96.875%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.168 Acc 95.537%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.165 Acc 95.658%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.182 Acc 94.841%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.181 Acc 94.842%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.179 Acc 94.845%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.179 Acc 94.865%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.172 Acc 95.599%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.169 Acc 95.721%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.148 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.166 Acc 95.189%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.168 Acc 95.025%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.168 Acc 95.087%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.173 Acc 94.983%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.175 Acc 94.899%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.175 Acc 95.529%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.172 Acc 95.449%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.192 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.168 Acc 95.042%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.173 Acc 95.130%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.174 Acc 95.017%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.176 Acc 94.907%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.176 Acc 94.918%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.189 Acc 94.957%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.187 Acc 94.920%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.213 Acc 92.188%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.168 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.170 Acc 95.122%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.173 Acc 94.980%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.172 Acc 95.022%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.171 Acc 95.091%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.177 Acc 95.436%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.175 Acc 95.441%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.189 Acc 92.969%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.173 Acc 95.220%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.170 Acc 95.165%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.169 Acc 95.123%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.172 Acc 95.085%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.172 Acc 95.091%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.169 Acc 95.645%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.168 Acc 95.643%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.198 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.167 Acc 95.196%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.167 Acc 95.138%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.171 Acc 95.061%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.171 Acc 95.028%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.174 Acc 94.976%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.162 Acc 95.684%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.162 Acc 95.674%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.165 Acc 95.142%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.166 Acc 95.103%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.164 Acc 95.167%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.166 Acc 95.092%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.169 Acc 95.079%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.163 Acc 95.653%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.160 Acc 95.686%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.163 Acc 95.088%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.171 Acc 95.126%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.168 Acc 95.185%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.167 Acc 95.155%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.170 Acc 95.072%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.176 Acc 95.498%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.174 Acc 95.487%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.169 Acc 95.243%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.161 Acc 95.355%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.166 Acc 95.264%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.167 Acc 95.233%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.182 Acc 95.258%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.180 Acc 95.347%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.168 Acc 95.243%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.168 Acc 95.165%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.164 Acc 95.300%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.165 Acc 95.258%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.165 Acc 95.292%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.178 Acc 95.382%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.174 Acc 95.429%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.150 Acc 95.692%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.157 Acc 95.511%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.160 Acc 95.419%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.162 Acc 95.346%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.165 Acc 95.258%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.163 Acc 95.777%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.161 Acc 95.888%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.162 Acc 95.227%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.163 Acc 95.118%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.163 Acc 95.167%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.162 Acc 95.258%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.164 Acc 95.253%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.176 Acc 95.429%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.174 Acc 95.476%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.165 Acc 95.270%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.166 Acc 95.300%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.165 Acc 95.299%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.164 Acc 95.345%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.166 Acc 95.676%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.163 Acc 95.728%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.147 Acc 95.738%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.152 Acc 95.713%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.154 Acc 95.621%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.158 Acc 95.552%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.160 Acc 95.515%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.170 Acc 95.552%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.168 Acc 95.569%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.214 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.152 Acc 95.674%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.152 Acc 95.691%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.155 Acc 95.599%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.160 Acc 95.472%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.167 Acc 95.699%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.162 Acc 95.752%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.320 Acc 92.188%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.154 Acc 95.498%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.156 Acc 95.410%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.159 Acc 95.331%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.159 Acc 95.375%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.159 Acc 95.362%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.169 Acc 95.583%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.165 Acc 95.573%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.157 Acc 95.575%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.157 Acc 95.612%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.157 Acc 95.528%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.157 Acc 95.488%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.156 Acc 95.506%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.173 Acc 95.568%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.171 Acc 95.542%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.149 Acc 95.436%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.155 Acc 95.340%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.155 Acc 95.450%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.155 Acc 95.451%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.157 Acc 95.439%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.170 Acc 95.599%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.166 Acc 95.713%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.161 Acc 95.452%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.155 Acc 95.581%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.157 Acc 95.541%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.157 Acc 95.560%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.159 Acc 95.501%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.169 Acc 95.498%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.149 Acc 95.645%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.150 Acc 95.666%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.153 Acc 95.653%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.154 Acc 95.566%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.156 Acc 95.545%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.168 Acc 95.738%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.164 Acc 95.814%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.155 Acc 95.484%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.152 Acc 95.608%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.153 Acc 95.642%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.154 Acc 95.590%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.168 Acc 95.599%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.162 Acc 95.791%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.152 Acc 95.800%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.155 Acc 95.655%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.152 Acc 95.629%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.152 Acc 95.611%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.152 Acc 95.589%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.192 Acc 95.166%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.187 Acc 95.114%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.145 Acc 95.877%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.145 Acc 95.837%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.148 Acc 95.738%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.150 Acc 95.667%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.151 Acc 95.613%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.164 Acc 95.769%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.158 Acc 95.923%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.174 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.142 Acc 95.800%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.147 Acc 95.748%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.150 Acc 95.689%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.150 Acc 95.675%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.149 Acc 95.724%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.164 Acc 95.877%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.160 Acc 95.896%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.143 Acc 95.924%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.145 Acc 95.767%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.147 Acc 95.736%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.149 Acc 95.749%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.150 Acc 95.721%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.163 Acc 95.777%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.161 Acc 95.826%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.135 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.146 Acc 95.947%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.145 Acc 95.911%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.148 Acc 95.787%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.148 Acc 95.784%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.149 Acc 95.768%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.161 Acc 96.024%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.158 Acc 95.997%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.137 Acc 95.970%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.144 Acc 95.860%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.146 Acc 95.799%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.194 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.177 Acc 95.511%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.141 Acc 96.194%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.143 Acc 95.896%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.141 Acc 95.907%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.141 Acc 95.899%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.144 Acc 95.802%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.174 Acc 95.568%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.168 Acc 95.670%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.141 Acc 95.962%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.142 Acc 95.885%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.144 Acc 95.874%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.180 Acc 95.521%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.569%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.129 Acc 96.334%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.137 Acc 96.024%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.139 Acc 95.982%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.141 Acc 95.913%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.142 Acc 95.888%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.171 Acc 95.620%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.148 Acc 95.862%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.142 Acc 95.973%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.144 Acc 95.922%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.142 Acc 95.952%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.140 Acc 95.989%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.134 Acc 96.071%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.139 Acc 96.039%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.142 Acc 95.918%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.144 Acc 95.833%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.163 Acc 95.869%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.161 Acc 95.880%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.141 Acc 96.016%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.142 Acc 95.893%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.142 Acc 95.880%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.171 Acc 95.722%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.787%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.136 Acc 95.947%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.134 Acc 96.140%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.135 Acc 96.044%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.137 Acc 96.107%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.139 Acc 96.045%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.169 Acc 95.560%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 95.592%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.143 Acc 95.777%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.139 Acc 96.051%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.140 Acc 96.003%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.138 Acc 96.078%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.140 Acc 96.002%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.170 Acc 95.709%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.136 Acc 96.035%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.139 Acc 95.967%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.137 Acc 96.045%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.140 Acc 95.966%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.169 Acc 95.684%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.165 Acc 95.775%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.131 Acc 96.101%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.132 Acc 96.140%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.135 Acc 96.057%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.138 Acc 96.049%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.159 Acc 95.931%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.155 Acc 95.977%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.128 Acc 96.272%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.133 Acc 96.257%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.137 Acc 96.138%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.137 Acc 96.129%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.137 Acc 96.130%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.158 Acc 95.893%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.158 Acc 95.962%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.127 Acc 96.504%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.133 Acc 96.137%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.138 Acc 95.926%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.138 Acc 95.966%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.168 Acc 95.838%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.131 Acc 96.195%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.132 Acc 96.166%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.133 Acc 96.154%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.134 Acc 96.095%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.178 Acc 96.094%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.171 Acc 95.692%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.806%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.203 Acc 93.750%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.136 Acc 95.934%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.136 Acc 95.977%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.135 Acc 96.033%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.136 Acc 96.010%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.171 Acc 95.738%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.133 Acc 96.442%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.133 Acc 96.261%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.134 Acc 96.190%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.136 Acc 96.166%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.135 Acc 96.145%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.146 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.175 Acc 95.831%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.171 Acc 95.787%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.133 Acc 96.194%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.137 Acc 96.105%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.136 Acc 96.107%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.135 Acc 96.148%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.133 Acc 96.128%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.158 Acc 95.993%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.157 Acc 96.004%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.125 Acc 96.380%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.126 Acc 96.314%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.129 Acc 96.244%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.132 Acc 96.114%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.168 Acc 95.947%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.164 Acc 95.950%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.203 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.128 Acc 96.304%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.130 Acc 96.265%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.135 Acc 96.125%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.134 Acc 96.117%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.166 Acc 95.885%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.161 Acc 95.989%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.121 Acc 98.438%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.129 Acc 96.132%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.125 Acc 96.296%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.125 Acc 96.395%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.126 Acc 96.349%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.129 Acc 96.273%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.166 Acc 95.738%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.163 Acc 95.853%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.128 Acc 96.241%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.128 Acc 96.253%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.131 Acc 96.234%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.131 Acc 96.211%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.091 Acc 95.312%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.155 Acc 96.148%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.153 Acc 96.175%\n",
      "Saving..\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.127 Acc 96.465%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.129 Acc 96.265%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.126 Acc 96.353%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.126 Acc 96.363%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.129 Acc 96.314%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.163 Acc 95.893%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.158 Acc 96.024%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.124 Acc 96.875%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.124 Acc 96.388%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.125 Acc 96.315%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.125 Acc 96.377%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.126 Acc 96.367%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.127 Acc 96.321%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.170 Acc 95.869%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.165 Acc 95.919%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.124 Acc 96.511%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.126 Acc 96.358%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.128 Acc 96.353%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.128 Acc 96.386%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.128 Acc 96.396%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.167 Acc 96.055%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.162 Acc 96.137%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.119 Acc 96.519%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.121 Acc 96.498%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.125 Acc 96.390%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.128 Acc 96.259%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.128 Acc 96.268%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.169 Acc 95.763%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.122 Acc 96.467%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.124 Acc 96.353%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.125 Acc 96.359%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.127 Acc 96.334%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.164 Acc 95.962%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.158 Acc 96.035%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.124 Acc 96.504%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.126 Acc 96.405%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.127 Acc 96.353%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.128 Acc 96.324%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.128 Acc 96.292%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.173 Acc 95.645%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.171 Acc 95.705%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.124 Acc 96.473%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.121 Acc 96.506%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.122 Acc 96.468%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.124 Acc 96.464%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.126 Acc 96.376%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.176 Acc 95.575%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.171 Acc 95.767%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.121 Acc 96.511%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.124 Acc 96.447%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.124 Acc 96.387%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.124 Acc 96.409%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.127 Acc 96.339%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.168 Acc 95.792%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.165 Acc 95.872%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.110 Acc 96.651%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.114 Acc 96.634%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.119 Acc 96.480%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.123 Acc 96.370%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.167 Acc 95.900%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.165 Acc 95.954%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.119 Acc 96.612%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.119 Acc 96.556%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.123 Acc 96.403%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.123 Acc 96.406%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.169 Acc 95.771%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.129 Acc 99.219%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.114 Acc 96.682%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.118 Acc 96.552%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.122 Acc 96.418%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.124 Acc 96.367%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.160 Acc 96.156%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.159 Acc 96.195%\n",
      "Saving..\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.119 Acc 96.542%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.121 Acc 96.556%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.124 Acc 96.468%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.123 Acc 96.478%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.123 Acc 96.457%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.166 Acc 95.916%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.162 Acc 96.016%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.111 Acc 96.790%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.114 Acc 96.813%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.120 Acc 96.548%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.119 Acc 96.596%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.120 Acc 96.498%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.171 Acc 95.692%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.166 Acc 95.775%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.117 Acc 96.705%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.115 Acc 96.770%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.115 Acc 96.724%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.117 Acc 96.655%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.120 Acc 96.537%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.162 Acc 95.993%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.158 Acc 96.070%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.171 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.121 Acc 96.364%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.125 Acc 96.234%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.125 Acc 96.317%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.124 Acc 96.367%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.124 Acc 96.342%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.167 Acc 95.970%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.166 Acc 95.962%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.118 Acc 96.720%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.120 Acc 96.661%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.119 Acc 96.602%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.122 Acc 96.548%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.122 Acc 96.507%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.163 Acc 96.063%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.159 Acc 96.156%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.182 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.115 Acc 96.604%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.116 Acc 96.580%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.117 Acc 96.566%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.120 Acc 96.462%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.121 Acc 96.431%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.166 Acc 95.939%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.163 Acc 96.012%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.114 Acc 96.767%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.112 Acc 96.758%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.115 Acc 96.605%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.119 Acc 96.509%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.121 Acc 96.456%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.163 Acc 96.035%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.120 Acc 96.457%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.119 Acc 96.471%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.120 Acc 96.499%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.120 Acc 96.470%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [105/200]Batch [500/573] Loss: 0.119 Acc 96.510%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.166 Acc 95.985%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.163 Acc 96.008%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.120 Acc 96.517%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.121 Acc 96.525%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.119 Acc 96.546%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.119 Acc 96.538%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.167 Acc 95.823%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.162 Acc 95.946%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.121 Acc 95.312%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.119 Acc 96.566%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.119 Acc 96.673%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.117 Acc 96.704%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.117 Acc 96.647%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.119 Acc 96.569%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.170 Acc 95.854%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.165 Acc 95.973%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.118 Acc 96.627%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.119 Acc 96.549%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.118 Acc 96.493%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.117 Acc 96.517%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.118 Acc 96.502%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.172 Acc 95.699%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.168 Acc 95.787%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.113 Acc 96.697%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.113 Acc 96.708%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.112 Acc 96.735%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.111 Acc 96.766%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.114 Acc 96.668%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.173 Acc 95.746%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.169 Acc 95.833%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.112 Acc 96.751%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.114 Acc 96.745%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.115 Acc 96.696%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.117 Acc 96.635%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.166 Acc 95.884%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.118 Acc 96.560%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.119 Acc 96.548%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.117 Acc 96.589%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.117 Acc 96.548%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.176 Acc 95.514%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.173 Acc 95.713%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.113 Acc 94.531%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.121 Acc 96.442%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.116 Acc 96.603%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.115 Acc 96.608%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.115 Acc 96.602%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.115 Acc 96.593%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.169 Acc 96.009%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.109 Acc 96.798%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.112 Acc 96.667%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.113 Acc 96.672%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.113 Acc 96.686%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.172 Acc 95.862%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.106 Acc 96.798%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.109 Acc 96.828%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.109 Acc 96.803%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.111 Acc 96.730%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.164 Acc 95.908%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.163 Acc 95.997%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.115 Acc 96.635%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.114 Acc 96.595%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.115 Acc 96.643%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.114 Acc 96.668%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 95.893%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.169 Acc 95.934%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.110 Acc 96.759%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.110 Acc 96.782%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.109 Acc 96.867%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.110 Acc 96.834%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.111 Acc 96.761%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.175 Acc 95.730%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.171 Acc 95.853%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.107 Acc 96.786%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.108 Acc 96.826%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.112 Acc 96.705%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.169 Acc 95.792%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.167 Acc 95.880%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.121 Acc 96.395%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.116 Acc 96.704%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.113 Acc 96.771%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.111 Acc 96.762%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.112 Acc 96.756%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.169 Acc 95.854%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.165 Acc 95.962%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.104 Acc 96.860%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.109 Acc 96.782%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.110 Acc 96.766%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.110 Acc 96.776%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.109 Acc 96.767%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.166 Acc 95.955%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.163 Acc 96.059%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.108 Acc 99.219%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.108 Acc 96.983%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.112 Acc 96.727%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.114 Acc 96.696%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.112 Acc 96.709%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.113 Acc 96.680%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.175 Acc 95.854%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.170 Acc 95.958%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.102 Acc 96.852%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.106 Acc 96.909%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.106 Acc 96.879%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.166 Acc 95.924%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.162 Acc 95.989%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.102 Acc 97.192%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.105 Acc 96.941%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.108 Acc 96.805%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.108 Acc 96.815%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.108 Acc 96.814%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.176 Acc 95.606%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.110 Acc 96.712%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.110 Acc 96.649%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.110 Acc 96.668%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.111 Acc 96.668%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.175 Acc 95.769%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.170 Acc 95.853%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.105 Acc 96.824%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.108 Acc 96.737%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.109 Acc 96.696%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.108 Acc 96.752%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.172 Acc 95.838%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.168 Acc 95.868%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.107 Acc 96.999%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.106 Acc 97.023%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.106 Acc 97.015%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.106 Acc 96.941%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.107 Acc 96.880%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.168 Acc 96.024%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.164 Acc 96.109%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.107 Acc 96.782%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.105 Acc 96.854%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.107 Acc 96.811%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.108 Acc 96.746%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.924%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.169 Acc 96.032%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.103 Acc 97.037%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.104 Acc 96.914%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.106 Acc 96.852%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.107 Acc 96.830%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.107 Acc 96.783%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.168 Acc 96.140%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.162 Acc 96.171%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.099 Acc 96.929%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.105 Acc 96.755%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.104 Acc 96.800%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.105 Acc 96.811%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.106 Acc 96.811%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.168 Acc 95.993%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.104 Acc 97.022%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.103 Acc 96.894%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.104 Acc 96.898%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.104 Acc 96.918%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.106 Acc 96.834%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.144 Acc 93.750%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.164 Acc 96.024%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.181 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.100 Acc 97.123%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.101 Acc 97.015%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.101 Acc 97.031%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.104 Acc 96.992%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.106 Acc 96.894%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.167 Acc 95.978%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.163 Acc 96.035%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.105 Acc 96.829%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.103 Acc 96.863%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.106 Acc 96.848%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.106 Acc 96.814%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.171 Acc 95.862%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.169 Acc 95.876%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.110 Acc 96.929%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.109 Acc 96.898%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.108 Acc 96.917%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.106 Acc 96.965%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.106 Acc 96.972%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.181 Acc 95.838%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.175 Acc 95.798%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.108 Acc 96.914%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.102 Acc 97.062%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.102 Acc 97.096%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.103 Acc 97.043%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.103 Acc 97.032%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.171 Acc 96.032%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.950%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.101 Acc 96.921%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.102 Acc 96.940%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.101 Acc 97.013%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.102 Acc 96.965%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.168 Acc 96.086%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.166 Acc 96.098%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.093 Acc 97.130%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.097 Acc 97.163%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.097 Acc 97.194%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.099 Acc 97.066%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.101 Acc 97.029%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.838%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.173 Acc 95.791%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.105 Acc 96.857%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.104 Acc 96.906%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.142 Acc 96.875%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.175 Acc 95.978%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.168 Acc 96.117%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.191 Acc 92.969%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.096 Acc 97.246%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.097 Acc 97.151%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.100 Acc 97.015%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.103 Acc 96.918%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.103 Acc 96.906%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.165 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.175 Acc 95.900%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.171 Acc 95.946%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.137 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.096 Acc 97.022%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.097 Acc 97.062%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.100 Acc 97.000%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.102 Acc 96.956%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.168 Acc 95.934%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.091 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.105 Acc 96.941%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.105 Acc 96.948%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.103 Acc 96.957%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.103 Acc 96.920%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.108 Acc 96.875%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.931%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 96.078%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.096 Acc 97.208%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.098 Acc 97.065%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.100 Acc 97.031%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.101 Acc 97.058%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.101 Acc 97.028%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.177 Acc 95.800%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.169 Acc 96.016%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.090 Acc 97.262%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.099 Acc 97.050%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.100 Acc 97.059%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.100 Acc 97.050%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.101 Acc 97.000%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.167 Acc 96.040%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.162 Acc 96.168%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.096 Acc 97.053%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.097 Acc 97.101%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.099 Acc 97.066%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.101 Acc 97.026%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.174 Acc 95.985%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.167 Acc 96.129%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.099 Acc 97.006%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.096 Acc 97.058%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.097 Acc 97.044%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.100 Acc 96.961%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.100 Acc 96.967%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.182 Acc 95.591%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.176 Acc 95.767%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.089 Acc 97.393%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.096 Acc 97.030%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.099 Acc 97.029%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.169 Acc 95.993%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.163 Acc 96.133%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.099 Acc 96.960%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.093 Acc 97.225%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.095 Acc 97.186%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.095 Acc 97.152%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.097 Acc 97.101%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.177 Acc 95.823%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.171 Acc 95.962%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.097 Acc 97.169%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.101 Acc 96.957%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.100 Acc 97.009%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.182 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.181 Acc 95.808%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.176 Acc 95.826%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.096 Acc 97.184%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.093 Acc 97.229%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.096 Acc 97.148%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.097 Acc 97.037%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.173 Acc 95.939%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.169 Acc 95.981%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.168 Acc 95.312%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.097 Acc 97.153%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.098 Acc 97.100%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.099 Acc 97.116%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.099 Acc 97.099%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.099 Acc 97.110%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.175 Acc 95.684%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.172 Acc 95.779%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.103 Acc 96.728%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.098 Acc 97.011%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.096 Acc 97.114%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.097 Acc 97.089%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.098 Acc 97.078%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.939%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 96.000%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.097 Acc 96.883%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.097 Acc 96.999%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.096 Acc 97.023%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.097 Acc 97.029%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.097 Acc 97.062%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.182 Acc 95.777%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.178 Acc 95.861%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.098 Acc 96.867%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.096 Acc 97.028%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.098 Acc 97.037%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.169 Acc 96.032%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.165 Acc 96.039%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.094 Acc 97.099%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.094 Acc 97.167%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.096 Acc 97.101%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.097 Acc 97.052%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.099 Acc 97.045%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.198 Acc 95.475%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.190 Acc 95.588%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.034 Acc 100.000%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.099 Acc 96.852%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.100 Acc 96.929%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.100 Acc 96.909%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.100 Acc 96.984%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.099 Acc 97.004%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.171 Acc 95.993%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.168 Acc 96.012%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.087 Acc 97.285%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.091 Acc 97.167%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.093 Acc 97.163%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.093 Acc 97.136%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.094 Acc 97.148%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.180 Acc 95.792%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.176 Acc 95.756%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.087 Acc 97.285%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.093 Acc 97.240%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.093 Acc 97.197%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.094 Acc 97.157%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.096 Acc 97.135%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.173 Acc 95.955%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.169 Acc 96.008%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.091 Acc 97.300%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.094 Acc 97.209%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.094 Acc 97.181%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.096 Acc 97.156%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.095 Acc 97.167%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.188 Acc 95.753%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.183 Acc 95.802%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.092 Acc 97.153%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.096 Acc 97.111%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.096 Acc 97.048%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.095 Acc 97.065%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.188 Acc 95.627%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.089 Acc 97.262%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.091 Acc 97.170%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.092 Acc 97.212%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.095 Acc 97.161%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.095 Acc 97.170%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.171 Acc 95.939%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.168 Acc 95.997%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.088 Acc 97.362%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.090 Acc 97.329%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.091 Acc 97.265%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.094 Acc 97.192%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.174 Acc 95.934%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.092 Acc 97.324%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.094 Acc 97.163%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.095 Acc 97.134%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.094 Acc 97.163%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.177 Acc 96.024%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.171 Acc 96.102%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.094 Acc 97.061%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.095 Acc 97.120%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.094 Acc 97.127%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.093 Acc 97.140%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.182 Acc 95.707%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.178 Acc 95.818%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.096 Acc 97.068%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.092 Acc 97.213%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.091 Acc 97.244%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.090 Acc 97.222%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.092 Acc 97.163%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.177 Acc 95.869%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.173 Acc 95.954%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.093 Acc 97.123%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.092 Acc 97.217%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.094 Acc 97.145%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.094 Acc 97.124%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.095 Acc 97.100%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.185 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.182 Acc 95.864%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.088 Acc 97.269%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.089 Acc 97.317%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.090 Acc 97.243%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.180 Acc 95.746%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.176 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.087 Acc 97.370%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.090 Acc 97.277%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.091 Acc 97.247%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.091 Acc 97.240%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.178 Acc 95.730%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.174 Acc 95.783%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.090 Acc 97.153%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.087 Acc 97.252%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.092 Acc 97.171%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.092 Acc 97.181%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.092 Acc 97.188%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.181 Acc 95.800%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.175 Acc 95.884%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.185 Acc 96.875%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.089 Acc 97.163%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.088 Acc 97.228%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.088 Acc 97.232%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.091 Acc 97.185%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.179 Acc 95.985%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.173 Acc 96.059%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.089 Acc 97.361%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.088 Acc 97.368%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.088 Acc 97.350%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.090 Acc 97.274%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.661%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.090 Acc 97.347%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.088 Acc 97.407%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.088 Acc 97.364%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.089 Acc 97.349%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.173 Acc 95.924%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.169 Acc 96.074%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.082 Acc 97.409%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.087 Acc 97.264%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.089 Acc 97.199%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.089 Acc 97.233%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.089 Acc 97.252%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.172 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.185 Acc 95.955%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.182 Acc 95.958%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.200 Acc 95.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.084 Acc 97.509%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.086 Acc 97.376%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.089 Acc 97.237%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.090 Acc 97.235%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.182 Acc 95.808%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.175 Acc 95.861%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.080 Acc 97.579%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.083 Acc 97.454%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.086 Acc 97.415%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.088 Acc 97.331%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.088 Acc 97.326%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.179 Acc 96.001%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.175 Acc 96.148%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.091 Acc 97.231%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.091 Acc 97.128%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.091 Acc 97.186%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.090 Acc 97.249%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.090 Acc 97.280%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.182 Acc 95.893%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.175 Acc 96.028%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.084 Acc 97.502%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.091 Acc 97.209%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.091 Acc 97.166%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.089 Acc 97.210%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.090 Acc 97.204%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.178 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.183 Acc 95.722%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.177 Acc 95.903%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.093 Acc 97.223%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.086 Acc 97.396%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.088 Acc 97.293%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.088 Acc 97.288%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.089 Acc 97.285%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.184 Acc 95.753%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.179 Acc 95.907%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.084 Acc 97.416%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.085 Acc 97.345%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.087 Acc 97.298%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.088 Acc 97.301%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.184 Acc 95.869%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.178 Acc 95.888%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.087 Acc 97.471%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.089 Acc 97.338%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.088 Acc 97.334%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.089 Acc 97.329%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.091 Acc 97.259%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.885%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.172 Acc 95.942%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.141 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.091 Acc 97.293%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.090 Acc 97.223%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.089 Acc 97.237%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.089 Acc 97.227%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.195 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.188 Acc 95.668%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.185 Acc 95.748%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.083 Acc 97.466%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.084 Acc 97.451%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.085 Acc 97.401%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.182 Acc 95.823%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.177 Acc 95.938%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.087 Acc 97.316%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.088 Acc 97.303%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.088 Acc 97.273%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.189 Acc 95.707%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.186 Acc 95.709%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.086 Acc 97.347%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.086 Acc 97.322%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.085 Acc 97.392%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.086 Acc 97.345%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.086 Acc 97.349%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.179 Acc 95.931%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.176 Acc 95.977%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.087 Acc 97.231%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.086 Acc 97.358%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.086 Acc 97.346%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.087 Acc 97.309%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.185 Acc 95.784%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.180 Acc 95.857%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.082 Acc 97.455%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.085 Acc 97.404%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.086 Acc 97.397%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.087 Acc 97.368%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.205 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.184 Acc 95.800%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.178 Acc 95.915%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.085 Acc 97.447%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.083 Acc 97.516%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.085 Acc 97.446%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.085 Acc 97.422%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.085 Acc 97.424%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.187 Acc 95.645%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.182 Acc 95.845%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.083 Acc 97.454%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.084 Acc 97.449%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.085 Acc 97.442%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.084 Acc 97.478%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.185 Acc 95.753%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.182 Acc 95.857%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.082 Acc 97.579%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.080 Acc 97.590%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.083 Acc 97.485%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.084 Acc 97.401%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.084 Acc 97.379%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.186 Acc 95.800%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.181 Acc 95.927%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.078 Acc 97.579%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.081 Acc 97.547%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.083 Acc 97.463%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.208 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.196 Acc 95.614%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.187 Acc 95.775%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.079 Acc 97.486%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.083 Acc 97.388%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.082 Acc 97.420%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.082 Acc 97.446%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.084 Acc 97.371%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.185 Acc 95.808%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.184 Acc 95.896%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.077 Acc 97.679%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.077 Acc 97.695%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.083 Acc 97.479%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.083 Acc 97.464%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.181 Acc 95.978%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.179 Acc 96.074%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.082 Acc 97.447%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.083 Acc 97.516%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.085 Acc 97.423%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.085 Acc 97.368%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.084 Acc 97.382%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.185 Acc 95.862%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.179 Acc 95.985%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.076 Acc 97.540%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.077 Acc 97.551%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.081 Acc 97.451%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.082 Acc 97.446%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.084 Acc 97.354%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.165 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.191 Acc 95.591%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.185 Acc 95.775%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.177 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.079 Acc 97.679%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.082 Acc 97.485%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.083 Acc 97.436%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.082 Acc 97.481%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.083 Acc 97.463%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.183 Acc 95.900%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.179 Acc 95.934%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.106 Acc 94.531%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.077 Acc 97.509%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.082 Acc 97.514%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.083 Acc 97.474%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.174 Acc 96.101%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.170 Acc 96.109%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.085 Acc 97.324%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.085 Acc 97.322%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.084 Acc 97.290%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.085 Acc 97.304%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.084 Acc 97.337%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.188 Acc 96.016%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.180 Acc 96.067%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.077 Acc 97.795%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.082 Acc 97.532%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.081 Acc 97.501%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.082 Acc 97.461%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.082 Acc 97.482%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.191 Acc 95.808%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.185 Acc 95.931%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.075 Acc 97.718%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [200/573] Loss: 0.076 Acc 97.606%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.079 Acc 97.612%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.082 Acc 97.553%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.083 Acc 97.486%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.182 Acc 95.730%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.132 Acc 94.531%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.076 Acc 97.401%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.081 Acc 97.361%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.081 Acc 97.417%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.082 Acc 97.419%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.083 Acc 97.405%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.185 Acc 95.792%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.182 Acc 95.853%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.079 Acc 97.587%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.082 Acc 97.435%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.082 Acc 97.425%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.081 Acc 97.469%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.083 Acc 97.404%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.190 Acc 95.753%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.185 Acc 95.919%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.083 Acc 97.625%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.080 Acc 97.629%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.082 Acc 97.558%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.082 Acc 97.553%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.081 Acc 97.567%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.174 Acc 96.117%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074af0a5984948e88e674dac2b2c88a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.310 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.240 Acc 18.975%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.898%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.240 Acc 18.816%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.239 Acc 18.840%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.220 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.221 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.277 Acc 17.188%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.231 Acc 18.696%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.226 Acc 19.026%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.194 Acc 20.416%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.137 Acc 22.765%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.069 Acc 25.787%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.452 Acc 54.688%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.411 Acc 54.100%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.412 Acc 54.023%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.561 Acc 45.312%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.437 Acc 52.081%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.369 Acc 54.019%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.306 Acc 56.240%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.257 Acc 58.031%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.218 Acc 59.433%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.977 Acc 67.969%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.926 Acc 69.980%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.922 Acc 69.963%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.128 Acc 62.500%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.948 Acc 69.237%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.936 Acc 69.706%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.912 Acc 70.606%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.898 Acc 71.080%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.883 Acc 71.526%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.764 Acc 76.562%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.681 Acc 78.473%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.675 Acc 78.455%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.635 Acc 82.812%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.754 Acc 76.075%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.745 Acc 76.345%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.735 Acc 76.630%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.722 Acc 76.991%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.713 Acc 77.320%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.644 Acc 81.250%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.574 Acc 81.946%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.566 Acc 82.012%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.714 Acc 77.344%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.643 Acc 79.672%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.628 Acc 80.096%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.626 Acc 80.238%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.618 Acc 80.510%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.612 Acc 80.757%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.516 Acc 85.938%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.467 Acc 85.659%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.462 Acc 85.599%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.509 Acc 82.812%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.577 Acc 81.784%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.568 Acc 82.008%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.564 Acc 82.267%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.555 Acc 82.501%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.547 Acc 82.753%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.409 Acc 88.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.418 Acc 87.593%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.414 Acc 87.547%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.497 Acc 83.594%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.512 Acc 84.120%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.507 Acc 84.107%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.506 Acc 84.160%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.502 Acc 84.320%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.498 Acc 84.381%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.364 Acc 89.844%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.381 Acc 88.521%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.377 Acc 88.569%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.388 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.475 Acc 85.087%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.476 Acc 85.211%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.475 Acc 85.263%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.471 Acc 85.359%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.468 Acc 85.481%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.356 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.352 Acc 89.542%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.349 Acc 89.498%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.363 Acc 88.281%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.444 Acc 86.270%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.437 Acc 86.451%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.435 Acc 86.584%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.437 Acc 86.491%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.437 Acc 86.446%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.370 Acc 89.062%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.344 Acc 89.627%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.339 Acc 89.646%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.413 Acc 85.938%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.429 Acc 86.719%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.421 Acc 86.960%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.419 Acc 87.007%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.422 Acc 87.044%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.420 Acc 87.096%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.317 Acc 89.062%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.335 Acc 90.231%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.330 Acc 90.314%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.530 Acc 87.500%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.407 Acc 87.446%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.397 Acc 87.799%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.400 Acc 87.653%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.397 Acc 87.708%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.397 Acc 87.765%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.365 Acc 89.062%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.320 Acc 90.463%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.316 Acc 90.547%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.320 Acc 90.625%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.388 Acc 88.041%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.385 Acc 88.106%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.381 Acc 88.214%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.379 Acc 88.324%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.379 Acc 88.275%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.326 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.311 Acc 90.903%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.306 Acc 90.975%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.249 Acc 92.188%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.387 Acc 88.088%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.379 Acc 88.301%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.376 Acc 88.367%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.373 Acc 88.490%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.370 Acc 88.601%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.268 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.291 Acc 91.538%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.286 Acc 91.752%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.358 Acc 87.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.353 Acc 89.101%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.349 Acc 89.199%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.353 Acc 89.133%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.350 Acc 89.197%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.354 Acc 89.098%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.274 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.281 Acc 91.677%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.276 Acc 91.818%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.400 Acc 87.500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.344 Acc 89.697%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.341 Acc 89.649%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.341 Acc 89.558%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.341 Acc 89.518%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.342 Acc 89.469%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.276 Acc 89.844%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.294 Acc 91.638%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.287 Acc 91.667%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.251 Acc 93.750%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.331 Acc 89.975%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.334 Acc 89.910%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.333 Acc 89.870%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.337 Acc 89.768%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.336 Acc 89.780%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.270 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.261 Acc 92.551%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.258 Acc 92.561%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.316 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.327 Acc 90.207%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.331 Acc 90.019%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.330 Acc 89.857%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.328 Acc 89.992%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.323 Acc 90.078%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.255 Acc 93.038%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.252 Acc 92.973%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.314 Acc 94.531%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.305 Acc 90.401%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.307 Acc 90.431%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.307 Acc 90.602%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.307 Acc 90.629%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.311 Acc 90.564%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.246 Acc 90.625%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.258 Acc 92.744%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.252 Acc 92.817%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.386 Acc 84.375%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.310 Acc 90.563%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.311 Acc 90.574%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.312 Acc 90.532%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.310 Acc 90.551%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.310 Acc 90.597%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.234 Acc 90.625%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.252 Acc 92.783%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.247 Acc 92.910%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.243 Acc 92.969%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.306 Acc 90.896%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.303 Acc 90.998%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.302 Acc 91.020%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.299 Acc 91.104%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.298 Acc 91.085%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.249 Acc 93.015%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.246 Acc 92.942%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.192 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.290 Acc 91.012%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.292 Acc 91.056%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.294 Acc 91.121%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.291 Acc 91.188%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.294 Acc 91.152%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.233 Acc 90.625%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.228 Acc 93.711%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.227 Acc 93.556%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.277 Acc 91.399%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.284 Acc 91.115%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.287 Acc 91.219%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.289 Acc 91.200%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.287 Acc 91.250%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.232 Acc 93.518%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.229 Acc 93.435%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.240 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.282 Acc 91.662%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.281 Acc 91.546%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.285 Acc 91.440%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.283 Acc 91.424%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.283 Acc 91.447%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.236 Acc 93.572%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.233 Acc 93.435%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.260 Acc 90.625%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.270 Acc 91.948%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.273 Acc 91.810%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.275 Acc 91.816%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.277 Acc 91.761%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.277 Acc 91.734%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.199 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.219 Acc 94.121%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.216 Acc 94.045%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.282 Acc 91.855%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.277 Acc 91.888%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.274 Acc 91.951%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.273 Acc 91.956%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.272 Acc 91.957%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.216 Acc 91.406%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.229 Acc 93.874%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.227 Acc 93.664%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.275 Acc 91.878%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.271 Acc 92.153%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.273 Acc 91.988%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.270 Acc 91.993%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.267 Acc 92.086%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.219 Acc 90.625%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.221 Acc 93.974%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.218 Acc 93.874%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.167 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.257 Acc 92.412%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.257 Acc 92.460%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.259 Acc 92.330%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.263 Acc 92.254%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.261 Acc 92.292%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.216 Acc 94.338%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.211 Acc 94.267%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.230 Acc 92.969%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.252 Acc 92.474%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.257 Acc 92.277%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.252 Acc 92.429%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.254 Acc 92.441%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.257 Acc 92.315%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.224 Acc 93.781%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.222 Acc 93.812%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.260 Acc 92.242%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.254 Acc 92.374%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.255 Acc 92.494%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.256 Acc 92.462%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.255 Acc 92.498%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.213 Acc 94.253%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.210 Acc 94.189%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.234 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.260 Acc 92.195%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.256 Acc 92.374%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.252 Acc 92.465%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.253 Acc 92.449%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.253 Acc 92.473%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.211 Acc 94.330%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.209 Acc 94.267%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.248 Acc 92.698%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.248 Acc 92.654%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.246 Acc 92.681%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.251 Acc 92.628%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.250 Acc 92.652%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.173 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.205 Acc 94.562%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.202 Acc 94.504%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.330 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.244 Acc 92.752%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.241 Acc 92.774%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.245 Acc 92.701%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.246 Acc 92.741%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.249 Acc 92.702%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.210 Acc 94.400%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.211 Acc 94.248%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.184 Acc 91.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.231 Acc 92.938%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.239 Acc 92.949%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.240 Acc 92.844%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.240 Acc 92.786%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.241 Acc 92.791%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.547%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.201 Acc 94.578%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.312 Acc 92.188%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.243 Acc 92.984%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.244 Acc 92.771%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.239 Acc 92.943%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.238 Acc 92.994%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.239 Acc 92.970%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.933%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.192 Acc 94.951%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.279 Acc 92.188%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.231 Acc 93.394%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.232 Acc 93.136%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.234 Acc 93.119%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.233 Acc 93.169%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.234 Acc 93.154%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.205 Acc 94.585%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.203 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.221 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.226 Acc 93.626%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.232 Acc 93.412%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.232 Acc 93.335%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.233 Acc 93.238%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.232 Acc 93.254%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.189 Acc 95.011%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.187 Acc 94.935%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.223 Acc 93.572%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.225 Acc 93.330%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.230 Acc 93.241%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.231 Acc 93.216%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.232 Acc 93.200%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.197 Acc 94.864%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.196 Acc 94.726%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.227 Acc 93.294%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.227 Acc 93.315%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.298%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.227 Acc 93.288%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.228 Acc 93.239%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.200 Acc 94.756%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.198 Acc 94.656%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.356 Acc 90.625%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.233 Acc 93.170%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.225 Acc 93.509%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.228 Acc 93.392%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.226 Acc 93.405%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.224 Acc 93.437%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.208 Acc 92.188%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.200 Acc 94.817%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.198 Acc 94.675%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.243 Acc 89.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.226 Acc 93.332%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.219 Acc 93.474%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.222 Acc 93.477%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.221 Acc 93.458%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.220 Acc 93.532%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.206 Acc 94.500%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.206 Acc 94.415%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.266 Acc 91.406%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.223 Acc 93.425%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.223 Acc 93.521%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.225 Acc 93.457%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.224 Acc 93.456%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.224 Acc 93.497%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.202 Acc 94.756%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.201 Acc 94.652%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.292 Acc 92.188%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.215 Acc 93.611%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.222 Acc 93.493%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.218 Acc 93.623%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.218 Acc 93.674%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.219 Acc 93.574%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.201 Acc 94.640%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.199 Acc 94.617%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.228 Acc 91.406%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.209 Acc 93.858%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.206 Acc 93.882%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.210 Acc 93.882%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.211 Acc 93.914%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.213 Acc 93.847%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.195 Acc 94.856%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.192 Acc 94.897%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.210 Acc 93.634%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.215 Acc 93.575%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.211 Acc 93.776%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.211 Acc 93.826%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.213 Acc 93.759%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.202 Acc 94.632%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.201 Acc 94.535%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.083 Acc 99.219%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.210 Acc 93.827%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.212 Acc 93.781%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.214 Acc 93.706%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.214 Acc 93.713%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.213 Acc 93.789%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.182 Acc 95.405%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.279 Acc 93.750%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.200 Acc 94.121%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.202 Acc 94.201%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.207 Acc 94.087%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.211 Acc 93.999%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.211 Acc 93.943%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.189 Acc 94.995%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.187 Acc 95.005%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.305 Acc 90.625%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.200 Acc 93.881%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.202 Acc 94.135%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.208 Acc 94.015%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.210 Acc 93.982%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.210 Acc 93.959%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.186 Acc 95.150%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.185 Acc 94.951%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.191 Acc 94.477%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.205 Acc 94.073%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.206 Acc 94.108%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.209 Acc 94.048%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.207 Acc 94.098%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.188 Acc 95.166%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.186 Acc 95.173%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.320 Acc 89.844%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.197 Acc 94.291%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.207 Acc 93.975%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.205 Acc 94.010%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.205 Acc 94.027%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.208 Acc 93.962%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.183 Acc 95.142%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.182 Acc 95.079%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.269 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.196 Acc 94.276%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.198 Acc 94.352%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.201 Acc 94.282%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.202 Acc 94.249%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.204 Acc 94.140%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.194 Acc 94.926%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.195 Acc 94.850%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.295 Acc 94.531%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.208 Acc 94.129%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.207 Acc 94.042%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.207 Acc 94.002%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.205 Acc 94.046%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.202 Acc 94.127%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.176 Acc 95.429%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.201 Acc 94.199%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.197 Acc 94.263%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.194 Acc 94.329%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.197 Acc 94.214%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.198 Acc 94.151%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.178 Acc 95.297%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.177 Acc 95.208%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.298 Acc 90.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.193 Acc 94.253%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.195 Acc 94.193%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.199 Acc 94.145%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.197 Acc 94.192%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.199 Acc 94.196%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.413%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.177 Acc 95.386%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.197 Acc 94.338%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.194 Acc 94.438%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.193 Acc 94.440%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.196 Acc 94.397%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.198 Acc 94.341%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.142 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.182 Acc 95.181%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.227%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.196 Acc 92.188%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.195 Acc 94.384%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.201 Acc 94.306%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.197 Acc 94.383%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.197 Acc 94.346%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.198 Acc 94.347%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.195 Acc 95.104%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.194 Acc 95.025%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.192 Acc 94.462%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.194 Acc 94.345%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.195 Acc 94.303%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.196 Acc 94.305%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.196 Acc 94.346%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.180 Acc 95.266%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.179 Acc 95.231%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.167 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.190 Acc 94.454%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.191 Acc 94.492%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.191 Acc 94.443%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.189 Acc 94.527%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.192 Acc 94.435%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.173 Acc 95.552%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.171 Acc 95.441%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.231 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.185 Acc 94.694%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.184 Acc 94.764%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.188 Acc 94.581%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.191 Acc 94.528%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.190 Acc 95.003%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.189 Acc 94.963%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.179 Acc 94.779%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.186 Acc 94.500%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.191 Acc 94.559%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.192 Acc 94.536%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.183 Acc 95.351%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.181 Acc 95.258%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.256 Acc 90.625%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.190 Acc 94.438%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.192 Acc 94.415%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.188 Acc 94.492%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.191 Acc 94.438%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.191 Acc 94.453%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.112 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.374%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.171 Acc 95.476%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.126 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.177 Acc 94.670%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.189 Acc 94.609%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.191 Acc 94.555%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.191 Acc 94.553%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.177 Acc 95.459%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.176 Acc 95.336%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.214 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.177 Acc 94.787%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.186 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.185 Acc 94.578%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.187 Acc 94.574%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.188 Acc 94.556%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.182 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.190 Acc 94.451%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.189 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.188 Acc 94.578%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.179 Acc 95.552%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.177 Acc 95.515%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.185 Acc 94.856%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.187 Acc 94.726%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.191 Acc 94.583%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.190 Acc 94.629%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.188 Acc 94.726%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.183 Acc 95.390%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.185 Acc 95.316%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.164 Acc 93.750%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.180 Acc 94.825%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.179 Acc 94.908%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.179 Acc 94.908%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.180 Acc 94.882%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.182 Acc 94.824%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.181 Acc 95.552%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.507%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.177 Acc 94.810%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.186 Acc 94.582%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.183 Acc 94.625%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.180 Acc 94.744%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.183 Acc 94.656%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.178 Acc 95.355%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.174 Acc 95.073%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.182 Acc 94.862%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.180 Acc 94.850%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.181 Acc 94.798%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.183 Acc 94.756%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.177 Acc 95.568%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.588%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.184 Acc 94.678%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.180 Acc 94.733%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.183 Acc 94.658%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.184 Acc 94.689%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.183 Acc 94.665%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.180 Acc 95.336%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.179 Acc 95.371%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.277 Acc 91.406%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.183 Acc 94.701%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.186 Acc 94.663%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.186 Acc 94.708%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.183 Acc 94.761%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.181 Acc 94.760%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.107 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.274%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.175 Acc 95.340%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.169 Acc 94.949%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.175 Acc 94.842%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.178 Acc 94.848%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.178 Acc 94.804%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.178 Acc 94.818%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.179 Acc 95.251%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.177 Acc 95.305%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.235 Acc 93.750%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.178 Acc 95.011%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.175 Acc 95.009%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.176 Acc 94.928%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.177 Acc 94.907%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.096 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.176 Acc 95.568%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.173 Acc 95.585%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.168 Acc 95.119%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.171 Acc 94.974%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.173 Acc 94.978%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.174 Acc 94.950%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.176 Acc 94.863%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.175 Acc 95.445%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.188 Acc 92.969%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.174 Acc 94.779%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.173 Acc 94.881%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.175 Acc 94.960%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.175 Acc 94.942%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.175 Acc 94.935%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.105 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.178 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.171 Acc 95.142%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 95.001%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.174 Acc 95.030%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.173 Acc 95.015%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.178 Acc 95.289%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.174 Acc 95.472%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.171 Acc 95.042%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.171 Acc 95.037%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.171 Acc 95.076%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.169 Acc 95.063%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.172 Acc 95.058%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.185 Acc 95.251%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.186 Acc 95.192%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.185 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.162 Acc 95.227%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.167 Acc 95.095%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.167 Acc 95.175%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.169 Acc 95.162%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.171 Acc 95.094%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.506%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.176 Acc 95.460%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.172 Acc 95.042%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.170 Acc 94.967%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.170 Acc 95.040%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.172 Acc 95.042%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.174 Acc 94.966%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.171 Acc 95.701%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.161 Acc 95.142%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.166 Acc 95.200%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.168 Acc 95.170%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.169 Acc 95.122%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.171 Acc 95.088%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.168 Acc 95.661%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.167 Acc 95.612%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.184 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.167 Acc 95.243%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.176%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.171 Acc 95.092%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.172 Acc 95.108%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.169 Acc 95.141%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.179 Acc 95.483%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.179 Acc 95.468%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.167 Acc 95.297%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.168 Acc 95.131%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.170 Acc 95.055%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.170 Acc 95.061%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.114 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.176 Acc 95.630%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.167 Acc 95.320%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.165 Acc 95.394%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.168 Acc 95.315%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.168 Acc 95.235%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.169 Acc 95.163%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.193 Acc 95.235%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.191 Acc 95.200%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.165 Acc 95.034%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.166 Acc 95.095%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.166 Acc 95.136%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.166 Acc 95.153%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.166 Acc 95.227%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.119 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.175 Acc 95.653%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.172 Acc 95.690%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.166 Acc 95.359%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.169 Acc 95.223%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.166 Acc 95.328%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.166 Acc 95.332%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.168 Acc 95.189%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.188 Acc 95.057%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.187 Acc 95.211%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.127 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.157 Acc 95.452%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.161 Acc 95.281%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.166 Acc 95.224%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.167 Acc 95.149%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.166 Acc 95.214%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.180 Acc 95.568%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.179 Acc 95.495%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.242 Acc 91.406%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.164 Acc 95.305%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.166 Acc 95.274%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.166 Acc 95.331%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.165 Acc 95.303%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.166 Acc 95.213%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.185 Acc 95.374%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.183 Acc 95.433%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.166 Acc 95.274%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.163 Acc 95.417%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.165 Acc 95.341%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.164 Acc 95.316%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.165 Acc 95.300%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.172 Acc 95.661%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.170 Acc 95.693%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.281 Acc 93.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.164 Acc 95.537%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.165 Acc 95.390%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.164 Acc 95.362%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.165 Acc 95.305%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.164 Acc 95.337%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.171 Acc 95.637%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.167 Acc 95.736%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.159 Acc 95.545%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.162 Acc 95.519%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.162 Acc 95.536%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.165 Acc 95.406%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.164 Acc 95.375%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.178 Acc 95.599%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.175 Acc 95.701%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.168 Acc 92.969%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.104%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.159 Acc 95.188%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.161 Acc 95.261%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.162 Acc 95.274%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.162 Acc 95.295%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.119 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.178 Acc 95.490%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.177 Acc 95.565%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.127 Acc 95.312%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.156 Acc 95.483%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.159 Acc 95.355%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.161 Acc 95.357%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.162 Acc 95.350%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.162 Acc 95.361%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.174 Acc 95.862%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.155 Acc 95.514%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.156 Acc 95.600%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.158 Acc 95.559%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.160 Acc 95.488%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.160 Acc 95.412%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.179 Acc 95.336%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.169 Acc 95.305%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.162 Acc 95.398%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.160 Acc 95.471%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.160 Acc 95.431%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.160 Acc 95.408%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.168 Acc 95.815%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.168 Acc 95.814%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.150 Acc 95.498%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.154 Acc 95.530%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.155 Acc 95.551%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.154 Acc 95.558%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.159 Acc 95.490%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.170 Acc 95.794%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.232 Acc 92.188%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.153 Acc 95.521%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.155 Acc 95.612%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.158 Acc 95.588%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.158 Acc 95.511%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.159 Acc 95.479%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.087 Acc 96.875%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.181 Acc 95.537%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.177 Acc 95.620%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.082 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.152 Acc 95.722%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.666%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.155 Acc 95.601%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.156 Acc 95.620%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.156 Acc 95.568%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.173 Acc 95.699%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.169 Acc 95.779%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.150 Acc 95.490%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.152 Acc 95.441%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.158 Acc 95.341%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.156 Acc 95.394%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.157 Acc 95.403%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.171 Acc 95.831%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.168 Acc 95.752%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.153 Acc 95.429%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.152 Acc 95.674%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.154 Acc 95.673%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.156 Acc 95.579%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.157 Acc 95.537%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.178 Acc 95.722%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.175 Acc 95.728%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.150 Acc 95.699%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.156 Acc 95.550%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.153 Acc 95.556%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.156 Acc 95.544%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.157 Acc 95.498%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.179 Acc 95.784%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.176 Acc 95.775%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.161 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.161 Acc 95.452%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.157 Acc 95.550%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.157 Acc 95.531%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.153 Acc 95.560%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.153 Acc 95.610%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.181 Acc 95.374%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.179 Acc 95.456%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.132 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.575%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.153 Acc 95.425%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.154 Acc 95.447%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.154 Acc 95.496%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.155 Acc 95.543%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.186 Acc 95.459%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.184 Acc 95.534%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.151 Acc 95.630%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.150 Acc 95.643%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.151 Acc 95.663%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.149 Acc 95.712%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.150 Acc 95.684%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.175 Acc 95.568%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.173 Acc 95.600%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.149 Acc 95.506%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.146 Acc 95.658%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.150 Acc 95.595%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.153 Acc 95.564%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.153 Acc 95.581%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.104 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.575%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.173 Acc 95.662%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.309 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.158 Acc 95.475%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.152 Acc 95.693%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.152 Acc 95.621%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.152 Acc 95.611%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.152 Acc 95.657%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.170 Acc 95.792%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.167 Acc 95.791%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.150 Acc 95.599%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.147 Acc 95.635%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.150 Acc 95.614%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.150 Acc 95.689%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.151 Acc 95.668%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.166 Acc 95.931%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.163 Acc 95.896%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.147 Acc 95.846%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.150 Acc 95.651%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.150 Acc 95.629%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.152 Acc 95.609%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.152 Acc 95.634%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.166 Acc 95.838%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.163 Acc 95.923%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.138 Acc 96.055%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.143 Acc 95.969%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.146 Acc 95.847%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.148 Acc 95.798%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.151 Acc 95.685%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.413%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.180 Acc 95.433%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.146 Acc 95.521%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.145 Acc 95.791%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.146 Acc 95.811%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.146 Acc 95.827%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.147 Acc 95.766%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.171 Acc 95.614%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.169 Acc 95.732%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.147 Acc 95.893%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.149 Acc 95.682%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.150 Acc 95.630%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.149 Acc 95.640%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.118 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.164 Acc 95.761%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.162 Acc 95.853%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.112 Acc 93.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.142 Acc 95.746%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.146 Acc 95.810%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.149 Acc 95.684%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.150 Acc 95.687%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.147 Acc 95.734%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.162 Acc 95.854%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.161 Acc 95.868%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.153 Acc 95.831%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.148 Acc 95.833%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.149 Acc 95.780%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.149 Acc 95.772%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.149 Acc 95.769%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.176 Acc 95.699%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.173 Acc 95.752%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.139 Acc 95.939%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.147 Acc 95.693%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.144 Acc 95.733%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.146 Acc 95.704%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.147 Acc 95.723%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.099 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.165 Acc 95.893%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.163 Acc 95.845%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.151 Acc 95.622%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.154 Acc 95.515%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.149 Acc 95.642%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.147 Acc 95.755%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.147 Acc 95.760%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.086 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 95.970%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.168 Acc 95.981%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.225 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.138 Acc 95.784%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.138 Acc 95.791%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.140 Acc 95.829%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.142 Acc 95.780%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.143 Acc 95.774%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.173 Acc 95.730%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.170 Acc 95.752%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.134 Acc 96.202%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.143 Acc 95.931%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.146 Acc 95.839%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.146 Acc 95.874%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.146 Acc 95.843%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.082 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.176 Acc 95.614%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.172 Acc 95.798%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.138 Acc 96.028%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.144 Acc 95.865%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.145 Acc 95.842%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.144 Acc 95.877%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.179 Acc 95.676%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.176 Acc 95.643%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.143 Acc 95.692%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.144 Acc 95.725%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.146 Acc 95.772%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.145 Acc 95.780%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.144 Acc 95.810%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.171 Acc 95.885%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.168 Acc 95.864%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.138 Acc 96.032%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.136 Acc 96.043%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.139 Acc 95.967%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.143 Acc 95.825%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.145 Acc 95.769%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.173 Acc 95.924%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.141 Acc 95.831%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.144 Acc 96.000%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.143 Acc 95.998%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.142 Acc 95.967%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.076 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.174 Acc 95.784%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.172 Acc 95.705%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.131 Acc 95.978%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.141 Acc 95.943%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.142 Acc 95.885%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.142 Acc 95.900%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.142 Acc 95.978%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.139 Acc 96.021%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.141 Acc 95.989%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.142 Acc 95.966%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.181 Acc 95.560%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.178 Acc 95.620%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.132 Acc 95.962%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.137 Acc 95.954%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.136 Acc 95.967%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.139 Acc 95.895%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.141 Acc 95.885%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.172 Acc 95.715%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.167 Acc 95.725%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.140 Acc 95.862%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.141 Acc 95.933%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.143 Acc 95.866%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.142 Acc 95.874%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.168 Acc 95.818%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.139 Acc 96.241%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.137 Acc 96.028%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.137 Acc 96.008%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.136 Acc 96.066%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.138 Acc 96.017%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.183 Acc 95.498%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.179 Acc 95.631%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.137 Acc 96.032%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.131 Acc 96.218%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.133 Acc 96.169%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.137 Acc 96.057%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.138 Acc 96.038%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.178 Acc 95.591%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.173 Acc 95.697%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.171 Acc 94.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.141 Acc 96.071%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.140 Acc 96.028%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.142 Acc 95.881%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.141 Acc 95.918%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.140 Acc 95.933%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.183 Acc 95.692%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.180 Acc 95.752%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.162 Acc 93.750%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.136 Acc 95.924%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.142 Acc 95.888%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.142 Acc 95.954%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.141 Acc 95.959%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.140 Acc 96.002%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.114 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.885%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.168 Acc 95.888%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.128 Acc 96.194%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.137 Acc 95.977%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.135 Acc 95.930%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.138 Acc 95.891%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.138 Acc 95.910%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.166 Acc 95.854%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.162 Acc 95.911%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.207 Acc 92.188%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.133 Acc 96.129%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.135 Acc 96.070%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.138 Acc 95.952%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.138 Acc 95.953%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.171 Acc 95.800%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.135 Acc 96.202%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.134 Acc 96.143%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.133 Acc 96.150%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.135 Acc 96.103%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.080 Acc 96.875%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.181 Acc 95.661%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.713%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.332 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.140 Acc 96.028%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.139 Acc 96.081%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.137 Acc 96.098%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.136 Acc 96.092%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.172 Acc 95.872%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.137 Acc 96.179%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.138 Acc 96.144%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.137 Acc 96.104%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.135 Acc 96.139%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.134 Acc 96.181%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.167 Acc 96.109%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.166 Acc 95.981%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.120 Acc 96.581%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.129 Acc 96.385%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.130 Acc 96.278%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.134 Acc 96.166%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.136 Acc 96.106%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.184 Acc 95.606%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.181 Acc 95.588%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.221 Acc 91.406%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.135 Acc 96.183%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.133 Acc 96.270%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.132 Acc 96.254%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.134 Acc 96.192%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.173 Acc 95.769%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.946%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.134 Acc 96.047%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.133 Acc 96.168%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.131 Acc 96.166%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.133 Acc 96.150%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.135 Acc 96.056%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.089 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.169 Acc 95.630%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.167 Acc 95.783%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.132 Acc 96.310%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.128 Acc 96.327%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.133 Acc 96.161%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.134 Acc 96.207%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.132 Acc 96.243%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.177 Acc 95.753%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.174 Acc 95.736%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.126 Acc 96.310%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.130 Acc 96.280%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.129 Acc 96.273%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.133 Acc 96.162%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.133 Acc 96.126%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.099 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.186 Acc 95.568%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.185 Acc 95.635%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.127 Acc 96.241%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.130 Acc 96.117%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.133 Acc 96.078%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.133 Acc 96.053%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.184 Acc 95.885%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.183 Acc 95.853%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.127 Acc 96.349%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.125 Acc 96.428%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.127 Acc 96.403%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.129 Acc 96.337%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.131 Acc 96.303%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.177 Acc 95.715%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.173 Acc 95.849%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.135 Acc 96.140%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.132 Acc 96.164%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.132 Acc 96.168%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.131 Acc 96.189%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.169 Acc 95.970%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 95.989%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.123 Acc 96.218%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.127 Acc 96.156%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.129 Acc 96.107%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.130 Acc 96.053%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.131 Acc 96.047%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.178 Acc 95.668%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.175 Acc 95.759%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.123 Acc 96.233%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.126 Acc 96.051%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.131 Acc 96.031%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.131 Acc 96.053%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.132 Acc 96.047%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.083 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.171 Acc 95.829%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.118 Acc 96.519%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.121 Acc 96.409%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.125 Acc 96.317%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.129 Acc 96.207%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.128 Acc 96.237%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.168 Acc 95.784%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.165 Acc 95.880%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.126 Acc 96.300%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.126 Acc 96.213%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.128 Acc 96.199%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.129 Acc 96.225%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.110 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.174 Acc 95.529%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.171 Acc 95.690%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.125 Acc 96.253%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.128 Acc 96.275%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.129 Acc 96.211%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.130 Acc 96.189%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.186 Acc 95.459%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.183 Acc 95.655%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.274 Acc 94.531%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.131 Acc 96.101%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.132 Acc 96.063%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.130 Acc 96.117%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.129 Acc 96.189%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.129 Acc 96.153%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.107 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.175 Acc 95.792%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.171 Acc 95.919%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.128 Acc 96.303%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.127 Acc 96.276%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.129 Acc 96.198%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.130 Acc 96.226%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.180 Acc 95.622%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.176 Acc 95.678%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.033 Acc 100.000%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.126 Acc 96.327%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.126 Acc 96.299%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.128 Acc 96.255%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.130 Acc 96.220%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.177 Acc 95.676%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.172 Acc 95.849%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.117 Acc 96.403%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.123 Acc 96.315%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.127 Acc 96.226%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.128 Acc 96.218%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.129 Acc 96.219%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.107 Acc 96.875%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.182 Acc 95.993%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.179 Acc 96.012%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.119 Acc 96.419%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.125 Acc 96.265%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.125 Acc 96.260%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.127 Acc 96.261%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.127 Acc 96.276%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.715%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 95.826%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.127 Acc 96.481%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.126 Acc 96.405%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.125 Acc 96.413%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.128 Acc 96.341%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.129 Acc 96.289%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.176 Acc 95.862%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.171 Acc 95.993%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.123 Acc 96.349%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.123 Acc 96.304%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.129 Acc 96.224%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.125 Acc 96.359%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.085 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.184 Acc 95.560%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.177 Acc 95.717%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.182 Acc 96.094%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.124 Acc 96.457%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.123 Acc 96.436%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.123 Acc 96.369%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.124 Acc 96.376%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.126 Acc 96.315%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.175 Acc 95.931%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.172 Acc 95.896%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.125 Acc 96.334%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.122 Acc 96.409%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.123 Acc 96.387%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.126 Acc 96.271%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.127 Acc 96.278%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.099 Acc 94.531%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.176 Acc 95.784%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.172 Acc 95.853%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.180 Acc 92.188%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.124 Acc 96.256%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.122 Acc 96.284%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.126 Acc 96.262%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.124 Acc 96.298%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.126 Acc 96.286%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.068 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.170 Acc 95.661%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.165 Acc 95.853%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.116 Acc 96.566%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.117 Acc 96.475%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.122 Acc 96.426%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.124 Acc 96.368%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.181 Acc 95.777%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.179 Acc 95.818%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.118 Acc 96.465%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.121 Acc 96.401%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.124 Acc 96.327%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.124 Acc 96.294%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.124 Acc 96.287%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.176 Acc 95.730%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.173 Acc 95.833%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.111 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.116 Acc 96.519%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.119 Acc 96.490%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.125 Acc 96.322%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.130 Acc 96.267%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.129 Acc 96.237%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.178 Acc 95.761%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.176 Acc 95.829%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.123 Acc 96.442%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.124 Acc 96.385%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.122 Acc 96.501%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.122 Acc 96.442%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.122 Acc 96.423%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.093 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.171 Acc 95.924%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.167 Acc 96.000%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.110 Acc 96.836%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.112 Acc 96.685%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.117 Acc 96.574%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.119 Acc 96.526%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.121 Acc 96.449%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.074 Acc 98.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.178 Acc 95.916%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.174 Acc 95.919%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.117 Acc 96.504%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.117 Acc 96.393%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.120 Acc 96.460%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.122 Acc 96.413%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.122 Acc 96.401%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.176 Acc 95.962%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.186 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.119 Acc 96.589%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.120 Acc 96.482%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.123 Acc 96.374%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.121 Acc 96.441%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.121 Acc 96.417%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.177 Acc 95.908%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.173 Acc 95.868%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.119 Acc 96.459%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.120 Acc 96.382%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.120 Acc 96.404%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.120 Acc 96.412%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.185 Acc 95.777%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.182 Acc 95.818%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.145 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.115 Acc 96.488%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.122 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.123 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.122 Acc 96.372%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.122 Acc 96.401%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.176 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.171 Acc 95.892%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.206 Acc 94.531%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.122 Acc 96.473%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.120 Acc 96.545%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.121 Acc 96.460%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.121 Acc 96.466%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.120 Acc 96.504%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.170 Acc 95.831%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.166 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.111 Acc 96.666%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.120 Acc 96.482%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.119 Acc 96.491%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.117 Acc 96.563%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.120 Acc 96.459%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.081 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.171 Acc 95.900%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.040 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.115 Acc 96.666%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.116 Acc 96.537%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.118 Acc 96.488%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.119 Acc 96.482%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.176 Acc 96.109%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.171 Acc 96.113%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.113 Acc 96.615%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.117 Acc 96.564%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.119 Acc 96.509%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.119 Acc 96.515%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.172 Acc 95.800%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.168 Acc 95.837%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.111 Acc 96.720%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.116 Acc 96.587%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.118 Acc 96.555%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.119 Acc 96.527%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.170 Acc 95.838%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.165 Acc 95.911%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.123 Acc 96.426%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.117 Acc 96.549%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.120 Acc 96.491%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.121 Acc 96.493%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.120 Acc 96.499%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.075 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.172 Acc 95.808%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.170 Acc 95.849%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.117 Acc 96.465%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.117 Acc 96.553%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.119 Acc 96.501%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.117 Acc 96.523%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.082 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.173 Acc 95.854%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.169 Acc 95.942%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.113 Acc 96.689%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.115 Acc 96.739%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.118 Acc 96.644%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.117 Acc 96.655%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.116 Acc 96.610%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.182 Acc 95.831%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.179 Acc 95.977%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.132 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.108 Acc 96.689%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.108 Acc 96.793%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.114 Acc 96.631%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.114 Acc 96.629%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.085 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.171 Acc 95.761%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.220 Acc 94.531%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.122 Acc 96.457%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.118 Acc 96.572%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.121 Acc 96.486%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.118 Acc 96.540%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.117 Acc 96.546%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.182 Acc 95.722%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.176 Acc 95.791%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.104 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.117 Acc 96.473%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.115 Acc 96.549%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.117 Acc 96.429%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.115 Acc 96.462%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.116 Acc 96.473%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.103 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.185 Acc 95.815%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.178 Acc 95.907%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.111 Acc 96.473%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.118 Acc 96.381%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.118 Acc 96.465%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.117 Acc 96.530%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.118 Acc 96.523%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.181 Acc 95.808%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.178 Acc 95.876%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.109 Acc 96.573%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.106 Acc 96.704%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.111 Acc 96.618%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.114 Acc 96.529%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.085 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.187 Acc 95.692%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.185 Acc 95.728%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.153 Acc 93.750%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.109 Acc 96.504%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.113 Acc 96.498%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.117 Acc 96.520%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.117 Acc 96.484%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.177 Acc 95.715%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.173 Acc 95.872%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.119 Acc 96.697%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.117 Acc 96.642%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.117 Acc 96.579%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.115 Acc 96.598%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.114 Acc 96.624%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.187 Acc 95.761%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.183 Acc 95.857%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.107 Acc 96.774%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.114 Acc 96.537%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.114 Acc 96.517%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.114 Acc 96.567%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.114 Acc 96.601%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.091 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.173 Acc 95.862%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.169 Acc 96.024%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.113 Acc 96.798%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.113 Acc 96.696%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.111 Acc 96.694%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.113 Acc 96.680%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.171 Acc 95.893%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.117 Acc 96.529%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.115 Acc 96.592%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.115 Acc 96.622%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.182 Acc 95.792%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.178 Acc 95.884%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.169 Acc 93.750%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.112 Acc 96.635%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.114 Acc 96.615%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.112 Acc 96.654%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.114 Acc 96.625%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.179 Acc 95.854%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.175 Acc 95.997%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.116 Acc 96.658%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.113 Acc 96.580%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.115 Acc 96.566%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.115 Acc 96.608%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.115 Acc 96.572%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.177 Acc 95.978%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.175 Acc 95.981%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.105 Acc 96.744%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.109 Acc 96.720%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.110 Acc 96.673%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.112 Acc 96.644%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.178 Acc 95.637%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.172 Acc 95.721%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.134 Acc 95.312%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.113 Acc 96.767%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.111 Acc 96.735%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.112 Acc 96.702%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.114 Acc 96.650%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.170 Acc 95.885%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.165 Acc 96.008%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.108 Acc 96.651%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.109 Acc 96.774%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.110 Acc 96.737%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.110 Acc 96.709%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.113 Acc 96.640%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.180 Acc 95.676%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.176 Acc 95.798%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.109 Acc 96.700%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.111 Acc 96.701%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.111 Acc 96.707%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.112 Acc 96.682%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.185 Acc 95.560%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.179 Acc 95.635%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.110 Acc 96.798%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.111 Acc 96.817%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.110 Acc 96.784%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.112 Acc 96.744%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.112 Acc 96.763%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.184 Acc 95.815%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.179 Acc 95.958%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.094 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.109 Acc 96.774%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.112 Acc 96.622%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.116 Acc 96.527%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.115 Acc 96.580%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.095 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.188 Acc 95.661%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.184 Acc 95.872%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.110 Acc 96.960%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.111 Acc 96.797%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.109 Acc 96.787%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.110 Acc 96.744%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.193 Acc 95.637%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.189 Acc 95.783%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.107 Acc 96.682%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.111 Acc 96.688%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.110 Acc 96.660%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.112 Acc 96.593%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.112 Acc 96.636%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.084 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.177 Acc 95.916%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.173 Acc 95.872%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.111 Acc 96.960%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.108 Acc 96.902%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.111 Acc 96.771%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.111 Acc 96.682%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.074 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.187 Acc 95.475%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.182 Acc 95.546%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.109 Acc 96.635%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.115 Acc 96.482%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.112 Acc 96.605%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.113 Acc 96.618%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.111 Acc 96.672%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.067 Acc 98.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.192 Acc 95.715%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.185 Acc 95.833%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.104 Acc 96.728%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.108 Acc 96.576%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.110 Acc 96.644%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.108 Acc 96.721%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.108 Acc 96.716%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.183 Acc 95.459%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.177 Acc 95.623%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.111 Acc 96.604%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.111 Acc 96.642%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.113 Acc 96.605%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.108 Acc 96.750%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.108 Acc 96.763%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.179 Acc 95.748%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.108 Acc 96.840%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.108 Acc 96.805%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.109 Acc 96.803%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.110 Acc 96.733%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.195 Acc 95.591%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.190 Acc 95.713%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.115 Acc 96.646%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.112 Acc 96.719%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.110 Acc 96.721%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.108 Acc 96.780%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.179 Acc 95.900%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.174 Acc 95.942%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.108 Acc 96.774%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.109 Acc 96.618%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.107 Acc 96.709%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.108 Acc 96.715%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.109 Acc 96.707%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.177 Acc 95.845%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.105 Acc 96.898%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.107 Acc 96.769%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.107 Acc 96.764%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.107 Acc 96.785%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.184 Acc 95.684%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.177 Acc 95.841%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbce4f4a26e45ad9884465c97009d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.331 Acc 5.469%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.271 Acc 14.875%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.254 Acc 16.857%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.249 Acc 17.385%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.242 Acc 17.745%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.225 Acc 18.755%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.992 Acc 32.031%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.036 Acc 30.794%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.039 Acc 30.803%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.003 Acc 32.031%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.887 Acc 34.677%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.819 Acc 37.310%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.748 Acc 40.111%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.673 Acc 42.994%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.600 Acc 45.613%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.994 Acc 67.969%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.020 Acc 67.188%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.016 Acc 67.137%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.092 Acc 65.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.128 Acc 63.281%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.097 Acc 64.179%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.060 Acc 65.441%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.030 Acc 66.398%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.004 Acc 67.237%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.713 Acc 79.688%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.734 Acc 76.679%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.725 Acc 76.889%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.996 Acc 69.531%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.847 Acc 72.409%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.830 Acc 72.998%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.815 Acc 73.656%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.796 Acc 74.295%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.783 Acc 74.772%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.624 Acc 82.812%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.631 Acc 79.943%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.624 Acc 80.049%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.822 Acc 74.219%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.722 Acc 77.313%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.702 Acc 77.880%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.691 Acc 78.159%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.680 Acc 78.497%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.668 Acc 78.842%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.512 Acc 82.031%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.525 Acc 83.725%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.517 Acc 84.033%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.566 Acc 79.688%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.606 Acc 80.933%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.601 Acc 80.927%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.593 Acc 81.206%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.592 Acc 81.289%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.586 Acc 81.528%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.441 Acc 85.156%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.462 Acc 85.837%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.454 Acc 86.124%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.540 Acc 85.156%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.532 Acc 83.470%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.530 Acc 83.586%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.533 Acc 83.308%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.531 Acc 83.457%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.530 Acc 83.416%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.401 Acc 87.500%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.410 Acc 87.454%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.403 Acc 87.815%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.548 Acc 82.812%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.509 Acc 83.880%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.506 Acc 83.947%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.498 Acc 84.141%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.497 Acc 84.299%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.495 Acc 84.430%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.370 Acc 85.938%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.370 Acc 89.124%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.363 Acc 89.358%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.466 Acc 84.375%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.478 Acc 85.272%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.469 Acc 85.397%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.463 Acc 85.644%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.458 Acc 85.776%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.460 Acc 85.688%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.353 Acc 87.500%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.349 Acc 89.519%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.341 Acc 89.801%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.410 Acc 88.281%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.445 Acc 86.139%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.443 Acc 86.291%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.437 Acc 86.451%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.438 Acc 86.458%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.439 Acc 86.441%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.300 Acc 90.625%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.341 Acc 89.867%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.337 Acc 90.007%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.640 Acc 82.031%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.414 Acc 87.423%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.423 Acc 87.096%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.419 Acc 87.168%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.418 Acc 87.134%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.418 Acc 87.121%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.315 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.326 Acc 90.408%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.320 Acc 90.536%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.281 Acc 91.406%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.397 Acc 87.701%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.396 Acc 87.861%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.395 Acc 87.879%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.398 Acc 87.771%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.398 Acc 87.703%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.274 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.300 Acc 91.182%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.296 Acc 91.348%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.490 Acc 83.594%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.374 Acc 88.738%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.385 Acc 88.386%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.386 Acc 88.286%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.382 Acc 88.328%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.384 Acc 88.225%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.255 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.295 Acc 91.491%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.292 Acc 91.566%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.334 Acc 87.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.368 Acc 88.513%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.371 Acc 88.495%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.367 Acc 88.676%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.366 Acc 88.702%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.367 Acc 88.682%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.277 Acc 89.062%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.288 Acc 91.793%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.283 Acc 91.861%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.295 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.354 Acc 89.240%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.356 Acc 89.031%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.352 Acc 89.203%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.355 Acc 89.183%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.355 Acc 89.245%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.240 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.277 Acc 92.048%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.274 Acc 92.145%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.329 Acc 89.844%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.350 Acc 89.140%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.339 Acc 89.587%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.345 Acc 89.522%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.341 Acc 89.511%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.342 Acc 89.490%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.218 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.268 Acc 92.466%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.265 Acc 92.514%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.468 Acc 89.062%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.333 Acc 89.921%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.339 Acc 89.509%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.344 Acc 89.330%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.344 Acc 89.349%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.339 Acc 89.543%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.254 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.261 Acc 92.636%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.258 Acc 92.821%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.466 Acc 85.938%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.333 Acc 89.790%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.328 Acc 90.023%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.329 Acc 89.974%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.326 Acc 90.027%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.327 Acc 90.012%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.212 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.254 Acc 92.884%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.252 Acc 92.922%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.330 Acc 89.844%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.319 Acc 90.292%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.327 Acc 90.089%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.328 Acc 89.984%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.321 Acc 90.155%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.321 Acc 90.193%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.193 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.246 Acc 93.147%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.242 Acc 93.237%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.382 Acc 89.844%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.309 Acc 90.617%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.311 Acc 90.648%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.315 Acc 90.454%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.314 Acc 90.391%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.313 Acc 90.452%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.254 Acc 92.737%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.248 Acc 92.875%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.366 Acc 89.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.307 Acc 90.548%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.314 Acc 90.435%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.311 Acc 90.511%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.310 Acc 90.518%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.308 Acc 90.553%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.218 Acc 91.406%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.241 Acc 93.216%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.238 Acc 93.179%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.220 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.291 Acc 91.120%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.297 Acc 91.045%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.304 Acc 90.843%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.302 Acc 90.882%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.302 Acc 90.807%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.235 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.236 Acc 93.448%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.231 Acc 93.458%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.437 Acc 88.281%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.301 Acc 90.787%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.300 Acc 90.994%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.301 Acc 91.009%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.298 Acc 91.108%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.296 Acc 91.144%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.223 Acc 90.625%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.228 Acc 93.479%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.224 Acc 93.630%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.437 Acc 89.844%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.296 Acc 91.182%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.296 Acc 91.274%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.293 Acc 91.201%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.292 Acc 91.206%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.293 Acc 91.202%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.232 Acc 93.472%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.228 Acc 93.517%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.268 Acc 91.406%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.285 Acc 91.437%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.282 Acc 91.395%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.280 Acc 91.523%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.281 Acc 91.494%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.283 Acc 91.403%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.232 Acc 93.557%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.226 Acc 93.672%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.268 Acc 92.157%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.274 Acc 91.748%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.280 Acc 91.627%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.281 Acc 91.566%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.281 Acc 91.584%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.218 Acc 92.188%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.232 Acc 93.603%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.227 Acc 93.618%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.252 Acc 91.406%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.273 Acc 91.801%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.277 Acc 91.674%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.278 Acc 91.720%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.281 Acc 91.603%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.279 Acc 91.684%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.221 Acc 93.820%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.218 Acc 93.921%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.188 Acc 95.312%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.261 Acc 92.110%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.266 Acc 92.051%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.269 Acc 91.894%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.269 Acc 91.913%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.270 Acc 91.829%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.217 Acc 94.114%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.214 Acc 94.092%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.262 Acc 92.203%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.277 Acc 91.659%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.270 Acc 91.796%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.270 Acc 91.870%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.268 Acc 91.952%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.188 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.219 Acc 93.990%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.214 Acc 93.979%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.250 Acc 92.234%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.258 Acc 92.028%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.262 Acc 91.988%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.262 Acc 92.043%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.262 Acc 92.066%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.188 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.216 Acc 94.377%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.212 Acc 94.290%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.299 Acc 92.188%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.254 Acc 92.249%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.260 Acc 92.121%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.259 Acc 92.219%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.260 Acc 92.186%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.263 Acc 92.136%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.212 Acc 94.245%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.208 Acc 94.213%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.303 Acc 89.062%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.266 Acc 91.878%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.270 Acc 91.877%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.264 Acc 92.019%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.261 Acc 92.045%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.261 Acc 92.064%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.213 Acc 94.199%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.209 Acc 94.282%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.406 Acc 89.062%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.256 Acc 92.791%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.257 Acc 92.518%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.257 Acc 92.481%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.257 Acc 92.505%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.255 Acc 92.487%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.213 Acc 94.230%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.207 Acc 94.325%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.322 Acc 92.188%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.254 Acc 92.489%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.255 Acc 92.405%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.252 Acc 92.431%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.249 Acc 92.540%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.250 Acc 92.566%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.207 Acc 94.353%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.204 Acc 94.341%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.194 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.255 Acc 92.342%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.247 Acc 92.553%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.250 Acc 92.556%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.249 Acc 92.562%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.249 Acc 92.565%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.209 Acc 94.230%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.205 Acc 94.263%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.243 Acc 94.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.245 Acc 92.752%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.245 Acc 92.751%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.247 Acc 92.634%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.247 Acc 92.571%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.247 Acc 92.616%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.191 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.198 Acc 94.725%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.195 Acc 94.656%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.322 Acc 90.625%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.232 Acc 93.178%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.241 Acc 92.930%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.246 Acc 92.818%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.246 Acc 92.786%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.244 Acc 92.755%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.208 Acc 94.384%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.205 Acc 94.349%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.234 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.233 Acc 92.953%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.239 Acc 92.895%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.244 Acc 92.784%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.242 Acc 92.879%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.242 Acc 92.846%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.200 Acc 94.779%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.196 Acc 94.729%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.201 Acc 91.406%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.240 Acc 92.884%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.239 Acc 92.883%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.239 Acc 92.906%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.239 Acc 92.938%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.239 Acc 92.928%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.200 Acc 94.570%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.197 Acc 94.543%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.307 Acc 93.750%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.229 Acc 93.394%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.237 Acc 93.249%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.235 Acc 93.218%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.235 Acc 93.162%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.235 Acc 93.164%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.198 Acc 94.794%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.193 Acc 94.772%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.241 Acc 93.093%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.233 Acc 93.186%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.235 Acc 93.117%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.234 Acc 93.074%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.236 Acc 93.001%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.196 Acc 94.918%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.192 Acc 94.881%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.268 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.222 Acc 93.441%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.228 Acc 93.431%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.230 Acc 93.265%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.230 Acc 93.298%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.233 Acc 93.195%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.190 Acc 95.111%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.187 Acc 95.017%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.222 Acc 93.611%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.222 Acc 93.424%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.226 Acc 93.239%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.228 Acc 93.195%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.230 Acc 93.200%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.191 Acc 92.969%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.201 Acc 94.609%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.194 Acc 94.714%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.223 Acc 93.286%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.220 Acc 93.517%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.223 Acc 93.605%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.225 Acc 93.407%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.225 Acc 93.462%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.167 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.194 Acc 94.810%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.189 Acc 94.823%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.218 Acc 93.502%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.220 Acc 93.490%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.223 Acc 93.472%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.225 Acc 93.382%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.224 Acc 93.399%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.192 Acc 94.771%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.230 Acc 93.185%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.225 Acc 93.365%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.225 Acc 93.433%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.224 Acc 93.440%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.224 Acc 93.457%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.208 Acc 92.188%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.194 Acc 94.841%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.189 Acc 94.757%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.246 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.222 Acc 93.425%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.221 Acc 93.501%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.220 Acc 93.553%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.223 Acc 93.516%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.221 Acc 93.544%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.185 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.191 Acc 94.794%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.187 Acc 94.838%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.177 Acc 92.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.212 Acc 93.928%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.217 Acc 93.734%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.220 Acc 93.677%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.222 Acc 93.567%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.222 Acc 93.515%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.190 Acc 95.003%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.183 Acc 95.091%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.229 Acc 92.969%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.213 Acc 93.549%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.211 Acc 93.641%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.215 Acc 93.625%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.218 Acc 93.542%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.219 Acc 93.527%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.197 Acc 94.732%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.191 Acc 94.815%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.214 Acc 93.742%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.208 Acc 93.878%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.212 Acc 93.773%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.214 Acc 93.660%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.216 Acc 93.649%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.183 Acc 95.021%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.259 Acc 89.844%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.204 Acc 93.982%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.219 Acc 93.688%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.215 Acc 93.753%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.217 Acc 93.694%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.214 Acc 93.734%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.189 Acc 95.034%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.184 Acc 95.060%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.200 Acc 93.812%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.207 Acc 93.750%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.208 Acc 93.771%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.209 Acc 93.881%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.210 Acc 93.834%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.181 Acc 95.119%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.178 Acc 95.169%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.206 Acc 94.106%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.209 Acc 93.987%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.209 Acc 93.945%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.210 Acc 93.953%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.210 Acc 93.943%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.188 Acc 95.042%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.183 Acc 95.033%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.264 Acc 92.188%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.205 Acc 93.974%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.205 Acc 93.983%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.205 Acc 93.971%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.207 Acc 93.939%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.207 Acc 93.926%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.172 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.186 Acc 95.050%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.182 Acc 95.068%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.183 Acc 95.312%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.219 Acc 93.804%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.212 Acc 93.991%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.210 Acc 94.061%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.209 Acc 94.083%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.207 Acc 94.092%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.189 Acc 95.088%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.184 Acc 95.072%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.204 Acc 93.982%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.209 Acc 93.925%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.208 Acc 93.973%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.206 Acc 93.951%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.208 Acc 93.901%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.186 Acc 95.042%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.182 Acc 95.138%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.289 Acc 92.188%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.208 Acc 94.168%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.202 Acc 94.166%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.207 Acc 94.025%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.208 Acc 93.990%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.206 Acc 94.000%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.181 Acc 95.215%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.123 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.206 Acc 94.059%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.202 Acc 94.193%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.203 Acc 94.108%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.202 Acc 94.103%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.203 Acc 94.127%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.174 Acc 92.188%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.181 Acc 95.111%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.176 Acc 95.305%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.198 Acc 94.152%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.200 Acc 94.205%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.200 Acc 94.142%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.201 Acc 94.142%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.200 Acc 94.145%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.190 Acc 95.135%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.186 Acc 95.052%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.230 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.196 Acc 94.330%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.200 Acc 94.294%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.203 Acc 94.157%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.202 Acc 94.157%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.199 Acc 94.243%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.178 Acc 95.351%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.153 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.200 Acc 94.361%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.194 Acc 94.446%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.199 Acc 94.272%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.198 Acc 94.336%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.200 Acc 94.260%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.185 Acc 95.196%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.180 Acc 95.223%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.189 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.195 Acc 94.321%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.195 Acc 94.292%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.196 Acc 94.280%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.198 Acc 94.174%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.184 Acc 95.274%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.178 Acc 95.336%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.197 Acc 94.261%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.196 Acc 94.360%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.196 Acc 94.430%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.196 Acc 94.407%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.196 Acc 94.413%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.187 Acc 95.150%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.182 Acc 95.200%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.233 Acc 89.844%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.184 Acc 94.423%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.189 Acc 94.492%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.189 Acc 94.409%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.192 Acc 94.387%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.192 Acc 94.391%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.187 Acc 95.142%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.181 Acc 95.200%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.196 Acc 92.188%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.195 Acc 94.199%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.193 Acc 94.314%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.193 Acc 94.321%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.194 Acc 94.294%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.196 Acc 94.272%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.179 Acc 92.188%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.212%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.178 Acc 95.371%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.182 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.196 Acc 94.315%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.194 Acc 94.275%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.193 Acc 94.360%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.193 Acc 94.366%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.193 Acc 94.422%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.183 Acc 95.297%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.320%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.199 Acc 94.307%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.194 Acc 94.372%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.193 Acc 94.383%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.191 Acc 94.399%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.193 Acc 94.336%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.177 Acc 95.320%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.171 Acc 95.437%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.272 Acc 92.188%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.182 Acc 94.601%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.574%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.184 Acc 94.588%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.186 Acc 94.502%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.189 Acc 94.469%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.188 Acc 95.026%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.183 Acc 95.075%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.246 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.201 Acc 94.168%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.191 Acc 94.457%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.188 Acc 94.505%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.190 Acc 94.518%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.191 Acc 94.447%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.186 Acc 95.134%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.177 Acc 94.717%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.182 Acc 94.675%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.185 Acc 94.555%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.187 Acc 94.477%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.188 Acc 94.464%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.176 Acc 95.514%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.169 Acc 95.581%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.202 Acc 95.312%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.190 Acc 94.570%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.185 Acc 94.761%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.184 Acc 94.697%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.186 Acc 94.613%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.187 Acc 94.575%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.174 Acc 95.467%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.169 Acc 95.499%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.185 Acc 93.750%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.190 Acc 94.346%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.186 Acc 94.516%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.188 Acc 94.430%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.188 Acc 94.471%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.188 Acc 94.511%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.183 Acc 95.343%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.177 Acc 95.367%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.182 Acc 94.717%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.187 Acc 94.570%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.181 Acc 94.726%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.184 Acc 94.670%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.186 Acc 94.567%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.177 Acc 95.514%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.171 Acc 95.553%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.159 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.186 Acc 94.794%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.186 Acc 94.733%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.181 Acc 94.804%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.183 Acc 94.695%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.184 Acc 94.650%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.181 Acc 95.266%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.175 Acc 95.429%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.151 Acc 93.750%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.182 Acc 94.609%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.180 Acc 94.815%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.179 Acc 94.791%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.181 Acc 94.722%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.183 Acc 94.706%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.661%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.165 Acc 95.728%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.189 Acc 94.369%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.188 Acc 94.516%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.183 Acc 94.619%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.183 Acc 94.646%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.182 Acc 94.648%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.174 Acc 95.320%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.168 Acc 95.553%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.184 Acc 94.640%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.176 Acc 94.807%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.174 Acc 94.830%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.181 Acc 94.703%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.182 Acc 94.740%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.182 Acc 95.382%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.176 Acc 95.449%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.181 Acc 94.972%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.179 Acc 94.970%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.180 Acc 94.936%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.180 Acc 94.898%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.182 Acc 94.823%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.116 Acc 94.531%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.176 Acc 95.459%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.171 Acc 95.565%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.152 Acc 97.656%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.184 Acc 94.802%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.185 Acc 94.823%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.182 Acc 94.835%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.181 Acc 94.859%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.181 Acc 94.881%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.183 Acc 95.289%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.176 Acc 95.371%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.180 Acc 94.686%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.177 Acc 94.842%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.180 Acc 94.762%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.180 Acc 94.831%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.180 Acc 94.778%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.189 Acc 93.750%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.178 Acc 95.374%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.172 Acc 95.546%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.173 Acc 94.895%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.177 Acc 94.838%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.177 Acc 94.866%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.177 Acc 94.864%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.175 Acc 94.926%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.183 Acc 95.212%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.178 Acc 95.281%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.211 Acc 95.312%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.172 Acc 95.091%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.175 Acc 95.001%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.176 Acc 94.974%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.176 Acc 94.940%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.182 Acc 95.359%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.176 Acc 95.433%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.169 Acc 95.274%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.173 Acc 95.048%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.176 Acc 94.991%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.179 Acc 94.933%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.180 Acc 94.924%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.178 Acc 95.421%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.173 Acc 95.472%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.173 Acc 94.848%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.173 Acc 94.900%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.172 Acc 94.967%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.172 Acc 94.979%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.173 Acc 94.977%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.179 Acc 95.382%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.172 Acc 95.538%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.157 Acc 95.204%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.169 Acc 94.963%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.175 Acc 94.861%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.175 Acc 94.890%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.175 Acc 94.898%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.176 Acc 95.374%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.169 Acc 95.569%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.154 Acc 92.969%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.177 Acc 94.887%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.176 Acc 94.831%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.173 Acc 94.822%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.172 Acc 94.866%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.174 Acc 94.854%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.179 Acc 95.405%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.172 Acc 95.581%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.179 Acc 94.756%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.177 Acc 94.831%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.175 Acc 94.952%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.177 Acc 94.964%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.175 Acc 94.985%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.171 Acc 95.721%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.163 Acc 95.149%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.166 Acc 95.146%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.170 Acc 95.102%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.173 Acc 95.022%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.174 Acc 95.449%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.145 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.172 Acc 94.879%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.165 Acc 95.130%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.165 Acc 95.152%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.167 Acc 95.110%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.167 Acc 95.111%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.176 Acc 95.367%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.170 Acc 95.553%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.283 Acc 91.406%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.160 Acc 95.243%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.162 Acc 95.173%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.167 Acc 95.126%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.171 Acc 95.016%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.170 Acc 95.044%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.128 Acc 92.969%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.183 Acc 95.328%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.175 Acc 95.472%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.167 Acc 95.096%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.168 Acc 95.052%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.172 Acc 94.980%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.170 Acc 95.090%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.169 Acc 95.102%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.176 Acc 95.475%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.169 Acc 95.534%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.160 Acc 95.166%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.167 Acc 95.114%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.169 Acc 95.097%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.167 Acc 95.147%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.168 Acc 95.132%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.177 Acc 95.444%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.170 Acc 95.585%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.102 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.172 Acc 95.135%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.169 Acc 95.122%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.170 Acc 95.162%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.168 Acc 95.198%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.168 Acc 95.189%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.266%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.180 Acc 95.375%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.170 Acc 95.135%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.169 Acc 95.044%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.168 Acc 95.131%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.169 Acc 95.090%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.169 Acc 95.091%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.184 Acc 95.166%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.176 Acc 95.363%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.160 Acc 95.467%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.162 Acc 95.460%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.159 Acc 95.460%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.161 Acc 95.396%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.163 Acc 95.334%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.171 Acc 95.637%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.163 Acc 95.771%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.161 Acc 95.212%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.170 Acc 95.106%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.166 Acc 95.268%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.165 Acc 95.237%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.165 Acc 95.277%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.180 Acc 95.343%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.173 Acc 95.538%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.158 Acc 95.483%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.161 Acc 95.297%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.160 Acc 95.393%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.160 Acc 95.351%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.162 Acc 95.297%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.166 Acc 95.692%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.160 Acc 95.857%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.159 Acc 95.336%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.165 Acc 95.204%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.163 Acc 95.268%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.166 Acc 95.198%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.179 Acc 95.274%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.171 Acc 95.522%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.159 Acc 95.459%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.163 Acc 95.456%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.163 Acc 95.362%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.165 Acc 95.330%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.164 Acc 95.355%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.181 Acc 95.328%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.173 Acc 95.565%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.405 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.164 Acc 95.088%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.163 Acc 95.176%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.165 Acc 95.136%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.163 Acc 95.246%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.163 Acc 95.238%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.170 Acc 95.606%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.165 Acc 95.705%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.166 Acc 95.258%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.167 Acc 95.223%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.163 Acc 95.263%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.161 Acc 95.334%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.162 Acc 95.292%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.175 Acc 95.498%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.168 Acc 95.732%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.150 Acc 95.545%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.155 Acc 95.371%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.158 Acc 95.422%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.162 Acc 95.289%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.162 Acc 95.334%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.173 Acc 95.526%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.076 Acc 99.219%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.161 Acc 95.220%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.153 Acc 95.328%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.158 Acc 95.294%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.158 Acc 95.314%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.160 Acc 95.270%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 95.651%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.155 Acc 95.467%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.398%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.158 Acc 95.408%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.159 Acc 95.408%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.137 Acc 93.750%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.176 Acc 95.490%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.168 Acc 95.655%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.155 Acc 95.645%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.152 Acc 95.639%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.155 Acc 95.595%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.157 Acc 95.550%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.160 Acc 95.420%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.175 Acc 95.506%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.166 Acc 95.643%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.274 Acc 92.188%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.161 Acc 95.545%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.158 Acc 95.522%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.159 Acc 95.419%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.161 Acc 95.427%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.158 Acc 95.464%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.177 Acc 95.336%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.170 Acc 95.596%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.262 Acc 92.188%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.144 Acc 95.784%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.151 Acc 95.678%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.154 Acc 95.614%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.153 Acc 95.613%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.156 Acc 95.515%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.113 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.165 Acc 95.794%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.160 Acc 95.421%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.160 Acc 95.441%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.155 Acc 95.541%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.156 Acc 95.496%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.158 Acc 95.442%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.178 Acc 95.359%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.170 Acc 95.596%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.151 Acc 95.715%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.156 Acc 95.550%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.158 Acc 95.510%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.157 Acc 95.513%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.157 Acc 95.495%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.176 Acc 95.421%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.168 Acc 95.701%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.151 Acc 95.483%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.146 Acc 95.705%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.149 Acc 95.619%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.151 Acc 95.552%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.152 Acc 95.520%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.179 Acc 95.351%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.171 Acc 95.623%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.211 Acc 93.750%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.150 Acc 95.653%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.150 Acc 95.690%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.154 Acc 95.632%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.155 Acc 95.628%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.157 Acc 95.562%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.185 Acc 95.150%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.177 Acc 95.359%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.155 Acc 95.351%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.154 Acc 95.503%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.153 Acc 95.536%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.158 Acc 95.414%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.157 Acc 95.420%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.169 Acc 95.692%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.163 Acc 95.903%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.153 Acc 95.519%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.152 Acc 95.549%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.153 Acc 95.593%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.153 Acc 95.581%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.176 Acc 95.351%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.170 Acc 95.468%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.147 Acc 95.645%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.146 Acc 95.690%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.150 Acc 95.642%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.150 Acc 95.677%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.152 Acc 95.662%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.166 Acc 95.763%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.153 Acc 95.568%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.153 Acc 95.546%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.152 Acc 95.525%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.153 Acc 95.519%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.154 Acc 95.512%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.174 Acc 95.413%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.165 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.146 Acc 95.630%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.150 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.149 Acc 95.712%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.149 Acc 95.681%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.150 Acc 95.656%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.170 Acc 95.560%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.162 Acc 95.872%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.137 Acc 95.862%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.144 Acc 95.794%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.148 Acc 95.722%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.149 Acc 95.640%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.174 Acc 95.475%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.166 Acc 95.620%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.139 Acc 95.962%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.143 Acc 95.841%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.146 Acc 95.816%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.148 Acc 95.766%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.150 Acc 95.674%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.181 Acc 95.506%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.174 Acc 95.662%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.321 Acc 89.844%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.154 Acc 95.452%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.156 Acc 95.499%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.151 Acc 95.629%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.151 Acc 95.673%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.150 Acc 95.654%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.124 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.172 Acc 95.622%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.164 Acc 95.787%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.143 Acc 95.815%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.145 Acc 95.631%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.148 Acc 95.590%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.147 Acc 95.624%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.150 Acc 95.562%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.176 Acc 95.583%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.167 Acc 95.794%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.143 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.141 Acc 95.978%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.145 Acc 95.868%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.148 Acc 95.766%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.149 Acc 95.705%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.179 Acc 95.560%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.170 Acc 95.678%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.148 Acc 95.614%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.152 Acc 95.596%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.150 Acc 95.691%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.151 Acc 95.630%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.149 Acc 95.654%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.176 Acc 95.583%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.168 Acc 95.767%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.149 Acc 95.614%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.147 Acc 95.767%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.148 Acc 95.808%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.150 Acc 95.739%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.149 Acc 95.776%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.178 Acc 95.614%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.172 Acc 95.771%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.166 Acc 92.188%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.146 Acc 95.645%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.148 Acc 95.693%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.146 Acc 95.749%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.145 Acc 95.803%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.147 Acc 95.754%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.174 Acc 95.612%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.195 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.147 Acc 95.637%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.143 Acc 95.899%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.143 Acc 95.839%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.144 Acc 95.823%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.145 Acc 95.794%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.177 Acc 95.490%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.167 Acc 95.732%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.141 Acc 96.040%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.145 Acc 95.771%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.141 Acc 95.928%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.144 Acc 95.911%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.147 Acc 95.810%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.176 Acc 95.545%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.169 Acc 95.725%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.149 Acc 95.753%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.145 Acc 95.911%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.146 Acc 95.873%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.146 Acc 95.800%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.148 Acc 95.735%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.175 Acc 95.581%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.136 Acc 96.163%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.140 Acc 96.063%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.139 Acc 96.006%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.141 Acc 95.994%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.144 Acc 95.960%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.176 Acc 95.668%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.168 Acc 95.841%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.148 Acc 95.885%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.148 Acc 95.763%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.144 Acc 95.870%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.146 Acc 95.791%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.176 Acc 95.444%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.168 Acc 95.791%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.135 Acc 95.962%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.141 Acc 95.849%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.143 Acc 95.800%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.143 Acc 95.793%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.181 Acc 95.274%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.172 Acc 95.522%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.197 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.144 Acc 95.826%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.144 Acc 95.798%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.144 Acc 95.889%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.144 Acc 95.838%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.179 Acc 95.537%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.170 Acc 95.748%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.139 Acc 96.009%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.143 Acc 95.985%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.142 Acc 95.959%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.145 Acc 95.889%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.144 Acc 95.894%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.118 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.175 Acc 95.637%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.168 Acc 95.829%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.140 Acc 95.900%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.141 Acc 95.837%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.141 Acc 95.855%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.145 Acc 95.809%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.144 Acc 95.838%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.182 Acc 95.398%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.173 Acc 95.639%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.141 Acc 95.784%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.140 Acc 95.771%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.142 Acc 95.815%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.142 Acc 95.833%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.178 Acc 95.429%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.135 Acc 95.924%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.136 Acc 95.872%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.138 Acc 95.915%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.141 Acc 95.876%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.142 Acc 95.882%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.179 Acc 95.328%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.171 Acc 95.592%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.066 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.147 Acc 95.746%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.147 Acc 95.802%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.145 Acc 95.764%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.145 Acc 95.790%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.143 Acc 95.865%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.661%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.167 Acc 95.806%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.245 Acc 94.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.134 Acc 96.163%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.135 Acc 96.102%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.138 Acc 96.024%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.141 Acc 95.961%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.140 Acc 96.011%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.181 Acc 95.405%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.173 Acc 95.608%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.225 Acc 93.750%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.140 Acc 95.869%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.136 Acc 96.004%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.138 Acc 96.018%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.139 Acc 95.942%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.140 Acc 95.927%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.183 Acc 95.204%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.176 Acc 95.398%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.265 Acc 91.406%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.145 Acc 95.893%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.137 Acc 96.065%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.138 Acc 95.963%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.140 Acc 95.942%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.179 Acc 95.490%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.170 Acc 95.783%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.143 Acc 96.109%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.142 Acc 95.946%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.141 Acc 95.972%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.139 Acc 95.948%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.140 Acc 95.944%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.444%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.167 Acc 95.666%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.063 Acc 96.875%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.133 Acc 96.117%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.135 Acc 96.102%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.134 Acc 96.089%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.135 Acc 96.074%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.137 Acc 96.022%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.172 Acc 95.622%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.165 Acc 95.861%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.269 Acc 94.531%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.136 Acc 95.970%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.132 Acc 96.168%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.137 Acc 96.035%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.137 Acc 96.008%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.172 Acc 95.630%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.164 Acc 95.888%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.132 Acc 96.364%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.132 Acc 96.238%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.133 Acc 96.135%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.137 Acc 96.035%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.137 Acc 96.036%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.181 Acc 95.568%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.172 Acc 95.767%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.117 Acc 96.434%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.129 Acc 96.195%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.131 Acc 96.107%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.133 Acc 96.053%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.135 Acc 95.991%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.174 Acc 95.514%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.167 Acc 95.736%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.128 Acc 96.395%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.124 Acc 96.412%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.130 Acc 96.104%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.133 Acc 96.082%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.135 Acc 96.058%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.171 Acc 95.707%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.164 Acc 95.931%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.127 Acc 96.109%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.135 Acc 96.137%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.133 Acc 96.135%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.133 Acc 96.121%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.135 Acc 96.091%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.178 Acc 95.498%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.168 Acc 95.872%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.131 Acc 96.132%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.133 Acc 96.152%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.133 Acc 96.086%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.136 Acc 96.033%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.174 Acc 95.552%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.166 Acc 95.861%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.135 Acc 96.024%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.134 Acc 96.047%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.133 Acc 96.097%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.180 Acc 95.490%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.181 Acc 93.750%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.130 Acc 96.261%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.135 Acc 96.091%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.134 Acc 96.080%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.135 Acc 96.056%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.173 Acc 95.560%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.164 Acc 95.857%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.128 Acc 96.272%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.129 Acc 96.206%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.129 Acc 96.161%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.132 Acc 96.074%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.134 Acc 96.014%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.177 Acc 95.668%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.169 Acc 95.919%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.126 Acc 96.140%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.130 Acc 96.152%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.133 Acc 96.096%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.131 Acc 96.154%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.133 Acc 96.109%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.180 Acc 95.552%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.173 Acc 95.814%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.129 Acc 96.055%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.127 Acc 96.156%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.131 Acc 96.070%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.132 Acc 96.068%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.132 Acc 96.088%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.172 Acc 95.854%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.163 Acc 96.086%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.131 Acc 96.295%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.130 Acc 96.218%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.131 Acc 96.169%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.132 Acc 96.170%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.132 Acc 96.203%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.176 Acc 95.676%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.167 Acc 95.915%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.148 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.143 Acc 95.862%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.138 Acc 95.985%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.135 Acc 96.013%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.135 Acc 96.041%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.133 Acc 96.077%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.180 Acc 95.722%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.171 Acc 95.896%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.116 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.130 Acc 96.109%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.128 Acc 96.226%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.129 Acc 96.244%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.131 Acc 96.195%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.176 Acc 95.690%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.131 Acc 96.272%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.133 Acc 96.199%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.131 Acc 96.191%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.133 Acc 96.173%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.178 Acc 95.684%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.168 Acc 95.849%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.128 Acc 96.364%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.130 Acc 96.257%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.131 Acc 96.198%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.132 Acc 96.158%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.133 Acc 96.103%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.140 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.176 Acc 95.761%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.168 Acc 95.931%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.257 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.132 Acc 96.194%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.131 Acc 96.121%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.131 Acc 96.164%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.131 Acc 96.164%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.129 Acc 96.395%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.126 Acc 96.385%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.129 Acc 96.301%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.130 Acc 96.283%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.131 Acc 96.254%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.174 Acc 95.622%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.167 Acc 95.896%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.131 Acc 96.395%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.132 Acc 96.284%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.129 Acc 96.294%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.130 Acc 96.240%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.130 Acc 96.231%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.165 Acc 95.927%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.119 Acc 96.318%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.123 Acc 96.362%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.128 Acc 96.283%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.130 Acc 96.209%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.129 Acc 96.248%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.187 Acc 95.374%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.179 Acc 95.600%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.154 Acc 93.750%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.129 Acc 96.009%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.128 Acc 96.133%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.130 Acc 96.127%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.130 Acc 96.148%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.130 Acc 96.155%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.176 Acc 95.637%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.132 Acc 96.248%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.125 Acc 96.350%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.125 Acc 96.327%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.128 Acc 96.255%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.128 Acc 96.245%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.180 Acc 95.661%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.174 Acc 95.864%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.126 Acc 96.248%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.123 Acc 96.343%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.125 Acc 96.327%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.125 Acc 96.326%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.127 Acc 96.245%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.168 Acc 95.884%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.128 Acc 96.218%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.127 Acc 96.308%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.127 Acc 96.252%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.128 Acc 96.250%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.127 Acc 96.250%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.181 Acc 95.692%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.174 Acc 95.868%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.126 Acc 96.372%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.125 Acc 96.408%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.125 Acc 96.405%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.125 Acc 96.398%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.177 Acc 95.583%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.167 Acc 95.845%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.121 Acc 96.481%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.121 Acc 96.463%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.124 Acc 96.366%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.124 Acc 96.390%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.124 Acc 96.374%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.181 Acc 95.421%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.171 Acc 95.756%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.214 Acc 95.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.123 Acc 96.279%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.123 Acc 96.315%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.125 Acc 96.275%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.123 Acc 96.304%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.122 Acc 96.328%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.178 Acc 95.692%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.168 Acc 95.927%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.121 Acc 96.303%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.125 Acc 96.199%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.127 Acc 96.244%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.127 Acc 96.240%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.125 Acc 96.292%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.185 Acc 95.429%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.176 Acc 95.635%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.125 Acc 96.078%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.124 Acc 96.249%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.123 Acc 96.333%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.122 Acc 96.400%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.124 Acc 96.357%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.181 Acc 95.328%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.172 Acc 95.573%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.125 Acc 96.419%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.127 Acc 96.416%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.125 Acc 96.462%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.124 Acc 96.437%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.124 Acc 96.404%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.183 Acc 95.684%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.175 Acc 95.946%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.116 Acc 96.620%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.117 Acc 96.552%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.118 Acc 96.496%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.119 Acc 96.478%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.123 Acc 96.370%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.155 Acc 96.875%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.181 Acc 95.637%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.172 Acc 95.826%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.109 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.119 Acc 96.481%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.120 Acc 96.537%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.120 Acc 96.501%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.121 Acc 96.478%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.121 Acc 96.456%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.182 Acc 95.119%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.171 Acc 95.519%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.372 Acc 92.188%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.124 Acc 96.318%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.123 Acc 96.459%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.122 Acc 96.449%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.123 Acc 96.402%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.124 Acc 96.406%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.183 Acc 95.599%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.172 Acc 95.981%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.125 Acc 96.241%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.120 Acc 96.393%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.122 Acc 96.408%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.124 Acc 96.355%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.123 Acc 96.384%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.092 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.176 Acc 95.622%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.167 Acc 95.950%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.122 Acc 96.380%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.119 Acc 96.467%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.123 Acc 96.361%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.123 Acc 96.374%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.125 Acc 96.325%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.170 Acc 95.876%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.125 Acc 96.372%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.127 Acc 96.273%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.124 Acc 96.365%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.173 Acc 95.794%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.112 Acc 96.651%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.115 Acc 96.688%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.119 Acc 96.540%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.120 Acc 96.544%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.121 Acc 96.435%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.653%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.166 Acc 95.927%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.125 Acc 96.310%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.122 Acc 96.447%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.123 Acc 96.400%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.122 Acc 96.392%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.122 Acc 96.395%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.180 Acc 95.498%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.169 Acc 95.915%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.125 Acc 94.531%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.114 Acc 96.542%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.119 Acc 96.374%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.119 Acc 96.455%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.117 Acc 96.567%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.120 Acc 96.488%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.179 Acc 95.583%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.171 Acc 95.853%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.119 Acc 96.651%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.115 Acc 96.650%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.118 Acc 96.569%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.120 Acc 96.499%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.120 Acc 96.509%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.180 Acc 95.668%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.173 Acc 95.907%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.118 Acc 96.372%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.122 Acc 96.374%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.118 Acc 96.478%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.118 Acc 96.505%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.120 Acc 96.479%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.175 Acc 95.753%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.169 Acc 96.004%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.109 Acc 96.852%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.114 Acc 96.681%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.118 Acc 96.621%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.118 Acc 96.583%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.121 Acc 96.509%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.172 Acc 95.884%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.114 Acc 96.511%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.116 Acc 96.467%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.120 Acc 96.382%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.121 Acc 96.386%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.119 Acc 96.415%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.171 Acc 96.875%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.181 Acc 95.429%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.173 Acc 95.655%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.113 Acc 96.612%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.118 Acc 96.482%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.115 Acc 96.545%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.116 Acc 96.511%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.118 Acc 96.498%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.181 Acc 95.529%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.173 Acc 95.791%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.117 Acc 96.658%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.114 Acc 96.774%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.117 Acc 96.567%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.118 Acc 96.551%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.183 Acc 95.467%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.174 Acc 95.717%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.165 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.115 Acc 96.630%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.117 Acc 96.569%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.118 Acc 96.548%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.119 Acc 96.505%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.175 Acc 95.521%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.167 Acc 95.802%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.107 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.113 Acc 96.627%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.115 Acc 96.583%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.114 Acc 96.587%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.117 Acc 96.507%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.117 Acc 96.510%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.177 Acc 95.599%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.170 Acc 95.756%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.120 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.117 Acc 96.349%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.117 Acc 96.470%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.117 Acc 96.460%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.118 Acc 96.440%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.161 Acc 97.656%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.186 Acc 95.436%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.176 Acc 95.736%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.112 Acc 96.535%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.117 Acc 96.444%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.115 Acc 96.522%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.116 Acc 96.528%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.116 Acc 96.558%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.179 Acc 95.552%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.056 Acc 100.000%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.108 Acc 96.929%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.111 Acc 96.727%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.113 Acc 96.680%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.114 Acc 96.600%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.115 Acc 96.560%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.179 Acc 95.630%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.116 Acc 96.380%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.119 Acc 96.377%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.118 Acc 96.418%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.118 Acc 96.388%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.116 Acc 96.493%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.189 Acc 95.692%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.180 Acc 95.814%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.117 Acc 96.612%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.117 Acc 96.642%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.118 Acc 96.473%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.116 Acc 96.466%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.117 Acc 96.463%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.173 Acc 95.864%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.109 Acc 96.914%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.112 Acc 96.720%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.115 Acc 96.592%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.117 Acc 96.610%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.174 Acc 95.732%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.134 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.117 Acc 96.295%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.118 Acc 96.315%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.115 Acc 96.499%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.115 Acc 96.517%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.115 Acc 96.541%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.183 Acc 95.715%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.173 Acc 95.931%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.111 Acc 96.743%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.112 Acc 96.683%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.115 Acc 96.582%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.125 Acc 96.875%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.187 Acc 95.490%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.176 Acc 95.763%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.110 Acc 96.550%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.112 Acc 96.700%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.115 Acc 96.631%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.114 Acc 96.657%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.113 Acc 96.635%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.184 Acc 95.676%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.174 Acc 95.802%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.115 Acc 96.380%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.116 Acc 96.436%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.114 Acc 96.579%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.113 Acc 96.637%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.113 Acc 96.657%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.188 Acc 95.599%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.178 Acc 95.767%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.113 Acc 96.798%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.112 Acc 96.709%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.114 Acc 96.600%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.114 Acc 96.602%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.180 Acc 95.630%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.171 Acc 95.907%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.109 Acc 96.705%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.109 Acc 96.735%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.111 Acc 96.673%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.113 Acc 96.633%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.113 Acc 96.649%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.179 Acc 95.831%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.171 Acc 96.032%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775f86c4cd6346e49ea23d0a9ba6cec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.321 Acc 17.969%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.250 Acc 19.872%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.242 Acc 19.306%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.232 Acc 19.440%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.194 Acc 21.010%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.124 Acc 23.944%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.583 Acc 47.656%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.619 Acc 46.612%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.615 Acc 46.723%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.731 Acc 38.281%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.520 Acc 48.461%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.444 Acc 51.586%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.374 Acc 54.015%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.322 Acc 55.858%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.273 Acc 57.663%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.831 Acc 72.656%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.833 Acc 73.762%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.830 Acc 73.729%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.889 Acc 68.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.980 Acc 68.116%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.952 Acc 69.213%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.921 Acc 70.159%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.892 Acc 71.061%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.876 Acc 71.655%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.574 Acc 81.250%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.606 Acc 81.219%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.600 Acc 81.367%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.710 Acc 74.219%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.719 Acc 77.011%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.711 Acc 77.367%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.698 Acc 77.775%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.687 Acc 78.113%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.677 Acc 78.463%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.417 Acc 86.719%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.474 Acc 85.620%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.466 Acc 85.844%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.724 Acc 80.469%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.598 Acc 80.879%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.592 Acc 81.161%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.587 Acc 81.312%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.583 Acc 81.521%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.578 Acc 81.766%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.382 Acc 87.500%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.429 Acc 87.399%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.422 Acc 87.438%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.590 Acc 80.469%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.542 Acc 83.269%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.535 Acc 83.364%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.528 Acc 83.498%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.523 Acc 83.701%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.519 Acc 83.772%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.361 Acc 87.500%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.389 Acc 88.351%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.383 Acc 88.378%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.470 Acc 87.500%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.493 Acc 84.599%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.482 Acc 84.962%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.483 Acc 84.860%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.479 Acc 84.987%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.475 Acc 85.187%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.349 Acc 88.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.360 Acc 89.503%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.353 Acc 89.576%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.414 Acc 85.156%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.452 Acc 85.512%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.454 Acc 85.833%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.452 Acc 85.979%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.450 Acc 86.107%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.446 Acc 86.173%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.290 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.332 Acc 90.130%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.326 Acc 90.267%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.375 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.414 Acc 87.299%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.423 Acc 87.193%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.425 Acc 86.942%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.422 Acc 86.923%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.422 Acc 87.013%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.347 Acc 88.281%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.332 Acc 90.370%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.327 Acc 90.454%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.414 Acc 85.938%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.418 Acc 87.067%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.410 Acc 87.360%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.401 Acc 87.635%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.404 Acc 87.570%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.399 Acc 87.703%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.282 Acc 89.062%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.300 Acc 91.244%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.294 Acc 91.465%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.438 Acc 86.719%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.393 Acc 87.786%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.393 Acc 87.869%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.390 Acc 88.019%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.385 Acc 88.186%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.385 Acc 88.167%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.287 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.302 Acc 91.236%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.297 Acc 91.301%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.386 Acc 90.625%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.379 Acc 88.459%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.381 Acc 88.382%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.377 Acc 88.476%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.371 Acc 88.648%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.367 Acc 88.755%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.272 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.285 Acc 91.832%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.280 Acc 91.892%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.386 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.337 Acc 89.449%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.345 Acc 89.253%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.350 Acc 89.182%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.350 Acc 89.082%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.351 Acc 89.128%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.283 Acc 92.041%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.278 Acc 92.203%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.282 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.339 Acc 89.581%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.347 Acc 89.471%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.343 Acc 89.597%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.345 Acc 89.516%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.343 Acc 89.540%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.261 Acc 90.625%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.266 Acc 92.296%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.264 Acc 92.331%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.393 Acc 87.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.338 Acc 89.720%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.338 Acc 89.692%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.333 Acc 89.763%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.332 Acc 89.832%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.332 Acc 89.828%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.270 Acc 92.435%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.266 Acc 92.409%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.327 Acc 87.500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.322 Acc 90.339%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.323 Acc 90.089%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.321 Acc 90.134%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.322 Acc 90.120%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.322 Acc 90.198%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.260 Acc 93.015%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.255 Acc 92.872%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.384 Acc 86.719%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.309 Acc 90.486%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.310 Acc 90.726%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.311 Acc 90.690%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.315 Acc 90.594%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.314 Acc 90.675%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.239 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.246 Acc 93.239%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.242 Acc 93.179%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.310 Acc 90.478%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.307 Acc 90.730%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.306 Acc 90.794%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.304 Acc 90.849%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.304 Acc 90.889%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.235 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.237 Acc 93.626%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.233 Acc 93.528%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.414 Acc 83.594%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.294 Acc 91.298%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.294 Acc 91.231%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.294 Acc 91.087%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.298 Acc 90.982%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.299 Acc 90.923%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.229 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.236 Acc 93.487%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.231 Acc 93.455%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.284 Acc 91.252%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.287 Acc 91.212%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.289 Acc 91.276%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.292 Acc 91.132%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.292 Acc 91.219%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.234 Acc 93.704%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.231 Acc 93.610%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.227 Acc 93.750%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.290 Acc 91.244%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.288 Acc 90.990%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.291 Acc 90.949%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.289 Acc 91.048%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.289 Acc 91.074%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.231 Acc 93.773%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.229 Acc 93.661%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.195 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.276 Acc 91.739%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.282 Acc 91.643%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.277 Acc 91.775%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.279 Acc 91.654%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.279 Acc 91.671%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.223 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.224 Acc 94.005%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.222 Acc 93.878%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.327 Acc 92.969%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.279 Acc 91.762%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.278 Acc 91.772%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.276 Acc 91.798%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.275 Acc 91.815%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.277 Acc 91.742%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.223 Acc 93.773%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.219 Acc 93.832%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.227 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.267 Acc 91.955%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.265 Acc 92.125%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.265 Acc 92.120%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.267 Acc 92.059%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.271 Acc 91.960%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.258 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.229 Acc 93.735%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.225 Acc 93.664%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.292 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.258 Acc 92.373%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.262 Acc 92.300%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.265 Acc 92.089%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.267 Acc 92.032%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.268 Acc 92.028%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.212 Acc 94.431%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.207 Acc 94.380%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.260 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.268 Acc 92.025%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.270 Acc 92.009%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.263 Acc 92.203%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.260 Acc 92.289%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.261 Acc 92.295%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.217 Acc 94.168%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.215 Acc 93.964%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.217 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.245 Acc 92.659%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.258 Acc 92.273%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.259 Acc 92.317%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.259 Acc 92.367%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.258 Acc 92.331%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.230 Acc 92.969%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.208 Acc 94.454%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.203 Acc 94.360%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.320 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.256 Acc 92.257%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.257 Acc 92.242%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.260 Acc 92.224%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.256 Acc 92.423%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.254 Acc 92.420%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.180 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.212 Acc 94.261%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.208 Acc 94.135%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.137 Acc 94.531%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.249 Acc 92.528%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.255 Acc 92.374%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.253 Acc 92.411%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.250 Acc 92.515%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.252 Acc 92.499%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.213 Acc 94.361%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.208 Acc 94.236%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.178 Acc 94.531%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.238 Acc 92.868%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.244 Acc 92.736%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.244 Acc 92.652%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.245 Acc 92.614%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.247 Acc 92.541%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.197 Acc 94.787%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.193 Acc 94.776%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.267 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.236 Acc 92.961%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.244 Acc 92.868%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.241 Acc 92.912%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.244 Acc 92.795%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.243 Acc 92.861%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.205 Acc 94.701%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.200 Acc 94.640%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.276 Acc 90.625%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.231 Acc 93.069%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.238 Acc 93.004%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.240 Acc 92.899%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.240 Acc 92.926%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.243 Acc 92.855%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.200 Acc 94.732%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.195 Acc 94.710%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.250 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.233 Acc 93.139%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.237 Acc 93.109%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.239 Acc 92.964%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.238 Acc 92.938%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.238 Acc 92.909%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.201 Acc 92.188%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.202 Acc 94.686%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.196 Acc 94.640%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.131 Acc 95.312%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.244 Acc 92.822%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.236 Acc 92.965%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.235 Acc 93.039%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.236 Acc 93.025%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.238 Acc 92.967%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.197 Acc 95.011%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.192 Acc 94.869%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.147 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.221 Acc 93.441%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.226 Acc 93.078%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.227 Acc 93.171%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.231 Acc 93.070%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.231 Acc 93.143%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.957%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.193 Acc 94.862%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.232 Acc 93.170%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.225 Acc 93.287%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.230 Acc 93.161%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.232 Acc 93.109%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.231 Acc 93.140%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.199 Acc 94.802%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.195 Acc 94.757%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.227 Acc 93.255%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.224 Acc 93.462%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.229 Acc 93.285%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.227 Acc 93.374%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.228 Acc 93.302%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.196 Acc 94.810%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.190 Acc 94.873%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.233 Acc 93.054%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.229 Acc 93.194%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.228 Acc 93.200%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.226 Acc 93.331%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.227 Acc 93.321%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.185 Acc 94.998%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.329 Acc 89.062%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.226 Acc 93.301%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.234 Acc 93.291%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.413%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.223 Acc 93.473%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.224 Acc 93.446%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.199 Acc 94.740%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.194 Acc 94.675%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.221 Acc 93.704%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.221 Acc 93.602%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.221 Acc 93.498%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.220 Acc 93.528%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.220 Acc 93.558%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.190 Acc 95.111%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.187 Acc 95.052%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.283 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.229 Acc 93.433%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.227 Acc 93.540%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.231 Acc 93.374%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.228 Acc 93.390%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.224 Acc 93.504%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.193 Acc 94.879%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.225 Acc 93.402%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.220 Acc 93.462%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.216 Acc 93.529%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.220 Acc 93.458%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.221 Acc 93.455%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.183 Acc 95.141%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.212 Acc 92.969%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.216 Acc 93.680%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.211 Acc 93.711%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.213 Acc 93.680%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.215 Acc 93.631%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.216 Acc 93.624%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.194 Acc 94.748%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.189 Acc 94.799%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.185 Acc 93.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.216 Acc 93.595%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.205 Acc 93.878%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.209 Acc 93.856%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.210 Acc 93.826%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.212 Acc 93.823%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.192 Acc 95.003%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.186 Acc 95.072%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.383 Acc 90.625%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.213 Acc 93.472%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.215 Acc 93.602%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.212 Acc 93.724%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.213 Acc 93.762%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.213 Acc 93.717%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.173 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.184 Acc 95.173%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.179 Acc 95.246%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.208 Acc 93.982%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.205 Acc 94.030%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.207 Acc 93.973%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.211 Acc 93.816%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.212 Acc 93.867%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.183 Acc 95.320%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.180 Acc 95.215%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.244 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.207 Acc 93.889%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.206 Acc 93.925%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.207 Acc 93.994%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.208 Acc 93.943%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.210 Acc 93.822%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.180 Acc 95.328%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.176 Acc 95.355%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.212 Acc 93.758%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.214 Acc 93.777%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.210 Acc 93.838%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.209 Acc 93.869%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.207 Acc 93.937%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.183 Acc 95.328%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.179 Acc 95.289%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.155 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.212 Acc 94.044%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.210 Acc 93.933%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.209 Acc 93.903%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.207 Acc 93.957%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.207 Acc 93.936%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.180 Acc 95.320%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.177 Acc 95.285%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.251 Acc 90.625%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.200 Acc 94.191%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.201 Acc 94.216%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.203 Acc 94.134%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.205 Acc 94.097%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.206 Acc 94.057%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.174 Acc 95.386%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.207 Acc 94.083%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.204 Acc 94.123%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.204 Acc 93.989%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.206 Acc 93.939%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.204 Acc 94.028%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.266%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.174 Acc 95.433%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.194 Acc 92.969%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.191 Acc 94.384%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.196 Acc 94.279%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.198 Acc 94.264%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.199 Acc 94.171%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.200 Acc 94.112%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.188 Acc 94.972%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 94.935%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.196 Acc 94.245%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.200 Acc 93.983%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.200 Acc 94.015%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.202 Acc 94.013%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.200 Acc 94.056%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.174 Acc 95.421%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.170 Acc 95.484%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.189 Acc 94.183%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.189 Acc 94.267%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.195 Acc 94.298%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.198 Acc 94.216%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.198 Acc 94.176%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.178 Acc 95.270%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.129 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.194 Acc 94.291%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.191 Acc 94.345%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.192 Acc 94.334%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.195 Acc 94.276%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.197 Acc 94.243%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.172 Acc 95.526%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.189 Acc 94.701%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.194 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.196 Acc 94.376%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.195 Acc 94.368%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.196 Acc 94.363%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.182 Acc 95.367%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.176 Acc 95.390%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.094 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.189 Acc 94.670%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.197 Acc 94.356%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.191 Acc 94.443%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.192 Acc 94.430%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.194 Acc 94.442%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.186 Acc 95.212%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.182 Acc 95.211%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.169 Acc 93.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.190 Acc 94.508%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.184 Acc 94.632%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.190 Acc 94.425%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.193 Acc 94.424%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.193 Acc 94.402%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.192 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.170 Acc 95.568%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.546%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.196 Acc 94.493%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.190 Acc 94.551%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.188 Acc 94.614%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.189 Acc 94.533%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.190 Acc 94.519%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.176 Acc 95.405%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.173 Acc 95.425%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.175 Acc 94.964%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.183 Acc 94.698%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.185 Acc 94.630%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.189 Acc 94.559%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.189 Acc 94.520%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.177 Acc 95.374%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.172 Acc 95.464%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.186 Acc 94.810%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.186 Acc 94.698%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.189 Acc 94.557%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.191 Acc 94.549%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.190 Acc 94.523%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.661%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.169 Acc 95.623%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.182 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.186 Acc 94.554%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.188 Acc 94.543%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.185 Acc 94.570%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.186 Acc 94.522%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.188 Acc 94.467%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.171 Acc 95.476%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.216 Acc 92.188%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.191 Acc 94.168%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.188 Acc 94.325%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.187 Acc 94.396%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.190 Acc 94.352%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.188 Acc 94.427%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.177 Acc 95.405%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.172 Acc 95.553%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.188 Acc 94.717%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.191 Acc 94.597%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.186 Acc 94.671%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.186 Acc 94.642%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.187 Acc 94.648%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.177 Acc 95.343%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.173 Acc 95.398%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.135 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.176 Acc 94.802%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.181 Acc 94.679%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.185 Acc 94.583%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.518%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.186 Acc 94.537%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.174 Acc 95.459%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.169 Acc 95.561%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.182 Acc 94.949%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.179 Acc 94.850%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.180 Acc 94.801%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.183 Acc 94.726%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.184 Acc 94.731%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.178 Acc 95.297%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.171 Acc 95.390%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.205 Acc 94.531%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.184 Acc 94.686%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.179 Acc 94.823%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.180 Acc 94.835%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.182 Acc 94.814%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.184 Acc 94.700%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.167 Acc 92.188%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.175 Acc 95.490%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.170 Acc 95.546%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.144 Acc 92.969%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.183 Acc 94.632%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.345%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.185 Acc 94.464%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.186 Acc 94.496%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.186 Acc 94.522%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.171 Acc 95.661%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.368 Acc 92.969%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.185 Acc 94.686%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.182 Acc 94.737%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.180 Acc 94.679%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.180 Acc 94.718%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.181 Acc 94.693%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.182 Acc 92.188%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.173 Acc 95.475%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.168 Acc 95.534%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.176 Acc 94.771%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.177 Acc 94.726%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.179 Acc 94.786%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.178 Acc 94.804%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.181 Acc 94.801%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.172 Acc 95.538%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.166 Acc 95.050%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.168 Acc 94.990%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.172 Acc 94.931%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.174 Acc 94.921%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.176 Acc 94.888%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.169 Acc 95.405%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.163 Acc 95.553%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.184 Acc 92.969%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.167 Acc 95.026%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.172 Acc 95.017%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.176 Acc 94.887%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.177 Acc 94.864%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.176 Acc 94.896%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.214 Acc 90.625%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.174 Acc 95.460%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.163 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.183 Acc 94.895%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.177 Acc 95.044%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.175 Acc 95.050%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.177 Acc 95.026%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.178 Acc 94.988%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.173 Acc 95.421%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.515%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.163 Acc 95.119%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.166 Acc 95.157%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.170 Acc 95.066%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.173 Acc 95.009%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.173 Acc 94.993%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.170 Acc 95.722%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 95.709%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.172 Acc 94.918%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.174 Acc 94.982%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.173 Acc 94.991%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.176 Acc 94.907%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.176 Acc 94.882%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.630%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.166 Acc 95.709%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.169 Acc 94.933%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.171 Acc 94.943%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.173 Acc 94.934%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.174 Acc 94.905%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.175 Acc 94.941%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.174 Acc 95.467%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.170 Acc 95.565%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.105 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.178 Acc 94.624%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.173 Acc 94.799%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.173 Acc 94.939%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.172 Acc 94.958%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.173 Acc 94.963%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.189 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.173 Acc 95.459%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.167 Acc 95.569%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.176 Acc 92.969%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.175 Acc 94.879%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.172 Acc 95.029%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.174 Acc 94.991%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.175 Acc 94.974%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.175 Acc 94.962%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.166 Acc 95.707%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.163 Acc 95.794%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.161 Acc 95.320%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.175 Acc 95.068%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.175 Acc 94.949%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.174 Acc 94.952%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.172 Acc 94.954%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.172 Acc 95.591%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.166 Acc 95.736%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.161 Acc 95.258%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.169 Acc 95.048%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.170 Acc 95.006%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.171 Acc 95.065%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.172 Acc 95.099%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.138 Acc 93.750%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.170 Acc 95.483%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.608%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.105 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.170 Acc 94.895%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.166 Acc 95.141%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.164 Acc 95.271%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.166 Acc 95.221%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.166 Acc 95.211%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.343%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.173 Acc 95.507%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.240 Acc 92.188%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.170 Acc 95.088%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.173 Acc 94.970%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.171 Acc 95.048%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.171 Acc 95.067%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.170 Acc 95.069%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.169 Acc 95.560%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.165 Acc 95.604%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.162 Acc 95.374%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.174 Acc 95.068%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.173 Acc 95.105%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.170 Acc 95.184%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.170 Acc 95.150%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.169 Acc 95.630%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.164 Acc 95.686%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.137 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.155 Acc 95.336%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.161 Acc 95.293%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.165 Acc 95.227%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.166 Acc 95.131%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.166 Acc 95.169%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.173 Acc 95.405%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.169 Acc 95.476%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.188 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.159 Acc 95.166%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.163 Acc 95.130%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.167 Acc 95.081%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.166 Acc 95.087%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.166 Acc 95.085%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.173 Acc 95.506%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.167 Acc 95.655%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.167 Acc 95.235%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.165 Acc 95.196%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.164 Acc 95.227%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.167 Acc 95.213%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.166 Acc 95.182%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.176 Acc 95.421%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.171 Acc 95.573%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.155 Acc 95.568%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.161 Acc 95.476%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.162 Acc 95.471%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.161 Acc 95.404%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.162 Acc 95.364%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.215 Acc 92.188%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.529%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.174 Acc 95.569%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.164 Acc 95.297%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.166 Acc 95.281%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.165 Acc 95.214%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.163 Acc 95.291%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.186 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.175 Acc 95.490%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.171 Acc 95.519%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.159 Acc 95.490%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.160 Acc 95.437%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.159 Acc 95.528%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.162 Acc 95.431%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.162 Acc 95.434%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.198 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.169 Acc 95.707%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.164 Acc 95.814%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.161 Acc 95.514%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.163 Acc 95.336%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.163 Acc 95.315%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.161 Acc 95.326%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.162 Acc 95.353%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.560%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.169 Acc 95.639%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.155 Acc 95.413%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.157 Acc 95.484%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.159 Acc 95.449%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.161 Acc 95.369%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.170 Acc 95.717%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.162 Acc 95.212%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.164 Acc 95.324%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.163 Acc 95.268%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.162 Acc 95.291%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.162 Acc 95.291%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.145 Acc 92.969%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.168 Acc 95.722%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.164 Acc 95.779%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.187 Acc 92.969%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.153 Acc 95.475%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.157 Acc 95.433%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.159 Acc 95.359%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.159 Acc 95.308%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.171 Acc 95.568%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.167 Acc 95.674%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.110 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.155 Acc 95.444%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.155 Acc 95.452%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.155 Acc 95.447%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.156 Acc 95.406%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.157 Acc 95.433%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.168 Acc 95.684%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.162 Acc 95.771%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.147 Acc 95.869%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.153 Acc 95.604%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.154 Acc 95.564%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.155 Acc 95.542%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.157 Acc 95.520%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.166 Acc 95.756%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.157 Acc 95.220%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.480%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.154 Acc 95.525%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.157 Acc 95.494%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.157 Acc 95.482%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.170 Acc 95.490%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.164 Acc 95.631%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.148 Acc 96.875%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.153 Acc 95.715%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.157 Acc 95.647%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.156 Acc 95.562%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.158 Acc 95.463%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.158 Acc 95.428%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.168 Acc 95.645%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.163 Acc 95.810%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.155 Acc 95.591%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.153 Acc 95.530%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.156 Acc 95.450%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.156 Acc 95.503%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.155 Acc 95.497%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.168 Acc 95.769%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.163 Acc 95.779%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.160 Acc 95.189%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.154 Acc 95.421%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.154 Acc 95.536%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.156 Acc 95.457%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.155 Acc 95.478%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.171 Acc 95.668%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.165 Acc 95.756%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.147 Acc 95.668%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.151 Acc 95.616%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.153 Acc 95.611%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.156 Acc 95.500%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.156 Acc 95.565%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.174 Acc 95.490%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.169 Acc 95.635%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.151 Acc 95.777%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.150 Acc 95.794%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.153 Acc 95.575%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.156 Acc 95.513%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.157 Acc 95.487%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.168 Acc 95.666%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.152 Acc 95.545%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.153 Acc 95.686%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.153 Acc 95.582%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.152 Acc 95.599%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.153 Acc 95.523%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.171 Acc 95.653%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.165 Acc 95.787%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.154 Acc 95.699%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.159 Acc 95.495%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.156 Acc 95.559%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.155 Acc 95.568%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.153 Acc 95.587%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.174 Acc 95.514%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.169 Acc 95.577%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.156 Acc 95.297%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.316%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.156 Acc 95.388%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.154 Acc 95.461%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.167 Acc 95.777%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.162 Acc 95.880%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.152 Acc 95.483%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.156 Acc 95.301%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.151 Acc 95.505%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.150 Acc 95.583%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.150 Acc 95.570%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.169 Acc 95.637%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.166 Acc 95.798%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.189 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.147 Acc 95.777%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.151 Acc 95.676%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.151 Acc 95.696%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.150 Acc 95.709%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.163 Acc 95.792%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.160 Acc 95.798%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.206 Acc 92.969%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.152 Acc 95.653%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.147 Acc 95.655%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.149 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.150 Acc 95.554%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.150 Acc 95.581%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.167 Acc 95.622%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.163 Acc 95.697%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.251 Acc 92.969%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.145 Acc 95.846%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.146 Acc 95.783%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.150 Acc 95.681%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.152 Acc 95.650%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.151 Acc 95.719%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.167 Acc 95.792%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.163 Acc 95.861%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.131 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.147 Acc 95.639%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.146 Acc 95.704%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.148 Acc 95.663%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.150 Acc 95.682%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.170 Acc 95.588%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.152 Acc 95.668%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.151 Acc 95.637%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.149 Acc 95.651%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.150 Acc 95.651%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.475%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.168 Acc 95.620%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.169 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.152 Acc 95.575%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.150 Acc 95.608%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.153 Acc 95.505%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.152 Acc 95.544%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.150 Acc 95.615%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.165 Acc 95.800%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.162 Acc 95.872%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.151 Acc 95.560%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.144 Acc 95.736%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.144 Acc 95.717%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.145 Acc 95.720%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.146 Acc 95.654%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.164 Acc 95.808%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.159 Acc 95.954%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.183 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.144 Acc 95.684%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.142 Acc 95.787%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.145 Acc 95.793%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.146 Acc 95.807%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.147 Acc 95.741%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.167 Acc 95.823%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.163 Acc 95.833%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.148 Acc 95.800%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.149 Acc 95.818%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.146 Acc 95.847%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.144 Acc 95.885%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.145 Acc 95.840%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.176 Acc 95.452%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.168 Acc 95.612%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.148 Acc 95.893%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.146 Acc 95.876%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.146 Acc 95.718%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.146 Acc 95.705%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.170 Acc 95.831%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.164 Acc 95.923%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.169 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.142 Acc 95.792%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.145 Acc 95.639%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.145 Acc 95.660%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.148 Acc 95.632%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.147 Acc 95.681%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.172 Acc 95.639%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.142 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.136 Acc 95.985%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.140 Acc 95.962%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.145 Acc 95.850%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.144 Acc 95.836%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.167 Acc 95.792%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.162 Acc 95.927%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.149 Acc 95.661%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.145 Acc 95.806%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.144 Acc 95.856%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.145 Acc 95.818%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.166 Acc 95.748%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.145 Acc 95.560%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.146 Acc 95.620%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.142 Acc 95.699%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.142 Acc 95.778%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.144 Acc 95.713%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.166 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.175 Acc 95.498%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.169 Acc 95.682%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.145 Acc 95.792%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.143 Acc 95.806%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.143 Acc 95.829%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.144 Acc 95.741%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.145 Acc 95.744%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.170 Acc 95.738%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.167 Acc 95.798%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.138 Acc 96.132%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.144 Acc 95.883%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.143 Acc 95.907%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.170 Acc 95.715%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.137 Acc 95.831%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.141 Acc 95.896%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.140 Acc 95.941%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.142 Acc 95.811%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.142 Acc 95.813%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.168 Acc 95.815%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.166 Acc 95.822%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.140 Acc 96.034%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.142 Acc 95.950%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.141 Acc 95.925%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.168 Acc 95.908%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.163 Acc 95.938%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.142 Acc 95.970%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.141 Acc 95.969%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.140 Acc 95.977%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.140 Acc 95.930%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.141 Acc 95.921%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.164 Acc 95.962%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.160 Acc 95.946%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.140 Acc 95.823%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.138 Acc 95.903%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.140 Acc 95.805%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.141 Acc 95.802%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.168 Acc 95.777%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 95.759%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.142 Acc 95.777%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.138 Acc 95.907%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.137 Acc 95.896%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.139 Acc 95.864%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.140 Acc 95.849%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.166 Acc 95.837%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.197 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.135 Acc 96.000%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.136 Acc 95.974%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.136 Acc 95.942%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.139 Acc 95.911%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.614%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.167 Acc 95.631%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.137 Acc 96.125%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.141 Acc 95.993%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.141 Acc 95.995%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.140 Acc 95.961%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.140 Acc 95.972%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.174 Acc 95.622%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.169 Acc 95.783%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.128 Acc 96.442%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.134 Acc 96.175%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.136 Acc 96.156%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.138 Acc 96.055%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.137 Acc 96.056%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.174 Acc 95.529%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.169 Acc 95.693%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.141 Acc 95.861%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.140 Acc 95.873%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.139 Acc 95.895%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.140 Acc 95.871%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.165 Acc 95.862%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.160 Acc 95.965%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.136 Acc 96.003%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.134 Acc 96.080%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.137 Acc 96.017%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.174 Acc 95.684%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.170 Acc 95.732%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.137 Acc 96.001%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.135 Acc 96.034%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.135 Acc 96.103%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.135 Acc 96.055%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.174 Acc 95.537%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.167 Acc 95.608%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.106 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.126 Acc 96.349%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.129 Acc 96.304%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.131 Acc 96.208%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.134 Acc 96.121%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.135 Acc 96.123%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.173 Acc 95.606%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.167 Acc 95.857%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.245 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.133 Acc 96.295%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.136 Acc 96.102%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.134 Acc 96.051%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.136 Acc 96.010%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.174 Acc 95.568%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.170 Acc 95.655%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.201 Acc 92.188%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.138 Acc 95.893%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.132 Acc 96.024%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.132 Acc 96.006%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.133 Acc 95.952%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.134 Acc 95.952%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.169 Acc 95.815%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.132 Acc 95.893%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.131 Acc 95.946%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.131 Acc 96.073%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.133 Acc 96.055%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.136 Acc 96.019%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.134 Acc 95.985%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.134 Acc 96.042%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.133 Acc 96.092%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.135 Acc 96.030%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.170 Acc 95.645%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.166 Acc 95.853%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.133 Acc 96.210%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.135 Acc 96.129%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.134 Acc 96.164%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.133 Acc 96.220%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.134 Acc 96.198%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.167 Acc 95.854%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.163 Acc 95.942%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.141 Acc 95.985%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.140 Acc 96.012%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.136 Acc 96.078%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.135 Acc 96.055%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.134 Acc 96.038%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.166 Acc 95.900%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.162 Acc 95.997%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.135 Acc 96.109%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.131 Acc 96.214%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.134 Acc 96.099%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.134 Acc 96.115%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.133 Acc 96.133%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.599%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 95.752%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.122 Acc 96.287%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.128 Acc 96.102%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.131 Acc 96.161%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.132 Acc 96.121%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.132 Acc 96.098%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.171 Acc 95.583%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.167 Acc 95.744%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.125 Acc 96.380%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.135 Acc 96.222%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.132 Acc 96.242%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.132 Acc 96.174%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.132 Acc 96.176%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.169 Acc 95.670%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.125 Acc 96.346%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.126 Acc 96.294%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.129 Acc 96.218%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.130 Acc 96.186%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.165 Acc 95.746%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.161 Acc 95.857%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.129 Acc 96.310%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.127 Acc 96.428%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.131 Acc 96.135%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.131 Acc 96.150%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.170 Acc 95.784%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.165 Acc 95.864%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.129 Acc 96.210%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.128 Acc 96.323%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.130 Acc 96.320%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.130 Acc 96.244%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.131 Acc 96.201%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.170 Acc 95.614%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.166 Acc 95.794%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.123 Acc 96.357%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.126 Acc 96.206%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.127 Acc 96.296%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.130 Acc 96.215%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.132 Acc 96.170%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.169 Acc 95.568%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.164 Acc 95.849%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.201 Acc 93.750%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.122 Acc 96.488%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.123 Acc 96.381%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.127 Acc 96.307%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.128 Acc 96.228%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.129 Acc 96.209%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.165 Acc 95.769%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.162 Acc 95.958%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.121 Acc 96.498%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.125 Acc 96.351%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.132 Acc 96.151%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.127 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.129 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.131 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.130 Acc 96.201%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.128 Acc 96.248%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.169 Acc 95.792%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.162 Acc 95.934%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.163 Acc 95.312%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.121 Acc 96.349%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.125 Acc 96.276%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.127 Acc 96.205%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.127 Acc 96.228%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.129 Acc 96.203%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.171 Acc 95.931%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.166 Acc 95.942%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.126 Acc 96.279%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.127 Acc 96.137%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.130 Acc 96.144%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.129 Acc 96.175%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.166 Acc 95.806%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.120 Acc 96.666%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.124 Acc 96.529%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.125 Acc 96.403%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.127 Acc 96.335%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.128 Acc 96.262%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.177 Acc 95.413%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.172 Acc 95.542%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.125 Acc 96.287%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.123 Acc 96.346%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.124 Acc 96.371%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.126 Acc 96.318%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.127 Acc 96.314%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.171 Acc 95.730%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.165 Acc 95.837%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.134 Acc 96.109%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.131 Acc 96.199%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.130 Acc 96.203%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.126 Acc 96.324%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.126 Acc 96.268%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.176 Acc 95.459%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.171 Acc 95.588%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.123 Acc 96.300%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.125 Acc 96.257%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.127 Acc 96.269%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.129 Acc 96.184%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.167 Acc 95.705%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.147 Acc 93.750%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.127 Acc 96.354%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.128 Acc 96.335%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.129 Acc 96.292%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.129 Acc 96.239%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.171 Acc 95.784%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.168 Acc 95.818%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.123 Acc 96.457%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.124 Acc 96.358%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.126 Acc 96.269%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.125 Acc 96.323%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.189 Acc 92.188%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.175 Acc 95.777%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.171 Acc 95.876%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.139 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.127 Acc 96.295%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.121 Acc 96.440%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.122 Acc 96.366%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.125 Acc 96.339%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.126 Acc 96.348%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.197 Acc 92.188%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.182 Acc 95.506%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.175 Acc 95.662%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.121 Acc 96.506%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.123 Acc 96.416%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.123 Acc 96.384%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.125 Acc 96.282%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.176 Acc 95.591%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.171 Acc 95.690%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.124 Acc 96.403%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.125 Acc 96.335%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.124 Acc 96.322%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.125 Acc 96.284%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.177 Acc 95.637%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.172 Acc 95.763%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.125 Acc 96.426%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.120 Acc 96.502%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.122 Acc 96.410%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.124 Acc 96.354%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.176 Acc 95.552%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.171 Acc 95.670%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.122 Acc 96.434%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.124 Acc 96.257%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.125 Acc 96.211%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.123 Acc 96.310%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.123 Acc 96.321%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.171 Acc 95.777%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.164 Acc 95.903%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.119 Acc 96.728%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.121 Acc 96.545%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.120 Acc 96.488%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.123 Acc 96.386%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.124 Acc 96.348%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.170 Acc 95.730%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.166 Acc 95.845%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.189 Acc 92.969%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.115 Acc 96.457%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.120 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.122 Acc 96.353%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.121 Acc 96.353%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.164 Acc 95.818%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.121 Acc 96.542%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.120 Acc 96.514%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.122 Acc 96.426%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.122 Acc 96.423%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.164 Acc 95.826%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.122 Acc 95.312%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.119 Acc 96.589%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.122 Acc 96.432%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.122 Acc 96.423%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.123 Acc 96.329%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.122 Acc 96.443%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.175 Acc 95.707%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.168 Acc 95.810%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.114 Acc 96.798%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.118 Acc 96.479%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.120 Acc 96.473%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.120 Acc 96.485%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.123 Acc 96.403%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.176 Acc 95.661%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.169 Acc 95.806%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.115 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.118 Acc 96.419%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.120 Acc 96.401%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.123 Acc 96.330%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.122 Acc 96.368%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.123 Acc 96.329%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.174 Acc 95.899%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.243 Acc 91.406%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.117 Acc 96.558%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.121 Acc 96.393%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.122 Acc 96.390%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.124 Acc 96.316%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.123 Acc 96.356%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.132 Acc 92.969%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.167 Acc 95.900%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.163 Acc 95.954%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.127 Acc 96.125%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.121 Acc 96.308%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.122 Acc 96.288%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.123 Acc 96.283%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.122 Acc 96.329%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.173 Acc 95.800%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.168 Acc 95.896%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.134 Acc 92.969%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.115 Acc 96.473%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.117 Acc 96.521%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.120 Acc 96.496%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.120 Acc 96.464%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.121 Acc 96.403%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.181 Acc 95.521%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.174 Acc 95.674%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.181 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.119 Acc 96.527%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.122 Acc 96.385%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.119 Acc 96.426%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.119 Acc 96.433%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.119 Acc 96.446%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.180 Acc 95.614%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.173 Acc 95.767%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.113 Acc 96.736%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.120 Acc 96.498%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.121 Acc 96.421%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.120 Acc 96.444%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.120 Acc 96.465%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.176 Acc 95.529%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.171 Acc 95.725%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.114 Acc 96.658%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.119 Acc 96.545%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.121 Acc 96.457%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.123 Acc 96.433%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.122 Acc 96.456%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.186 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.174 Acc 95.869%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.115 Acc 96.643%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.119 Acc 96.479%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.119 Acc 96.474%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.121 Acc 96.421%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.167 Acc 95.857%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.116 Acc 96.612%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.115 Acc 96.630%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.116 Acc 96.634%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.118 Acc 96.542%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.118 Acc 96.533%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.176 Acc 95.753%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.172 Acc 95.849%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.150 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.109 Acc 96.767%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.112 Acc 96.766%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.113 Acc 96.683%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.114 Acc 96.614%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.116 Acc 96.593%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.166 Acc 95.761%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.161 Acc 95.868%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.114 Acc 96.504%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.115 Acc 96.607%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.116 Acc 96.532%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.115 Acc 96.489%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.118 Acc 96.406%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.514%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.165 Acc 95.779%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.190 Acc 96.094%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.121 Acc 96.457%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.117 Acc 96.490%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.117 Acc 96.517%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.118 Acc 96.458%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.119 Acc 96.445%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.170 Acc 95.753%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.166 Acc 95.896%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.117 Acc 96.651%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.118 Acc 96.568%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.119 Acc 96.519%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.118 Acc 96.462%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.182 Acc 95.413%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.174 Acc 95.600%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.112 Acc 96.682%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.112 Acc 96.630%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.111 Acc 96.641%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.114 Acc 96.569%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.116 Acc 96.499%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.171 Acc 95.514%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.164 Acc 95.759%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.041 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.111 Acc 96.573%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.116 Acc 96.479%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.116 Acc 96.538%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.117 Acc 96.537%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.170 Acc 95.868%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.116 Acc 96.612%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.119 Acc 96.583%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.119 Acc 96.522%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.119 Acc 96.523%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.175 Acc 95.684%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.169 Acc 95.822%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.102 Acc 96.960%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.109 Acc 96.677%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.112 Acc 96.628%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.113 Acc 96.555%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.114 Acc 96.532%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.174 Acc 95.908%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.169 Acc 95.927%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.091 Acc 96.094%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.112 Acc 96.488%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.114 Acc 96.510%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.119 Acc 96.405%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.118 Acc 96.501%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.119 Acc 96.495%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.166 Acc 95.965%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.113 Acc 96.674%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.116 Acc 96.595%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.115 Acc 96.673%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.116 Acc 96.645%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.117 Acc 96.576%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.167 Acc 95.868%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.112 Acc 96.762%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.114 Acc 96.649%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.114 Acc 96.659%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.115 Acc 96.601%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.169 Acc 95.965%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.138 Acc 97.656%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.112 Acc 96.678%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.115 Acc 96.583%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.171 Acc 96.001%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.167 Acc 96.000%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.179 Acc 96.094%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.112 Acc 96.689%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.118 Acc 96.506%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.119 Acc 96.452%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.117 Acc 96.530%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.115 Acc 96.568%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.176 Acc 95.692%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.171 Acc 95.806%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.116 Acc 96.627%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.114 Acc 96.615%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.114 Acc 96.597%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.115 Acc 96.571%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.114 Acc 96.577%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.169 Acc 95.908%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.163 Acc 96.039%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.126 Acc 92.969%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.111 Acc 96.736%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.112 Acc 96.699%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.113 Acc 96.616%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.112 Acc 96.627%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.175 Acc 95.769%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.169 Acc 95.857%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.196 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.109 Acc 96.713%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.111 Acc 96.587%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.111 Acc 96.610%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.112 Acc 96.579%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.165 Acc 95.769%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.159 Acc 95.993%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.108 Acc 96.836%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.111 Acc 96.700%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.113 Acc 96.610%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.115 Acc 96.604%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.115 Acc 96.551%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.182 Acc 95.653%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.177 Acc 95.721%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.114 Acc 96.728%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.110 Acc 96.743%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.111 Acc 96.636%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.115 Acc 96.555%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.114 Acc 96.529%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.183 Acc 95.738%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.176 Acc 95.802%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.107 Acc 96.728%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.112 Acc 96.595%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.114 Acc 96.594%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.177 Acc 95.596%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.117 Acc 96.620%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.115 Acc 96.638%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.112 Acc 96.692%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.112 Acc 96.650%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.173 Acc 95.808%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.167 Acc 95.896%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.106 Acc 96.713%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.109 Acc 96.688%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.111 Acc 96.722%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.111 Acc 96.727%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.111 Acc 96.722%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.179 Acc 95.715%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.106 Acc 96.713%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.106 Acc 96.793%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.110 Acc 96.683%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.109 Acc 96.659%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.111 Acc 96.616%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.180 Acc 95.630%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.174 Acc 95.791%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.114 Acc 96.589%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.112 Acc 96.634%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.112 Acc 96.644%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.111 Acc 96.657%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.114 Acc 96.615%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.174 Acc 95.722%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.168 Acc 95.814%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.108 Acc 96.705%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.109 Acc 96.747%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.112 Acc 96.602%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.113 Acc 96.546%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.113 Acc 96.548%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.176 Acc 95.661%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.170 Acc 95.775%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a3282cc94a49e0bb961a8f7ca197fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.338 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.285 Acc 15.231%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.265 Acc 16.818%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.250 Acc 17.720%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.200 Acc 20.244%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.115 Acc 23.832%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.376 Acc 50.781%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.383 Acc 52.591%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.379 Acc 52.394%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.413 Acc 53.906%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.261 Acc 57.805%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.181 Acc 60.969%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.116 Acc 63.164%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.059 Acc 65.272%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.008 Acc 67.066%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.654 Acc 75.781%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.618 Acc 80.879%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.608 Acc 81.429%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.808 Acc 78.906%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.715 Acc 77.669%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.695 Acc 78.152%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.676 Acc 78.914%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.655 Acc 79.454%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.643 Acc 79.818%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.511 Acc 83.594%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.468 Acc 85.466%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.464 Acc 85.665%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.684 Acc 82.812%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.539 Acc 83.199%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.535 Acc 83.306%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.523 Acc 83.638%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.519 Acc 83.775%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.516 Acc 83.935%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.383 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.382 Acc 88.877%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.380 Acc 88.685%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.747 Acc 86.719%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.450 Acc 86.077%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.447 Acc 86.151%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.450 Acc 86.161%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.449 Acc 86.187%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.445 Acc 86.263%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.354 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.358 Acc 89.411%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.355 Acc 89.335%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.320 Acc 89.844%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.416 Acc 87.013%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.420 Acc 86.952%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.414 Acc 87.163%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.408 Acc 87.369%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.404 Acc 87.506%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.320 Acc 90.888%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.314 Acc 90.913%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.434 Acc 85.938%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.381 Acc 88.498%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.382 Acc 88.413%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.378 Acc 88.491%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.376 Acc 88.556%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.374 Acc 88.618%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.261 Acc 92.188%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.301 Acc 91.360%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.297 Acc 91.418%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.364 Acc 89.062%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.352 Acc 89.434%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.353 Acc 89.237%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.347 Acc 89.418%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.350 Acc 89.349%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.351 Acc 89.382%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.230 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.277 Acc 92.071%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.273 Acc 92.125%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.302 Acc 91.406%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.335 Acc 89.759%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.337 Acc 89.727%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.335 Acc 89.805%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.333 Acc 89.883%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.329 Acc 89.933%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.269 Acc 92.296%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.266 Acc 92.347%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.353 Acc 89.062%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.307 Acc 90.501%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.314 Acc 90.400%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.318 Acc 90.301%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.315 Acc 90.454%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.315 Acc 90.449%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.293 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.268 Acc 92.396%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.266 Acc 92.409%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.252 Acc 92.969%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.309 Acc 90.880%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.306 Acc 90.885%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.307 Acc 90.830%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.305 Acc 90.880%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.304 Acc 90.854%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.252 Acc 92.938%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.251 Acc 92.833%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.423 Acc 86.719%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.295 Acc 91.143%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.293 Acc 91.091%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.291 Acc 91.271%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.288 Acc 91.385%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.288 Acc 91.431%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.262 Acc 92.481%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.257 Acc 92.491%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.276 Acc 91.515%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.277 Acc 91.737%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.274 Acc 91.788%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.279 Acc 91.687%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.280 Acc 91.684%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.248 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.238 Acc 93.356%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.235 Acc 93.350%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.323 Acc 92.969%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.270 Acc 91.979%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.265 Acc 92.055%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.272 Acc 91.770%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.270 Acc 91.917%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.270 Acc 91.908%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.230 Acc 93.758%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.228 Acc 93.692%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.264 Acc 92.079%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.262 Acc 92.176%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.257 Acc 92.322%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.260 Acc 92.314%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.261 Acc 92.304%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.231 Acc 93.580%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.226 Acc 93.521%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.334 Acc 90.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.250 Acc 92.597%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.248 Acc 92.697%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.253 Acc 92.476%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.255 Acc 92.460%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.255 Acc 92.425%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.243 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.232 Acc 93.595%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.228 Acc 93.657%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.127 Acc 96.094%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.245 Acc 92.729%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.247 Acc 92.658%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.250 Acc 92.668%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.249 Acc 92.624%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.251 Acc 92.548%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.225 Acc 93.704%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.224 Acc 93.672%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.245 Acc 92.675%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.246 Acc 92.837%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.242 Acc 92.919%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.245 Acc 92.840%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.246 Acc 92.797%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.212 Acc 94.160%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.209 Acc 94.174%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.213 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.230 Acc 93.031%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.233 Acc 93.062%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.238 Acc 92.964%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.238 Acc 93.016%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.237 Acc 93.003%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.218 Acc 94.075%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.214 Acc 94.065%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.236 Acc 92.775%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.234 Acc 93.074%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.235 Acc 93.041%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.235 Acc 93.031%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.236 Acc 93.028%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.214 Acc 94.144%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.210 Acc 94.154%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.247 Acc 92.188%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.240 Acc 92.930%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.230 Acc 93.260%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.229 Acc 93.376%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.229 Acc 93.308%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.228 Acc 93.327%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.205 Acc 94.462%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.204 Acc 94.349%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.241 Acc 92.188%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.219 Acc 93.487%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.226 Acc 93.408%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.226 Acc 93.420%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.226 Acc 93.353%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.227 Acc 93.370%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.214 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.212 Acc 94.268%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.210 Acc 94.154%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.295 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.219 Acc 93.580%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.223 Acc 93.482%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.222 Acc 93.449%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.222 Acc 93.514%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.219 Acc 93.621%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.215 Acc 95.312%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.209 Acc 94.400%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.208 Acc 94.267%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.191 Acc 92.969%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.225 Acc 93.765%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.219 Acc 93.789%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.216 Acc 93.794%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.218 Acc 93.680%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.217 Acc 93.666%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.197 Acc 94.810%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.195 Acc 94.687%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.239 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.204 Acc 94.036%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.211 Acc 93.828%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.210 Acc 93.906%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.210 Acc 93.884%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.210 Acc 93.909%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.198 Acc 94.856%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.198 Acc 94.737%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.205 Acc 94.083%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.210 Acc 93.972%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.212 Acc 93.776%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.210 Acc 93.793%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.208 Acc 93.850%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.210 Acc 94.129%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.206 Acc 94.076%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.141 Acc 98.438%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.198 Acc 94.230%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.200 Acc 94.150%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.203 Acc 94.025%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.203 Acc 94.048%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.204 Acc 94.034%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.186 Acc 95.013%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.256 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.193 Acc 94.407%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.199 Acc 94.131%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.203 Acc 94.010%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.203 Acc 94.015%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.201 Acc 94.087%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.202 Acc 94.740%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.197 Acc 94.652%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.196 Acc 94.516%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.194 Acc 94.352%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.195 Acc 94.277%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.197 Acc 94.220%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.199 Acc 94.159%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.194 Acc 94.825%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.192 Acc 94.819%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.253 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.178 Acc 95.073%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.181 Acc 94.862%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.186 Acc 94.718%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.190 Acc 94.584%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.194 Acc 94.525%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.190 Acc 94.725%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.187 Acc 94.733%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.184 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.187 Acc 94.656%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.190 Acc 94.604%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.192 Acc 94.580%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.192 Acc 94.833%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.135 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.196 Acc 94.369%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.195 Acc 94.391%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.189 Acc 94.472%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.191 Acc 94.488%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.196 Acc 94.802%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.192 Acc 94.803%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.235 Acc 89.844%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.179 Acc 94.601%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.181 Acc 94.582%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.183 Acc 94.622%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.186 Acc 94.543%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.187 Acc 94.548%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.193 Acc 94.995%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.189 Acc 94.904%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.192 Acc 94.771%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.185 Acc 94.710%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.184 Acc 94.679%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.184 Acc 94.681%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.186 Acc 94.654%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.200 Acc 94.740%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.195 Acc 94.772%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.181 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.185 Acc 94.794%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.184 Acc 94.811%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.187 Acc 94.638%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.185 Acc 94.590%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.184 Acc 94.639%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.185 Acc 95.189%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.181 Acc 95.134%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.182 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.171 Acc 95.009%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.176 Acc 94.957%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.177 Acc 94.960%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.178 Acc 94.851%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.182 Acc 95.270%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.255 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.167 Acc 95.274%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.175 Acc 94.959%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.177 Acc 94.918%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.177 Acc 94.876%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.177 Acc 94.885%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.128 Acc 96.875%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.191 Acc 94.903%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.189 Acc 94.908%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.173 Acc 95.119%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.171 Acc 95.095%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.171 Acc 95.074%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.176 Acc 94.956%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.176 Acc 94.955%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.184 Acc 95.204%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.181 Acc 95.149%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.164 Acc 95.266%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.169 Acc 95.110%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.167 Acc 95.198%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.171 Acc 95.094%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.173 Acc 95.030%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.191 Acc 94.787%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.186 Acc 94.850%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.165 Acc 95.343%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.168 Acc 95.134%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.172 Acc 95.030%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.171 Acc 95.032%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.172 Acc 94.994%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.186 Acc 95.104%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.182 Acc 95.173%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.243 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.163 Acc 95.467%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.162 Acc 95.293%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.166 Acc 95.229%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.213%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.169 Acc 95.147%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.175 Acc 95.464%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.158 Acc 95.343%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.161 Acc 95.285%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.163 Acc 95.341%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.166 Acc 95.256%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.168 Acc 95.182%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.184 Acc 95.328%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.180 Acc 95.285%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.160 Acc 95.490%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.162 Acc 95.386%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.164 Acc 95.364%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.164 Acc 95.294%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.184 Acc 95.088%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.179 Acc 95.169%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.169 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.167 Acc 95.328%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.164 Acc 95.325%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.163 Acc 95.377%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.163 Acc 95.358%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.187 Acc 95.080%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.181 Acc 95.161%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.168 Acc 95.204%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.163 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.163 Acc 95.333%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.163 Acc 95.305%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.162 Acc 95.342%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.193 Acc 95.135%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.189 Acc 95.176%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.161 Acc 95.212%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.162 Acc 95.417%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.161 Acc 95.372%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.159 Acc 95.435%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.159 Acc 95.428%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.183 Acc 95.274%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.181 Acc 95.149%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.149 Acc 95.630%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.152 Acc 95.522%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.153 Acc 95.479%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.156 Acc 95.418%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.158 Acc 95.389%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.176 Acc 95.382%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.175 Acc 95.355%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.149 Acc 95.792%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.151 Acc 95.569%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.489%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.154 Acc 95.511%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.156 Acc 95.492%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.180 Acc 95.359%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.178 Acc 95.336%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.145 Acc 95.676%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.152 Acc 95.588%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.153 Acc 95.544%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.155 Acc 95.478%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.155 Acc 95.484%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.183 Acc 95.181%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.179 Acc 95.281%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.147 Acc 96.024%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.143 Acc 95.923%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.146 Acc 95.829%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.149 Acc 95.763%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.151 Acc 95.688%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.183 Acc 95.110%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.193 Acc 92.188%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.148 Acc 95.784%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.151 Acc 95.713%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.156 Acc 95.616%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.156 Acc 95.622%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.152 Acc 95.665%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.177 Acc 95.429%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.148 Acc 95.728%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.148 Acc 95.704%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.148 Acc 95.718%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.149 Acc 95.642%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 95.336%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.183 Acc 95.297%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.151 Acc 95.846%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.149 Acc 95.678%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.151 Acc 95.660%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.149 Acc 95.706%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.149 Acc 95.702%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.177 Acc 95.568%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.175 Acc 95.542%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.133 Acc 96.047%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.139 Acc 96.043%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.144 Acc 95.878%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.146 Acc 95.819%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.137 Acc 96.875%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.183 Acc 95.367%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.179 Acc 95.367%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.142 Acc 95.958%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.140 Acc 96.016%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.141 Acc 95.959%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.143 Acc 95.904%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.178 Acc 95.490%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.235 Acc 90.625%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.142 Acc 95.722%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.142 Acc 95.829%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.143 Acc 95.824%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.143 Acc 95.848%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.144 Acc 95.812%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.183 Acc 95.135%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.181 Acc 95.118%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.128 Acc 96.481%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.136 Acc 96.102%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.139 Acc 96.013%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.141 Acc 95.965%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.141 Acc 95.944%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.181 Acc 95.204%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.176 Acc 95.297%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.228 Acc 95.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.132 Acc 96.163%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.135 Acc 96.090%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.135 Acc 96.073%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.137 Acc 96.010%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.138 Acc 96.005%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.179 Acc 95.266%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.131 Acc 96.357%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.137 Acc 96.144%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.139 Acc 96.109%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.138 Acc 96.090%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.140 Acc 96.027%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.095 Acc 96.875%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.197 Acc 95.104%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.196 Acc 95.114%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.134 Acc 96.295%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.140 Acc 96.133%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.138 Acc 96.081%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.137 Acc 96.041%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.139 Acc 96.028%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.166 Acc 96.875%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.183 Acc 95.529%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.182 Acc 95.542%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.141 Acc 95.931%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.137 Acc 95.993%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.137 Acc 95.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.135 Acc 96.084%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.137 Acc 96.034%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.187 Acc 95.297%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.185 Acc 95.332%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.978%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.140 Acc 95.931%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.140 Acc 95.941%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.136 Acc 96.103%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.136 Acc 96.064%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.173 Acc 95.599%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.170 Acc 95.678%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.128 Acc 96.318%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.128 Acc 96.331%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.129 Acc 96.273%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.128 Acc 96.326%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.270%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.081 Acc 97.656%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.188 Acc 95.359%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.184 Acc 95.309%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.131 Acc 96.349%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.135 Acc 96.273%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.134 Acc 96.255%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.132 Acc 96.259%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.132 Acc 96.159%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.258%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.183 Acc 95.243%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.124 Acc 96.233%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.128 Acc 96.230%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.131 Acc 96.211%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.132 Acc 96.160%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.133 Acc 96.170%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.100 Acc 96.875%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.181 Acc 95.441%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.162 Acc 95.312%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.121 Acc 96.542%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.126 Acc 96.482%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.128 Acc 96.348%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.127 Acc 96.337%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.129 Acc 96.290%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.186 Acc 95.231%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.123 Acc 96.496%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.122 Acc 96.401%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.122 Acc 96.439%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.125 Acc 96.353%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.126 Acc 96.335%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.194 Acc 95.351%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.191 Acc 95.316%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.218 Acc 95.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.126 Acc 96.465%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.127 Acc 96.315%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.125 Acc 96.269%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.127 Acc 96.229%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.080 Acc 97.656%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.178 Acc 95.545%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.530%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.117 Acc 96.581%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.125 Acc 96.440%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.122 Acc 96.473%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.123 Acc 96.444%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.125 Acc 96.346%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.178 Acc 95.452%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.175 Acc 95.441%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.120 Acc 96.568%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.121 Acc 96.447%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.125 Acc 96.335%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.172 Acc 95.658%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.124 Acc 96.287%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.122 Acc 96.331%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.122 Acc 96.309%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.124 Acc 96.250%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.124 Acc 96.250%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.183 Acc 95.452%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.180 Acc 95.449%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.121 Acc 96.558%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.122 Acc 96.444%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.123 Acc 96.361%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.122 Acc 96.384%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.124 Acc 96.329%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.183 Acc 95.436%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.182 Acc 95.417%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.116 Acc 96.774%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.118 Acc 96.618%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.119 Acc 96.564%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.119 Acc 96.563%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.121 Acc 96.519%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.192 Acc 95.065%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.188 Acc 95.095%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.116 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.112 Acc 96.805%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.545%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.120 Acc 96.519%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.120 Acc 96.522%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.120 Acc 96.533%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.180 Acc 95.599%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.178 Acc 95.534%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.121 Acc 96.432%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.117 Acc 96.558%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.119 Acc 96.505%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.119 Acc 96.529%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.179 Acc 95.382%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.176 Acc 95.414%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.116 Acc 96.457%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.114 Acc 96.599%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.115 Acc 96.561%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.116 Acc 96.548%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.117 Acc 96.527%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.193 Acc 95.135%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.189 Acc 95.208%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.114 Acc 96.720%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.116 Acc 96.580%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.114 Acc 96.680%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.117 Acc 96.616%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.117 Acc 96.610%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.181 Acc 95.490%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.180 Acc 95.495%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.106 Acc 96.867%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.108 Acc 96.774%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.114 Acc 96.573%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.115 Acc 96.562%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.182 Acc 95.506%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.181 Acc 95.557%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.117 Acc 96.448%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.117 Acc 96.484%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.184 Acc 95.661%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.184 Acc 95.616%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.115 Acc 96.674%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.117 Acc 96.665%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.117 Acc 96.587%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.115 Acc 96.616%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.114 Acc 96.646%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.184 Acc 95.521%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.181 Acc 95.487%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.113 Acc 96.751%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.109 Acc 96.778%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.113 Acc 96.696%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.113 Acc 96.697%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.599%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.178 Acc 95.480%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.682%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.113 Acc 96.636%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.188 Acc 95.390%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.186 Acc 95.367%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.108 Acc 96.906%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.112 Acc 96.774%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.110 Acc 96.789%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.111 Acc 96.760%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.092 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.180 Acc 95.480%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.108 Acc 96.739%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.106 Acc 96.735%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.110 Acc 96.668%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.111 Acc 96.661%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.197 Acc 95.297%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.195 Acc 95.297%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.108 Acc 96.867%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.105 Acc 96.836%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.107 Acc 96.823%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.104 Acc 96.873%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.084 Acc 97.656%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.188 Acc 95.467%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.185 Acc 95.464%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.105 Acc 96.727%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.106 Acc 96.766%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.106 Acc 96.780%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.107 Acc 96.786%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.186 Acc 95.158%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.186 Acc 95.165%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.094 Acc 97.231%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.104 Acc 96.888%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.106 Acc 96.832%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.107 Acc 96.810%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.187 Acc 95.405%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.186 Acc 95.402%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.118 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.105 Acc 96.910%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.105 Acc 96.924%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.106 Acc 96.870%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.186 Acc 95.444%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.186 Acc 95.433%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.103 Acc 97.073%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.105 Acc 96.984%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.105 Acc 96.951%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.104 Acc 96.965%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.200 Acc 95.328%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.197 Acc 95.285%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 97.169%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.102 Acc 96.949%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.102 Acc 96.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.104 Acc 96.943%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.105 Acc 96.897%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.195 Acc 95.243%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.194 Acc 95.270%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.102 Acc 96.828%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.101 Acc 96.914%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.103 Acc 96.844%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.103 Acc 96.847%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.201 Acc 95.189%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.199 Acc 95.106%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.097 Acc 97.200%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.102 Acc 96.953%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.101 Acc 97.020%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.101 Acc 97.019%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.101 Acc 96.986%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.103 Acc 97.656%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.188 Acc 95.343%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.188 Acc 95.324%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.099 Acc 96.890%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.103 Acc 96.786%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.100 Acc 96.870%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.101 Acc 96.863%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.102 Acc 96.820%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.183 Acc 95.777%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.183 Acc 95.643%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.093 Acc 97.003%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.100 Acc 96.893%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.101 Acc 96.858%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.189 Acc 95.498%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.189 Acc 95.379%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.096 Acc 96.952%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.097 Acc 96.995%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.100 Acc 97.015%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.102 Acc 96.922%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.102 Acc 96.926%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.197 Acc 95.305%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.194 Acc 95.363%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.098 Acc 97.092%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.099 Acc 97.178%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.100 Acc 97.072%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.099 Acc 97.009%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.100 Acc 96.997%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.199 Acc 95.235%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.201 Acc 95.130%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.056 Acc 96.875%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.099 Acc 97.084%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.101 Acc 96.933%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.099 Acc 97.007%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.098 Acc 97.060%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.097 Acc 97.098%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.198 Acc 95.367%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.195 Acc 95.239%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.089 Acc 97.239%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.094 Acc 97.093%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.096 Acc 97.007%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.096 Acc 97.056%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.098 Acc 97.018%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.189 Acc 95.452%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.186 Acc 95.542%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.092 Acc 97.037%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.094 Acc 97.116%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.097 Acc 97.076%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.189 Acc 95.577%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.224 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.091 Acc 97.300%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.094 Acc 97.139%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.096 Acc 97.077%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.097 Acc 97.037%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.099 Acc 97.009%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.198 Acc 95.351%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.195 Acc 95.375%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.088 Acc 97.393%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.090 Acc 97.306%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.090 Acc 97.308%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.092 Acc 97.255%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.094 Acc 97.182%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.200 Acc 95.421%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.198 Acc 95.351%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.153 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.087 Acc 97.339%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.095 Acc 97.159%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.095 Acc 97.088%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.094 Acc 97.154%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.094 Acc 97.153%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.192 Acc 95.320%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.090 Acc 97.370%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.091 Acc 97.314%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.092 Acc 97.207%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.096 Acc 97.095%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.095 Acc 97.131%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.134 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.206 Acc 95.266%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.204 Acc 95.176%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.077 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.085 Acc 97.378%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.085 Acc 97.326%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.093 Acc 97.176%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.092 Acc 97.142%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.199 Acc 95.065%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.195 Acc 95.083%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.093 Acc 97.208%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.093 Acc 97.236%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.092 Acc 97.239%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.092 Acc 97.209%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.151 Acc 97.656%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.205 Acc 95.467%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.202 Acc 95.390%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.279 Acc 93.750%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.090 Acc 97.146%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.089 Acc 97.236%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.090 Acc 97.282%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.091 Acc 97.232%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.194 Acc 95.289%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.190 Acc 95.425%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.085 Acc 97.432%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.087 Acc 97.225%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.090 Acc 97.224%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.091 Acc 97.170%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.118 Acc 97.656%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.199 Acc 95.251%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.196 Acc 95.289%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.092 Acc 97.269%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.092 Acc 97.318%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.091 Acc 97.264%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.092 Acc 97.169%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.092 Acc 97.163%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.199 Acc 95.382%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.198 Acc 95.316%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.088 Acc 97.208%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.086 Acc 97.334%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.089 Acc 97.244%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.088 Acc 97.259%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.090 Acc 97.274%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.194 Acc 95.459%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.191 Acc 95.480%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.092 Acc 97.200%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.091 Acc 97.198%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.090 Acc 97.238%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.091 Acc 97.204%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.090 Acc 97.204%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.166 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.207 Acc 95.119%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.204 Acc 95.141%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.081 Acc 97.525%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.084 Acc 97.380%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.086 Acc 97.368%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.087 Acc 97.352%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.093 Acc 97.656%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.196 Acc 95.459%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.193 Acc 95.503%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.079 Acc 97.594%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.086 Acc 97.384%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.087 Acc 97.368%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.086 Acc 97.389%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.088 Acc 97.346%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.198 Acc 95.057%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.195 Acc 95.103%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.085 Acc 97.347%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.084 Acc 97.291%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.084 Acc 97.363%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.085 Acc 97.346%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.087 Acc 97.310%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.205 Acc 95.111%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.205 Acc 95.021%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.084 Acc 97.362%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.085 Acc 97.373%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.084 Acc 97.386%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.085 Acc 97.276%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.085 Acc 97.241%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.197 Acc 95.289%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.198 Acc 95.266%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.079 Acc 97.532%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.082 Acc 97.474%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.083 Acc 97.423%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.085 Acc 97.387%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.087 Acc 97.277%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.206 Acc 95.073%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.202 Acc 95.126%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.082 Acc 97.493%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.084 Acc 97.428%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.084 Acc 97.458%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.084 Acc 97.464%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.204 Acc 95.274%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.203 Acc 95.246%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.080 Acc 97.440%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.082 Acc 97.477%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.084 Acc 97.451%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.083 Acc 97.475%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.084 Acc 97.376%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.203 Acc 95.158%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.198 Acc 95.250%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.083 Acc 97.339%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.084 Acc 97.357%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.083 Acc 97.412%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.084 Acc 97.385%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.085 Acc 97.337%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.200 Acc 95.119%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.198 Acc 95.208%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.194 Acc 94.531%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.086 Acc 97.330%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.084 Acc 97.358%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.084 Acc 97.378%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.083 Acc 97.396%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.200 Acc 95.320%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.197 Acc 95.344%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.081 Acc 97.556%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.077 Acc 97.567%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.080 Acc 97.488%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.079 Acc 97.491%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.082 Acc 97.386%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.201 Acc 95.196%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.202 Acc 95.118%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.083 Acc 97.471%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.084 Acc 97.431%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.084 Acc 97.425%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.085 Acc 97.385%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.084 Acc 97.418%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.195 Acc 95.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.196 Acc 95.592%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.084 Acc 97.331%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.081 Acc 97.410%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.081 Acc 97.413%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.083 Acc 97.386%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.208 Acc 95.398%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.205 Acc 95.355%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.152 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.073 Acc 97.811%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.074 Acc 97.695%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.079 Acc 97.571%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.081 Acc 97.533%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.209 Acc 95.328%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.206 Acc 95.305%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.072 Acc 97.765%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.076 Acc 97.676%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.076 Acc 97.659%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.079 Acc 97.582%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.080 Acc 97.522%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.200 Acc 95.289%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.197 Acc 95.398%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.067 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.076 Acc 97.579%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.076 Acc 97.560%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.078 Acc 97.456%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.080 Acc 97.419%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.205 Acc 95.196%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.202 Acc 95.270%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.075 Acc 97.579%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.081 Acc 97.467%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.080 Acc 97.510%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.081 Acc 97.507%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.219 Acc 95.065%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.213 Acc 95.165%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.070 Acc 97.749%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.075 Acc 97.660%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.074 Acc 97.646%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.075 Acc 97.615%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.077 Acc 97.589%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.197 Acc 95.382%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.196 Acc 95.371%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.074 Acc 97.734%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.071 Acc 97.746%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.073 Acc 97.633%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.076 Acc 97.569%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.077 Acc 97.556%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.202 Acc 95.467%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.200 Acc 95.433%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.114 Acc 94.531%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.077 Acc 97.532%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.077 Acc 97.439%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.075 Acc 97.508%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.076 Acc 97.491%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.076 Acc 97.494%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.208 Acc 95.065%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.201 Acc 95.165%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.071 Acc 97.826%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.072 Acc 97.761%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.074 Acc 97.674%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.076 Acc 97.597%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.212 Acc 95.490%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.212 Acc 95.476%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.133 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.073 Acc 97.649%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.076 Acc 97.652%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.075 Acc 97.680%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.075 Acc 97.639%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.076 Acc 97.585%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.197 Acc 95.359%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.193 Acc 95.476%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.070 Acc 97.649%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.071 Acc 97.660%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.072 Acc 97.700%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.074 Acc 97.662%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.214 Acc 95.196%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.211 Acc 95.235%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.079 Acc 97.455%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.075 Acc 97.629%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.078 Acc 97.537%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.078 Acc 97.516%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.090 Acc 97.656%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.213 Acc 95.150%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.208 Acc 95.297%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.067 Acc 97.912%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.071 Acc 97.788%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.072 Acc 97.713%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.072 Acc 97.715%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.074 Acc 97.670%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.208 Acc 95.483%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.205 Acc 95.449%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.070 Acc 97.811%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.074 Acc 97.695%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.073 Acc 97.700%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.074 Acc 97.659%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.208 Acc 95.235%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.203 Acc 95.309%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.070 Acc 97.788%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.073 Acc 97.761%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.073 Acc 97.706%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.073 Acc 97.682%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.073 Acc 97.680%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.151 Acc 96.875%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.212 Acc 95.266%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.209 Acc 95.266%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.070 Acc 97.659%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.072 Acc 97.629%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.072 Acc 97.613%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.208 Acc 95.374%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.074 Acc 97.633%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.072 Acc 97.641%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.070 Acc 97.698%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.071 Acc 97.709%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.208 Acc 95.336%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.205 Acc 95.336%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.070 Acc 97.769%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.071 Acc 97.716%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.209 Acc 95.328%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.067 Acc 97.851%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.069 Acc 97.752%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.071 Acc 97.709%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.207 Acc 95.235%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.202 Acc 95.281%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.104 Acc 94.531%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.067 Acc 97.772%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.071 Acc 97.628%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.072 Acc 97.645%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.216 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.212 Acc 95.270%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.069 Acc 97.857%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.070 Acc 97.718%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.069 Acc 97.711%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.072 Acc 97.681%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.176 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.215 Acc 95.204%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.212 Acc 95.200%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.068 Acc 97.826%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.069 Acc 97.800%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.070 Acc 97.755%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.070 Acc 97.728%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.070 Acc 97.733%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.212 Acc 95.227%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.207 Acc 95.266%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.069 Acc 97.695%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.066 Acc 97.816%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.066 Acc 97.866%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.069 Acc 97.751%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.200 Acc 95.258%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.198 Acc 95.351%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.065 Acc 97.858%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.069 Acc 97.796%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.069 Acc 97.789%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.070 Acc 97.770%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.213 Acc 95.235%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.210 Acc 95.145%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.070 Acc 97.772%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.067 Acc 97.831%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.068 Acc 97.861%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.069 Acc 97.798%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.069 Acc 97.795%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.214 Acc 95.173%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.211 Acc 95.211%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.068 Acc 97.796%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.070 Acc 97.693%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.070 Acc 97.730%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.210 Acc 95.367%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.210 Acc 95.355%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.066 Acc 97.887%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.066 Acc 97.859%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.068 Acc 97.817%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.221 Acc 94.848%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.219 Acc 94.935%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.044 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.061 Acc 98.089%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.067 Acc 97.901%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.066 Acc 97.916%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.066 Acc 97.880%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.066 Acc 97.843%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.223 Acc 94.910%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.219 Acc 95.091%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.062 Acc 98.028%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.062 Acc 97.944%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.064 Acc 97.915%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.066 Acc 97.832%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.151 Acc 96.875%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.042%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.211 Acc 95.204%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.068 Acc 97.802%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.068 Acc 97.803%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.225 Acc 95.196%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.218 Acc 95.246%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.063 Acc 97.901%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.065 Acc 97.817%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.066 Acc 97.810%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.066 Acc 97.829%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.210 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.224 Acc 95.104%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.222 Acc 95.130%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.068 Acc 97.803%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.064 Acc 97.944%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.065 Acc 97.859%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.067 Acc 97.836%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.229 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.227 Acc 95.011%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.222 Acc 95.079%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.057 Acc 98.089%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.063 Acc 97.991%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.063 Acc 97.955%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.064 Acc 97.917%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.066 Acc 97.823%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.233 Acc 94.740%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.230 Acc 94.819%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.064 Acc 98.066%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.065 Acc 97.956%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.064 Acc 97.986%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.065 Acc 97.915%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.067 Acc 97.831%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.219 Acc 95.390%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.216 Acc 95.394%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.062 Acc 97.847%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.065 Acc 97.737%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.065 Acc 97.779%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.065 Acc 97.798%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.216 Acc 95.289%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.213 Acc 95.402%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.063 Acc 97.893%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.064 Acc 97.906%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.064 Acc 97.906%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.224 Acc 94.980%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.221 Acc 95.068%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.065 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.056 Acc 98.229%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.059 Acc 98.084%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.062 Acc 97.981%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.062 Acc 97.954%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.062 Acc 97.931%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.215 Acc 95.274%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.215 Acc 95.270%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.067 Acc 97.757%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.065 Acc 97.778%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.064 Acc 97.830%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.064 Acc 97.854%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.220 Acc 95.065%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.216 Acc 95.180%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.054 Acc 98.167%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.054 Acc 98.193%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.058 Acc 98.066%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.059 Acc 98.048%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.060 Acc 98.013%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.216 Acc 95.150%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.210 Acc 95.394%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.063 Acc 97.803%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.065 Acc 97.835%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.065 Acc 97.856%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.064 Acc 97.871%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.065 Acc 97.828%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.223 Acc 94.964%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.222 Acc 95.072%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.057 Acc 98.028%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.059 Acc 97.936%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.062 Acc 97.905%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.061 Acc 97.933%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.062 Acc 97.912%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.226 Acc 95.011%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.220 Acc 95.040%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.063 Acc 97.888%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.061 Acc 97.998%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.061 Acc 98.014%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.062 Acc 97.938%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.230 Acc 95.328%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.226 Acc 95.340%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.068 Acc 99.219%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.054 Acc 98.244%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.058 Acc 98.084%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.060 Acc 98.056%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.061 Acc 98.048%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.060 Acc 98.029%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.209 Acc 95.374%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.472%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.059 Acc 98.035%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.058 Acc 98.045%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.059 Acc 98.020%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.059 Acc 98.023%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.061 Acc 97.988%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.189 Acc 91.406%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.232 Acc 94.941%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.229 Acc 95.075%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.065 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.058 Acc 98.113%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.061 Acc 97.987%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.062 Acc 97.908%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.062 Acc 97.939%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.063 Acc 97.935%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.227 Acc 95.243%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.226 Acc 95.188%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.059 Acc 98.159%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.059 Acc 98.150%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.060 Acc 98.074%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.061 Acc 98.024%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.062 Acc 98.001%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.211 Acc 95.312%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.216 Acc 95.305%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.212 Acc 95.367%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.052 Acc 98.205%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.053 Acc 98.216%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.055 Acc 98.108%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.057 Acc 98.099%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.058 Acc 98.079%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.229 Acc 95.336%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.224 Acc 95.460%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.059 Acc 98.012%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.058 Acc 97.998%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.059 Acc 97.955%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.060 Acc 97.950%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.060 Acc 97.967%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.229 Acc 95.080%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.228 Acc 95.079%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.055 Acc 98.082%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.057 Acc 98.014%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.060 Acc 97.973%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.060 Acc 97.982%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.059 Acc 97.992%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.220 Acc 95.452%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.220 Acc 95.375%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.055 Acc 98.236%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.056 Acc 98.212%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.058 Acc 98.136%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.061 Acc 98.015%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.061 Acc 97.988%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.221 Acc 95.367%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.219 Acc 95.340%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.056 Acc 98.120%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.058 Acc 98.099%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.058 Acc 98.131%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.059 Acc 98.054%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.060 Acc 98.034%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.223 Acc 95.405%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.222 Acc 95.281%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.054 Acc 98.154%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.056 Acc 98.092%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.058 Acc 98.046%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.058 Acc 98.034%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.215 Acc 95.475%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.217 Acc 95.487%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.051 Acc 98.376%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.054 Acc 98.193%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.056 Acc 98.108%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.056 Acc 98.122%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.058 Acc 98.066%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.097 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.220 Acc 95.266%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.216 Acc 95.336%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.054 Acc 98.208%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.057 Acc 98.087%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.057 Acc 98.102%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.057 Acc 98.108%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.234 Acc 95.080%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.232 Acc 95.002%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.052 Acc 98.267%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.055 Acc 98.216%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.056 Acc 98.136%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.058 Acc 98.079%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.059 Acc 98.029%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.150 Acc 96.875%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.227 Acc 95.336%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.219 Acc 95.340%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.054 Acc 98.144%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.057 Acc 98.084%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.056 Acc 98.095%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.056 Acc 98.114%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.057 Acc 98.088%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.230 Acc 95.034%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.227 Acc 94.932%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.060 Acc 98.058%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.057 Acc 98.181%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.059 Acc 98.085%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.059 Acc 98.051%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.231 Acc 95.227%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.228 Acc 95.250%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.050 Acc 98.345%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.053 Acc 98.220%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.055 Acc 98.147%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.058 Acc 98.084%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.231 Acc 95.189%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.227 Acc 95.266%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.055 Acc 98.291%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.059 Acc 98.177%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.058 Acc 98.123%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.057 Acc 98.137%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.056 Acc 98.124%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.230 Acc 95.282%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.225 Acc 95.320%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.053 Acc 98.260%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.056 Acc 98.115%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.056 Acc 98.064%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.057 Acc 98.069%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.059 Acc 98.041%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.238 Acc 94.988%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.234 Acc 95.064%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.054 Acc 98.105%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [200/573] Loss: 0.053 Acc 98.165%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.053 Acc 98.186%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.055 Acc 98.126%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.222 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.220 Acc 95.297%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.057 Acc 98.035%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.057 Acc 98.123%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.055 Acc 98.181%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.055 Acc 98.192%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.055 Acc 98.172%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.251 Acc 95.065%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.249 Acc 95.103%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.049 Acc 98.395%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.051 Acc 98.334%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.050 Acc 98.323%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.052 Acc 98.239%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.227 Acc 95.212%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.223 Acc 95.180%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.056 Acc 96.875%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.052 Acc 98.244%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.054 Acc 98.231%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.054 Acc 98.196%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.236 Acc 95.266%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.233 Acc 95.332%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.054 Acc 98.260%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.055 Acc 98.185%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.054 Acc 98.178%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.054 Acc 98.161%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.054 Acc 98.154%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.145 Acc 97.656%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.231 Acc 95.135%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.227 Acc 95.184%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.050 Acc 98.336%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.051 Acc 98.297%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.052 Acc 98.216%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.232 Acc 95.274%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.229 Acc 95.305%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.059 Acc 96.875%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.056 Acc 98.082%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.055 Acc 98.134%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.055 Acc 98.113%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.055 Acc 98.079%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.055 Acc 98.060%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.219 Acc 95.475%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.216 Acc 95.437%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.053 Acc 98.198%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.054 Acc 98.196%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.053 Acc 98.207%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.238 Acc 95.204%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.236 Acc 95.192%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.096 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.052 Acc 98.244%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.056 Acc 98.100%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.055 Acc 98.132%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.054 Acc 98.172%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.242 Acc 94.964%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.237 Acc 95.072%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.045 Acc 98.608%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.050 Acc 98.418%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.048 Acc 98.440%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.048 Acc 98.418%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.050 Acc 98.364%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.226 Acc 95.305%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.226 Acc 95.200%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.051 Acc 98.453%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.050 Acc 98.395%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.051 Acc 98.328%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.052 Acc 98.293%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.053 Acc 98.238%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.242 Acc 95.220%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.241 Acc 95.223%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.059 Acc 97.989%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.054 Acc 98.146%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.050 Acc 98.274%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.053 Acc 98.207%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.231 Acc 95.166%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.227 Acc 95.141%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.051 Acc 98.267%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.052 Acc 98.278%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.053 Acc 98.212%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.053 Acc 98.225%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.053 Acc 98.247%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.169 Acc 97.656%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.233 Acc 95.537%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.231 Acc 95.484%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.051 Acc 98.267%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.052 Acc 98.329%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.051 Acc 98.323%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.053 Acc 98.249%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.054 Acc 98.224%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.233 Acc 95.204%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.228 Acc 95.293%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.047 Acc 98.453%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.048 Acc 98.461%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.049 Acc 98.419%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.050 Acc 98.356%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.051 Acc 98.299%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.242 Acc 95.251%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.237 Acc 95.274%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.049 Acc 98.321%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.049 Acc 98.309%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [300/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.051 Acc 98.245%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.052 Acc 98.225%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.229 Acc 95.096%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.225 Acc 95.153%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.051 Acc 98.229%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.051 Acc 98.208%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.049 Acc 98.287%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.050 Acc 98.262%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.051 Acc 98.263%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.109 Acc 97.656%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.241 Acc 94.926%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.237 Acc 95.079%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.050 Acc 98.283%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.048 Acc 98.386%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.049 Acc 98.340%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.050 Acc 98.311%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.236 Acc 95.158%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.232 Acc 95.141%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.041 Acc 98.592%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.048 Acc 98.348%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.050 Acc 98.284%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.050 Acc 98.274%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.051 Acc 98.249%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.244 Acc 94.957%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.240 Acc 94.955%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc176bbbc354a0d94deb269ca94e442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.306 Acc 10.938%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.264 Acc 17.628%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.249 Acc 18.412%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.724%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.212 Acc 20.011%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.165 Acc 22.062%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.777 Acc 39.844%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.796 Acc 38.289%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.798 Acc 38.130%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.881 Acc 28.906%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.831 Acc 37.554%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.780 Acc 39.521%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.719 Acc 41.998%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.659 Acc 44.377%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.597 Acc 46.613%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.011 Acc 66.406%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.105 Acc 64.349%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.106 Acc 64.183%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.196 Acc 58.594%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.183 Acc 61.750%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.140 Acc 63.083%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.091 Acc 64.779%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.058 Acc 65.835%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.027 Acc 66.918%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.701 Acc 73.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.715 Acc 77.769%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.713 Acc 77.694%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.787 Acc 78.125%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.798 Acc 74.667%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.782 Acc 75.078%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.765 Acc 75.571%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.748 Acc 76.066%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.735 Acc 76.509%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.574 Acc 80.469%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.555 Acc 82.882%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.550 Acc 82.995%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.838 Acc 76.562%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.627 Acc 80.252%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.618 Acc 80.527%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.611 Acc 80.855%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.598 Acc 81.223%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.588 Acc 81.563%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.474 Acc 84.375%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.463 Acc 86.200%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.455 Acc 86.373%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.589 Acc 83.594%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.536 Acc 83.192%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.524 Acc 83.497%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.517 Acc 83.726%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.510 Acc 84.034%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.504 Acc 84.199%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.511 Acc 85.156%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.420 Acc 87.129%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.415 Acc 87.348%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.532 Acc 86.719%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.467 Acc 85.419%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.460 Acc 85.627%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.457 Acc 85.766%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.453 Acc 85.920%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.445 Acc 86.075%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.394 Acc 86.719%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.376 Acc 88.916%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.372 Acc 89.024%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.375 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.412 Acc 87.392%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.412 Acc 87.290%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.410 Acc 87.383%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.412 Acc 87.278%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.406 Acc 87.436%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.329 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.345 Acc 89.952%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.339 Acc 90.081%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.423 Acc 88.281%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.385 Acc 88.080%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.380 Acc 88.293%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.377 Acc 88.349%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.375 Acc 88.525%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.375 Acc 88.531%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.317 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.326 Acc 90.486%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.320 Acc 90.637%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.288 Acc 90.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.353 Acc 89.109%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.346 Acc 89.323%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.349 Acc 89.281%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.352 Acc 89.158%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.351 Acc 89.234%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.302 Acc 90.625%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.300 Acc 91.259%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.297 Acc 91.309%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.255 Acc 91.406%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.333 Acc 89.913%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.334 Acc 89.844%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.333 Acc 89.818%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.332 Acc 89.861%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.330 Acc 89.954%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.279 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.295 Acc 91.476%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.289 Acc 91.690%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.243 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.301 Acc 90.571%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.310 Acc 90.411%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.310 Acc 90.358%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.311 Acc 90.374%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.311 Acc 90.435%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.296 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.283 Acc 91.808%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.277 Acc 92.005%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.350 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.302 Acc 90.888%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.299 Acc 90.905%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.301 Acc 90.864%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.303 Acc 90.859%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.300 Acc 90.954%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.264 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.261 Acc 92.597%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.256 Acc 92.739%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.269 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.275 Acc 91.731%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.278 Acc 91.519%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.278 Acc 91.570%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.282 Acc 91.459%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.283 Acc 91.486%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.264 Acc 92.621%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.260 Acc 92.650%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.319 Acc 89.062%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.279 Acc 91.847%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.276 Acc 91.554%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.274 Acc 91.702%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.274 Acc 91.741%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.276 Acc 91.727%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.249 Acc 93.139%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.244 Acc 93.214%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.153 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.266 Acc 92.319%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.262 Acc 92.289%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.267 Acc 92.138%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.268 Acc 92.069%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.266 Acc 92.064%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.246 Acc 93.178%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.242 Acc 93.218%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.301 Acc 91.406%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.251 Acc 92.512%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.255 Acc 92.238%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.258 Acc 92.286%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.260 Acc 92.258%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.238 Acc 93.394%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.235 Acc 93.466%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.272 Acc 92.969%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.251 Acc 92.644%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.255 Acc 92.600%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.256 Acc 92.579%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.254 Acc 92.638%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.253 Acc 92.574%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.238 Acc 93.417%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.234 Acc 93.575%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.301 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.253 Acc 92.884%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.248 Acc 92.860%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.247 Acc 92.784%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.247 Acc 92.758%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.246 Acc 92.774%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.225 Acc 93.688%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.221 Acc 93.816%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.247 Acc 92.814%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.241 Acc 92.883%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.239 Acc 92.862%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.239 Acc 92.936%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.238 Acc 92.942%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.225 Acc 93.874%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.221 Acc 93.851%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.189 Acc 95.312%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.227 Acc 93.247%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.227 Acc 93.210%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.227 Acc 93.176%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.229 Acc 93.243%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.232 Acc 93.182%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.216 Acc 93.735%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.212 Acc 93.937%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.166 Acc 92.969%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.234 Acc 93.193%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.222 Acc 93.490%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.224 Acc 93.480%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.227 Acc 93.339%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.229 Acc 93.310%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.216 Acc 93.920%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.212 Acc 94.127%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.189 Acc 93.750%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.221 Acc 93.619%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.219 Acc 93.676%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.221 Acc 93.555%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.223 Acc 93.514%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.223 Acc 93.496%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.214 Acc 94.036%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.209 Acc 94.115%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.193 Acc 93.750%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.221 Acc 93.626%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.219 Acc 93.696%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.218 Acc 93.631%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.220 Acc 93.608%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.220 Acc 93.605%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.209 Acc 94.338%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.206 Acc 94.286%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.201 Acc 93.874%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.217 Acc 93.618%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.216 Acc 93.639%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.216 Acc 93.669%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.214 Acc 93.874%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.212 Acc 94.045%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.228 Acc 92.188%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.218 Acc 93.773%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.213 Acc 93.828%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.213 Acc 93.817%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.212 Acc 93.805%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.212 Acc 93.766%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.213 Acc 94.067%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.208 Acc 94.228%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.207 Acc 92.188%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.206 Acc 94.237%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.205 Acc 94.115%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.205 Acc 94.116%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.204 Acc 94.144%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.208 Acc 94.018%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.202 Acc 94.570%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.200 Acc 94.609%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.272 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.198 Acc 94.400%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.201 Acc 94.220%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.204 Acc 94.147%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.202 Acc 94.167%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.204 Acc 94.026%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.203 Acc 94.291%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.201 Acc 94.465%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.198 Acc 94.090%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.197 Acc 94.286%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.200 Acc 94.212%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.199 Acc 94.221%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.202 Acc 94.196%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.196 Acc 94.585%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.193 Acc 94.753%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.192 Acc 94.361%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.194 Acc 94.251%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.198 Acc 94.189%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.197 Acc 94.288%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.196 Acc 94.257%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.205 Acc 94.315%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.204 Acc 94.395%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.253 Acc 91.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.195 Acc 94.098%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.189 Acc 94.271%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.189 Acc 94.321%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.191 Acc 94.368%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.193 Acc 94.353%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.200 Acc 94.554%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.196 Acc 94.628%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.184 Acc 92.188%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.169 Acc 95.019%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.838%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.182 Acc 94.674%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.188 Acc 94.523%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.189 Acc 94.484%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.194 Acc 94.794%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.190 Acc 94.959%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.196 Acc 94.268%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.191 Acc 94.566%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.184 Acc 94.638%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.184 Acc 94.652%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.188 Acc 94.586%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.194 Acc 94.709%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.192 Acc 94.780%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.180 Acc 95.312%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.182 Acc 94.802%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.188 Acc 94.652%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.187 Acc 94.695%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.188 Acc 94.646%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.187 Acc 94.636%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.195 Acc 94.748%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.192 Acc 94.788%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.179 Acc 94.926%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.185 Acc 94.722%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.825%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.184 Acc 94.769%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.184 Acc 94.754%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.197 Acc 94.709%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.196 Acc 94.776%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.173 Acc 95.073%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.179 Acc 94.788%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.182 Acc 94.747%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.180 Acc 94.783%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.181 Acc 94.753%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.187 Acc 94.841%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.185 Acc 94.939%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.168 Acc 95.184%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.174 Acc 94.985%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.178 Acc 94.882%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.193 Acc 94.748%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.191 Acc 94.885%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.166 Acc 95.080%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.174 Acc 94.932%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.179 Acc 94.866%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.177 Acc 94.862%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.176 Acc 94.856%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.194 Acc 94.841%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.193 Acc 94.811%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.170 Acc 95.251%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.173 Acc 95.165%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.172 Acc 95.123%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.171 Acc 95.124%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.174 Acc 95.071%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.189 Acc 94.964%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.189 Acc 94.955%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.162 Acc 95.189%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.165 Acc 95.211%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.102%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.171 Acc 95.044%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.170 Acc 95.075%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.193 Acc 94.740%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.192 Acc 94.807%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.203 Acc 91.406%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.173 Acc 95.189%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.171 Acc 95.126%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.167 Acc 95.258%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.219%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.166 Acc 95.253%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.161 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.193 Acc 94.694%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.192 Acc 94.745%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 92.188%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.162 Acc 95.258%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.164 Acc 95.223%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.168 Acc 95.089%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.166 Acc 95.137%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.168 Acc 95.086%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.186 Acc 94.926%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.185 Acc 95.052%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.162 Acc 95.282%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.166 Acc 95.200%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.166 Acc 95.211%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.165 Acc 95.237%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.180 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.188 Acc 94.918%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.190 Acc 94.920%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.163 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.161 Acc 95.417%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.163 Acc 95.349%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.164 Acc 95.346%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.162 Acc 95.350%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.192 Acc 94.663%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.191 Acc 94.788%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.161 Acc 95.441%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.161 Acc 95.450%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.161 Acc 95.406%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.160 Acc 95.395%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.188 Acc 94.841%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.187 Acc 94.877%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.151 Acc 95.753%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.155 Acc 95.569%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.157 Acc 95.536%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.159 Acc 95.507%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.159 Acc 95.443%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.187 Acc 94.794%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.182 Acc 95.005%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.157 Acc 95.498%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.156 Acc 95.511%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.162 Acc 95.372%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.162 Acc 95.353%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.158 Acc 95.411%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.192 Acc 94.879%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.192 Acc 94.904%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.154 Acc 95.653%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.156 Acc 95.472%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.388%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.155 Acc 95.500%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.154 Acc 95.514%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.193 Acc 94.632%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.191 Acc 94.761%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.149 Acc 95.606%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.149 Acc 95.635%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.150 Acc 95.642%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.152 Acc 95.591%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.153 Acc 95.565%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.188 Acc 94.872%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.186 Acc 95.017%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.149 Acc 95.900%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.149 Acc 95.833%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.151 Acc 95.749%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.153 Acc 95.687%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.154 Acc 95.690%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.183 Acc 95.189%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.182 Acc 95.235%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.138 Acc 95.815%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.147 Acc 95.627%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.150 Acc 95.582%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.150 Acc 95.589%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.152 Acc 95.581%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.190 Acc 94.833%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.189 Acc 94.928%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.277 Acc 95.312%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.141 Acc 95.838%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.143 Acc 95.759%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.145 Acc 95.741%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.148 Acc 95.689%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.149 Acc 95.663%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.157 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 94.825%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 94.998%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.241 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.146 Acc 95.885%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.142 Acc 95.899%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.145 Acc 95.829%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.146 Acc 95.819%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.148 Acc 95.802%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.195 Acc 94.833%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.194 Acc 94.998%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.140 Acc 95.969%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.143 Acc 95.930%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.144 Acc 95.881%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.145 Acc 95.852%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.188 Acc 94.787%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.025%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.142 Acc 96.071%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.144 Acc 95.919%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.145 Acc 95.839%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.145 Acc 95.825%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.145 Acc 95.850%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.180 Acc 95.251%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.355%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.136 Acc 95.808%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.145 Acc 95.713%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.144 Acc 95.808%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.142 Acc 95.879%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.144 Acc 95.832%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.187 Acc 94.988%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.184 Acc 95.184%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.307 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.135 Acc 95.908%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.140 Acc 95.861%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.139 Acc 95.917%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.141 Acc 95.946%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.140 Acc 95.938%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.190 Acc 94.787%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.189 Acc 94.893%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.138 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.136 Acc 95.970%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.134 Acc 96.067%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.134 Acc 96.081%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.136 Acc 96.068%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.138 Acc 96.014%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.189 Acc 95.096%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.188 Acc 95.141%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.130 Acc 97.656%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.129 Acc 96.318%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.132 Acc 96.296%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.135 Acc 96.226%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.136 Acc 96.119%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.137 Acc 96.105%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.192 Acc 95.173%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.189 Acc 95.293%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.291 Acc 92.188%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.126 Acc 96.372%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.131 Acc 96.210%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.132 Acc 96.151%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.134 Acc 96.111%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.136 Acc 96.069%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.190 Acc 94.941%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.189 Acc 94.998%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.136 Acc 96.187%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.128 Acc 96.280%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.132 Acc 96.138%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.135 Acc 96.043%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.136 Acc 96.022%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.191 Acc 95.080%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.190 Acc 95.157%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.133 Acc 95.978%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.132 Acc 96.057%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.134 Acc 96.045%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.135 Acc 96.011%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.199 Acc 94.941%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.198 Acc 95.017%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.156 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.128 Acc 96.388%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.135 Acc 96.222%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.131 Acc 96.255%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.132 Acc 96.154%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.164%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.193 Acc 94.802%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.192 Acc 94.947%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.134 Acc 96.040%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.129 Acc 96.200%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.133 Acc 96.139%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.132 Acc 96.190%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.196 Acc 94.756%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.194 Acc 94.850%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.132 Acc 95.947%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.128 Acc 96.152%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.129 Acc 96.177%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.129 Acc 96.187%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.127 Acc 96.231%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.180 Acc 95.250%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.115 Acc 96.682%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.119 Acc 96.510%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.126 Acc 96.317%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.127 Acc 96.259%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.311%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.188 Acc 95.158%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.188 Acc 95.231%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.123 Acc 96.620%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.127 Acc 96.416%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.125 Acc 96.426%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.127 Acc 96.368%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.127 Acc 96.339%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.192 Acc 94.972%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.190 Acc 95.091%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.123 Acc 96.498%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.123 Acc 96.444%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.126 Acc 96.326%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.218 Acc 92.188%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.186 Acc 95.165%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.114 Acc 96.535%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.116 Acc 96.482%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.118 Acc 96.468%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.120 Acc 96.415%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.121 Acc 96.427%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.183 Acc 95.251%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.181 Acc 95.332%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.111 Acc 96.883%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.117 Acc 96.653%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.118 Acc 96.571%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.118 Acc 96.563%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.121 Acc 96.509%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.190 Acc 95.065%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.190 Acc 95.048%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.122 Acc 96.496%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.117 Acc 96.583%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.117 Acc 96.597%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.119 Acc 96.489%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.120 Acc 96.438%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.190 Acc 92.188%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.189 Acc 95.227%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.189 Acc 95.239%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.113 Acc 96.767%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.110 Acc 96.762%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.113 Acc 96.641%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.117 Acc 96.487%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.118 Acc 96.445%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.196 Acc 94.903%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.195 Acc 94.866%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.111 Acc 96.689%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.114 Acc 96.720%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.116 Acc 96.623%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.117 Acc 96.507%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.119 Acc 96.468%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.191 Acc 94.895%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.189 Acc 95.060%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.117 Acc 96.442%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.498%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.116 Acc 96.558%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.117 Acc 96.555%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.119 Acc 96.515%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.203 Acc 94.562%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.201 Acc 94.586%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.651%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.112 Acc 96.688%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.116 Acc 96.587%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.115 Acc 96.631%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.116 Acc 96.587%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.194 Acc 95.042%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.193 Acc 95.130%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.119 Acc 96.426%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.118 Acc 96.494%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.117 Acc 96.545%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.118 Acc 96.491%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.116 Acc 96.523%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.191 Acc 95.034%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.188 Acc 95.270%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.130 Acc 94.531%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.115 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.114 Acc 96.595%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.111 Acc 96.644%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.112 Acc 96.596%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.114 Acc 96.579%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.196 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.190 Acc 95.134%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.100 Acc 97.223%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.108 Acc 96.937%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.112 Acc 96.745%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.112 Acc 96.725%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.111 Acc 96.705%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.191 Acc 94.833%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 94.974%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.108 Acc 96.767%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.113 Acc 96.720%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.110 Acc 96.784%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.111 Acc 96.746%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.114 Acc 96.622%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.202 Acc 94.872%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.198 Acc 94.986%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.101 Acc 96.890%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.107 Acc 96.778%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.110 Acc 96.740%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.112 Acc 96.683%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.202 Acc 94.748%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.203 Acc 94.823%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.097 Acc 97.030%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.108 Acc 96.739%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.111 Acc 96.626%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.111 Acc 96.631%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.112 Acc 96.643%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.206 Acc 94.508%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.203 Acc 94.745%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.100 Acc 96.960%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.104 Acc 96.922%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.106 Acc 96.832%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.108 Acc 96.819%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.200 Acc 94.833%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.198 Acc 94.959%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.097 Acc 96.906%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.106 Acc 96.731%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.109 Acc 96.623%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.108 Acc 96.674%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.108 Acc 96.680%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.206 Acc 95.011%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.204 Acc 95.040%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.118 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.103 Acc 96.945%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.107 Acc 96.805%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.106 Acc 96.823%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.105 Acc 96.838%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.204 Acc 94.841%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.203 Acc 94.877%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.275 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.099 Acc 96.929%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.103 Acc 96.918%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.104 Acc 96.901%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.105 Acc 96.850%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.106 Acc 96.805%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.202 Acc 94.802%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.200 Acc 94.873%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.105 Acc 96.945%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.105 Acc 96.848%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.104 Acc 96.772%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.104 Acc 96.774%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.203 Acc 94.856%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.201 Acc 94.928%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.103 Acc 96.829%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.105 Acc 96.863%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.104 Acc 96.871%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.105 Acc 96.864%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.280 Acc 90.625%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.211 Acc 94.609%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.209 Acc 94.784%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.094 Acc 97.076%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.099 Acc 97.000%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.101 Acc 96.974%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.102 Acc 96.934%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.191 Acc 95.142%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.189 Acc 95.141%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.096 Acc 97.007%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.096 Acc 97.020%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.098 Acc 97.021%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.101 Acc 96.981%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.202 Acc 94.624%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.200 Acc 94.823%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 97.153%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.101 Acc 97.019%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.101 Acc 96.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.101 Acc 96.959%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.099 Acc 96.997%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.203 Acc 94.872%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.200 Acc 95.029%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.104 Acc 96.972%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.100 Acc 97.070%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.100 Acc 97.031%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.099 Acc 96.989%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.186 Acc 92.969%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.194 Acc 95.158%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.194 Acc 95.231%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.137 Acc 94.531%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.099 Acc 97.014%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.100 Acc 96.927%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.100 Acc 96.978%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.100 Acc 96.950%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.194 Acc 95.065%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.193 Acc 95.173%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.201 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.094 Acc 97.223%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.095 Acc 97.174%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.094 Acc 97.168%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.094 Acc 97.198%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.097 Acc 97.125%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.204 Acc 94.918%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.202 Acc 95.017%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.096 Acc 97.073%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.096 Acc 97.013%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.098 Acc 96.931%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.099 Acc 96.970%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.204 Acc 94.933%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.201 Acc 95.056%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.091 Acc 97.161%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.093 Acc 97.073%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.097 Acc 97.078%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.213 Acc 94.547%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.209 Acc 94.687%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.101 Acc 96.960%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.098 Acc 97.007%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.097 Acc 97.028%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.097 Acc 97.060%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.097 Acc 97.053%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.204 Acc 95.011%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.202 Acc 95.149%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.097 Acc 97.053%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.090 Acc 97.252%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.091 Acc 97.254%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.090 Acc 97.265%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.093 Acc 97.173%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.210 Acc 94.864%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.206 Acc 95.009%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.030 Acc 100.000%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.087 Acc 97.277%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.089 Acc 97.334%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.092 Acc 97.208%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.092 Acc 97.173%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.215 Acc 94.732%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.209 Acc 94.834%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.111 Acc 94.531%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.090 Acc 97.147%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.092 Acc 97.158%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.092 Acc 97.124%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.201 Acc 94.995%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.198 Acc 95.099%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.122 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.090 Acc 97.339%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.089 Acc 97.314%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.091 Acc 97.181%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.091 Acc 97.216%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.092 Acc 97.170%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.206 Acc 94.910%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.206 Acc 94.904%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.083 Acc 97.378%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.088 Acc 97.268%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.090 Acc 97.228%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.091 Acc 97.189%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.091 Acc 97.193%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.208 Acc 94.709%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.207 Acc 94.912%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.088 Acc 97.269%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.090 Acc 97.260%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.090 Acc 97.244%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.092 Acc 97.157%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.090 Acc 97.215%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.214 Acc 94.554%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.212 Acc 94.640%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.085 Acc 97.300%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.085 Acc 97.349%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.087 Acc 97.340%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.088 Acc 97.346%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.089 Acc 97.326%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.205 Acc 95.057%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.205 Acc 95.122%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.156 Acc 96.875%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.086 Acc 97.355%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.086 Acc 97.392%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.088 Acc 97.353%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.089 Acc 97.302%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.089 Acc 97.312%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.207 Acc 94.941%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.205 Acc 95.029%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.087 Acc 97.200%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.087 Acc 97.310%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.088 Acc 97.293%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.088 Acc 97.267%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.088 Acc 97.255%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.212 Acc 94.616%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.211 Acc 94.733%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.088 Acc 97.308%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.086 Acc 97.319%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.088 Acc 97.286%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.217 Acc 94.848%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.214 Acc 94.955%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.165 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.082 Acc 97.440%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.085 Acc 97.301%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.086 Acc 97.274%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.087 Acc 97.288%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.213 Acc 94.879%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.211 Acc 94.963%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.091 Acc 98.438%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.087 Acc 97.146%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.083 Acc 97.388%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.082 Acc 97.394%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.087 Acc 97.287%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.211 Acc 94.748%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.212 Acc 94.873%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.082 Acc 97.509%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.082 Acc 97.407%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.083 Acc 97.451%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.086 Acc 97.317%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.085 Acc 97.341%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.208 Acc 94.988%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.205 Acc 95.118%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.083 Acc 97.401%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.085 Acc 97.427%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.085 Acc 97.394%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.086 Acc 97.343%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.084 Acc 97.421%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.219 Acc 94.787%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.216 Acc 94.932%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.078 Acc 97.548%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.078 Acc 97.501%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.083 Acc 97.337%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.084 Acc 97.326%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.156 Acc 92.969%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.204 Acc 95.050%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.204 Acc 95.138%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.071 Acc 97.772%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.078 Acc 97.582%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.078 Acc 97.503%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.080 Acc 97.467%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.083 Acc 97.399%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.207 Acc 95.034%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.205 Acc 95.040%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.077 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.072 Acc 97.517%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.075 Acc 97.493%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.078 Acc 97.438%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.080 Acc 97.397%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.082 Acc 97.369%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.208 Acc 95.073%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.208 Acc 95.072%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.123 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.079 Acc 97.563%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.081 Acc 97.489%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.082 Acc 97.443%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.081 Acc 97.498%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.081 Acc 97.503%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.227 Acc 94.485%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.221 Acc 94.671%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.079 Acc 97.765%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.080 Acc 97.571%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.080 Acc 97.526%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.083 Acc 97.434%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.082 Acc 97.424%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.213 Acc 94.964%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.209 Acc 95.118%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.072 Acc 97.602%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.073 Acc 97.672%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.077 Acc 97.549%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.217 Acc 92.188%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.232 Acc 94.493%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.228 Acc 94.512%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.072 Acc 97.625%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.076 Acc 97.610%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.080 Acc 97.495%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.080 Acc 97.508%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.079 Acc 97.517%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.266 Acc 92.188%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.230 Acc 94.655%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.226 Acc 94.768%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.076 Acc 97.401%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.073 Acc 97.606%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.074 Acc 97.584%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.075 Acc 97.555%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.076 Acc 97.524%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.236 Acc 94.547%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.233 Acc 94.551%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.072 Acc 97.726%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.077 Acc 97.506%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.077 Acc 97.516%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.077 Acc 97.485%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.211 Acc 95.011%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.211 Acc 94.974%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.107 Acc 94.531%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.075 Acc 97.532%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.073 Acc 97.635%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.075 Acc 97.592%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.075 Acc 97.600%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.254 Acc 92.969%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.224 Acc 94.640%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.224 Acc 94.640%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.071 Acc 97.857%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.071 Acc 97.808%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.073 Acc 97.703%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.075 Acc 97.606%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.076 Acc 97.588%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.218 Acc 94.833%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.219 Acc 94.792%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.071 Acc 97.664%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.071 Acc 97.680%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.072 Acc 97.654%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.073 Acc 97.616%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.225 Acc 94.895%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.225 Acc 94.912%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.070 Acc 97.749%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.069 Acc 97.711%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.071 Acc 97.742%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.073 Acc 97.658%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.217 Acc 94.995%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.216 Acc 95.083%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.071 Acc 97.761%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.073 Acc 97.611%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.074 Acc 97.609%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.233 Acc 94.787%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.228 Acc 94.850%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.070 Acc 97.713%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.071 Acc 97.728%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.072 Acc 97.678%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.226 Acc 94.864%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.223 Acc 94.873%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.066 Acc 97.772%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.070 Acc 97.715%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.069 Acc 97.724%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.070 Acc 97.687%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.071 Acc 97.658%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.202 Acc 92.969%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.227 Acc 94.949%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.226 Acc 94.932%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.068 Acc 97.795%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.069 Acc 97.742%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.072 Acc 97.630%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.071 Acc 97.678%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.072 Acc 97.670%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.235 Acc 94.678%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.232 Acc 94.691%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.068 Acc 97.795%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.069 Acc 97.715%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.071 Acc 97.719%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.071 Acc 97.689%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.212 Acc 91.406%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.230 Acc 94.601%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.227 Acc 94.698%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.074 Acc 97.571%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.067 Acc 97.742%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.068 Acc 97.783%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.072 Acc 97.633%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.232 Acc 94.879%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.229 Acc 94.970%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.068 Acc 97.842%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.068 Acc 97.917%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.071 Acc 97.763%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.071 Acc 97.703%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.190 Acc 92.188%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.225 Acc 94.709%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.224 Acc 94.815%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.066 Acc 97.850%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.069 Acc 97.715%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.070 Acc 97.703%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.071 Acc 97.705%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.232 Acc 94.485%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.232 Acc 94.617%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.152 Acc 94.531%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.066 Acc 97.927%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.068 Acc 97.835%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.069 Acc 97.789%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.069 Acc 97.763%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.070 Acc 97.739%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.236 Acc 94.670%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.234 Acc 94.722%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.061 Acc 98.198%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.068 Acc 97.889%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.068 Acc 97.879%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.070 Acc 97.775%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.071 Acc 97.736%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.236 Acc 94.678%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.230 Acc 94.819%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.067 Acc 97.812%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.068 Acc 97.809%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.068 Acc 97.769%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.069 Acc 97.734%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.224 Acc 94.740%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.223 Acc 94.885%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.063 Acc 97.904%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.064 Acc 97.839%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.067 Acc 97.770%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.068 Acc 97.723%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.235 Acc 94.879%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.234 Acc 94.982%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.065 Acc 97.862%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.068 Acc 97.732%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.067 Acc 97.785%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.067 Acc 97.786%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.230 Acc 94.787%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.229 Acc 94.842%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.062 Acc 97.857%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.062 Acc 97.913%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.065 Acc 97.817%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.067 Acc 97.785%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.068 Acc 97.751%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.228 Acc 94.841%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.228 Acc 94.842%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.060 Acc 98.190%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.063 Acc 98.033%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.064 Acc 97.911%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.066 Acc 97.845%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.067 Acc 97.836%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.230 Acc 94.686%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.228 Acc 94.799%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.056 Acc 97.997%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.062 Acc 97.909%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.063 Acc 97.885%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.064 Acc 97.859%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.065 Acc 97.837%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.257 Acc 94.400%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.250 Acc 94.469%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.068 Acc 97.912%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.068 Acc 97.781%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.068 Acc 97.779%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.068 Acc 97.747%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.255 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.235 Acc 94.810%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.233 Acc 94.924%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.062 Acc 98.014%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.063 Acc 97.955%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.065 Acc 97.831%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.233 Acc 95.019%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.228 Acc 95.173%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.058 Acc 98.028%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.058 Acc 98.076%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.060 Acc 98.020%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.062 Acc 97.962%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.062 Acc 97.974%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.220 Acc 92.188%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.239 Acc 94.756%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.235 Acc 94.819%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.064 Acc 97.901%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.063 Acc 97.924%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.062 Acc 97.941%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.063 Acc 97.901%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.273 Acc 92.969%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.238 Acc 94.771%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.234 Acc 94.842%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.063 Acc 97.850%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.064 Acc 97.905%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.063 Acc 97.947%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.064 Acc 97.895%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.235 Acc 94.964%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.232 Acc 95.056%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.079 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.061 Acc 97.983%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.062 Acc 97.921%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.062 Acc 97.941%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.062 Acc 97.910%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.241 Acc 94.848%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.239 Acc 94.986%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.062 Acc 97.873%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.062 Acc 97.913%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.060 Acc 97.965%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.061 Acc 97.945%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.062 Acc 97.931%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.235 Acc 95.080%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.233 Acc 95.157%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.056 Acc 98.252%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.061 Acc 98.018%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.064 Acc 97.910%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.063 Acc 97.918%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.242 Acc 94.446%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.237 Acc 94.636%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.057 Acc 98.159%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.058 Acc 98.084%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.059 Acc 98.066%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.060 Acc 97.989%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.062 Acc 97.973%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.238 Acc 94.740%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.237 Acc 94.869%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.058 Acc 98.120%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.059 Acc 98.041%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.063 Acc 97.869%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.063 Acc 97.882%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.234 Acc 94.779%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.230 Acc 94.869%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.061 Acc 97.888%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.058 Acc 98.002%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.060 Acc 97.903%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.061 Acc 97.923%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.060 Acc 97.946%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.268 Acc 92.969%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.236 Acc 94.794%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.232 Acc 94.924%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.073 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.062 Acc 97.850%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.060 Acc 97.956%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.060 Acc 97.999%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.060 Acc 97.978%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.061 Acc 97.920%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.243 Acc 94.794%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.240 Acc 94.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.056 Acc 98.105%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.056 Acc 98.189%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.058 Acc 98.079%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.059 Acc 98.032%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.060 Acc 98.016%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.271 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.257 Acc 94.454%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.251 Acc 94.531%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.058 Acc 98.028%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.059 Acc 98.033%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.059 Acc 98.051%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.058 Acc 98.065%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.058 Acc 98.063%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.255 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.239 Acc 94.732%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.234 Acc 94.974%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.052 Acc 98.190%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.057 Acc 98.103%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.056 Acc 98.056%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.057 Acc 98.056%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.058 Acc 98.031%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.285 Acc 91.406%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.238 Acc 94.678%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.236 Acc 94.706%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.055 Acc 98.298%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.057 Acc 98.189%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.057 Acc 98.126%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.058 Acc 98.050%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.060 Acc 97.982%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.241 Acc 94.732%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.242 Acc 94.733%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.052 Acc 98.275%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.054 Acc 98.150%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.055 Acc 98.142%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.055 Acc 98.161%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.056 Acc 98.123%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.208 Acc 93.750%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.244 Acc 94.848%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.241 Acc 95.002%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.053 Acc 98.144%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.055 Acc 98.082%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.055 Acc 98.073%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.057 Acc 98.046%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.248 Acc 94.732%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.246 Acc 94.714%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.054 Acc 98.136%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.054 Acc 98.181%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.054 Acc 98.162%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.056 Acc 98.097%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.056 Acc 98.101%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.260 Acc 94.531%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.244 Acc 94.392%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.240 Acc 94.597%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.052 Acc 98.329%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.057 Acc 98.115%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.057 Acc 98.079%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.059 Acc 98.040%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.057 Acc 98.071%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.259 Acc 92.969%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.244 Acc 94.701%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.242 Acc 94.900%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.060 Acc 97.857%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.057 Acc 97.944%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.057 Acc 97.965%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.058 Acc 97.952%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.058 Acc 97.984%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.274 Acc 90.625%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.240 Acc 94.879%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.237 Acc 94.947%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.053 Acc 98.213%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.050 Acc 98.313%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.051 Acc 98.297%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.054 Acc 98.223%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.055 Acc 98.199%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.241 Acc 94.694%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.241 Acc 94.733%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.048 Acc 98.229%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.052 Acc 98.146%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.053 Acc 98.144%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.053 Acc 98.137%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.056 Acc 98.101%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.279 Acc 92.969%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.254 Acc 94.562%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.253 Acc 94.636%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.051 Acc 98.244%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.050 Acc 98.235%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.054 Acc 98.134%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.054 Acc 98.106%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.056 Acc 98.055%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.238 Acc 94.810%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.236 Acc 94.788%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.051 Acc 98.383%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.052 Acc 98.282%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.051 Acc 98.274%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.053 Acc 98.192%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.054 Acc 98.143%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.251 Acc 92.969%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.248 Acc 94.524%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.245 Acc 94.745%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.049 Acc 98.247%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.053 Acc 98.175%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.054 Acc 98.130%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.054 Acc 98.143%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.267 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.249 Acc 94.810%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.244 Acc 94.924%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.054 Acc 98.229%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.052 Acc 98.231%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.053 Acc 98.217%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.054 Acc 98.178%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.055 Acc 98.146%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.254 Acc 94.725%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.249 Acc 94.881%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.043 Acc 99.219%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [100/573] Loss: 0.055 Acc 98.120%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.052 Acc 98.228%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.052 Acc 98.219%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.054 Acc 98.204%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.054 Acc 98.158%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.277 Acc 91.406%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.257 Acc 94.585%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.255 Acc 94.601%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.053 Acc 98.252%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.051 Acc 98.298%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.054 Acc 98.186%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.054 Acc 98.188%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.260 Acc 94.864%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.258 Acc 94.881%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.046 Acc 98.383%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.051 Acc 98.270%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.052 Acc 98.201%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.052 Acc 98.174%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.054 Acc 98.146%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.217 Acc 92.188%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.250 Acc 94.817%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.243 Acc 94.982%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.048 Acc 98.376%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.053 Acc 98.191%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.055 Acc 98.169%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.053 Acc 98.225%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.293 Acc 92.969%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.253 Acc 94.261%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.248 Acc 94.566%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.052 Acc 98.128%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.050 Acc 98.224%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.052 Acc 98.136%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.053 Acc 98.128%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.053 Acc 98.126%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.246 Acc 94.771%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.243 Acc 94.947%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.043 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.049 Acc 98.383%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.052 Acc 98.290%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.053 Acc 98.269%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.052 Acc 98.270%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.052 Acc 98.300%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.251 Acc 94.794%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.248 Acc 94.974%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.082 Acc 99.219%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.047 Acc 98.252%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.049 Acc 98.309%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.049 Acc 98.336%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.051 Acc 98.274%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.052 Acc 98.233%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.232 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.260 Acc 94.547%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.257 Acc 94.706%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.049 Acc 98.244%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.048 Acc 98.266%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.050 Acc 98.225%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.050 Acc 98.221%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.051 Acc 98.219%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.246 Acc 94.647%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.242 Acc 94.827%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.050 Acc 98.221%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.050 Acc 98.248%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.050 Acc 98.233%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.051 Acc 98.230%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.268 Acc 94.895%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.263 Acc 94.990%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.051 Acc 98.260%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.049 Acc 98.270%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.051 Acc 98.238%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.052 Acc 98.215%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.053 Acc 98.183%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.236 Acc 92.969%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.248 Acc 94.616%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.248 Acc 94.718%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.048 Acc 98.391%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.050 Acc 98.309%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.051 Acc 98.256%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.052 Acc 98.208%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.051 Acc 98.222%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.262 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.251 Acc 94.647%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.249 Acc 94.714%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.062 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.047 Acc 98.383%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.049 Acc 98.356%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.049 Acc 98.352%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.051 Acc 98.289%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.052 Acc 98.233%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.256 Acc 92.969%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.262 Acc 94.763%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.258 Acc 94.862%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.043 Acc 98.577%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.045 Acc 98.476%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.047 Acc 98.344%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.049 Acc 98.286%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.050 Acc 98.269%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.281 Acc 91.406%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.251 Acc 94.926%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.244 Acc 95.083%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.048 Acc 98.356%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.049 Acc 98.349%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.049 Acc 98.346%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.049 Acc 98.322%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.300 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.254 Acc 94.841%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.251 Acc 94.916%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.029 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.047 Acc 98.283%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.049 Acc 98.266%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.050 Acc 98.227%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.050 Acc 98.225%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.050 Acc 98.268%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.149 Acc 96.875%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.256 Acc 94.787%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.253 Acc 94.916%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.046 Acc 98.461%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.046 Acc 98.434%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.048 Acc 98.386%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.049 Acc 98.313%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.050 Acc 98.263%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.306 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.247 Acc 94.872%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.242 Acc 95.025%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.045 Acc 98.530%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.048 Acc 98.352%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.048 Acc 98.336%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.049 Acc 98.315%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.051 Acc 98.235%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.248 Acc 92.188%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.252 Acc 94.624%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.249 Acc 94.772%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.047 Acc 98.267%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.047 Acc 98.364%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.047 Acc 98.352%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.046 Acc 98.393%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.047 Acc 98.383%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.254 Acc 94.438%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.253 Acc 94.566%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.046 Acc 98.352%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.046 Acc 98.371%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.048 Acc 98.334%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.048 Acc 98.350%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.048 Acc 98.347%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.263 Acc 94.787%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.257 Acc 94.866%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.045 Acc 98.399%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.046 Acc 98.441%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.046 Acc 98.443%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.048 Acc 98.366%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.266 Acc 94.686%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.262 Acc 94.807%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.043 Acc 98.523%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.044 Acc 98.519%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.046 Acc 98.466%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.046 Acc 98.441%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.047 Acc 98.413%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.265 Acc 94.593%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.261 Acc 94.706%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.046 Acc 98.360%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.044 Acc 98.422%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.046 Acc 98.425%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.048 Acc 98.385%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.049 Acc 98.358%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.257 Acc 94.732%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.254 Acc 94.866%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.045 Acc 98.345%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.046 Acc 98.387%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.047 Acc 98.378%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.047 Acc 98.379%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.047 Acc 98.411%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.251 Acc 94.787%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.246 Acc 94.893%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.041 Acc 98.507%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.043 Acc 98.453%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.044 Acc 98.416%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.045 Acc 98.414%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.307 Acc 91.406%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.265 Acc 94.678%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.261 Acc 94.772%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.028 Acc 100.000%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.047 Acc 98.476%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.048 Acc 98.403%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.049 Acc 98.365%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.047 Acc 98.431%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.270 Acc 92.969%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.251 Acc 94.601%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.251 Acc 94.671%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.045 Acc 98.383%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.045 Acc 98.410%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.046 Acc 98.378%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.046 Acc 98.389%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.046 Acc 98.366%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.252 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.257 Acc 94.624%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.250 Acc 94.831%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.042 Acc 98.530%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.044 Acc 98.434%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.045 Acc 98.409%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.047 Acc 98.338%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.047 Acc 98.353%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.268 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.261 Acc 94.640%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.260 Acc 94.764%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.043 Acc 98.492%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.044 Acc 98.461%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.047 Acc 98.334%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.047 Acc 98.356%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.046 Acc 98.388%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.216 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.259 Acc 94.678%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.254 Acc 94.733%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.042 Acc 98.523%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.044 Acc 98.472%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.045 Acc 98.414%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.046 Acc 98.413%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.335 Acc 91.406%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.269 Acc 94.500%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.263 Acc 94.780%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.037 Acc 98.675%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.040 Acc 98.630%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.042 Acc 98.545%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.044 Acc 98.472%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.261 Acc 94.531%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.263 Acc 94.725%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.261 Acc 94.850%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [100/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.043 Acc 98.465%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.046 Acc 98.408%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.046 Acc 98.406%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.220 Acc 92.188%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.258 Acc 94.508%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.251 Acc 94.733%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.040 Acc 98.675%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.042 Acc 98.609%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.041 Acc 98.630%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.042 Acc 98.586%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.236 Acc 93.750%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.259 Acc 94.825%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.256 Acc 94.811%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.041 Acc 98.584%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.043 Acc 98.469%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.043 Acc 98.482%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.044 Acc 98.439%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.045 Acc 98.413%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.260 Acc 94.701%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.260 Acc 94.842%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.045 Acc 98.461%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.046 Acc 98.410%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.047 Acc 98.349%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.046 Acc 98.377%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.046 Acc 98.366%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.263 Acc 94.562%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.258 Acc 94.737%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcedda52b8c4468c80b990ce4a16d1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8536e2b5567c499f933d1c6046d62456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.292 Acc 21.875%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.239 Acc 19.143%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.999%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.231 Acc 19.014%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.840 Acc 40.625%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.912 Acc 32.488%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.914 Acc 32.210%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.957 Acc 35.938%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.623 Acc 43.897%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.406 Acc 52.099%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.247 Acc 57.955%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.118 Acc 62.634%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.020 Acc 66.180%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.516 Acc 83.594%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.462 Acc 86.193%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.449 Acc 86.505%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.411 Acc 89.844%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.528 Acc 83.849%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.505 Acc 84.542%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.490 Acc 85.021%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.482 Acc 85.265%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.470 Acc 85.576%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.436 Acc 86.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.338 Acc 90.548%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.333 Acc 90.516%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.270 Acc 95.312%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.379 Acc 88.745%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.387 Acc 88.452%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.388 Acc 88.372%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.386 Acc 88.396%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.384 Acc 88.500%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.413 Acc 88.281%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.304 Acc 91.476%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.298 Acc 91.519%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.264 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.353 Acc 89.233%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.356 Acc 89.214%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.351 Acc 89.392%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.349 Acc 89.477%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.349 Acc 89.566%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.298 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.290 Acc 91.754%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.280 Acc 91.873%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.593 Acc 81.250%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.329 Acc 90.408%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.325 Acc 90.493%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.318 Acc 90.674%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.320 Acc 90.559%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.319 Acc 90.558%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.270 Acc 92.621%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.263 Acc 92.802%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.340 Acc 85.938%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.311 Acc 90.594%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.308 Acc 90.792%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.307 Acc 90.942%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.306 Acc 90.974%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.305 Acc 90.995%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.316 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.267 Acc 92.744%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.257 Acc 92.825%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.295 Acc 91.298%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.298 Acc 91.002%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.295 Acc 91.032%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.293 Acc 91.213%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.291 Acc 91.311%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.256 Acc 93.270%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.245 Acc 93.396%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.365 Acc 87.500%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.272 Acc 91.855%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.284 Acc 91.643%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.284 Acc 91.725%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.284 Acc 91.683%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.285 Acc 91.657%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.230 Acc 93.727%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.222 Acc 93.894%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.273 Acc 92.273%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.275 Acc 91.908%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.273 Acc 92.027%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.272 Acc 92.026%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.272 Acc 92.064%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.304 Acc 89.844%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.250 Acc 93.224%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.244 Acc 93.237%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.338 Acc 88.281%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.273 Acc 91.971%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.266 Acc 92.238%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.268 Acc 92.226%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.269 Acc 92.182%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.265 Acc 92.275%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.240 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.215 Acc 94.114%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.210 Acc 94.201%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.271 Acc 91.406%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.240 Acc 92.961%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.249 Acc 92.666%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.256 Acc 92.553%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.258 Acc 92.519%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.262 Acc 92.417%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.190 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.227 Acc 93.851%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.221 Acc 93.975%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.342 Acc 91.406%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.258 Acc 92.644%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.261 Acc 92.615%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.256 Acc 92.730%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.257 Acc 92.583%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.258 Acc 92.517%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.250 Acc 93.131%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.243 Acc 93.116%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.171 Acc 91.406%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.261 Acc 92.481%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.250 Acc 92.802%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.249 Acc 92.686%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.252 Acc 92.643%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.255 Acc 92.554%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.230 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.211 Acc 94.284%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.204 Acc 94.415%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.385 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.246 Acc 92.659%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.248 Acc 92.802%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.250 Acc 92.753%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.249 Acc 92.807%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.248 Acc 92.836%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.212 Acc 94.825%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.203 Acc 94.932%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.229 Acc 92.953%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.238 Acc 92.934%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.236 Acc 93.026%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.238 Acc 93.037%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.239 Acc 93.062%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.251 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.217 Acc 94.485%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.206 Acc 94.590%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.247 Acc 92.690%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.244 Acc 92.895%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.244 Acc 92.909%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.242 Acc 92.969%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.243 Acc 92.970%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.225 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.206 Acc 94.663%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.198 Acc 94.683%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.285 Acc 90.625%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.229 Acc 93.348%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.229 Acc 93.151%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.231 Acc 93.202%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.235 Acc 93.154%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.238 Acc 93.047%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.205 Acc 94.825%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.199 Acc 94.803%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.204 Acc 91.406%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.219 Acc 93.796%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.225 Acc 93.571%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.228 Acc 93.459%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.231 Acc 93.347%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.232 Acc 93.313%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.198 Acc 95.065%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.190 Acc 95.079%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.181 Acc 96.094%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.229 Acc 93.510%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.233 Acc 93.377%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.231 Acc 93.389%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.230 Acc 93.368%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.230 Acc 93.384%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.258 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.206 Acc 94.508%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.201 Acc 94.597%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.249 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.228 Acc 93.309%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.223 Acc 93.458%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.226 Acc 93.464%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.226 Acc 93.487%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.225 Acc 93.502%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.207 Acc 94.732%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.198 Acc 94.862%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.159 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.215 Acc 93.804%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.221 Acc 93.458%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.222 Acc 93.332%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.223 Acc 93.399%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.227 Acc 93.402%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.272 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.206 Acc 94.524%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.199 Acc 94.660%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.319 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.225 Acc 93.889%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.216 Acc 93.894%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.220 Acc 93.768%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.222 Acc 93.625%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.221 Acc 93.628%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.257 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.205 Acc 94.446%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.196 Acc 94.656%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.205 Acc 94.052%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.213 Acc 93.952%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.210 Acc 93.932%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.213 Acc 93.898%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.214 Acc 93.825%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.201 Acc 95.312%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.204 Acc 94.485%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.194 Acc 94.667%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.294 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.219 Acc 93.526%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.221 Acc 93.528%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.217 Acc 93.664%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.219 Acc 93.619%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.218 Acc 93.666%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.211 Acc 94.291%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.202 Acc 94.558%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.477 Acc 89.844%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.215 Acc 93.765%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.215 Acc 93.738%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.216 Acc 93.644%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.215 Acc 93.697%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.215 Acc 93.688%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.211 Acc 94.469%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.203 Acc 94.523%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.218 Acc 93.665%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.213 Acc 93.754%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.214 Acc 93.734%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.214 Acc 93.707%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.214 Acc 93.656%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.206 Acc 95.104%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.196 Acc 95.091%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.276 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.204 Acc 93.959%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.210 Acc 93.797%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.208 Acc 93.986%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.209 Acc 93.927%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.212 Acc 93.844%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.200 Acc 94.655%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.192 Acc 94.788%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.227 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.202 Acc 94.059%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.203 Acc 94.162%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.205 Acc 94.087%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.207 Acc 94.031%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.210 Acc 93.951%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.200 Acc 94.895%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.191 Acc 95.103%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.304 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.204 Acc 93.881%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.204 Acc 93.925%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.212 Acc 93.802%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.213 Acc 93.828%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.211 Acc 93.884%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.204 Acc 94.864%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.194 Acc 94.970%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.290 Acc 91.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.211 Acc 93.889%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.209 Acc 93.894%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.208 Acc 93.955%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.207 Acc 93.957%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.208 Acc 93.981%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.197 Acc 94.817%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.189 Acc 95.009%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.171 Acc 93.750%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.199 Acc 94.377%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.205 Acc 94.088%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.203 Acc 94.080%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.204 Acc 94.089%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.207 Acc 93.940%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.221 Acc 94.469%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.209 Acc 94.718%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.200 Acc 91.406%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.206 Acc 93.796%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.208 Acc 93.905%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.212 Acc 93.882%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.207 Acc 93.966%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.210 Acc 93.917%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.159 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.188 Acc 95.196%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.181 Acc 95.281%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.203 Acc 94.106%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.199 Acc 94.139%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.201 Acc 94.129%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.202 Acc 94.103%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.200 Acc 94.116%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.616%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.195 Acc 94.780%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.236 Acc 91.406%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.194 Acc 94.315%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.193 Acc 94.380%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.198 Acc 94.254%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.200 Acc 94.169%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.202 Acc 94.146%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.206 Acc 95.274%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.196 Acc 95.262%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.111 Acc 95.312%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.199 Acc 93.951%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.206 Acc 93.890%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.202 Acc 94.108%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.200 Acc 94.087%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.201 Acc 94.054%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.194 Acc 95.019%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.183 Acc 95.278%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.209 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.196 Acc 94.330%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.195 Acc 94.356%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.198 Acc 94.272%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.199 Acc 94.243%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.200 Acc 94.215%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.347 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.215 Acc 94.562%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.205 Acc 94.644%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.196 Acc 94.315%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.205 Acc 94.100%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.198 Acc 94.212%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.197 Acc 94.233%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.199 Acc 94.159%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.204 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.186 Acc 95.599%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.179 Acc 95.491%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.180 Acc 94.670%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.192 Acc 94.403%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.195 Acc 94.274%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.196 Acc 94.296%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.197 Acc 94.291%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.207 Acc 95.135%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.197 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.174 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.189 Acc 94.640%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.190 Acc 94.570%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.192 Acc 94.479%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.193 Acc 94.430%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.196 Acc 94.355%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.204 Acc 94.547%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.195 Acc 94.764%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.183 Acc 94.539%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.192 Acc 94.282%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.192 Acc 94.373%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.195 Acc 94.225%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.194 Acc 94.343%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.177 Acc 95.565%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.204 Acc 92.188%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.187 Acc 94.168%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.191 Acc 94.251%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.195 Acc 94.238%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.195 Acc 94.258%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.194 Acc 94.291%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.186 Acc 95.145%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.229 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.187 Acc 94.547%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.191 Acc 94.457%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.193 Acc 94.305%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.194 Acc 94.266%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.194 Acc 94.272%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.187 Acc 95.421%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.182 Acc 95.464%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.177 Acc 94.988%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.187 Acc 94.643%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.188 Acc 94.533%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.194 Acc 95.328%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.189 Acc 95.390%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.188 Acc 94.361%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.186 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.188 Acc 94.547%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.189 Acc 94.471%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.190 Acc 94.428%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.193 Acc 94.972%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.186 Acc 95.040%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.156 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.174 Acc 94.779%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.182 Acc 94.555%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.185 Acc 94.560%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.188 Acc 94.492%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.190 Acc 94.460%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.187 Acc 95.467%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.181 Acc 95.484%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.265 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.178 Acc 94.879%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.185 Acc 94.562%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.185 Acc 94.572%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.188 Acc 94.475%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.199 Acc 95.173%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.192 Acc 95.204%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.162 Acc 93.750%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.180 Acc 94.554%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.186 Acc 94.523%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.190 Acc 94.457%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.192 Acc 94.369%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.188 Acc 95.073%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.180 Acc 95.219%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.174 Acc 94.941%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.180 Acc 94.757%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.182 Acc 94.645%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.190 Acc 94.489%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.202 Acc 94.988%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.194 Acc 95.110%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.281 Acc 91.406%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.186 Acc 94.547%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.181 Acc 94.691%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.185 Acc 94.542%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.187 Acc 94.514%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.187 Acc 94.523%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.206 Acc 95.336%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.198 Acc 95.305%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.153 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.185 Acc 94.647%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.180 Acc 94.788%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.181 Acc 94.731%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.185 Acc 94.600%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.191 Acc 92.188%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.201 Acc 94.787%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.193 Acc 94.869%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.180 Acc 94.825%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.178 Acc 94.873%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.181 Acc 94.830%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.183 Acc 94.751%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.184 Acc 94.656%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.189 Acc 95.592%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.156 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.181 Acc 94.725%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.184 Acc 94.617%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.186 Acc 94.482%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.185 Acc 94.477%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.187 Acc 94.436%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.184 Acc 95.359%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.179 Acc 95.379%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.253 Acc 91.406%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.182 Acc 94.771%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.186 Acc 94.565%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.186 Acc 94.566%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.186 Acc 94.575%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.425%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.337 Acc 92.188%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.185 Acc 94.299%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.187 Acc 94.333%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.185 Acc 94.469%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.188 Acc 94.481%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.187 Acc 94.456%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.207 Acc 95.042%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.194 Acc 95.219%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.175 Acc 94.903%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.177 Acc 94.698%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.177 Acc 94.739%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.179 Acc 94.638%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.180 Acc 94.667%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.164 Acc 92.188%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.205 Acc 94.903%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.196 Acc 94.978%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.181 Acc 94.740%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.176 Acc 94.846%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.177 Acc 94.791%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.178 Acc 94.746%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.181 Acc 94.659%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.208 Acc 94.887%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.201 Acc 95.040%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.203 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.174 Acc 94.663%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.178 Acc 94.628%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.179 Acc 94.586%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.179 Acc 94.586%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.182 Acc 94.562%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.202 Acc 95.088%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.193 Acc 95.188%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.232 Acc 96.094%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.182 Acc 94.817%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.175 Acc 94.897%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.180 Acc 94.734%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.183 Acc 94.677%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.184 Acc 94.681%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.187 Acc 95.452%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.167 Acc 95.026%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.173 Acc 94.916%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.174 Acc 94.791%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.177 Acc 94.710%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.178 Acc 94.745%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.200 Acc 91.406%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.194 Acc 95.459%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.188 Acc 95.491%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.168 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.175 Acc 94.872%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.182 Acc 94.593%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.181 Acc 94.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.183 Acc 94.594%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.181 Acc 94.703%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.184 Acc 95.483%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.175 Acc 95.717%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.260 Acc 91.406%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.176 Acc 94.725%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.178 Acc 94.780%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.180 Acc 94.770%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.178 Acc 94.823%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.180 Acc 94.736%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.206 Acc 95.096%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.196 Acc 95.320%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.248 Acc 90.625%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.183 Acc 94.508%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.179 Acc 94.593%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.175 Acc 94.775%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.181 Acc 94.648%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.181 Acc 94.622%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.200 Acc 95.166%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.187 Acc 95.316%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.229 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.166 Acc 94.926%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.177 Acc 94.601%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.181 Acc 94.568%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.178 Acc 94.633%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.178 Acc 94.645%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.192 Acc 95.135%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.181 Acc 95.340%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.221 Acc 94.531%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.180 Acc 94.740%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.176 Acc 94.866%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.175 Acc 94.876%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.178 Acc 94.794%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.176 Acc 94.842%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.225 Acc 93.750%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.429%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.179 Acc 95.484%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.169 Acc 95.026%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.169 Acc 94.959%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.169 Acc 94.983%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.175 Acc 94.818%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.174 Acc 94.846%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.221 Acc 95.189%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.206 Acc 95.297%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.183 Acc 94.485%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.177 Acc 94.737%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.174 Acc 94.773%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.177 Acc 94.744%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.179 Acc 94.731%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.231 Acc 92.188%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.222 Acc 95.042%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.210 Acc 95.243%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.169 Acc 94.864%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.173 Acc 94.889%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.175 Acc 94.856%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.178 Acc 94.773%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.175 Acc 94.868%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.223 Acc 95.096%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.212 Acc 95.211%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.175 Acc 90.625%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.174 Acc 94.794%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.172 Acc 95.037%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.175 Acc 94.939%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.177 Acc 94.831%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.177 Acc 94.795%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.273 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.233 Acc 94.949%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.220 Acc 95.083%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.226 Acc 93.750%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.172 Acc 94.887%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.167 Acc 95.025%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.170 Acc 94.892%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.169 Acc 94.859%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.172 Acc 94.848%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.204 Acc 94.910%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.197 Acc 95.025%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.167 Acc 95.042%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.175 Acc 94.924%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.175 Acc 94.949%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.174 Acc 94.950%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.176 Acc 94.879%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.199 Acc 95.266%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.187 Acc 95.433%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.168 Acc 95.065%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.167 Acc 95.173%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.172 Acc 94.947%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.172 Acc 94.907%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.174 Acc 94.807%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.223 Acc 94.825%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.213 Acc 94.963%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.162 Acc 95.019%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.173 Acc 94.967%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.173 Acc 94.921%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.172 Acc 94.962%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.173 Acc 94.910%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.214 Acc 94.918%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.198 Acc 95.297%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.175 Acc 94.872%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.172 Acc 94.998%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.174 Acc 94.918%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.174 Acc 94.857%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.173 Acc 94.848%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.298 Acc 92.969%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.221 Acc 95.111%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.205 Acc 95.371%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.162 Acc 95.243%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.165 Acc 95.141%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.169 Acc 95.040%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.170 Acc 95.034%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.170 Acc 94.988%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.226 Acc 92.188%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.207 Acc 95.181%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.196 Acc 95.421%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.159 Acc 95.297%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.165 Acc 95.075%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.168 Acc 94.952%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.170 Acc 94.952%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.169 Acc 94.996%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.198 Acc 95.096%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.190 Acc 95.262%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.162 Acc 95.088%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.161 Acc 95.110%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.163 Acc 95.092%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.168 Acc 94.979%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.168 Acc 94.969%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.277 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.205 Acc 95.204%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.197 Acc 95.281%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.162 Acc 92.969%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.176 Acc 94.933%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.172 Acc 94.935%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.175 Acc 94.814%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.175 Acc 94.818%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.172 Acc 94.870%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.206 Acc 95.135%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.196 Acc 95.270%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.163 Acc 95.080%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.169 Acc 95.005%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.172 Acc 94.944%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.172 Acc 94.958%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.172 Acc 94.965%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.229 Acc 92.188%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.209 Acc 94.732%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.200 Acc 94.897%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.166 Acc 95.019%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.075%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.165 Acc 95.141%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.166 Acc 95.092%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.170 Acc 94.998%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.241 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.204 Acc 95.104%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.194 Acc 95.274%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.162 Acc 95.189%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.167 Acc 95.009%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.168 Acc 95.006%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.167 Acc 95.098%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.170 Acc 94.954%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.221 Acc 91.406%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.211 Acc 95.096%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.196 Acc 95.421%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.169 Acc 94.802%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.166 Acc 94.897%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.169 Acc 94.871%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.166 Acc 94.962%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.167 Acc 94.946%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.272 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.216 Acc 94.933%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.205 Acc 95.176%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.166 Acc 94.988%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.162 Acc 95.153%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.164 Acc 95.089%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.167 Acc 94.991%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.167 Acc 94.979%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.206 Acc 95.166%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.198 Acc 95.266%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.250 Acc 92.188%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.160 Acc 95.289%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.168 Acc 95.106%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.170 Acc 95.019%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.171 Acc 94.933%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.171 Acc 94.943%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.214 Acc 94.926%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.206 Acc 95.087%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.164 Acc 95.034%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.160 Acc 95.149%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.164 Acc 95.074%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.167 Acc 94.997%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.168 Acc 94.957%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.187 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.211 Acc 95.243%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.200 Acc 95.355%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.167 Acc 94.978%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.167 Acc 95.022%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.169 Acc 94.933%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.169 Acc 94.948%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.215 Acc 95.003%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.208 Acc 95.114%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.199 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.157 Acc 95.367%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.166 Acc 95.122%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.166 Acc 95.053%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.168 Acc 95.009%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.167 Acc 95.018%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.203 Acc 94.817%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.197 Acc 94.904%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.174 Acc 93.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.152 Acc 95.150%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.155 Acc 95.180%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.159 Acc 95.170%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.163 Acc 95.051%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.165 Acc 95.051%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.206 Acc 95.019%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.195 Acc 95.254%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.164 Acc 94.872%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.161 Acc 95.021%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.163 Acc 95.001%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.166 Acc 94.919%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.166 Acc 94.969%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.203 Acc 95.065%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.065%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.165 Acc 95.017%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.162 Acc 95.152%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.164 Acc 95.112%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.166 Acc 95.077%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.194 Acc 95.235%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.188 Acc 95.515%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.231 Acc 92.969%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.164 Acc 95.173%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.157 Acc 95.246%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.164 Acc 95.120%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.165 Acc 95.125%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.283 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.226 Acc 95.019%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.217 Acc 95.153%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.162 Acc 95.320%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.163 Acc 95.200%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.162 Acc 95.159%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.165 Acc 95.048%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.165 Acc 95.054%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.242 Acc 92.969%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.220 Acc 94.779%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.208 Acc 95.029%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.233 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.154 Acc 95.274%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.160 Acc 95.211%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.162 Acc 95.159%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.160 Acc 95.184%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.162 Acc 95.063%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.230 Acc 94.833%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.215 Acc 95.110%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.117 Acc 94.531%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.154 Acc 95.429%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.160 Acc 95.258%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.163 Acc 95.110%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.165 Acc 95.005%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.167 Acc 94.952%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.204 Acc 95.119%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.192 Acc 95.309%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.159 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.164 Acc 95.099%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.164 Acc 95.113%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.164 Acc 95.098%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.164 Acc 95.052%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.297 Acc 91.406%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.219 Acc 95.065%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.208 Acc 95.316%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.167 Acc 93.750%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.166 Acc 95.336%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.160 Acc 95.301%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.162 Acc 95.242%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.162 Acc 95.198%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.164 Acc 95.091%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.214 Acc 94.802%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.201 Acc 94.982%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.160 Acc 95.212%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.161 Acc 95.153%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.163 Acc 95.105%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.161 Acc 95.159%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.162 Acc 95.172%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.229 Acc 95.096%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.219 Acc 95.254%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.166 Acc 94.918%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.169 Acc 94.796%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.165 Acc 94.991%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.166 Acc 94.942%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.167 Acc 94.969%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.222 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.206 Acc 95.367%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.194 Acc 95.484%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.148 Acc 95.436%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.153 Acc 95.382%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.158 Acc 95.248%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.163 Acc 95.105%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.198 Acc 95.189%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.188 Acc 95.402%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.160 Acc 95.158%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.158 Acc 95.141%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.158 Acc 95.227%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.161 Acc 95.219%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.163 Acc 95.130%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.228 Acc 94.895%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.213 Acc 95.138%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.152 Acc 95.460%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.159 Acc 95.203%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.160 Acc 95.182%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.163 Acc 95.122%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.206 Acc 94.980%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.197 Acc 95.165%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.147 Acc 95.444%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.160 Acc 95.099%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.161 Acc 95.110%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.161 Acc 95.147%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.161 Acc 95.147%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.225 Acc 95.119%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.209 Acc 95.324%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.153 Acc 95.467%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.158 Acc 95.227%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.159 Acc 95.185%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.159 Acc 95.238%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.160 Acc 95.205%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.176 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.210 Acc 95.142%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.146 Acc 96.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.149 Acc 95.777%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.491%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.159 Acc 95.364%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.161 Acc 95.293%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.160 Acc 95.266%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.262 Acc 92.969%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.219 Acc 95.235%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.209 Acc 95.262%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.149 Acc 95.382%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.151 Acc 95.250%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.158 Acc 95.146%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.160 Acc 95.079%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.160 Acc 95.119%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.209 Acc 95.429%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.197 Acc 95.546%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.197 Acc 92.969%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.157 Acc 95.266%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.149 Acc 95.588%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.154 Acc 95.414%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.158 Acc 95.314%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.160 Acc 95.281%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.217 Acc 95.506%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.207 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.229 Acc 94.531%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.154 Acc 95.266%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.158 Acc 95.184%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.158 Acc 95.237%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.157 Acc 95.285%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.158 Acc 95.220%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.227 Acc 95.119%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.209 Acc 95.328%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.155 Acc 94.980%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.159 Acc 94.982%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.160 Acc 95.081%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.159 Acc 95.067%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.160 Acc 95.136%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.204 Acc 95.413%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.196 Acc 95.542%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.224 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.159 Acc 95.289%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.159 Acc 95.250%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.163 Acc 95.094%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.165 Acc 95.049%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.165 Acc 95.086%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.251 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.209 Acc 95.251%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.201 Acc 95.375%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.145 Acc 95.552%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.148 Acc 95.538%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.154 Acc 95.401%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.156 Acc 95.299%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.159 Acc 95.252%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.220 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.246 Acc 94.887%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.235 Acc 95.114%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.159 Acc 93.750%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.157 Acc 95.374%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.157 Acc 95.285%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.160 Acc 95.120%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.161 Acc 95.096%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.162 Acc 95.107%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.281 Acc 93.750%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.213 Acc 94.879%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.199 Acc 95.180%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.144 Acc 95.792%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.152 Acc 95.421%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.153 Acc 95.326%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.154 Acc 95.345%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.218 Acc 95.227%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.206 Acc 95.460%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.157 Acc 95.088%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.158 Acc 95.161%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.160 Acc 95.149%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.158 Acc 95.153%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.159 Acc 95.150%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.215 Acc 95.119%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.207 Acc 95.293%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.336 Acc 92.969%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.162 Acc 95.180%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.163 Acc 95.063%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.162 Acc 95.174%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.162 Acc 95.163%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.216 Acc 95.142%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.204 Acc 95.359%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.144 Acc 95.591%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.145 Acc 95.608%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.155 Acc 95.409%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.154 Acc 95.433%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.158 Acc 95.309%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.210 Acc 92.969%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.233 Acc 94.918%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.229 Acc 94.994%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.160 Acc 95.166%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.160 Acc 95.138%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.158 Acc 95.193%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.157 Acc 95.244%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.160 Acc 95.189%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.213 Acc 95.258%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.204 Acc 95.468%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.160 Acc 95.266%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.154 Acc 95.324%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.155 Acc 95.315%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.156 Acc 95.277%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.158 Acc 95.228%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.258 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.214 Acc 95.297%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.201 Acc 95.530%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.148 Acc 95.575%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.152 Acc 95.522%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.155 Acc 95.398%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.156 Acc 95.350%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.159 Acc 95.302%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.242 Acc 94.446%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.230 Acc 94.613%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.146 Acc 95.514%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.155 Acc 95.305%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.156 Acc 95.328%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.156 Acc 95.363%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.156 Acc 95.359%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.229 Acc 92.969%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.210 Acc 95.382%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.198 Acc 95.616%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.156 Acc 95.235%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.159 Acc 95.237%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.158 Acc 95.256%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.158 Acc 95.199%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.215 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.266 Acc 94.980%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.250 Acc 95.165%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.154 Acc 95.173%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.153 Acc 95.246%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.155 Acc 95.300%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.156 Acc 95.299%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.157 Acc 95.263%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.234 Acc 94.616%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.218 Acc 94.955%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.197 Acc 91.406%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.154 Acc 95.537%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.150 Acc 95.534%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.152 Acc 95.473%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.153 Acc 95.359%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.156 Acc 95.228%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.216 Acc 94.918%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.204 Acc 95.099%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.154 Acc 95.521%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.148 Acc 95.546%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.152 Acc 95.406%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.155 Acc 95.377%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.157 Acc 95.334%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.224 Acc 95.104%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.216 Acc 95.184%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.212 Acc 94.531%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.151 Acc 95.289%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.152 Acc 95.188%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.153 Acc 95.206%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.154 Acc 95.201%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.156 Acc 95.211%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.254 Acc 92.188%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.251 Acc 94.903%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.240 Acc 95.134%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.157 Acc 95.119%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.152 Acc 95.340%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.151 Acc 95.388%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.152 Acc 95.404%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.152 Acc 95.431%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.218 Acc 95.227%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.210 Acc 95.235%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.150 Acc 95.545%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.151 Acc 95.440%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.153 Acc 95.371%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.154 Acc 95.344%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.231 Acc 96.875%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.218 Acc 95.328%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.204 Acc 95.515%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.152 Acc 95.243%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.153 Acc 95.239%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.153 Acc 95.263%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.156 Acc 95.244%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.154 Acc 95.288%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.261 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.236 Acc 95.119%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.225 Acc 95.390%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.144 Acc 95.483%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.146 Acc 95.542%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.152 Acc 95.292%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.154 Acc 95.217%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.158 Acc 95.122%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.217 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.219 Acc 95.181%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.209 Acc 95.223%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.141 Acc 95.560%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.154 Acc 95.307%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.152 Acc 95.363%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.154 Acc 95.319%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.319 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.241 Acc 95.405%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.227 Acc 95.499%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.150 Acc 95.591%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.157 Acc 95.367%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.155 Acc 95.371%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.153 Acc 95.417%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.269 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.231 Acc 95.282%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.218 Acc 95.410%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.152 Acc 95.490%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.150 Acc 95.480%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.150 Acc 95.455%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.153 Acc 95.338%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.153 Acc 95.337%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.243 Acc 92.969%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.227 Acc 95.135%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.216 Acc 95.266%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.148 Acc 95.421%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.150 Acc 95.455%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.151 Acc 95.449%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.151 Acc 95.453%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.232 Acc 95.127%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.216 Acc 95.394%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.142 Acc 95.583%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.147 Acc 95.522%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.148 Acc 95.510%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.151 Acc 95.476%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.152 Acc 95.423%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.226 Acc 95.189%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.213 Acc 95.312%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.167 Acc 95.235%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.159 Acc 95.452%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.157 Acc 95.411%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.156 Acc 95.377%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.156 Acc 95.298%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.223 Acc 94.972%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.215 Acc 95.044%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.195 Acc 95.312%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.146 Acc 95.367%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.151 Acc 95.386%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.151 Acc 95.385%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.152 Acc 95.403%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.212 Acc 94.949%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.205 Acc 95.025%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.147 Acc 95.436%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.148 Acc 95.507%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.154 Acc 95.388%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.155 Acc 95.363%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.155 Acc 95.320%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.220 Acc 95.305%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.208 Acc 95.367%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.290 Acc 89.062%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.143 Acc 95.661%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.150 Acc 95.464%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.153 Acc 95.396%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.153 Acc 95.400%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.154 Acc 95.387%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.233 Acc 95.034%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.220 Acc 95.227%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.145 Acc 95.722%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.152 Acc 95.398%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.154 Acc 95.320%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.153 Acc 95.307%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.156 Acc 95.233%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.224 Acc 95.367%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.214 Acc 95.464%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.148 Acc 95.452%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.152 Acc 95.382%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.151 Acc 95.427%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.154 Acc 95.363%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.153 Acc 95.361%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.211 Acc 95.150%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.199 Acc 95.351%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.137 Acc 95.568%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.144 Acc 95.441%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.145 Acc 95.476%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.150 Acc 95.361%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.152 Acc 95.314%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.246 Acc 90.625%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.213 Acc 95.050%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.204 Acc 95.180%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.173 Acc 93.750%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.142 Acc 95.753%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.145 Acc 95.585%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.147 Acc 95.538%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.150 Acc 95.424%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.151 Acc 95.434%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.223 Acc 93.750%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.220 Acc 95.297%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.210 Acc 95.305%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.124 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.148 Acc 95.459%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.147 Acc 95.456%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.149 Acc 95.409%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.149 Acc 95.412%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.148 Acc 95.454%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.327 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.212 Acc 95.258%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.205 Acc 95.386%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.161 Acc 95.243%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.155 Acc 95.250%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.153 Acc 95.307%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.154 Acc 95.277%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.156 Acc 95.186%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.225 Acc 95.413%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.213 Acc 95.631%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.144 Acc 95.529%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.147 Acc 95.425%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.153 Acc 95.305%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.149 Acc 95.357%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.150 Acc 95.386%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.229 Acc 94.848%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.217 Acc 94.920%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.151 Acc 95.498%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.156 Acc 95.332%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.153 Acc 95.357%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.151 Acc 95.406%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.152 Acc 95.395%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.236 Acc 95.073%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.228 Acc 95.180%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.148 Acc 95.445%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.144 Acc 95.541%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.147 Acc 95.496%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.148 Acc 95.479%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.250 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.227 Acc 95.080%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.218 Acc 95.239%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.150 Acc 95.390%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.152 Acc 95.287%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.153 Acc 95.235%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.151 Acc 95.334%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.253 Acc 92.969%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.271 Acc 94.346%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.261 Acc 94.446%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.233 Acc 92.969%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.141 Acc 95.591%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.145 Acc 95.596%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.147 Acc 95.551%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.149 Acc 95.498%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.150 Acc 95.437%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.316 Acc 91.406%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.241 Acc 95.390%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.230 Acc 95.394%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.189 Acc 93.750%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.156 Acc 95.042%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.151 Acc 95.301%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.148 Acc 95.424%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.149 Acc 95.400%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.152 Acc 95.322%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.253 Acc 94.918%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.242 Acc 94.920%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.148 Acc 95.398%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.147 Acc 95.406%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.152 Acc 95.393%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.151 Acc 95.422%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.151 Acc 95.409%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.179 Acc 96.875%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.211 Acc 95.429%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.203 Acc 95.460%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.257 Acc 92.188%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.151 Acc 95.436%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.148 Acc 95.449%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.148 Acc 95.463%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.151 Acc 95.373%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.153 Acc 95.328%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.230 Acc 95.104%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.220 Acc 95.254%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.150 Acc 95.436%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.148 Acc 95.445%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.150 Acc 95.429%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.152 Acc 95.396%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.151 Acc 95.401%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.311 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.228 Acc 95.196%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.218 Acc 95.274%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.139 Acc 95.769%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.139 Acc 95.763%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.145 Acc 95.616%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.146 Acc 95.515%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.147 Acc 95.498%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.267 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.233 Acc 95.552%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.220 Acc 95.725%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.138 Acc 95.769%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.146 Acc 95.491%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.146 Acc 95.471%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.146 Acc 95.500%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.149 Acc 95.443%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.313 Acc 92.188%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.253 Acc 94.972%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.241 Acc 95.145%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.129 Acc 95.815%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.141 Acc 95.530%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.144 Acc 95.492%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.146 Acc 95.503%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.147 Acc 95.459%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.272 Acc 90.625%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.232 Acc 95.011%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.215 Acc 95.188%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.206 Acc 92.969%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.155 Acc 94.988%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.156 Acc 95.200%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.155 Acc 95.235%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.152 Acc 95.324%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.153 Acc 95.319%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.301 Acc 91.406%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.258 Acc 94.872%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.244 Acc 94.959%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.142 Acc 95.653%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.147 Acc 95.449%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.154 Acc 95.285%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.153 Acc 95.328%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.274 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.218 Acc 95.204%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.209 Acc 95.285%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.134 Acc 95.715%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.140 Acc 95.655%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.146 Acc 95.453%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.147 Acc 95.427%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.150 Acc 95.367%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.328 Acc 91.406%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.237 Acc 94.918%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.220 Acc 95.072%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.137 Acc 95.862%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.139 Acc 95.826%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.142 Acc 95.668%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.144 Acc 95.642%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.144 Acc 95.587%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.238 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.233 Acc 95.227%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.221 Acc 95.367%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.138 Acc 95.761%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.138 Acc 95.658%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.146 Acc 95.518%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.148 Acc 95.463%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.150 Acc 95.406%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.286 Acc 93.750%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.231 Acc 95.080%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.218 Acc 95.258%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.398 Acc 92.188%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.149 Acc 95.374%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.147 Acc 95.519%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.146 Acc 95.523%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.148 Acc 95.490%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.146 Acc 95.504%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.226 Acc 95.065%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.214 Acc 95.250%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.144 Acc 95.715%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.142 Acc 95.693%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.142 Acc 95.614%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.146 Acc 95.476%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.148 Acc 95.420%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.256 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.225 Acc 95.282%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.216 Acc 95.332%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.143 Acc 93.750%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.146 Acc 95.413%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.146 Acc 95.484%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.143 Acc 95.588%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.148 Acc 95.519%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.149 Acc 95.512%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.229 Acc 95.289%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.218 Acc 95.367%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.149 Acc 95.575%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.145 Acc 95.651%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.145 Acc 95.598%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.145 Acc 95.603%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.146 Acc 95.595%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.258 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.212 Acc 95.467%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.487%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.146 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.141 Acc 95.552%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.139 Acc 95.647%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.141 Acc 95.712%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.144 Acc 95.603%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.145 Acc 95.613%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.244 Acc 94.972%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.236 Acc 95.138%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.151 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.148 Acc 95.444%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.150 Acc 95.328%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.145 Acc 95.523%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.149 Acc 95.461%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.149 Acc 95.451%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.251 Acc 93.750%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.226 Acc 94.957%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.217 Acc 95.103%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.154 Acc 95.390%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.154 Acc 95.301%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.150 Acc 95.401%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.150 Acc 95.422%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.150 Acc 95.406%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.258 Acc 95.243%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.240 Acc 95.347%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.207 Acc 96.094%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.130 Acc 96.024%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.139 Acc 95.771%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.141 Acc 95.681%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.143 Acc 95.675%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.145 Acc 95.613%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.247 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.237 Acc 95.073%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.227 Acc 95.250%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.265 Acc 92.969%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.140 Acc 95.637%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.146 Acc 95.445%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.144 Acc 95.520%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.146 Acc 95.494%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.148 Acc 95.428%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.228 Acc 95.166%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.215 Acc 95.355%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.147 Acc 95.374%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.148 Acc 95.402%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.147 Acc 95.401%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.147 Acc 95.443%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.146 Acc 95.481%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.277 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.231 Acc 95.328%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.220 Acc 95.487%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.137 Acc 95.753%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.145 Acc 95.530%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.149 Acc 95.440%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.150 Acc 95.402%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.150 Acc 95.439%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.282 Acc 92.188%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.252 Acc 94.609%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.238 Acc 94.799%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.148 Acc 95.490%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.149 Acc 95.394%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.146 Acc 95.531%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.147 Acc 95.492%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.147 Acc 95.458%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.235 Acc 94.864%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.223 Acc 95.040%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.128 Acc 93.750%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.143 Acc 95.490%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.142 Acc 95.526%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.143 Acc 95.582%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.145 Acc 95.490%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.146 Acc 95.470%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.230 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.230 Acc 95.398%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.215 Acc 95.620%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.129 Acc 94.531%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.141 Acc 95.452%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.140 Acc 95.608%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.146 Acc 95.486%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.147 Acc 95.433%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.148 Acc 95.451%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.286 Acc 92.969%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.267 Acc 94.663%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.252 Acc 94.819%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.138 Acc 95.676%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.142 Acc 95.623%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.144 Acc 95.593%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.144 Acc 95.605%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.145 Acc 95.578%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.285 Acc 93.750%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.253 Acc 94.964%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.245 Acc 95.002%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.134 Acc 95.769%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.136 Acc 95.756%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.138 Acc 95.730%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.141 Acc 95.618%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.145 Acc 95.514%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.224 Acc 94.670%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.215 Acc 94.885%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.135 Acc 95.993%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.145 Acc 95.655%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.146 Acc 95.554%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.146 Acc 95.484%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.148 Acc 95.428%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.218 Acc 95.413%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.206 Acc 95.402%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.145 Acc 95.622%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.145 Acc 95.581%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.148 Acc 95.554%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.146 Acc 95.576%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.148 Acc 95.528%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.252 Acc 92.188%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.253 Acc 94.841%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.239 Acc 94.881%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.138 Acc 95.761%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.145 Acc 95.468%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.145 Acc 95.440%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.147 Acc 95.439%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.147 Acc 95.423%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.267 Acc 94.864%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.253 Acc 95.138%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.132 Acc 95.815%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.141 Acc 95.585%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.144 Acc 95.489%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.145 Acc 95.463%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.146 Acc 95.420%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.253 Acc 94.531%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.229 Acc 95.297%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.222 Acc 95.281%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.142 Acc 95.645%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.141 Acc 95.623%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.144 Acc 95.523%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.146 Acc 95.470%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.145 Acc 95.498%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.271 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.236 Acc 95.150%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.226 Acc 95.281%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.100 Acc 95.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.131 Acc 95.738%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.136 Acc 95.728%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.144 Acc 95.535%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.147 Acc 95.443%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.263 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.220 Acc 95.266%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.208 Acc 95.437%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.134 Acc 95.939%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.139 Acc 95.861%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.143 Acc 95.665%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.147 Acc 95.521%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.146 Acc 95.512%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.231 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.211 Acc 95.212%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.199 Acc 95.460%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.264 Acc 90.625%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.142 Acc 95.661%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.144 Acc 95.596%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.144 Acc 95.601%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.147 Acc 95.496%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.146 Acc 95.531%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.307 Acc 92.969%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.254 Acc 94.756%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.245 Acc 94.924%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.145 Acc 95.452%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.143 Acc 95.616%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.146 Acc 95.590%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.147 Acc 95.523%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.145 Acc 95.520%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.323 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.233 Acc 94.802%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.225 Acc 94.924%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.138 Acc 95.591%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.142 Acc 95.577%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.144 Acc 95.479%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.144 Acc 95.488%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.145 Acc 95.489%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.287 Acc 92.969%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.250 Acc 95.104%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.239 Acc 95.355%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.241 Acc 94.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.146 Acc 95.537%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.149 Acc 95.371%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.146 Acc 95.476%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.144 Acc 95.509%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.145 Acc 95.521%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.235 Acc 94.841%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.229 Acc 94.998%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.155 Acc 95.258%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.145 Acc 95.495%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.146 Acc 95.479%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.147 Acc 95.478%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.146 Acc 95.515%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.337 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.248 Acc 95.111%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.236 Acc 95.153%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.139 Acc 95.645%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.137 Acc 95.744%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.140 Acc 95.686%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.143 Acc 95.640%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.142 Acc 95.623%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.253 Acc 92.188%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.230 Acc 94.864%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.217 Acc 94.986%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.147 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.139 Acc 95.715%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.138 Acc 95.759%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.139 Acc 95.767%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.139 Acc 95.735%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.140 Acc 95.705%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.252 Acc 93.750%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.259 Acc 94.895%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.245 Acc 94.986%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.140 Acc 95.777%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.146 Acc 95.530%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.148 Acc 95.437%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.146 Acc 95.449%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.147 Acc 95.439%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.245 Acc 94.980%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.238 Acc 95.002%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.133 Acc 96.875%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.149 Acc 95.150%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.144 Acc 95.246%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.146 Acc 95.266%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.145 Acc 95.348%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.146 Acc 95.367%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.251 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.264 Acc 94.717%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.252 Acc 94.796%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.138 Acc 95.436%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.144 Acc 95.367%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.142 Acc 95.471%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.143 Acc 95.463%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.142 Acc 95.537%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.305 Acc 94.531%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.237 Acc 95.258%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.228 Acc 95.449%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.153 Acc 94.531%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.143 Acc 95.459%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.138 Acc 95.573%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.144 Acc 95.463%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.143 Acc 95.474%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.143 Acc 95.481%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.278 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.245 Acc 95.181%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.232 Acc 95.235%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.141 Acc 92.188%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.150 Acc 95.351%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.146 Acc 95.526%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.142 Acc 95.653%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.143 Acc 95.587%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.144 Acc 95.556%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.240 Acc 93.750%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.229 Acc 95.251%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.213 Acc 95.507%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.132 Acc 95.962%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.132 Acc 95.896%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.139 Acc 95.668%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.142 Acc 95.626%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.144 Acc 95.607%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.237 Acc 95.227%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.223 Acc 95.363%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.179 Acc 96.094%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.132 Acc 95.939%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.136 Acc 95.849%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.143 Acc 95.653%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.146 Acc 95.546%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.147 Acc 95.534%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.265 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.243 Acc 95.019%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.226 Acc 95.211%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.135 Acc 95.846%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.142 Acc 95.647%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.142 Acc 95.567%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.142 Acc 95.550%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.144 Acc 95.498%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.195 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.244 Acc 95.034%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.232 Acc 95.196%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.272 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.136 Acc 95.614%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.137 Acc 95.767%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.137 Acc 95.790%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.139 Acc 95.718%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.140 Acc 95.712%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.255 Acc 94.802%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.243 Acc 94.834%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.141 Acc 95.728%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.140 Acc 95.751%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.141 Acc 95.679%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.140 Acc 95.715%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.251 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.254 Acc 95.382%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.239 Acc 95.491%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd442e70148474499c761bba69a6c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.355 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.219 Acc 19.601%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.057 Acc 25.610%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.875 Acc 32.254%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.691 Acc 39.955%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.522 Acc 47.006%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.546 Acc 85.938%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.550 Acc 83.601%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.541 Acc 83.835%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.623 Acc 82.812%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.583 Acc 82.689%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.536 Acc 84.227%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.512 Acc 84.892%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.489 Acc 85.622%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.471 Acc 86.093%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.375 Acc 85.938%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.357 Acc 89.264%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.355 Acc 89.199%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.459 Acc 87.500%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.377 Acc 88.591%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.362 Acc 89.043%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.358 Acc 89.239%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.356 Acc 89.238%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.354 Acc 89.370%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.362 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.353 Acc 88.962%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.345 Acc 89.300%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.326 Acc 89.062%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.325 Acc 90.037%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.312 Acc 90.629%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.312 Acc 90.604%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.313 Acc 90.594%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.311 Acc 90.662%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.337 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.291 Acc 91.399%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.285 Acc 91.500%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.310 Acc 92.969%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.300 Acc 91.205%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.297 Acc 91.266%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.292 Acc 91.365%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.290 Acc 91.414%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.287 Acc 91.466%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.288 Acc 92.188%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.274 Acc 91.917%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.275 Acc 91.954%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.329 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.265 Acc 92.048%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.266 Acc 91.880%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.266 Acc 91.969%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.270 Acc 91.870%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.269 Acc 91.913%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.320 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.250 Acc 92.930%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.241 Acc 93.167%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.225 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.257 Acc 92.311%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.255 Acc 92.390%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.255 Acc 92.343%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.256 Acc 92.330%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.257 Acc 92.312%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.288 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.252 Acc 92.791%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.245 Acc 92.953%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.248 Acc 92.342%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.251 Acc 92.327%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.248 Acc 92.517%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.248 Acc 92.643%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.248 Acc 92.646%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.236 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.228 Acc 93.588%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.224 Acc 93.610%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.355 Acc 88.281%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.235 Acc 92.721%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.240 Acc 92.833%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.239 Acc 92.834%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.241 Acc 92.747%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.242 Acc 92.785%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.281 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.203 Acc 94.268%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.202 Acc 94.457%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.187 Acc 95.312%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.235 Acc 93.108%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.238 Acc 92.957%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.240 Acc 92.990%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.239 Acc 93.025%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.236 Acc 93.079%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.176 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.191 Acc 94.756%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.186 Acc 94.862%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.274 Acc 93.750%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.218 Acc 93.619%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.222 Acc 93.575%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.229 Acc 93.317%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.231 Acc 93.236%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.227 Acc 93.312%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.301 Acc 90.625%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.220 Acc 93.959%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.216 Acc 93.995%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.227 Acc 93.278%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.224 Acc 93.334%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.222 Acc 93.410%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.222 Acc 93.415%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.222 Acc 93.410%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.167 Acc 92.969%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.196 Acc 94.701%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.189 Acc 94.877%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.186 Acc 96.094%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.219 Acc 93.773%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.218 Acc 93.591%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.218 Acc 93.633%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.219 Acc 93.596%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.217 Acc 93.617%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.202 Acc 94.462%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.197 Acc 94.605%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.209 Acc 93.928%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.211 Acc 93.820%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.210 Acc 93.815%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.212 Acc 93.816%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.215 Acc 93.752%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.213 Acc 94.152%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.209 Acc 94.267%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.314 Acc 92.188%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.200 Acc 93.881%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.207 Acc 93.804%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.209 Acc 93.755%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.208 Acc 93.832%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.208 Acc 93.876%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.245 Acc 92.188%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.189 Acc 94.694%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.183 Acc 94.928%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.094 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.207 Acc 93.796%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.208 Acc 93.882%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.205 Acc 94.015%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.206 Acc 93.970%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.205 Acc 93.984%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.204 Acc 94.330%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.203 Acc 94.255%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.193 Acc 94.446%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.198 Acc 94.302%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.201 Acc 94.163%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.202 Acc 94.107%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.203 Acc 94.110%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.233 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.188 Acc 94.988%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.186 Acc 95.048%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.207 Acc 91.406%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.204 Acc 93.998%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.201 Acc 94.197%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.197 Acc 94.324%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.197 Acc 94.218%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.198 Acc 94.205%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.206 Acc 93.750%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.198 Acc 94.825%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.192 Acc 94.939%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.181 Acc 94.686%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.190 Acc 94.403%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.193 Acc 94.339%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.193 Acc 94.344%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.195 Acc 94.343%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.179 Acc 95.227%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.174 Acc 95.359%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.244 Acc 92.188%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.192 Acc 94.407%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.191 Acc 94.465%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.191 Acc 94.459%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.193 Acc 94.424%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.195 Acc 94.325%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.195 Acc 94.469%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.188 Acc 94.698%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.326 Acc 92.969%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.187 Acc 94.709%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.193 Acc 94.504%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.189 Acc 94.586%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.191 Acc 94.518%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.191 Acc 94.486%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.191 Acc 94.810%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.187 Acc 94.974%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.178 Acc 94.957%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.181 Acc 94.761%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.187 Acc 94.570%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.188 Acc 94.533%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.190 Acc 94.488%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.152 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.167 Acc 95.583%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.163 Acc 95.658%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.227 Acc 92.188%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.180 Acc 94.949%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.185 Acc 94.687%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.184 Acc 94.677%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.183 Acc 94.677%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.182 Acc 94.721%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.174 Acc 95.382%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.168 Acc 95.515%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.287 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.181 Acc 94.725%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.175 Acc 94.904%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.176 Acc 94.884%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.182 Acc 94.672%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.182 Acc 94.714%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.229 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.170 Acc 95.506%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.168 Acc 95.639%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.179 Acc 94.841%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.176 Acc 95.040%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.177 Acc 94.928%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.180 Acc 94.823%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.181 Acc 94.834%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.171 Acc 95.359%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.165 Acc 95.596%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.184 Acc 94.701%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.173 Acc 94.970%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.173 Acc 94.944%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.175 Acc 94.864%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.175 Acc 94.898%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.204 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.174 Acc 95.243%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.167 Acc 95.503%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.161 Acc 97.656%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.180 Acc 94.686%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.177 Acc 94.846%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.179 Acc 94.830%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.179 Acc 94.866%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.177 Acc 94.909%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.185 Acc 95.282%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.402%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.199 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.180 Acc 94.794%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.175 Acc 95.130%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.176 Acc 95.045%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.173 Acc 95.094%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.173 Acc 95.072%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.182 Acc 95.251%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.192 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.171 Acc 94.941%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.172 Acc 94.877%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.172 Acc 94.996%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.173 Acc 94.962%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.172 Acc 95.013%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.172 Acc 95.467%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.201 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.165 Acc 95.452%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.171 Acc 95.184%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.172 Acc 95.056%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.174 Acc 95.003%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.173 Acc 95.046%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.171 Acc 95.483%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.164 Acc 95.756%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.164 Acc 93.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.168 Acc 95.297%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.163 Acc 95.340%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.164 Acc 95.385%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.167 Acc 95.221%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.168 Acc 95.216%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.180 Acc 95.405%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.173 Acc 95.546%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.162 Acc 95.359%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.163 Acc 95.208%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.167 Acc 95.120%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.168 Acc 95.094%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.168 Acc 95.082%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.168 Acc 95.529%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.162 Acc 95.717%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.148 Acc 95.769%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.153 Acc 95.600%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.158 Acc 95.486%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.163 Acc 95.383%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.165 Acc 95.323%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.177 Acc 95.429%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.171 Acc 95.464%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.157 Acc 95.425%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.164 Acc 95.281%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.244%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.164 Acc 95.288%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.170 Acc 95.467%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.164 Acc 95.627%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.157 Acc 95.402%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.159 Acc 95.427%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.160 Acc 95.411%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.171 Acc 95.498%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.169 Acc 95.507%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.170 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.155 Acc 95.846%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.155 Acc 95.771%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.162 Acc 95.512%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.160 Acc 95.511%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.159 Acc 95.475%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.125 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.175 Acc 95.467%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.148 Acc 95.622%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.160 Acc 95.292%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.162 Acc 95.246%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.160 Acc 95.292%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.363%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.226 Acc 92.969%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.141 Acc 95.823%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.149 Acc 95.639%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.155 Acc 95.515%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.155 Acc 95.540%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.156 Acc 95.546%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.146 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.168 Acc 95.583%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.164 Acc 95.775%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.149 Acc 95.599%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.157 Acc 95.414%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.154 Acc 95.492%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.155 Acc 95.468%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.155 Acc 95.436%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.170 Acc 95.637%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.164 Acc 95.697%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.197 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.149 Acc 95.877%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.151 Acc 95.562%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.152 Acc 95.531%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.154 Acc 95.534%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.194 Acc 91.406%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.175 Acc 95.459%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.168 Acc 95.639%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.074 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.160 Acc 95.483%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.159 Acc 95.410%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.153 Acc 95.572%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.155 Acc 95.548%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.155 Acc 95.501%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.162 Acc 95.746%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.157 Acc 95.993%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.189 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.149 Acc 95.877%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.156 Acc 95.705%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.154 Acc 95.624%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.155 Acc 95.665%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.153 Acc 95.670%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.170 Acc 95.575%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.162 Acc 95.756%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.151 Acc 95.815%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.147 Acc 95.899%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.147 Acc 95.891%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.150 Acc 95.766%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.150 Acc 95.766%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.240 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.173 Acc 95.715%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.167 Acc 95.845%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.142 Acc 95.908%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.149 Acc 95.736%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.148 Acc 95.746%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.149 Acc 95.704%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.150 Acc 95.702%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.171 Acc 95.467%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.167 Acc 95.585%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.144 Acc 95.630%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.144 Acc 95.814%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.147 Acc 95.761%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.148 Acc 95.721%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.169 Acc 95.653%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.163 Acc 95.802%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.147 Acc 95.924%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.148 Acc 95.818%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.148 Acc 95.803%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.149 Acc 95.835%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.149 Acc 95.762%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.160 Acc 95.838%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.157 Acc 95.934%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.133 Acc 96.156%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.138 Acc 96.000%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.140 Acc 95.967%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.143 Acc 95.829%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.146 Acc 95.774%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.180 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.166 Acc 95.831%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.163 Acc 95.853%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.144 Acc 95.864%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.147 Acc 95.860%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.144 Acc 95.879%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.145 Acc 95.838%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.113 Acc 94.531%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.161 Acc 95.792%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.156 Acc 96.032%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.144 Acc 95.970%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.145 Acc 95.837%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.146 Acc 95.808%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.144 Acc 95.876%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.144 Acc 95.821%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.167 Acc 95.777%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.163 Acc 95.845%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.135 Acc 96.071%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.138 Acc 95.997%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.139 Acc 95.972%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.141 Acc 95.926%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.143 Acc 95.894%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.170 Acc 95.753%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.166 Acc 95.899%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.136 Acc 95.939%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.139 Acc 96.004%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.139 Acc 96.024%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.139 Acc 95.955%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.178 Acc 95.374%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.171 Acc 95.460%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.129 Acc 96.395%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.130 Acc 96.393%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.137 Acc 96.174%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.140 Acc 96.020%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.140 Acc 95.958%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.161 Acc 95.893%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.157 Acc 96.028%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.137 Acc 95.972%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.137 Acc 95.963%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.140 Acc 95.913%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.170 Acc 95.568%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.165 Acc 95.732%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.134 Acc 96.016%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.138 Acc 96.043%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.138 Acc 96.029%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.138 Acc 95.977%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.137 Acc 95.986%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.166 Acc 95.862%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.162 Acc 95.903%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.122 Acc 96.550%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.131 Acc 96.172%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.135 Acc 96.061%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.137 Acc 96.013%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.167 Acc 95.808%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.162 Acc 95.880%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.159 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.136 Acc 96.132%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.138 Acc 95.948%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.139 Acc 95.983%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.138 Acc 96.013%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.167 Acc 95.916%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.162 Acc 96.024%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.256 Acc 96.094%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.129 Acc 96.542%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.129 Acc 96.339%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.132 Acc 96.199%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.133 Acc 96.181%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.164 Acc 95.900%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.159 Acc 95.993%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.139 Acc 95.924%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.131 Acc 96.151%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.131 Acc 96.150%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.131 Acc 96.123%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.171 Acc 95.738%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.775%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.131 Acc 96.253%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.131 Acc 96.226%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.132 Acc 96.218%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.134 Acc 96.155%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.162 Acc 95.815%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.158 Acc 96.020%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.126 Acc 96.527%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.127 Acc 96.374%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.129 Acc 96.237%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.131 Acc 96.168%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.132 Acc 96.125%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.167 Acc 95.761%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.163 Acc 95.934%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.120 Acc 96.612%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.122 Acc 96.471%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.124 Acc 96.416%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.126 Acc 96.347%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.130 Acc 96.267%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.305%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.178 Acc 95.410%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.128 Acc 96.187%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.130 Acc 96.098%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.133 Acc 96.045%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.133 Acc 96.067%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.164 Acc 95.877%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.161 Acc 95.985%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.127 Acc 93.750%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.131 Acc 96.248%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.126 Acc 96.319%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.128 Acc 96.234%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.128 Acc 96.203%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.129 Acc 96.195%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.157 Acc 96.163%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.154 Acc 96.226%\n",
      "Saving..\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.115 Acc 96.782%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.121 Acc 96.657%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.123 Acc 96.574%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.126 Acc 96.480%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.127 Acc 96.409%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.174 Acc 95.676%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.168 Acc 95.802%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.110 Acc 98.438%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.122 Acc 96.519%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.123 Acc 96.502%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.124 Acc 96.356%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.127 Acc 96.291%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.127 Acc 96.296%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.134 Acc 97.656%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.168 Acc 95.931%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.126 Acc 96.295%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.126 Acc 96.311%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.124 Acc 96.379%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.286%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.104 Acc 96.875%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.162 Acc 96.001%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.161 Acc 96.067%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.125 Acc 96.381%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.128 Acc 96.356%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.127 Acc 96.285%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.128 Acc 96.254%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.178 Acc 95.599%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.172 Acc 95.682%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.115 Acc 96.682%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.115 Acc 96.653%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.119 Acc 96.543%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.124 Acc 96.376%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.168 Acc 95.738%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.164 Acc 95.919%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.109 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.122 Acc 96.411%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.124 Acc 96.471%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.125 Acc 96.343%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.126 Acc 96.308%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.126 Acc 96.334%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.178 Acc 95.753%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.752%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.120 Acc 96.357%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.119 Acc 96.389%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.119 Acc 96.418%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.122 Acc 96.355%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.125 Acc 96.307%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.172 Acc 95.746%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.166 Acc 95.880%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.103 Acc 94.531%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.133 Acc 96.009%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.124 Acc 96.346%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.123 Acc 96.394%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.126 Acc 96.326%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.172 Acc 95.748%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.114 Acc 96.697%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.114 Acc 96.685%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.116 Acc 96.626%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.117 Acc 96.542%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.118 Acc 96.510%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.134 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.176 Acc 95.552%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.171 Acc 95.721%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.115 Acc 96.581%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.118 Acc 96.486%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.121 Acc 96.384%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.122 Acc 96.399%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.167 Acc 95.837%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.108 Acc 96.867%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.110 Acc 96.782%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.113 Acc 96.701%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.116 Acc 96.668%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.119 Acc 96.579%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.172 Acc 95.955%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.114 Acc 96.716%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.117 Acc 96.649%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.118 Acc 96.604%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.120 Acc 96.526%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.761%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.169 Acc 95.810%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.114 Acc 96.813%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.115 Acc 96.743%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.118 Acc 96.621%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.118 Acc 96.614%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.119 Acc 96.530%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.086 Acc 97.656%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.167 Acc 95.838%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.162 Acc 95.997%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.212 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.115 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.114 Acc 96.618%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.116 Acc 96.584%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.117 Acc 96.544%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.118 Acc 96.540%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.156 Acc 96.248%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.153 Acc 96.343%\n",
      "Saving..\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.110 Acc 96.744%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.113 Acc 96.704%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.114 Acc 96.696%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.114 Acc 96.670%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.115 Acc 96.636%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.168 Acc 95.777%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.164 Acc 95.911%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.161 Acc 95.312%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.118 Acc 96.434%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.117 Acc 96.486%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.117 Acc 96.506%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.118 Acc 96.516%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.164 Acc 95.931%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.162 Acc 95.969%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.117 Acc 96.589%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.113 Acc 96.735%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.114 Acc 96.717%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.114 Acc 96.698%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.115 Acc 96.619%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.171 Acc 95.777%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.896%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.126 Acc 93.750%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.112 Acc 96.697%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.111 Acc 96.797%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.112 Acc 96.645%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.114 Acc 96.593%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.075 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.161 Acc 96.070%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.107 Acc 96.770%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.109 Acc 96.670%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.606%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.114 Acc 96.568%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.101 Acc 97.656%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.171 Acc 95.767%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.108 Acc 96.852%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.110 Acc 96.800%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.111 Acc 96.709%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.115 Acc 96.613%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.170 Acc 95.854%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.165 Acc 96.000%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.161 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.100 Acc 97.107%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.109 Acc 96.848%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.112 Acc 96.727%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.114 Acc 96.647%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.114 Acc 96.666%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.161 Acc 95.993%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.160 Acc 96.035%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.145 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.108 Acc 96.744%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.109 Acc 96.832%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.107 Acc 96.836%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.112 Acc 96.716%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.170 Acc 96.009%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.164 Acc 96.082%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.114 Acc 96.364%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.118 Acc 96.447%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.119 Acc 96.447%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.118 Acc 96.439%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.117 Acc 96.470%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.169 Acc 95.800%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.166 Acc 95.880%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.031 Acc 100.000%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.104 Acc 96.728%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.108 Acc 96.751%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.110 Acc 96.667%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.112 Acc 96.631%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.113 Acc 96.594%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.167 Acc 96.071%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.163 Acc 96.210%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.069 Acc 99.219%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.104 Acc 96.960%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.110 Acc 96.727%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.113 Acc 96.614%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.115 Acc 96.576%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.177 Acc 95.753%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.170 Acc 95.899%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.231 Acc 93.750%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.102 Acc 96.952%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.103 Acc 96.949%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.103 Acc 96.927%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.108 Acc 96.764%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.110 Acc 96.683%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.174 Acc 95.684%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.170 Acc 95.845%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.102 Acc 96.736%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.108 Acc 96.771%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.108 Acc 96.780%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.107 Acc 96.824%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.172 Acc 95.903%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.146 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.105 Acc 96.759%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.102 Acc 96.840%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.105 Acc 96.828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.107 Acc 96.768%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.108 Acc 96.718%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.172 Acc 95.815%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.166 Acc 95.969%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.104 Acc 96.689%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.105 Acc 96.786%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.105 Acc 96.787%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.107 Acc 96.799%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.108 Acc 96.750%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.178 Acc 95.429%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.095 Acc 97.146%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.106 Acc 96.863%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.107 Acc 96.805%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.091 Acc 96.875%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.169 Acc 95.831%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.165 Acc 96.059%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.098 Acc 97.045%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.100 Acc 96.961%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.106 Acc 96.820%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.107 Acc 96.811%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.175 Acc 95.924%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.168 Acc 95.969%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.075 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.100 Acc 97.045%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.099 Acc 97.100%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.101 Acc 97.039%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.103 Acc 97.021%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.106 Acc 96.905%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.171 Acc 95.985%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.167 Acc 96.020%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.099 Acc 97.061%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.102 Acc 97.042%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.104 Acc 97.015%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.102 Acc 96.996%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.103 Acc 96.990%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.086 Acc 97.656%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.173 Acc 95.831%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.167 Acc 96.020%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.104 Acc 96.976%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.102 Acc 97.054%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.103 Acc 97.018%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.103 Acc 96.984%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.105 Acc 96.887%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.170 Acc 95.919%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.102 Acc 96.860%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.103 Acc 96.856%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.104 Acc 96.839%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.104 Acc 96.857%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.105 Acc 96.852%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.171 Acc 96.001%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.166 Acc 96.113%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.105 Acc 96.929%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.102 Acc 96.968%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.103 Acc 96.889%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.104 Acc 96.847%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.181 Acc 95.846%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.179 Acc 95.771%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.106 Acc 96.960%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.103 Acc 96.941%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.107 Acc 96.810%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.104 Acc 96.894%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.104 Acc 96.902%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.175 Acc 95.838%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.172 Acc 95.919%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.100 Acc 97.192%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.104 Acc 96.941%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.104 Acc 96.883%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.102 Acc 96.928%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.173 Acc 95.916%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.169 Acc 96.047%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.098 Acc 97.099%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.099 Acc 97.072%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.101 Acc 97.035%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.102 Acc 97.009%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.166 Acc 96.063%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.161 Acc 96.148%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.098 Acc 97.061%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.098 Acc 97.030%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.099 Acc 97.005%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.100 Acc 96.972%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.101 Acc 96.956%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.869%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 95.942%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.100 Acc 97.076%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.101 Acc 97.085%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.099 Acc 97.127%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.102 Acc 97.021%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.103 Acc 96.955%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.071 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.173 Acc 95.761%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.171 Acc 95.779%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.093 Acc 97.192%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.097 Acc 97.089%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.099 Acc 96.949%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.100 Acc 96.939%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.099 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.183 Acc 95.784%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.178 Acc 95.829%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.136 Acc 94.531%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.097 Acc 96.906%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.098 Acc 96.937%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.098 Acc 97.044%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.098 Acc 97.043%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [105/200]Batch [500/573] Loss: 0.100 Acc 97.026%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.179 Acc 95.792%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.173 Acc 95.892%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.105 Acc 96.929%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.104 Acc 96.867%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.101 Acc 96.898%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.101 Acc 96.916%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.101 Acc 96.958%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.175 Acc 95.893%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.170 Acc 95.896%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.095 Acc 97.092%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.096 Acc 97.046%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.098 Acc 97.013%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.099 Acc 97.007%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.098 Acc 96.995%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.160 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.180 Acc 95.537%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.176 Acc 95.682%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.100 Acc 97.022%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.095 Acc 97.112%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.097 Acc 97.067%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.098 Acc 97.048%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.100 Acc 96.978%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.173 Acc 95.877%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.169 Acc 95.907%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.103 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.099 Acc 97.014%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.097 Acc 97.030%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.097 Acc 97.059%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.167 Acc 95.993%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.059 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.096 Acc 97.269%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.097 Acc 97.178%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.099 Acc 97.075%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.097 Acc 97.105%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.098 Acc 97.048%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.170 Acc 95.893%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.167 Acc 96.035%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.128 Acc 97.656%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.090 Acc 97.161%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.097 Acc 96.992%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.097 Acc 97.046%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.098 Acc 97.034%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.166 Acc 95.893%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.162 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.091 Acc 97.200%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.092 Acc 97.201%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.097 Acc 97.041%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.097 Acc 97.019%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.098 Acc 96.953%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 96.047%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.167 Acc 96.148%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.089 Acc 97.208%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.091 Acc 97.190%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.093 Acc 97.111%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.094 Acc 97.142%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.095 Acc 97.132%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.171 Acc 95.985%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.047 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.096 Acc 97.068%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.095 Acc 97.213%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.095 Acc 97.137%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.097 Acc 97.048%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.098 Acc 97.029%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.076 Acc 98.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.181 Acc 95.885%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.174 Acc 96.125%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.090 Acc 97.316%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.091 Acc 97.233%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.092 Acc 97.155%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.093 Acc 97.136%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.094 Acc 97.142%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.104 Acc 97.656%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 96.001%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.171 Acc 96.059%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.095 Acc 96.988%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.095 Acc 96.992%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.096 Acc 96.992%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.095 Acc 97.037%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.167 Acc 95.985%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.165 Acc 96.074%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.175 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.093 Acc 97.169%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.094 Acc 97.120%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.097 Acc 97.035%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.097 Acc 97.067%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.097 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.176 Acc 95.970%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 96.109%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.092 Acc 97.161%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.088 Acc 97.236%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.092 Acc 97.199%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.092 Acc 97.208%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.093 Acc 97.153%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.172 Acc 95.872%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.091 Acc 97.262%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.094 Acc 97.182%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.096 Acc 97.051%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.095 Acc 97.082%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.093 Acc 97.162%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.168 Acc 96.163%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.165 Acc 96.276%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.089 Acc 97.316%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.093 Acc 97.173%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.092 Acc 97.181%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.094 Acc 97.137%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.178 Acc 95.746%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.175 Acc 95.962%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.090 Acc 97.223%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.092 Acc 97.229%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.091 Acc 97.259%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.092 Acc 97.202%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.100 Acc 96.875%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.180 Acc 95.947%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.175 Acc 95.981%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.093 Acc 97.061%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.093 Acc 97.135%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.094 Acc 97.113%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.094 Acc 97.089%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.176 Acc 96.001%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.096 Acc 97.107%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.094 Acc 97.124%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.092 Acc 97.176%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.091 Acc 97.210%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.093 Acc 97.181%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.181 Acc 95.761%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.176 Acc 95.923%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.086 Acc 97.215%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.089 Acc 97.135%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.091 Acc 97.103%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.093 Acc 97.076%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.095 Acc 97.059%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.091 Acc 97.656%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.171 Acc 96.063%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 96.133%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.086 Acc 97.347%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.087 Acc 97.318%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.090 Acc 97.244%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.092 Acc 97.198%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.092 Acc 97.210%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.169 Acc 96.194%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.164 Acc 96.253%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.085 Acc 97.355%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.090 Acc 97.229%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.091 Acc 97.202%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.091 Acc 97.157%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.090 Acc 97.207%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.069 Acc 98.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.182 Acc 95.916%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.178 Acc 95.911%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.088 Acc 97.246%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.086 Acc 97.322%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.090 Acc 97.185%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.090 Acc 97.163%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.072 Acc 97.656%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.178 Acc 95.900%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.173 Acc 95.993%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.088 Acc 97.334%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.088 Acc 97.262%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.088 Acc 97.339%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.088 Acc 97.280%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.072 Acc 96.875%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.173 Acc 95.885%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.171 Acc 95.973%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.090 Acc 97.246%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.085 Acc 97.314%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.086 Acc 97.321%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.087 Acc 97.304%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.089 Acc 97.245%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.079 Acc 96.875%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.172 Acc 96.179%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.168 Acc 96.148%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.088 Acc 97.169%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.084 Acc 97.330%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.087 Acc 97.244%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.086 Acc 97.350%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.088 Acc 97.298%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.176 Acc 95.838%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.176 Acc 95.791%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.117 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.083 Acc 97.269%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.086 Acc 97.381%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.086 Acc 97.370%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.088 Acc 97.305%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.185 Acc 95.692%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.086 Acc 97.509%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.089 Acc 97.384%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.092 Acc 97.205%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.090 Acc 97.232%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.091 Acc 97.212%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.185 Acc 95.769%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.183 Acc 95.818%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.085 Acc 97.200%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.087 Acc 97.306%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.087 Acc 97.282%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.088 Acc 97.270%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.179 Acc 95.962%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.174 Acc 96.016%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.085 Acc 97.370%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.089 Acc 97.252%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.089 Acc 97.272%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.090 Acc 97.263%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.089 Acc 97.285%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.176 Acc 95.978%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.173 Acc 96.082%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.091 Acc 97.190%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.089 Acc 97.246%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.089 Acc 97.204%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.087 Acc 97.260%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.178 Acc 95.738%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.177 Acc 95.845%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.080 Acc 97.757%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.084 Acc 97.540%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.086 Acc 97.464%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.089 Acc 97.374%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.088 Acc 97.374%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.178 Acc 95.792%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.176 Acc 95.938%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.086 Acc 97.463%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.085 Acc 97.509%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.086 Acc 97.410%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.086 Acc 97.399%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.086 Acc 97.390%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.180 Acc 95.722%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.175 Acc 95.911%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.083 Acc 97.404%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.083 Acc 97.392%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.085 Acc 97.378%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.086 Acc 97.344%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.181 Acc 95.947%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.176 Acc 96.020%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.077 Acc 97.641%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.078 Acc 97.590%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.081 Acc 97.534%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.082 Acc 97.504%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.085 Acc 97.422%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.177 Acc 95.900%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.173 Acc 96.039%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.084 Acc 97.379%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.084 Acc 97.368%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.086 Acc 97.326%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.178 Acc 95.947%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.175 Acc 96.070%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.080 Acc 97.401%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.082 Acc 97.404%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.084 Acc 97.319%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.087 Acc 97.270%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.086 Acc 97.301%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.170 Acc 95.931%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.171 Acc 96.020%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.080 Acc 97.525%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.082 Acc 97.497%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.085 Acc 97.373%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.084 Acc 97.346%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.085 Acc 97.354%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.178 Acc 95.947%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.177 Acc 95.954%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.082 Acc 97.512%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.084 Acc 97.456%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.084 Acc 97.422%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.085 Acc 97.352%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.183 Acc 95.777%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.177 Acc 95.907%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.076 Acc 97.587%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.076 Acc 97.571%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.079 Acc 97.501%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.080 Acc 97.485%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.082 Acc 97.422%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.062 Acc 98.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.180 Acc 95.969%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.082 Acc 97.540%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.084 Acc 97.386%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.084 Acc 97.291%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.189 Acc 95.599%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.183 Acc 95.767%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.097 Acc 95.312%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.071 Acc 97.780%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.076 Acc 97.625%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.080 Acc 97.545%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.082 Acc 97.461%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.083 Acc 97.394%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.076 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.181 Acc 95.761%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.173 Acc 96.055%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.076 Acc 97.633%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.079 Acc 97.621%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.079 Acc 97.581%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.081 Acc 97.526%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.082 Acc 97.418%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.187 Acc 95.746%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.181 Acc 95.849%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.068 Acc 97.826%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.075 Acc 97.610%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.078 Acc 97.529%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.080 Acc 97.483%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.081 Acc 97.463%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.174 Acc 96.163%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.170 Acc 96.261%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.122 Acc 94.531%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.078 Acc 97.447%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.078 Acc 97.547%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.079 Acc 97.552%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.082 Acc 97.483%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.083 Acc 97.425%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.862%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 95.954%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.082 Acc 97.439%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.084 Acc 97.335%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.185 Acc 95.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.180 Acc 95.787%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.071 Acc 96.094%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.085 Acc 97.269%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.078 Acc 97.540%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.079 Acc 97.555%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.080 Acc 97.502%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.080 Acc 97.488%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.085 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.174 Acc 96.040%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.168 Acc 96.199%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.076 Acc 97.649%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.081 Acc 97.493%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.081 Acc 97.513%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.081 Acc 97.485%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.083 Acc 97.436%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.184 Acc 95.846%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.179 Acc 96.051%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.092 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.080 Acc 97.517%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.078 Acc 97.524%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.079 Acc 97.477%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.081 Acc 97.422%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.081 Acc 97.438%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.065 Acc 97.656%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.184 Acc 95.993%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.179 Acc 96.074%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.131 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.086 Acc 97.308%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.079 Acc 97.512%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.077 Acc 97.594%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.081 Acc 97.487%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.082 Acc 97.455%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.187 Acc 95.800%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.958%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.077 Acc 97.486%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.078 Acc 97.526%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.079 Acc 97.481%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.079 Acc 97.468%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.159 Acc 96.875%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.189 Acc 95.846%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.183 Acc 96.016%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.078 Acc 97.560%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.079 Acc 97.508%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.181 Acc 95.722%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.176 Acc 95.954%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.075 Acc 97.826%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.075 Acc 97.699%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.076 Acc 97.620%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.079 Acc 97.534%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.079 Acc 97.522%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.089 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.189 Acc 95.908%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.185 Acc 95.954%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.116 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.073 Acc 97.579%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.076 Acc 97.470%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.079 Acc 97.419%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.080 Acc 97.380%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.080 Acc 96.875%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.183 Acc 95.854%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.179 Acc 95.876%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.070 Acc 97.780%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.074 Acc 97.711%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.078 Acc 97.557%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.079 Acc 97.513%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.182 Acc 95.777%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.177 Acc 95.903%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.093 Acc 94.531%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.079 Acc 97.610%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.077 Acc 97.637%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.077 Acc 97.565%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.077 Acc 97.547%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.078 Acc 97.517%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.120 Acc 96.875%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.182 Acc 95.993%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.176 Acc 96.129%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.078 Acc 97.587%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.077 Acc 97.607%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.079 Acc 97.549%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.080 Acc 97.508%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.126 Acc 96.875%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.182 Acc 95.939%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.176 Acc 96.078%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.072 Acc 97.734%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.075 Acc 97.645%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.078 Acc 97.519%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.078 Acc 97.506%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.080 Acc 97.466%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.187 Acc 95.916%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.179 Acc 96.032%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.076 Acc 97.602%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.078 Acc 97.509%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.077 Acc 97.542%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.077 Acc 97.567%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.089 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.175 Acc 96.047%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.172 Acc 96.113%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.074 Acc 97.645%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.075 Acc 97.621%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.077 Acc 97.561%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.191 Acc 95.862%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.184 Acc 95.896%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.065 Acc 98.012%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.072 Acc 97.831%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.073 Acc 97.763%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.075 Acc 97.701%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.075 Acc 97.658%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.190 Acc 95.862%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.183 Acc 95.931%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.074 Acc 97.610%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.076 Acc 97.629%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.075 Acc 97.669%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.076 Acc 97.609%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.077 Acc 97.544%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.186 Acc 95.962%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.182 Acc 96.082%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.076 Acc 97.494%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.075 Acc 97.511%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.078 Acc 97.458%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.077 Acc 97.488%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.188 Acc 95.877%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.183 Acc 96.121%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.073 Acc 97.757%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.074 Acc 97.726%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.074 Acc 97.668%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.075 Acc 97.628%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.188 Acc 95.939%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.185 Acc 96.117%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.070 Acc 97.679%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.073 Acc 97.610%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.074 Acc 97.617%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.077 Acc 97.549%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.076 Acc 97.592%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.184 Acc 96.070%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.073 Acc 97.703%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.075 Acc 97.659%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.075 Acc 97.617%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.193 Acc 95.831%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.188 Acc 95.997%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.071 Acc 97.765%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.071 Acc 97.812%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.181 Acc 96.078%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.178 Acc 96.179%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.070 Acc 97.857%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.071 Acc 97.690%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.073 Acc 97.654%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.074 Acc 97.628%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.196 Acc 95.622%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.189 Acc 95.923%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.069 Acc 97.718%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.074 Acc 97.576%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.076 Acc 97.527%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.191 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.189 Acc 95.684%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.184 Acc 95.934%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.075 Acc 97.587%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.077 Acc 97.575%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.076 Acc 97.638%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.075 Acc 97.648%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.189 Acc 95.815%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.183 Acc 96.016%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.070 Acc 97.785%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.071 Acc 97.799%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.072 Acc 97.728%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.072 Acc 97.765%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.209 Acc 95.289%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.200 Acc 95.581%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.079 Acc 97.579%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.075 Acc 97.621%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.072 Acc 97.721%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.072 Acc 97.740%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.074 Acc 97.695%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.090 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.184 Acc 95.815%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.181 Acc 96.016%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.074 Acc 97.587%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.074 Acc 97.646%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.074 Acc 97.639%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.189 Acc 95.924%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.185 Acc 96.012%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.072 Acc 97.788%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.071 Acc 97.695%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.072 Acc 97.670%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.186 Acc 96.047%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.182 Acc 96.218%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.065 Acc 97.842%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.069 Acc 97.742%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.068 Acc 97.812%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.072 Acc 97.694%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.181 Acc 96.156%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.179 Acc 96.245%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.033 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.072 Acc 97.610%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.073 Acc 97.613%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.075 Acc 97.571%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.076 Acc 97.569%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.194 Acc 95.931%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.189 Acc 95.989%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.065 Acc 98.028%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.069 Acc 97.897%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.068 Acc 97.879%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.069 Acc 97.865%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.071 Acc 97.781%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.180 Acc 96.016%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.177 Acc 96.144%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.067 Acc 97.865%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.068 Acc 97.843%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.070 Acc 97.807%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.071 Acc 97.769%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.072 Acc 97.756%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.101 Acc 96.875%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.184 Acc 96.047%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.181 Acc 96.140%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.076 Acc 97.618%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.071 Acc 97.711%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.071 Acc 97.713%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.073 Acc 97.673%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.185 Acc 96.098%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.073 Acc 97.757%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.070 Acc 97.804%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.070 Acc 97.773%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.071 Acc 97.721%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.072 Acc 97.691%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.184 Acc 95.862%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.181 Acc 96.024%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.070 Acc 97.742%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.071 Acc 97.659%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.072 Acc 97.682%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.072 Acc 97.641%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.195 Acc 95.599%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.193 Acc 95.623%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.073 Acc 97.587%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.071 Acc 97.685%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.070 Acc 97.719%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.808%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.915%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.065 Acc 97.981%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.068 Acc 97.882%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.067 Acc 97.918%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.069 Acc 97.814%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.070 Acc 97.787%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.199 Acc 95.653%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.193 Acc 95.763%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.095 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.070 Acc 97.734%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.069 Acc 97.854%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.070 Acc 97.781%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.070 Acc 97.777%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.071 Acc 97.742%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.188 Acc 95.831%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.187 Acc 95.927%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.100 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.067 Acc 97.912%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.067 Acc 97.799%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.070 Acc 97.721%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.071 Acc 97.703%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.194 Acc 95.846%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.190 Acc 95.927%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.070 Acc 97.618%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.070 Acc 97.667%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.072 Acc 97.705%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.206 Acc 95.537%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.197 Acc 95.752%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.068 Acc 97.788%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.069 Acc 97.773%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.071 Acc 97.700%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.072 Acc 97.711%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.072 Acc 97.680%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.188 Acc 95.946%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.071 Acc 97.857%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.072 Acc 97.683%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.073 Acc 97.628%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.073 Acc 97.617%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.073 Acc 97.619%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.194 Acc 95.931%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.189 Acc 96.016%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.039 Acc 97.656%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.067 Acc 97.896%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.067 Acc 97.778%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.069 Acc 97.748%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.202 Acc 95.854%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.194 Acc 95.927%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.068 Acc 97.765%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.066 Acc 97.851%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.066 Acc 97.859%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.066 Acc 97.863%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.068 Acc 97.789%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.210 Acc 95.661%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.204 Acc 95.779%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.065 Acc 97.919%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.067 Acc 97.816%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.070 Acc 97.723%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.194 Acc 96.117%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.190 Acc 96.117%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.066 Acc 97.888%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [200/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.068 Acc 97.719%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.069 Acc 97.719%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.069 Acc 97.739%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.194 Acc 95.831%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.189 Acc 95.981%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.066%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.066 Acc 97.812%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.069 Acc 97.734%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.070 Acc 97.747%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.193 Acc 95.862%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.191 Acc 95.899%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.064 Acc 98.012%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.066 Acc 97.936%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.068 Acc 97.830%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.069 Acc 97.740%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.070 Acc 97.736%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.193 Acc 95.823%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.190 Acc 95.864%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.061 Acc 97.966%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.064 Acc 97.851%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.065 Acc 97.807%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.067 Acc 97.763%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.070 Acc 97.722%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.134 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.195 Acc 95.808%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.191 Acc 95.837%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a834b66fe94d4a87e65b66a341bf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.322 Acc 10.156%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.241 Acc 18.951%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.241 Acc 18.983%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.958%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.239 Acc 18.953%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.237 Acc 19.176%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.057 Acc 27.344%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.027 Acc 27.235%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.028 Acc 27.282%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.171 Acc 20.312%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.858 Acc 34.878%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.637 Acc 43.653%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.484 Acc 49.359%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.381 Acc 53.335%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.296 Acc 56.501%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.860 Acc 75.781%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.828 Acc 73.507%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.825 Acc 73.465%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.846 Acc 73.438%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.813 Acc 74.103%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.764 Acc 75.952%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.734 Acc 76.993%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.705 Acc 77.991%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.679 Acc 78.825%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.438 Acc 85.938%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.445 Acc 86.549%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.435 Acc 86.738%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.401 Acc 87.500%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.530 Acc 83.385%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.513 Acc 83.889%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.509 Acc 84.191%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.500 Acc 84.451%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.495 Acc 84.649%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.426 Acc 87.500%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.400 Acc 88.382%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.386 Acc 88.522%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.394 Acc 87.500%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.445 Acc 86.394%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.443 Acc 86.350%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.433 Acc 86.732%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.431 Acc 86.752%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.428 Acc 86.792%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.353 Acc 89.844%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.346 Acc 90.022%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.336 Acc 90.186%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.352 Acc 88.281%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.391 Acc 88.041%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.395 Acc 87.885%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.398 Acc 87.876%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.400 Acc 87.839%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.394 Acc 88.035%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.335 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.324 Acc 90.470%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.313 Acc 90.718%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.377 Acc 88.281%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.379 Acc 88.622%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.372 Acc 88.588%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.367 Acc 88.754%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.367 Acc 88.772%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.369 Acc 88.777%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.351 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.293 Acc 91.445%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.282 Acc 91.752%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.423 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.360 Acc 89.086%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.353 Acc 89.296%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.348 Acc 89.423%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.346 Acc 89.487%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.346 Acc 89.496%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.321 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.283 Acc 91.909%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.274 Acc 92.016%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.336 Acc 89.844%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.323 Acc 89.975%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.332 Acc 90.011%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.330 Acc 90.114%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.331 Acc 90.101%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.330 Acc 90.118%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.278 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.274 Acc 92.474%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.261 Acc 92.743%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.300 Acc 89.844%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.337 Acc 89.882%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.323 Acc 90.108%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.318 Acc 90.282%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.317 Acc 90.376%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.314 Acc 90.450%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.250 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.291 Acc 91.770%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.278 Acc 92.071%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.690 Acc 84.375%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.309 Acc 90.756%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.310 Acc 90.738%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.305 Acc 90.851%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.309 Acc 90.732%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.309 Acc 90.736%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.273 Acc 92.311%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.261 Acc 92.568%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.492 Acc 87.500%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.305 Acc 90.787%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.307 Acc 90.854%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.307 Acc 90.804%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.303 Acc 90.894%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.298 Acc 91.068%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.241 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.246 Acc 93.417%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.235 Acc 93.404%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.210 Acc 93.750%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.282 Acc 91.422%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.289 Acc 91.262%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.289 Acc 91.313%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.286 Acc 91.439%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.287 Acc 91.425%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.250 Acc 93.023%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.239 Acc 93.264%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.279 Acc 88.281%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.287 Acc 91.476%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.283 Acc 91.639%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.283 Acc 91.632%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.282 Acc 91.658%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.281 Acc 91.682%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.252 Acc 93.054%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.243 Acc 93.179%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.248 Acc 90.625%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.274 Acc 91.491%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.268 Acc 92.001%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.272 Acc 91.967%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.272 Acc 91.907%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.271 Acc 91.844%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.230 Acc 93.704%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.224 Acc 93.762%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.274 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.252 Acc 92.304%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.258 Acc 92.176%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.261 Acc 92.120%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.265 Acc 92.086%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.267 Acc 92.060%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.231 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.240 Acc 93.502%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.232 Acc 93.622%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.169 Acc 95.312%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.257 Acc 92.466%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.260 Acc 92.257%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.262 Acc 92.289%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.262 Acc 92.263%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.262 Acc 92.237%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.243 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.238 Acc 93.425%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.231 Acc 93.626%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.402 Acc 87.500%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.265 Acc 92.350%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.259 Acc 92.281%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.258 Acc 92.278%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.254 Acc 92.396%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.257 Acc 92.311%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.221 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.231 Acc 93.827%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.224 Acc 93.867%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.315 Acc 90.625%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.262 Acc 92.296%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.258 Acc 92.417%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.257 Acc 92.538%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.254 Acc 92.511%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.254 Acc 92.492%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.177 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.220 Acc 94.261%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.213 Acc 94.298%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.215 Acc 92.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.245 Acc 92.737%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.242 Acc 92.903%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.245 Acc 92.823%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.244 Acc 92.854%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.245 Acc 92.861%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.220 Acc 94.291%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.213 Acc 94.399%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.237 Acc 92.984%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.240 Acc 92.922%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.241 Acc 92.891%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.241 Acc 92.910%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.243 Acc 92.900%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.206 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.201 Acc 94.817%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.194 Acc 94.908%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.286 Acc 89.844%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.238 Acc 93.038%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.236 Acc 92.949%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.238 Acc 92.961%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.241 Acc 92.920%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.240 Acc 92.947%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.217 Acc 94.137%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.208 Acc 94.244%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.324 Acc 89.062%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.226 Acc 93.286%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.233 Acc 93.167%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.234 Acc 93.080%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.236 Acc 93.060%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.237 Acc 93.111%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.210 Acc 94.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.204 Acc 94.562%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.335 Acc 89.062%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.235 Acc 93.015%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.230 Acc 93.128%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.227 Acc 93.249%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.227 Acc 93.228%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.229 Acc 93.204%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.215 Acc 94.361%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.207 Acc 94.380%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.366 Acc 89.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.228 Acc 93.502%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.226 Acc 93.501%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.230 Acc 93.348%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.231 Acc 93.343%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.230 Acc 93.352%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.213 Acc 94.438%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.205 Acc 94.586%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.226 Acc 92.188%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.222 Acc 93.526%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.219 Acc 93.587%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.221 Acc 93.480%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.225 Acc 93.405%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.225 Acc 93.380%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.243 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.213 Acc 94.083%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.203 Acc 94.314%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.301 Acc 95.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.217 Acc 93.642%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.220 Acc 93.439%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.220 Acc 93.558%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.220 Acc 93.522%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.222 Acc 93.500%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.202 Acc 94.941%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.193 Acc 95.009%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.212 Acc 94.531%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.202 Acc 94.137%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.217 Acc 93.672%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.219 Acc 93.631%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.219 Acc 93.592%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.219 Acc 93.631%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.202 Acc 94.794%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.196 Acc 94.877%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.232 Acc 93.487%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.219 Acc 93.781%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.219 Acc 93.807%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.218 Acc 93.773%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.217 Acc 93.759%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.202 Acc 94.732%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.193 Acc 94.842%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.222 Acc 93.441%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.215 Acc 93.680%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.214 Acc 93.690%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.215 Acc 93.707%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.218 Acc 93.649%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.200 Acc 94.756%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.192 Acc 94.831%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.200 Acc 94.307%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.204 Acc 94.131%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.211 Acc 93.981%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.209 Acc 93.966%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.212 Acc 93.895%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.201 Acc 94.709%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.192 Acc 94.850%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.210 Acc 93.765%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.205 Acc 94.080%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.209 Acc 93.926%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.210 Acc 93.902%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.210 Acc 93.903%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.196 Acc 94.787%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.189 Acc 94.842%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.199 Acc 92.188%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.198 Acc 94.222%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.197 Acc 94.282%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.201 Acc 94.157%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.202 Acc 94.099%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.203 Acc 94.060%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.187 Acc 95.196%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.180 Acc 95.254%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.238 Acc 92.969%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.204 Acc 94.090%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.207 Acc 93.960%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.204 Acc 94.113%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.205 Acc 94.097%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.206 Acc 94.065%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.185 Acc 95.382%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.178 Acc 95.371%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.198 Acc 94.183%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.204 Acc 93.999%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.202 Acc 94.090%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.201 Acc 94.190%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.202 Acc 94.190%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.194 Acc 95.005%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.100 Acc 98.438%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.195 Acc 94.500%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.196 Acc 94.395%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.197 Acc 94.324%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.201 Acc 94.202%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.200 Acc 94.247%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.210 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.185 Acc 95.095%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.205 Acc 93.982%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.199 Acc 94.174%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.198 Acc 94.228%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.198 Acc 94.229%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.200 Acc 94.219%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.191 Acc 95.073%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.182 Acc 95.138%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.219 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.198 Acc 94.454%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.196 Acc 94.442%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.192 Acc 94.472%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.192 Acc 94.453%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.193 Acc 94.397%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.192 Acc 95.096%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.183 Acc 95.192%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.186 Acc 94.686%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.193 Acc 94.516%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.192 Acc 94.568%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.193 Acc 94.500%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.196 Acc 94.414%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.176 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.191 Acc 95.065%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.182 Acc 95.270%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.173 Acc 94.763%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.184 Acc 94.609%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.192 Acc 94.445%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.198 Acc 94.825%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.191 Acc 94.994%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.276 Acc 94.531%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.189 Acc 94.748%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.192 Acc 94.539%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.191 Acc 94.560%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.194 Acc 94.467%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.193 Acc 94.466%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.198 Acc 94.856%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.191 Acc 94.935%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.187 Acc 94.926%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.190 Acc 94.535%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.189 Acc 94.586%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.184 Acc 95.382%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.178 Acc 95.476%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.281 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.182 Acc 94.624%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.185 Acc 94.601%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.188 Acc 94.557%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.188 Acc 94.568%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.188 Acc 94.580%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.270 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.199 Acc 94.980%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.191 Acc 95.075%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.142 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.185 Acc 94.570%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.190 Acc 94.481%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.187 Acc 94.591%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.188 Acc 94.623%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.187 Acc 95.413%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.178 Acc 95.480%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.285 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.171 Acc 94.995%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.168 Acc 94.924%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.174 Acc 94.780%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.180 Acc 94.726%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.185 Acc 94.622%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.188 Acc 95.204%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.246%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.315 Acc 92.188%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.179 Acc 94.732%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.177 Acc 94.799%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.179 Acc 94.835%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.181 Acc 94.777%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.180 Acc 94.785%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.182 Acc 95.421%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.499%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.272 Acc 95.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.176 Acc 95.019%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.179 Acc 94.850%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.186 Acc 94.700%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.187 Acc 94.761%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.183 Acc 94.818%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.174 Acc 95.777%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.165 Acc 95.899%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.226 Acc 94.531%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.158 Acc 95.189%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.175 Acc 94.974%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.183 Acc 94.804%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.179 Acc 94.931%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.179 Acc 94.895%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.168 Acc 95.721%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.162 Acc 95.235%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.176 Acc 94.842%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.175 Acc 94.967%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.175 Acc 95.009%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.177 Acc 94.915%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.181 Acc 95.459%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.174 Acc 95.456%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.182 Acc 94.895%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.182 Acc 94.796%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.180 Acc 94.770%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.178 Acc 94.796%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.179 Acc 94.793%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.250 Acc 92.969%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.189 Acc 95.606%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.181 Acc 95.759%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.176 Acc 95.003%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.176 Acc 94.897%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.177 Acc 94.915%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.179 Acc 94.876%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.179 Acc 94.863%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.184 Acc 95.498%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.179 Acc 95.561%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.282 Acc 93.750%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.171 Acc 94.903%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.174 Acc 94.908%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.175 Acc 94.874%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.176 Acc 94.880%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.175 Acc 94.887%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.177 Acc 95.661%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.171 Acc 95.709%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.166 Acc 95.359%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.169 Acc 95.208%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.167 Acc 95.201%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.170 Acc 95.116%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.173 Acc 95.013%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.175 Acc 95.606%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.167 Acc 95.686%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.165 Acc 95.274%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.169 Acc 95.146%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.171 Acc 95.125%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.172 Acc 95.158%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.529%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.171 Acc 95.585%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.169 Acc 95.166%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.170 Acc 95.134%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.173 Acc 95.123%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.171 Acc 95.153%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.171 Acc 95.068%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.187 Acc 95.367%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.180 Acc 95.472%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.171 Acc 94.988%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.171 Acc 95.048%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.169 Acc 95.133%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.167 Acc 95.170%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.169 Acc 95.138%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.184 Acc 95.552%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.176 Acc 95.608%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.177 Acc 95.080%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.174 Acc 95.099%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.172 Acc 94.991%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.170 Acc 95.046%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.170 Acc 95.043%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.170 Acc 95.845%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.158 Acc 92.188%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.158 Acc 95.351%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.156 Acc 95.526%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.161 Acc 95.325%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.167 Acc 95.219%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.180 Acc 95.351%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.174 Acc 95.452%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.275 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.157 Acc 95.560%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.164 Acc 95.270%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.166 Acc 95.216%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.165 Acc 95.233%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.165 Acc 95.231%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.168 Acc 95.854%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.163 Acc 95.927%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.158 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.166 Acc 95.305%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.165 Acc 95.324%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.164 Acc 95.279%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.164 Acc 95.211%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.166 Acc 95.186%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.162 Acc 95.829%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.162 Acc 95.343%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.156 Acc 95.472%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.159 Acc 95.359%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.162 Acc 95.332%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.162 Acc 95.362%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.823%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.170 Acc 95.969%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.155 Acc 95.606%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.159 Acc 95.449%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.161 Acc 95.419%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.161 Acc 95.422%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.162 Acc 95.339%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.173 Acc 95.730%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.166 Acc 95.829%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.197 Acc 93.750%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.160 Acc 95.243%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.157 Acc 95.292%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.162 Acc 95.260%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.162 Acc 95.259%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.180 Acc 95.297%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.174 Acc 95.487%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.130 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.155 Acc 95.630%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.159 Acc 95.417%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.159 Acc 95.432%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.161 Acc 95.365%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.161 Acc 95.384%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.390%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.176 Acc 95.511%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.132 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.158 Acc 95.483%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.155 Acc 95.495%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.159 Acc 95.549%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.161 Acc 95.451%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.162 Acc 95.389%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.179 Acc 95.614%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.172 Acc 95.600%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.151 Acc 95.552%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.159 Acc 95.442%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.158 Acc 95.470%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.160 Acc 95.403%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.413%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.511%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.158 Acc 95.637%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.156 Acc 95.620%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.157 Acc 95.562%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.157 Acc 95.533%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.158 Acc 95.509%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.190 Acc 95.173%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.182 Acc 95.367%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.162 Acc 95.212%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.156 Acc 95.414%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.158 Acc 95.367%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.157 Acc 95.361%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.158 Acc 95.367%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.167 Acc 95.678%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.185 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.163 Acc 95.328%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.156 Acc 95.390%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.155 Acc 95.393%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.154 Acc 95.425%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.155 Acc 95.420%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.193 Acc 95.166%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.184 Acc 95.347%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.146 Acc 95.730%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.147 Acc 95.701%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.154 Acc 95.577%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.155 Acc 95.574%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.156 Acc 95.545%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.182 Acc 95.893%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.173 Acc 95.977%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.154 Acc 95.583%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.152 Acc 95.678%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.152 Acc 95.595%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.154 Acc 95.558%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.154 Acc 95.528%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.176 Acc 95.800%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.169 Acc 95.814%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.081 Acc 96.094%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.149 Acc 95.591%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.148 Acc 95.674%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.152 Acc 95.502%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.153 Acc 95.443%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.154 Acc 95.476%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.167 Acc 93.750%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.186 Acc 95.421%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.180 Acc 95.476%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.149 Acc 95.684%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.150 Acc 95.715%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.152 Acc 95.632%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.153 Acc 95.604%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.176 Acc 95.599%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.146 Acc 95.676%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.153 Acc 95.620%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.148 Acc 95.646%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.150 Acc 95.624%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.177 Acc 95.792%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.239 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.155 Acc 95.514%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.150 Acc 95.577%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.148 Acc 95.658%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.150 Acc 95.640%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.150 Acc 95.635%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.184 Acc 95.575%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.178 Acc 95.655%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.252 Acc 91.406%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.151 Acc 95.606%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.154 Acc 95.522%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.151 Acc 95.598%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.147 Acc 95.685%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.152 Acc 95.564%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.182 Acc 95.529%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.546%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.153 Acc 95.490%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.154 Acc 95.604%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.148 Acc 95.689%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.150 Acc 95.613%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.149 Acc 95.637%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.186 Acc 95.800%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.177 Acc 95.833%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.141 Acc 96.009%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.138 Acc 96.037%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.143 Acc 95.907%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.147 Acc 95.768%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.182 Acc 95.363%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.145 Acc 95.908%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.146 Acc 95.748%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.148 Acc 95.671%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.151 Acc 95.583%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.149 Acc 95.652%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.174 Acc 96.001%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.169 Acc 96.039%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.150 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.135 Acc 96.194%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.142 Acc 95.981%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.144 Acc 95.850%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.146 Acc 95.772%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.148 Acc 95.674%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.138 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.176 Acc 95.931%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.169 Acc 96.051%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.160 Acc 96.875%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.130 Acc 96.364%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.136 Acc 96.191%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.141 Acc 96.070%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.144 Acc 95.965%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.143 Acc 95.935%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.151 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.173 Acc 95.838%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.166 Acc 95.954%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.142 Acc 96.047%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.145 Acc 95.880%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.149 Acc 95.759%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.149 Acc 95.747%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.148 Acc 95.751%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.185 Acc 95.730%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.179 Acc 95.748%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.147 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.145 Acc 95.744%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.143 Acc 95.798%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.145 Acc 95.745%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.145 Acc 95.777%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.183 Acc 95.722%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.176 Acc 95.779%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.069 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.149 Acc 95.931%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.143 Acc 95.989%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.142 Acc 95.925%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.143 Acc 95.918%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.144 Acc 95.836%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.175 Acc 95.722%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.168 Acc 95.884%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.148 Acc 95.560%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.147 Acc 95.740%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.143 Acc 95.800%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.144 Acc 95.803%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.144 Acc 95.826%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.098 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.174 Acc 95.877%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.170 Acc 95.849%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.143 Acc 95.900%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.141 Acc 96.032%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.144 Acc 95.933%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.144 Acc 95.895%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.143 Acc 95.886%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.174 Acc 96.055%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.167 Acc 96.125%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.127 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.151 Acc 95.661%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.145 Acc 95.821%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.142 Acc 95.907%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.142 Acc 95.910%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.173 Acc 95.746%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.166 Acc 95.872%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.130 Acc 96.140%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.140 Acc 95.888%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.141 Acc 95.819%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.141 Acc 95.831%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.140 Acc 95.868%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.118 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.166 Acc 95.862%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.160 Acc 95.989%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.131 Acc 96.303%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.133 Acc 96.137%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.134 Acc 96.073%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.138 Acc 95.979%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.139 Acc 95.938%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.174 Acc 95.722%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.168 Acc 95.903%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.213 Acc 92.969%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.140 Acc 95.861%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.139 Acc 95.863%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.140 Acc 95.934%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.139 Acc 95.978%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.176 Acc 95.900%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.168 Acc 96.008%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.127 Acc 96.248%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.135 Acc 96.078%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.140 Acc 95.905%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.138 Acc 95.930%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.209 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.184 Acc 95.738%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.130 Acc 96.055%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.133 Acc 95.954%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.138 Acc 95.894%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.136 Acc 96.022%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.137 Acc 95.989%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.179 Acc 95.692%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.171 Acc 95.876%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.131 Acc 96.202%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.132 Acc 96.070%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.137 Acc 95.964%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.140 Acc 95.862%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.140 Acc 95.880%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.645%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.176 Acc 95.896%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.141 Acc 95.846%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.136 Acc 95.967%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.139 Acc 95.936%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.137 Acc 95.974%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.180 Acc 95.684%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.174 Acc 95.806%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.189 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.141 Acc 95.823%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.134 Acc 96.008%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.138 Acc 95.948%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.134 Acc 96.039%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.135 Acc 96.014%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.174 Acc 95.893%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.167 Acc 96.004%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.132 Acc 95.955%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.132 Acc 96.086%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.131 Acc 96.153%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.131 Acc 96.172%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.133 Acc 96.117%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.169 Acc 95.927%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.128 Acc 96.411%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.130 Acc 96.304%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.130 Acc 96.198%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.132 Acc 96.146%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.133 Acc 96.080%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.124 Acc 94.531%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.176 Acc 95.653%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.170 Acc 95.752%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.195 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.126 Acc 96.179%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.135 Acc 96.016%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.135 Acc 95.933%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.135 Acc 95.930%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.134 Acc 96.010%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.186 Acc 95.722%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.282 Acc 91.406%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.122 Acc 96.233%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.126 Acc 96.265%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.130 Acc 96.198%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.131 Acc 96.133%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.132 Acc 96.122%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.178 Acc 95.707%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.173 Acc 95.752%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.139 Acc 96.148%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.132 Acc 96.169%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.132 Acc 96.176%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.134 Acc 96.131%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.123 Acc 93.750%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.174 Acc 95.896%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.185 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.123 Acc 96.496%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.126 Acc 96.343%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.131 Acc 96.195%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.132 Acc 96.127%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.133 Acc 96.108%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.166 Acc 95.993%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.161 Acc 96.020%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.121 Acc 96.279%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.128 Acc 96.308%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.130 Acc 96.190%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.133 Acc 96.084%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.133 Acc 96.027%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.129 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.169 Acc 95.815%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.162 Acc 95.923%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.118 Acc 96.658%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.121 Acc 96.416%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.125 Acc 96.320%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.126 Acc 96.310%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.130 Acc 96.229%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.180 Acc 96.016%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 96.028%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.125 Acc 96.272%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.122 Acc 96.397%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.126 Acc 96.221%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.127 Acc 96.168%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.128 Acc 96.151%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.169 Acc 95.938%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.130 Acc 96.295%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.126 Acc 96.401%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.129 Acc 96.296%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.128 Acc 96.335%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.128 Acc 96.311%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.183 Acc 95.916%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.178 Acc 95.965%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.122 Acc 96.403%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.127 Acc 96.265%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.126 Acc 96.340%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.127 Acc 96.281%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.128 Acc 96.233%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.179 Acc 95.692%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.177 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.124 Acc 96.194%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.126 Acc 96.234%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.127 Acc 96.244%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.130 Acc 96.207%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.129 Acc 96.223%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.637%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.174 Acc 95.798%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.141 Acc 95.908%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.132 Acc 96.140%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.128 Acc 96.236%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.129 Acc 96.187%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.192 Acc 95.707%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.184 Acc 95.771%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.199 Acc 90.625%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.126 Acc 96.225%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.123 Acc 96.234%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.126 Acc 96.166%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.128 Acc 96.150%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.129 Acc 96.123%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.082 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.183 Acc 95.939%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.177 Acc 96.043%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.130 Acc 96.442%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.130 Acc 96.174%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.129 Acc 96.239%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.189 Acc 95.854%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.181 Acc 95.872%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.130 Acc 95.970%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.127 Acc 96.133%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.129 Acc 96.200%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.129 Acc 96.230%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.129 Acc 96.254%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.171 Acc 96.032%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.162 Acc 96.121%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.109 Acc 94.531%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.124 Acc 96.401%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.126 Acc 96.301%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.124 Acc 96.386%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.126 Acc 96.339%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.161 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.189 Acc 95.429%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.185 Acc 95.577%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.182 Acc 92.188%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.130 Acc 96.241%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.128 Acc 96.182%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.125 Acc 96.216%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.126 Acc 96.209%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.181 Acc 95.614%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.173 Acc 95.732%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.113 Acc 96.682%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.121 Acc 96.416%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.122 Acc 96.400%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.125 Acc 96.265%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.124 Acc 96.257%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.169 Acc 95.939%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.163 Acc 96.070%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.120 Acc 96.426%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.122 Acc 96.374%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.121 Acc 96.418%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.124 Acc 96.320%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.185 Acc 95.962%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.177 Acc 96.090%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.111 Acc 96.736%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.115 Acc 96.580%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.120 Acc 96.447%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.123 Acc 96.339%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.124 Acc 96.304%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 95.815%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.165 Acc 95.962%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.118 Acc 96.450%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.119 Acc 96.482%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.120 Acc 96.442%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.122 Acc 96.409%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.123 Acc 96.345%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.146 Acc 93.750%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.182 Acc 95.537%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.175 Acc 95.779%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.112 Acc 96.666%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.115 Acc 96.482%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.120 Acc 96.371%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.123 Acc 96.261%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.126 Acc 96.237%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.164 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.178 Acc 95.645%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 95.783%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.121 Acc 96.419%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.115 Acc 96.545%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.119 Acc 96.480%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.121 Acc 96.431%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.124 Acc 96.378%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.187 Acc 95.630%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.179 Acc 95.759%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.119 Acc 96.527%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.118 Acc 96.521%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.119 Acc 96.517%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.119 Acc 96.465%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.199 Acc 95.893%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.193 Acc 95.872%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.121 Acc 96.444%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.120 Acc 96.429%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.120 Acc 96.415%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.121 Acc 96.395%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.174 Acc 95.978%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.165 Acc 96.067%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.115 Acc 96.607%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.118 Acc 96.553%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.119 Acc 96.474%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.121 Acc 96.384%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.176 Acc 95.869%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.170 Acc 96.028%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.112 Acc 96.666%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.112 Acc 96.564%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.116 Acc 96.483%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.116 Acc 96.437%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.117 Acc 96.490%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.182 Acc 95.985%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.174 Acc 96.012%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.120 Acc 96.372%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.121 Acc 96.354%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.119 Acc 96.405%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.120 Acc 96.402%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.120 Acc 96.432%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.171 Acc 95.997%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.089 Acc 95.312%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.112 Acc 96.612%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.119 Acc 96.444%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.117 Acc 96.457%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.120 Acc 96.474%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.119 Acc 96.480%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.184 Acc 95.645%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.178 Acc 95.759%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.113 Acc 96.697%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.114 Acc 96.665%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.117 Acc 96.548%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.117 Acc 96.557%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.119 Acc 96.468%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.193 Acc 95.730%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.186 Acc 95.752%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.111 Acc 96.689%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.116 Acc 96.556%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.121 Acc 96.392%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.122 Acc 96.392%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.120 Acc 96.424%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.204 Acc 95.769%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.194 Acc 95.826%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.120 Acc 96.581%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.117 Acc 96.556%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.115 Acc 96.561%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.116 Acc 96.491%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.119 Acc 96.449%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.201 Acc 95.552%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.194 Acc 95.542%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.275 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.119 Acc 96.496%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.118 Acc 96.490%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.118 Acc 96.480%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.119 Acc 96.437%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.118 Acc 96.462%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.201 Acc 95.591%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.194 Acc 95.623%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.204 Acc 92.188%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.110 Acc 96.689%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.115 Acc 96.556%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.114 Acc 96.584%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.116 Acc 96.532%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.116 Acc 96.552%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.208 Acc 95.320%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.200 Acc 95.379%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.116 Acc 96.666%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.119 Acc 96.576%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.118 Acc 96.535%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.118 Acc 96.515%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.192 Acc 95.699%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.184 Acc 95.787%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.116 Acc 96.395%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.116 Acc 96.424%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.117 Acc 96.423%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.116 Acc 96.513%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.116 Acc 96.457%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.193 Acc 95.715%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.183 Acc 95.822%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.109 Acc 96.566%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.112 Acc 96.587%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.112 Acc 96.564%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.114 Acc 96.503%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.113 Acc 96.538%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.186 Acc 95.924%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.175 Acc 96.078%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.218 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.107 Acc 96.682%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.110 Acc 96.696%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.114 Acc 96.626%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.113 Acc 96.641%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.114 Acc 96.608%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.205 Acc 95.483%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.195 Acc 95.507%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.110 Acc 96.708%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.111 Acc 96.636%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.111 Acc 96.626%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.114 Acc 96.583%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.182 Acc 95.916%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.176 Acc 95.938%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.103 Acc 96.790%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.110 Acc 96.622%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.111 Acc 96.605%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.114 Acc 96.577%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.166 Acc 95.939%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.160 Acc 96.016%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.108 Acc 96.758%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.113 Acc 96.613%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.114 Acc 96.602%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.170 Acc 96.067%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.190 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.107 Acc 96.968%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.108 Acc 96.786%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.111 Acc 96.732%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.112 Acc 96.684%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.115 Acc 96.610%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.193 Acc 95.862%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.187 Acc 95.938%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.114 Acc 96.682%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.108 Acc 96.789%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.109 Acc 96.795%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.110 Acc 96.725%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.176 Acc 95.831%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.168 Acc 95.950%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.115 Acc 96.689%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.115 Acc 96.533%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.115 Acc 96.577%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.113 Acc 96.637%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.113 Acc 96.611%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.178 Acc 95.893%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.170 Acc 95.969%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.110 Acc 96.697%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.113 Acc 96.603%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.111 Acc 96.709%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.113 Acc 96.620%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.111 Acc 96.663%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.188 Acc 95.452%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.182 Acc 95.608%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.106 Acc 96.744%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.110 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.109 Acc 96.753%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.111 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.111 Acc 96.719%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.199 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.185 Acc 95.908%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.177 Acc 95.923%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.107 Acc 96.914%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.112 Acc 96.743%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.111 Acc 96.766%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.111 Acc 96.737%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.113 Acc 96.685%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.188 Acc 95.614%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.180 Acc 95.791%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.101 Acc 96.805%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.100 Acc 96.937%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.107 Acc 96.758%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.111 Acc 96.581%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.112 Acc 96.557%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.193 Acc 95.823%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.185 Acc 95.931%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.108 Acc 96.782%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.107 Acc 96.776%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.110 Acc 96.743%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.111 Acc 96.685%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.196 Acc 95.521%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.190 Acc 95.519%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.085 Acc 99.219%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.105 Acc 96.890%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.105 Acc 96.898%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.108 Acc 96.833%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.107 Acc 96.799%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.110 Acc 96.753%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.191 Acc 95.630%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.184 Acc 95.705%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.107 Acc 96.736%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.107 Acc 96.688%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.109 Acc 96.631%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.110 Acc 96.624%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.109 Acc 96.605%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.188 Acc 95.701%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.108 Acc 96.798%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.104 Acc 96.848%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.105 Acc 96.810%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.104 Acc 96.830%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.106 Acc 96.794%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.179 Acc 95.911%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.105 Acc 96.906%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.104 Acc 96.840%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.106 Acc 96.823%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.105 Acc 96.811%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.107 Acc 96.750%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.199 Acc 95.769%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.189 Acc 95.853%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.095 Acc 97.130%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.102 Acc 96.968%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.104 Acc 96.909%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.109 Acc 96.809%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.107 Acc 96.847%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.194 Acc 95.808%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.185 Acc 95.864%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.102 Acc 96.774%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.108 Acc 96.801%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.108 Acc 96.813%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.107 Acc 96.820%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.108 Acc 96.813%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.193 Acc 95.506%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.183 Acc 95.763%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.130 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.104 Acc 96.860%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.104 Acc 96.805%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.107 Acc 96.761%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.108 Acc 96.744%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.108 Acc 96.744%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.205 Acc 95.746%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.194 Acc 95.841%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.108 Acc 96.968%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.104 Acc 96.904%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.103 Acc 96.879%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.105 Acc 96.822%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.195 Acc 95.429%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.187 Acc 95.573%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.130 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.101 Acc 97.161%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.104 Acc 96.910%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.106 Acc 96.808%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.107 Acc 96.809%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.109 Acc 96.736%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.187 Acc 95.877%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.179 Acc 95.993%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.126 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.101 Acc 97.030%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.103 Acc 96.988%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.104 Acc 96.958%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.106 Acc 96.856%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.105 Acc 96.853%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.192 Acc 95.746%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.919%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.101 Acc 96.697%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.104 Acc 96.731%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.104 Acc 96.763%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.105 Acc 96.797%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.104 Acc 96.827%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 96.001%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.181 Acc 96.016%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.174 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.097 Acc 97.084%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.100 Acc 96.909%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.101 Acc 96.815%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.102 Acc 96.791%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.181 Acc 95.924%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.172 Acc 96.051%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.146 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.100 Acc 97.014%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.102 Acc 96.867%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.104 Acc 96.780%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.105 Acc 96.761%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.191 Acc 95.730%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.104 Acc 97.022%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.102 Acc 96.984%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.102 Acc 97.013%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.101 Acc 96.994%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.101 Acc 97.034%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.116 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.191 Acc 95.800%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.184 Acc 95.853%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.080 Acc 96.094%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.102 Acc 96.759%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.103 Acc 96.786%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.105 Acc 96.793%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.104 Acc 96.836%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.196 Acc 95.746%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.187 Acc 95.841%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.096 Acc 96.968%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.097 Acc 96.941%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.101 Acc 96.857%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.101 Acc 96.854%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.102 Acc 96.831%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.191 Acc 95.978%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.183 Acc 96.051%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.092 Acc 97.300%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.101 Acc 96.922%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.103 Acc 96.865%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.104 Acc 96.833%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.200 Acc 95.568%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.192 Acc 95.565%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.100 Acc 96.898%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.100 Acc 96.898%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.104 Acc 96.842%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.104 Acc 96.803%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.196 Acc 95.568%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.094 Acc 97.053%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.100 Acc 96.859%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.100 Acc 96.896%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.099 Acc 96.883%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.101 Acc 96.842%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.196 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.190 Acc 95.697%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.101 Acc 96.890%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.099 Acc 96.852%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.101 Acc 96.857%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.101 Acc 96.865%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.103 Acc 96.838%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.190 Acc 96.024%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.183 Acc 96.004%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.101 Acc 96.999%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.102 Acc 96.999%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.102 Acc 96.958%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.102 Acc 96.959%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.101 Acc 96.959%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.196 Acc 95.591%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.187 Acc 95.802%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.100 Acc 96.960%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.100 Acc 96.945%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.099 Acc 96.971%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.103 Acc 96.845%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.199 Acc 95.738%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.191 Acc 95.818%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.091 Acc 97.254%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.096 Acc 97.065%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.098 Acc 97.018%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.098 Acc 97.023%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.099 Acc 96.975%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.190 Acc 95.900%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.181 Acc 95.946%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.098 Acc 97.053%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.101 Acc 96.984%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.102 Acc 96.880%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.101 Acc 96.891%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.102 Acc 96.856%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.197 Acc 95.722%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.189 Acc 95.759%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.100 Acc 96.999%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.104 Acc 96.898%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.103 Acc 96.870%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.102 Acc 96.883%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.102 Acc 96.889%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.194 Acc 95.622%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.185 Acc 95.791%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.036 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.094 Acc 96.976%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.097 Acc 96.929%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.101 Acc 96.898%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.099 Acc 96.982%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.100 Acc 96.922%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.207 Acc 95.506%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.202 Acc 95.573%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.096 Acc 97.107%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.095 Acc 97.143%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.099 Acc 96.958%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.098 Acc 97.025%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.099 Acc 96.979%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.199 Acc 95.653%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.193 Acc 95.767%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.099 Acc 96.887%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.096 Acc 96.948%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.098 Acc 96.931%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.098 Acc 96.947%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.186 Acc 95.880%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.102 Acc 96.844%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.099 Acc 96.859%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.102 Acc 96.865%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.100 Acc 96.930%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.205 Acc 95.560%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.198 Acc 95.542%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.090 Acc 97.215%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.096 Acc 97.114%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.094 Acc 97.105%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.097 Acc 97.026%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.110 Acc 96.875%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.194 Acc 95.746%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.112 Acc 93.750%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.088 Acc 97.254%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.091 Acc 97.201%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.096 Acc 97.096%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.098 Acc 96.981%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.144 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.191 Acc 95.838%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.182 Acc 95.973%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.099 Acc 96.968%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.100 Acc 96.863%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.098 Acc 96.927%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.097 Acc 96.949%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.099 Acc 96.908%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.186 Acc 95.849%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.092 Acc 97.246%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.095 Acc 97.087%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.097 Acc 97.012%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.199 Acc 95.637%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.193 Acc 95.787%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.035 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.090 Acc 97.293%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.094 Acc 97.108%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.096 Acc 97.033%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.097 Acc 96.984%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.184 Acc 95.722%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.101 Acc 96.736%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.097 Acc 96.972%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.096 Acc 96.997%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.096 Acc 97.000%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.096 Acc 97.017%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.132 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.184 Acc 95.869%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.180 Acc 95.950%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.094 Acc 97.231%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.094 Acc 97.097%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.094 Acc 97.155%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.094 Acc 97.091%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.096 Acc 97.020%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.189 Acc 95.792%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.182 Acc 95.868%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.093 Acc 97.277%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.095 Acc 97.062%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.094 Acc 97.098%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.095 Acc 97.095%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.096 Acc 97.071%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.273 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.200 Acc 95.722%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.193 Acc 95.713%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.091 Acc 97.151%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.093 Acc 97.116%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.093 Acc 97.146%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.096 Acc 97.070%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.196 Acc 95.924%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.188 Acc 95.997%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.094 Acc 97.177%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.097 Acc 97.046%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.097 Acc 96.932%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.097 Acc 96.975%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.186 Acc 95.815%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.179 Acc 95.942%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.085 Acc 97.463%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.092 Acc 97.225%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.093 Acc 97.148%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.094 Acc 97.136%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.095 Acc 97.078%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.191 Acc 96.001%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.184 Acc 95.969%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.137 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.086 Acc 97.262%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.091 Acc 97.248%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.091 Acc 97.171%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.093 Acc 97.120%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.094 Acc 97.106%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.183 Acc 95.947%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.179 Acc 95.954%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.091 Acc 97.100%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.091 Acc 97.064%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.094 Acc 97.031%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.093 Acc 97.086%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.209 Acc 95.568%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.200 Acc 95.705%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.092 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.088 Acc 97.192%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.097 Acc 96.989%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.096 Acc 96.986%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.096 Acc 97.036%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.207 Acc 95.398%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.200 Acc 95.565%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.090 Acc 97.061%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.096 Acc 96.898%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.095 Acc 96.981%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.095 Acc 97.011%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.096 Acc 96.969%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.197 Acc 95.792%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.189 Acc 95.911%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.089 Acc 97.246%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.093 Acc 97.170%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.093 Acc 97.140%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.092 Acc 97.175%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.093 Acc 97.156%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.182 Acc 95.753%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.174 Acc 95.899%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.092 Acc 97.277%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.091 Acc 97.217%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.092 Acc 97.179%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.092 Acc 97.163%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.093 Acc 97.123%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.202 Acc 95.792%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.194 Acc 95.849%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.082 Acc 97.424%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.088 Acc 97.209%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.091 Acc 97.130%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.091 Acc 97.120%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.198 Acc 95.707%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.190 Acc 95.826%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.091 Acc 97.192%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.090 Acc 97.182%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.091 Acc 97.225%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.092 Acc 97.191%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.092 Acc 97.167%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.191 Acc 95.746%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.186 Acc 95.833%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.086 Acc 97.208%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.089 Acc 97.143%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.091 Acc 97.119%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.091 Acc 97.103%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.092 Acc 97.062%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.210 Acc 95.282%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.204 Acc 95.254%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.091 Acc 97.123%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.086 Acc 97.248%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.090 Acc 97.197%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.089 Acc 97.167%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.092 Acc 97.132%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.197 Acc 95.908%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.190 Acc 95.892%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.082 Acc 97.362%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.085 Acc 97.260%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.087 Acc 97.161%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.089 Acc 97.154%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.090 Acc 97.103%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.191 Acc 96.024%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.184 Acc 96.059%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.088 Acc 97.194%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.090 Acc 97.119%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.091 Acc 97.105%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.195 Acc 95.792%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.190 Acc 95.771%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.087 Acc 97.092%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.088 Acc 97.186%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.091 Acc 97.090%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.091 Acc 97.105%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.092 Acc 97.128%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.197 Acc 95.514%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.191 Acc 95.538%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.082 Acc 97.563%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.084 Acc 97.415%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.088 Acc 97.270%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.089 Acc 97.252%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.199 Acc 95.877%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.194 Acc 95.802%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.088 Acc 97.223%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.088 Acc 97.178%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.089 Acc 97.129%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.090 Acc 97.161%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.090 Acc 97.167%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.204 Acc 95.545%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.198 Acc 95.585%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb75da2af4764a89a9b833909cc030a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.321 Acc 16.406%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.235 Acc 18.665%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.023 Acc 27.585%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.743 Acc 38.668%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.526 Acc 46.842%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.356 Acc 53.219%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.451 Acc 85.938%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.482 Acc 84.878%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.476 Acc 85.055%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.511 Acc 84.375%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.546 Acc 82.898%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.532 Acc 83.403%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.514 Acc 84.071%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.499 Acc 84.546%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.486 Acc 84.924%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.392 Acc 86.719%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.376 Acc 89.117%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.370 Acc 89.234%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.453 Acc 87.500%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.418 Acc 87.067%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.408 Acc 87.310%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.401 Acc 87.627%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.396 Acc 87.845%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.391 Acc 87.990%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.385 Acc 86.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.350 Acc 89.472%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.344 Acc 89.486%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.332 Acc 89.844%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.368 Acc 88.691%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.357 Acc 88.899%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.352 Acc 89.229%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.351 Acc 89.267%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.348 Acc 89.416%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.377 Acc 87.500%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.289 Acc 91.507%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.283 Acc 91.659%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.233 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.330 Acc 90.084%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.326 Acc 90.155%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.321 Acc 90.179%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.321 Acc 90.313%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.318 Acc 90.427%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.267 Acc 92.690%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.261 Acc 92.701%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.390 Acc 85.938%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.302 Acc 90.780%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.301 Acc 90.901%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.297 Acc 90.952%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.296 Acc 91.087%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.296 Acc 91.082%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.304 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.258 Acc 92.628%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.252 Acc 92.712%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.242 Acc 93.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.278 Acc 91.700%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.282 Acc 91.577%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.282 Acc 91.604%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.281 Acc 91.580%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.279 Acc 91.724%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.253 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.245 Acc 92.822%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.241 Acc 93.008%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.278 Acc 95.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.246 Acc 92.474%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.258 Acc 92.040%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.264 Acc 92.071%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.266 Acc 92.113%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.267 Acc 92.081%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.220 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.219 Acc 94.067%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.212 Acc 94.045%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.194 Acc 92.969%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.273 Acc 92.002%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.265 Acc 92.273%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.262 Acc 92.367%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.260 Acc 92.330%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.204 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.216 Acc 93.936%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.209 Acc 94.042%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.120 Acc 97.656%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.247 Acc 92.683%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.257 Acc 92.456%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.254 Acc 92.564%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.252 Acc 92.607%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.239 Acc 89.844%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.235 Acc 93.634%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.229 Acc 93.571%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.269 Acc 89.844%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.255 Acc 92.636%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.247 Acc 92.654%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.249 Acc 92.551%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.247 Acc 92.671%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.246 Acc 92.749%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.222 Acc 94.121%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.218 Acc 94.096%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.237 Acc 92.969%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.233 Acc 93.170%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.234 Acc 93.151%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.236 Acc 93.041%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.239 Acc 93.019%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.236 Acc 93.075%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.254 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.202 Acc 94.446%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.196 Acc 94.663%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.233 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.234 Acc 93.363%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.234 Acc 93.198%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.234 Acc 93.278%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.236 Acc 93.129%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.233 Acc 93.203%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.209 Acc 94.346%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.205 Acc 94.306%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.094 Acc 98.438%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.222 Acc 93.209%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.230 Acc 93.245%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.227 Acc 93.381%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.226 Acc 93.473%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.226 Acc 93.433%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.173 Acc 92.188%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.216 Acc 94.075%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.211 Acc 94.096%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.163 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.223 Acc 93.502%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.225 Acc 93.424%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.222 Acc 93.548%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.222 Acc 93.534%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.222 Acc 93.502%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.197 Acc 94.833%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.193 Acc 94.799%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.311 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.209 Acc 93.773%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.212 Acc 93.668%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.213 Acc 93.737%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.215 Acc 93.674%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.218 Acc 93.568%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.210 Acc 94.438%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.205 Acc 94.345%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.268 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.203 Acc 93.912%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.207 Acc 93.734%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.207 Acc 93.869%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.208 Acc 93.869%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.212 Acc 93.809%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.191 Acc 94.825%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.187 Acc 94.838%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.208 Acc 93.944%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.205 Acc 94.051%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.207 Acc 93.966%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.209 Acc 93.909%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.189 Acc 90.625%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.196 Acc 94.717%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.192 Acc 94.753%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.263 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.199 Acc 94.593%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.200 Acc 94.352%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.202 Acc 94.251%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.204 Acc 94.161%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.204 Acc 94.154%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.195 Acc 94.949%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.189 Acc 94.897%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.193 Acc 94.291%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.200 Acc 94.189%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.204 Acc 94.098%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.202 Acc 94.171%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.203 Acc 94.129%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.194 Acc 94.628%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.204 Acc 94.407%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.202 Acc 94.333%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.201 Acc 94.300%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.203 Acc 94.227%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.199 Acc 94.330%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.137 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.190 Acc 94.895%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.183 Acc 95.048%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.188 Acc 94.407%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.190 Acc 94.446%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.195 Acc 94.269%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.194 Acc 94.334%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.195 Acc 94.382%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.203 Acc 94.415%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.196 Acc 94.667%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.190 Acc 94.593%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.191 Acc 94.555%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.193 Acc 94.503%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.194 Acc 94.527%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.195 Acc 94.441%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.184 Acc 95.258%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.181 Acc 95.254%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.186 Acc 94.609%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.186 Acc 94.601%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.188 Acc 94.567%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.185 Acc 95.150%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.181 Acc 95.266%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.176 Acc 95.057%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.175 Acc 95.040%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.184 Acc 94.778%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.184 Acc 94.759%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.187 Acc 94.683%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.185 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.181 Acc 95.289%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.179 Acc 95.192%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.124 Acc 94.531%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.191 Acc 94.400%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.180 Acc 94.784%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.183 Acc 94.716%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.187 Acc 94.701%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.187 Acc 94.728%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.179 Acc 95.429%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.173 Acc 95.472%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.184 Acc 94.787%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.184 Acc 94.718%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.185 Acc 94.651%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.181 Acc 94.734%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.182 Acc 94.734%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.183 Acc 95.258%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.184%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.210 Acc 92.969%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.174 Acc 94.856%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.175 Acc 94.885%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.177 Acc 94.879%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.176 Acc 94.954%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.179 Acc 94.890%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.161 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.187 Acc 94.841%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.183 Acc 94.955%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.168 Acc 95.111%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.169 Acc 95.075%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.175 Acc 94.934%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.178 Acc 94.872%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.178 Acc 94.884%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.146 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.186 Acc 95.166%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.181 Acc 95.161%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.176 Acc 94.957%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.175 Acc 94.994%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.178 Acc 94.892%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.176 Acc 94.993%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.176 Acc 94.957%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.185 Acc 95.274%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.181 Acc 95.211%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.207 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.163 Acc 95.258%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.164 Acc 95.208%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.170 Acc 95.032%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.173 Acc 95.018%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.174 Acc 94.996%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.148 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.170 Acc 95.699%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.163 Acc 95.783%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.146 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.164 Acc 95.320%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.165 Acc 95.274%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.167 Acc 95.255%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.166 Acc 95.254%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.168 Acc 95.192%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.182 Acc 95.243%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.176 Acc 95.336%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.168 Acc 95.158%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.169 Acc 95.107%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.171 Acc 95.079%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.171 Acc 95.090%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.162 Acc 95.759%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.247 Acc 96.875%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.166 Acc 95.367%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.166 Acc 95.219%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.165 Acc 95.307%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.311%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.165 Acc 95.306%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.182 Acc 95.367%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.177 Acc 95.359%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.184 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.174 Acc 95.289%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.164 Acc 95.324%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.167 Acc 95.305%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.166 Acc 95.305%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.166 Acc 95.303%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.186 Acc 95.305%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.184 Acc 95.099%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.148 Acc 95.753%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.157 Acc 95.542%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.160 Acc 95.538%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.163 Acc 95.367%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.163 Acc 95.320%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.166 Acc 95.701%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.152 Acc 95.413%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.156 Acc 95.421%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.158 Acc 95.367%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.158 Acc 95.408%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.163 Acc 95.283%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.144 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.168 Acc 95.746%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.161 Acc 95.829%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.170 Acc 95.243%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.159 Acc 95.390%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.160 Acc 95.403%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.159 Acc 95.396%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.160 Acc 95.356%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.188 Acc 95.127%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.181 Acc 95.169%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.191 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.163 Acc 95.475%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.162 Acc 95.445%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.164 Acc 95.294%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.160 Acc 95.406%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.159 Acc 95.409%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.177 Acc 95.382%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.170 Acc 95.546%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.148 Acc 95.684%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.149 Acc 95.653%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.153 Acc 95.593%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.157 Acc 95.465%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.167 Acc 95.670%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.150 Acc 95.779%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.154 Acc 95.699%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.157 Acc 95.616%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.157 Acc 95.595%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.174 Acc 95.390%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.225 Acc 93.750%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.145 Acc 96.040%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.151 Acc 95.802%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.156 Acc 95.736%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.154 Acc 95.745%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.155 Acc 95.663%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.170 Acc 95.722%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.165 Acc 95.802%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.087 Acc 98.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.150 Acc 95.823%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.152 Acc 95.559%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.152 Acc 95.519%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.153 Acc 95.543%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.167 Acc 95.730%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.164 Acc 95.686%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.144 Acc 95.916%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.153 Acc 95.725%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.151 Acc 95.717%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.152 Acc 95.644%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.153 Acc 95.654%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.172 Acc 95.583%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.166 Acc 95.740%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.142 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.142 Acc 95.506%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.143 Acc 95.639%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.146 Acc 95.697%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.148 Acc 95.696%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.152 Acc 95.649%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.182 Acc 95.405%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.178 Acc 95.406%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.191 Acc 93.750%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.142 Acc 95.846%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.148 Acc 95.717%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.150 Acc 95.684%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.149 Acc 95.724%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.150 Acc 95.695%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.179 Acc 95.560%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.170 Acc 95.623%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.143 Acc 95.792%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.141 Acc 95.833%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.145 Acc 95.710%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.145 Acc 95.763%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.146 Acc 95.741%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.191 Acc 94.918%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.183 Acc 95.114%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.138 Acc 96.063%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.138 Acc 95.927%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.145 Acc 95.811%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.145 Acc 95.813%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.146 Acc 95.785%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.179 Acc 95.514%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.174 Acc 95.577%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.150 Acc 95.521%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.149 Acc 95.779%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.146 Acc 95.775%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.145 Acc 95.796%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.146 Acc 95.751%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.178 Acc 95.614%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.173 Acc 95.713%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.175 Acc 96.875%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.142 Acc 96.024%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.146 Acc 95.791%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.146 Acc 95.850%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.145 Acc 95.850%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.145 Acc 95.854%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.173 Acc 95.722%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.166 Acc 95.818%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.139 Acc 95.893%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.138 Acc 95.923%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.141 Acc 95.858%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.141 Acc 95.907%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.141 Acc 95.942%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.170 Acc 95.581%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.131 Acc 96.450%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.137 Acc 96.226%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.140 Acc 96.151%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.139 Acc 96.109%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.141 Acc 95.992%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.173 Acc 95.561%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.139 Acc 96.194%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.133 Acc 96.249%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.136 Acc 96.185%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.139 Acc 96.033%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.140 Acc 96.028%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.177 Acc 95.792%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.169 Acc 95.884%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.136 Acc 96.171%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.138 Acc 96.021%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.137 Acc 96.066%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.139 Acc 96.066%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.177 Acc 95.483%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.171 Acc 95.542%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.135 Acc 96.032%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.135 Acc 96.070%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.136 Acc 96.065%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.136 Acc 96.068%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.134 Acc 96.114%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.175 Acc 95.560%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.168 Acc 95.744%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.168 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.128 Acc 96.171%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.133 Acc 96.078%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.134 Acc 96.068%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.136 Acc 96.017%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.177 Acc 95.630%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.207 Acc 93.750%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.144 Acc 96.140%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.136 Acc 96.195%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.138 Acc 96.102%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.136 Acc 96.111%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.104 Acc 98.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.173 Acc 95.596%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.273 Acc 93.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.129 Acc 96.403%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.134 Acc 96.168%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.132 Acc 96.143%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.133 Acc 96.063%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.133 Acc 96.091%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.174 Acc 95.552%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.167 Acc 95.627%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.132 Acc 96.113%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.136 Acc 96.080%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.133 Acc 96.176%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.172 Acc 95.815%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.164 Acc 95.915%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.130 Acc 96.148%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.132 Acc 96.160%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.131 Acc 96.187%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.131 Acc 96.220%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.130 Acc 96.262%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.170 Acc 95.668%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.162 Acc 95.787%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.128 Acc 96.233%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.128 Acc 96.206%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.130 Acc 96.172%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.131 Acc 96.109%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.133 Acc 96.106%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.173 Acc 95.591%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.166 Acc 95.771%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.140 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.124 Acc 96.248%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.123 Acc 96.273%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.127 Acc 96.262%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.127 Acc 96.248%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.130 Acc 96.203%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.125 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.174 Acc 95.630%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.170 Acc 95.670%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.130 Acc 96.295%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.128 Acc 96.385%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.127 Acc 96.343%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.129 Acc 96.254%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.178%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.176 Acc 95.738%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.168 Acc 95.969%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.119 Acc 96.434%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.126 Acc 96.261%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.127 Acc 96.348%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.129 Acc 96.296%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.130 Acc 96.256%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.173 Acc 96.071%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.164 Acc 96.113%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.127 Acc 96.349%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.125 Acc 96.292%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.127 Acc 96.216%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.128 Acc 96.198%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.185 Acc 95.653%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.177 Acc 95.713%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.118 Acc 96.272%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.124 Acc 96.323%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.125 Acc 96.361%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.126 Acc 96.341%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.303%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.182 Acc 95.692%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.175 Acc 95.693%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.127 Acc 96.481%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.127 Acc 96.300%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.130 Acc 96.229%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.128 Acc 96.223%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.181 Acc 95.622%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.172 Acc 95.794%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.123 Acc 96.457%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.123 Acc 96.440%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.127 Acc 96.366%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.126 Acc 96.353%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.126 Acc 96.348%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.186 Acc 95.367%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.596%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.122 Acc 96.455%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.120 Acc 96.455%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.121 Acc 96.429%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.122 Acc 96.446%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.182 Acc 95.320%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.503%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.222 Acc 92.969%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.121 Acc 96.426%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.122 Acc 96.455%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.126 Acc 96.397%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.125 Acc 96.400%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.124 Acc 96.418%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.808%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.168 Acc 95.903%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.117 Acc 96.357%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.119 Acc 96.420%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.122 Acc 96.431%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.123 Acc 96.384%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.124 Acc 96.353%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.175 Acc 95.614%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.147 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.116 Acc 96.697%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.118 Acc 96.591%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.118 Acc 96.504%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.120 Acc 96.476%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.123 Acc 96.420%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.173 Acc 95.676%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.165 Acc 95.826%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.123 Acc 96.504%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.116 Acc 96.681%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.118 Acc 96.593%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.119 Acc 96.510%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.180 Acc 95.637%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.172 Acc 95.864%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.126 Acc 96.163%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.393%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.122 Acc 96.294%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.122 Acc 96.345%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.120 Acc 96.396%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.177 Acc 95.661%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.111 Acc 96.716%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.114 Acc 96.631%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.116 Acc 96.579%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.117 Acc 96.572%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.185 Acc 95.668%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.179 Acc 95.779%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.109 Acc 96.782%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.116 Acc 96.571%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.118 Acc 96.518%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.191 Acc 95.653%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.183 Acc 95.756%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.114 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.113 Acc 96.665%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.114 Acc 96.582%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.116 Acc 96.577%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.117 Acc 96.530%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.182 Acc 95.599%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.111 Acc 96.767%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.115 Acc 96.533%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.114 Acc 96.579%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.116 Acc 96.530%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.118 Acc 96.502%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.177 Acc 95.653%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.169 Acc 95.829%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.079 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.114 Acc 96.612%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.114 Acc 96.613%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.116 Acc 96.610%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.116 Acc 96.571%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.182 Acc 95.591%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.120 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.107 Acc 96.627%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.109 Acc 96.716%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.112 Acc 96.647%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.114 Acc 96.606%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.115 Acc 96.582%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.467%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.179 Acc 95.643%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.112 Acc 96.419%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.112 Acc 96.552%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.566%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.115 Acc 96.557%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.114 Acc 96.568%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.194 Acc 95.289%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.187 Acc 95.546%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.110 Acc 96.774%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.111 Acc 96.622%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.112 Acc 96.644%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.672%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.113 Acc 96.616%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.178 Acc 95.690%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.095 Acc 96.983%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.109 Acc 96.789%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.110 Acc 96.748%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.112 Acc 96.675%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.170 Acc 95.784%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.164 Acc 95.919%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.086 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.107 Acc 96.705%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.107 Acc 96.716%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.110 Acc 96.675%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.111 Acc 96.672%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.185 Acc 95.560%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.176 Acc 95.740%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.104 Acc 96.883%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.107 Acc 96.840%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.111 Acc 96.740%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.110 Acc 96.817%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.110 Acc 96.766%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.195 Acc 95.382%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.186 Acc 95.519%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.103 Acc 96.952%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.107 Acc 96.739%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.108 Acc 96.735%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.109 Acc 96.721%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.137 Acc 96.875%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.180 Acc 95.692%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.176 Acc 95.763%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.101 Acc 96.914%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.108 Acc 96.763%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.107 Acc 96.774%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.108 Acc 96.766%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.183 Acc 95.591%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.176 Acc 95.709%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.107 Acc 96.728%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.109 Acc 96.731%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.110 Acc 96.750%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.110 Acc 96.707%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.108 Acc 96.725%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.182 Acc 95.583%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.173 Acc 95.744%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.109 Acc 96.805%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.107 Acc 96.817%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.108 Acc 96.760%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.107 Acc 96.799%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.188 Acc 95.560%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.180 Acc 95.725%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 96.898%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.099 Acc 96.937%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.103 Acc 96.844%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.107 Acc 96.769%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.134 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.924%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.168 Acc 95.977%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.096 Acc 96.983%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.099 Acc 97.011%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.103 Acc 96.930%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.108 Acc 96.791%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.189 Acc 95.475%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.180 Acc 95.585%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.104 Acc 96.813%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.103 Acc 96.891%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.105 Acc 96.857%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.106 Acc 96.785%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.221 Acc 93.750%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.194 Acc 95.367%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.185 Acc 95.588%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.099 Acc 97.027%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.102 Acc 96.927%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.102 Acc 96.906%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.104 Acc 96.870%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.182 Acc 95.761%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.174 Acc 95.849%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.110 Acc 96.658%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.108 Acc 96.758%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.106 Acc 96.834%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.105 Acc 96.825%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.191 Acc 95.390%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.184 Acc 95.507%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.106 Acc 96.945%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.103 Acc 97.023%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.104 Acc 96.984%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.104 Acc 96.951%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.106 Acc 96.872%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.190 Acc 95.490%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.179 Acc 95.732%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.095 Acc 97.045%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.099 Acc 96.992%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.100 Acc 96.979%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.101 Acc 96.931%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.103 Acc 96.933%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.192 Acc 95.684%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.181 Acc 95.802%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.104 Acc 96.844%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.103 Acc 96.856%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.102 Acc 96.818%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.103 Acc 96.805%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.104 Acc 96.822%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.176 Acc 95.622%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.168 Acc 95.837%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.101 Acc 96.832%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.103 Acc 96.800%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.103 Acc 96.799%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.103 Acc 96.855%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.194 Acc 95.475%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.184 Acc 95.627%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.132 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.099 Acc 97.076%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.097 Acc 97.062%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.101 Acc 96.911%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.101 Acc 96.887%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.194 Acc 95.374%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.186 Acc 95.476%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.104 Acc 96.705%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.100 Acc 96.918%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.103 Acc 96.878%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.102 Acc 96.854%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.102 Acc 96.850%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.148 Acc 92.969%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.192 Acc 95.591%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.183 Acc 95.810%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.094 Acc 97.023%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.099 Acc 96.951%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.100 Acc 96.944%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.137 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.175 Acc 95.907%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.092 Acc 97.030%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.093 Acc 97.111%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.097 Acc 97.031%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.100 Acc 96.965%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.177 Acc 95.862%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.170 Acc 96.012%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.091 Acc 97.153%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.093 Acc 97.042%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.097 Acc 96.945%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.098 Acc 96.920%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.098 Acc 96.969%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.191 Acc 95.692%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.186 Acc 95.794%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.101 Acc 97.053%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.097 Acc 97.217%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.096 Acc 97.127%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.097 Acc 97.050%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.099 Acc 96.990%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.195 Acc 95.599%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.186 Acc 95.798%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.098 Acc 97.037%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.098 Acc 96.941%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.097 Acc 96.992%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.097 Acc 96.986%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.098 Acc 97.003%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.201 Acc 95.444%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.189 Acc 95.604%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.093 Acc 96.976%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.095 Acc 96.988%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.096 Acc 97.049%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.098 Acc 97.027%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.097 Acc 97.054%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.183 Acc 95.676%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.173 Acc 95.841%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.097 Acc 97.107%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.096 Acc 97.077%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.098 Acc 97.034%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.199 Acc 95.746%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.187 Acc 95.931%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.184 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.099 Acc 96.968%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.097 Acc 97.155%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.095 Acc 97.150%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.095 Acc 97.148%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.097 Acc 97.093%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.202 Acc 95.452%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.189 Acc 95.693%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.102 Acc 96.890%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.104 Acc 96.824%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.098 Acc 96.996%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.098 Acc 96.997%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.201 Acc 95.575%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.190 Acc 95.736%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.161 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.097 Acc 97.177%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.095 Acc 97.111%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.096 Acc 97.037%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.097 Acc 97.022%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.189 Acc 95.738%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.179 Acc 95.888%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.091 Acc 97.120%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.090 Acc 97.155%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.093 Acc 97.095%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.095 Acc 97.011%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.194 Acc 95.483%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.183 Acc 95.670%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.093 Acc 97.099%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.095 Acc 97.030%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.094 Acc 97.116%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.093 Acc 97.132%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.096 Acc 97.042%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.194 Acc 95.583%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.187 Acc 95.623%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.093 Acc 97.231%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.092 Acc 97.104%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.093 Acc 97.096%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.095 Acc 97.051%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.192 Acc 95.614%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.180 Acc 95.771%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.094 Acc 97.146%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.091 Acc 97.194%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.096 Acc 97.039%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.097 Acc 97.039%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.095 Acc 97.106%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.194 Acc 95.514%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.186 Acc 95.682%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.101 Acc 97.076%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.095 Acc 97.062%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.094 Acc 97.099%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.094 Acc 97.109%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.200 Acc 95.746%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.187 Acc 95.977%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.092 Acc 97.200%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.090 Acc 97.279%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.093 Acc 97.106%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.091 Acc 97.179%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.092 Acc 97.162%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.198 Acc 95.459%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.187 Acc 95.662%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.087 Acc 97.262%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.091 Acc 97.233%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.090 Acc 97.210%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.090 Acc 97.216%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.091 Acc 97.176%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.120 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.196 Acc 95.707%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.187 Acc 95.888%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.090 Acc 97.285%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.092 Acc 97.171%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.092 Acc 97.132%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.183 Acc 95.622%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.174 Acc 95.818%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.086 Acc 97.409%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.092 Acc 97.221%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.092 Acc 97.155%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.092 Acc 97.156%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.093 Acc 97.110%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.198 Acc 95.800%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.189 Acc 95.884%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.085 Acc 97.355%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.085 Acc 97.330%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.085 Acc 97.290%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.088 Acc 97.206%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.090 Acc 97.173%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.205 Acc 95.266%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.193 Acc 95.495%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.163 Acc 94.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.089 Acc 97.386%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.092 Acc 97.283%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.092 Acc 97.218%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.091 Acc 97.202%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.092 Acc 97.174%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.132 Acc 92.188%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.202 Acc 95.490%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.190 Acc 95.767%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.086 Acc 97.494%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.088 Acc 97.365%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.090 Acc 97.272%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.090 Acc 97.265%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.190 Acc 95.545%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.083 Acc 97.458%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.088 Acc 97.218%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.192 Acc 95.606%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.186 Acc 95.670%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.091 Acc 97.138%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.084 Acc 97.260%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.085 Acc 97.270%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.087 Acc 97.239%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.088 Acc 97.217%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.181 Acc 95.903%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.083 Acc 97.409%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.083 Acc 97.400%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.084 Acc 97.329%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.085 Acc 97.317%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.086 Acc 97.298%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.193 Acc 95.542%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.084 Acc 97.463%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.086 Acc 97.388%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.087 Acc 97.371%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.087 Acc 97.352%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.088 Acc 97.312%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.199 Acc 95.235%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.190 Acc 95.530%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.080 Acc 97.462%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.085 Acc 97.327%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.087 Acc 97.285%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.202 Acc 95.444%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.078 Acc 97.316%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.086 Acc 97.198%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.085 Acc 97.249%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.087 Acc 97.249%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.221 Acc 95.452%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.205 Acc 95.588%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.081 Acc 97.455%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.082 Acc 97.349%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.084 Acc 97.340%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.085 Acc 97.308%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.086 Acc 97.232%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.205 Acc 95.405%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.193 Acc 95.542%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.091 Acc 97.161%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.086 Acc 97.337%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.086 Acc 97.335%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.086 Acc 97.360%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.198 Acc 95.777%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.188 Acc 95.934%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.082 Acc 97.378%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.085 Acc 97.326%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.086 Acc 97.298%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.086 Acc 97.348%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.087 Acc 97.307%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.212 Acc 95.753%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.199 Acc 95.899%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.073 Acc 97.795%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.081 Acc 97.483%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.085 Acc 97.338%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.199 Acc 95.413%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.190 Acc 95.519%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.080 Acc 97.512%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.081 Acc 97.392%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.083 Acc 97.331%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.084 Acc 97.307%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.196 Acc 95.792%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.185 Acc 95.923%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.078 Acc 97.540%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.081 Acc 97.427%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.081 Acc 97.462%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.084 Acc 97.315%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.196 Acc 95.614%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.184 Acc 95.868%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.080 Acc 97.361%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.081 Acc 97.379%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.081 Acc 97.360%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.082 Acc 97.291%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.206 Acc 95.699%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.196 Acc 95.849%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.083 Acc 97.316%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.083 Acc 97.334%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.084 Acc 97.363%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.084 Acc 97.331%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.086 Acc 97.287%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.198 Acc 95.521%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.187 Acc 95.794%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.085 Acc 97.269%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.085 Acc 97.295%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.084 Acc 97.311%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.084 Acc 97.296%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.085 Acc 97.270%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.192 Acc 95.823%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.180 Acc 95.989%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.074 Acc 97.633%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.077 Acc 97.579%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.077 Acc 97.576%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.079 Acc 97.528%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.081 Acc 97.455%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.200 Acc 95.514%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.189 Acc 95.779%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.083 Acc 97.347%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.081 Acc 97.446%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.081 Acc 97.475%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.080 Acc 97.475%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.081 Acc 97.419%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.215 Acc 95.753%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.202 Acc 95.907%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.077 Acc 97.672%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.083 Acc 97.376%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.084 Acc 97.358%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.084 Acc 97.325%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.083 Acc 97.346%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.196 Acc 95.444%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.186 Acc 95.655%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.084 Acc 97.277%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.083 Acc 97.365%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.079 Acc 97.467%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.080 Acc 97.448%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.082 Acc 97.390%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.204 Acc 95.715%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.195 Acc 95.829%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.105 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.078 Acc 97.509%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.078 Acc 97.555%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.078 Acc 97.604%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.078 Acc 97.598%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.079 Acc 97.533%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.197 Acc 95.343%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.187 Acc 95.662%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.079 Acc 97.528%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.080 Acc 97.498%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.080 Acc 97.500%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.081 Acc 97.466%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.204 Acc 95.606%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.195 Acc 95.674%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.070 Acc 97.633%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.080 Acc 97.451%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.080 Acc 97.465%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.080 Acc 97.486%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.201 Acc 95.606%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.191 Acc 95.662%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.079 Acc 97.525%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.078 Acc 97.512%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.081 Acc 97.451%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.082 Acc 97.397%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.209 Acc 95.467%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.197 Acc 95.534%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.071 Acc 97.710%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.071 Acc 97.613%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.076 Acc 97.513%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.076 Acc 97.532%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.077 Acc 97.471%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.213 Acc 95.552%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.204 Acc 95.616%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.085 Acc 97.277%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.081 Acc 97.411%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.079 Acc 97.446%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.079 Acc 97.467%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.079 Acc 97.444%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.210 Acc 95.707%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.198 Acc 95.872%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.075 Acc 97.455%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.078 Acc 97.469%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.079 Acc 97.481%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.080 Acc 97.436%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.219 Acc 95.560%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.208 Acc 95.709%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.077 Acc 97.633%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.075 Acc 97.630%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.076 Acc 97.613%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.079 Acc 97.555%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.220 Acc 95.537%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.206 Acc 95.748%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.075 Acc 97.649%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.076 Acc 97.641%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.077 Acc 97.539%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.078 Acc 97.549%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.079 Acc 97.483%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.382%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.202 Acc 95.569%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.081 Acc 97.486%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.084 Acc 97.407%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.080 Acc 97.529%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.078 Acc 97.578%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.080 Acc 97.510%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.218 Acc 95.475%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.205 Acc 95.686%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.070 Acc 97.865%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.072 Acc 97.711%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.074 Acc 97.643%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.077 Acc 97.555%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.194 Acc 95.514%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.185 Acc 95.674%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.081 Acc 97.455%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.079 Acc 97.436%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.078 Acc 97.512%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.079 Acc 97.469%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.194 Acc 95.637%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.184 Acc 95.771%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.074 Acc 97.602%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.077 Acc 97.491%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.078 Acc 97.477%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.208 Acc 95.467%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.201 Acc 95.631%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.071 Acc 97.726%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.074 Acc 97.652%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.077 Acc 97.552%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.075 Acc 97.611%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.141 Acc 92.969%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.208 Acc 95.637%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.198 Acc 95.864%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.073 Acc 97.819%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.074 Acc 97.750%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.075 Acc 97.706%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.075 Acc 97.668%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.075 Acc 97.638%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.205 Acc 95.753%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.195 Acc 95.861%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.074 Acc 97.525%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.075 Acc 97.559%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.074 Acc 97.586%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.076 Acc 97.569%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.206 Acc 95.390%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.194 Acc 95.616%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.071 Acc 97.726%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.076 Acc 97.573%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.078 Acc 97.493%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.078 Acc 97.486%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.215 Acc 95.668%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.205 Acc 95.818%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.071 Acc 97.587%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.072 Acc 97.555%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.072 Acc 97.628%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.075 Acc 97.596%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.075 Acc 97.583%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.205 Acc 95.490%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.192 Acc 95.791%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.075 Acc 97.548%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.074 Acc 97.637%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.073 Acc 97.635%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.073 Acc 97.629%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.073 Acc 97.608%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.191 Acc 95.761%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.184 Acc 95.892%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.074 Acc 97.610%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.073 Acc 97.652%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.073 Acc 97.677%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.074 Acc 97.647%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.074 Acc 97.620%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.206 Acc 95.815%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.196 Acc 95.903%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.072 Acc 97.676%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.073 Acc 97.664%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.074 Acc 97.678%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.075 Acc 97.617%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.202 Acc 95.475%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.191 Acc 95.639%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.072 Acc 97.643%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.072 Acc 97.650%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.216 Acc 95.560%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.204 Acc 95.841%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.066 Acc 97.749%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.070 Acc 97.715%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.072 Acc 97.638%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.072 Acc 97.652%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.074 Acc 97.599%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.216 Acc 95.413%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.204 Acc 95.588%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.075 Acc 97.637%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.075 Acc 97.634%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.222 Acc 95.297%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.213 Acc 95.433%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.082 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.071 Acc 97.687%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.072 Acc 97.594%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.072 Acc 97.612%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.072 Acc 97.623%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.074 Acc 97.608%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.220 Acc 95.413%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.210 Acc 95.526%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.068 Acc 97.757%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.070 Acc 97.672%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.072 Acc 97.659%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.072 Acc 97.637%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.073 Acc 97.613%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.209 Acc 95.452%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.198 Acc 95.526%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.063 Acc 99.219%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.073 Acc 97.618%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.073 Acc 97.637%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.073 Acc 97.643%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.072 Acc 97.680%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.073 Acc 97.624%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.204 Acc 95.568%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.194 Acc 95.767%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.067 Acc 97.734%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.070 Acc 97.718%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.072 Acc 97.669%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.072 Acc 97.631%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.205 Acc 95.908%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.195 Acc 96.059%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.064 Acc 97.795%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.067 Acc 97.777%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.070 Acc 97.706%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.070 Acc 97.678%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.212 Acc 95.444%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.202 Acc 95.581%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.064 Acc 97.857%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.069 Acc 97.738%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.070 Acc 97.707%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.072 Acc 97.666%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.220 Acc 95.637%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.210 Acc 95.806%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.064 Acc 97.873%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.069 Acc 97.757%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.069 Acc 97.798%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.069 Acc 97.758%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.212 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.225 Acc 95.661%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.215 Acc 95.666%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.068 Acc 97.749%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.067 Acc 97.839%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.070 Acc 97.744%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.071 Acc 97.728%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.071 Acc 97.716%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.202 Acc 95.537%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.194 Acc 95.740%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.053 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.068 Acc 97.803%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.069 Acc 97.769%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.069 Acc 97.737%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.069 Acc 97.722%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.070 Acc 97.728%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.202 Acc 95.746%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.194 Acc 95.911%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.065 Acc 97.866%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.070 Acc 97.714%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.220 Acc 95.606%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.209 Acc 95.798%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.069 Acc 97.726%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.067 Acc 97.776%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.068 Acc 97.750%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.070 Acc 97.730%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.213 Acc 95.668%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.203 Acc 95.810%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.051 Acc 96.875%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.067 Acc 97.679%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.066 Acc 97.804%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.069 Acc 97.700%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.069 Acc 97.684%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.070 Acc 97.683%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.205 Acc 95.591%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.198 Acc 95.775%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.066 Acc 97.795%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.063 Acc 97.835%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.066 Acc 97.812%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.069 Acc 97.752%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.069 Acc 97.734%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.192 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.224 Acc 95.545%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.211 Acc 95.709%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.065 Acc 97.857%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.066 Acc 97.827%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.069 Acc 97.737%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.208 Acc 95.591%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.200 Acc 95.756%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.068 Acc 97.881%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.067 Acc 97.827%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.070 Acc 97.752%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.069 Acc 97.750%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.070 Acc 97.726%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.207 Acc 95.676%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.197 Acc 95.775%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.065 Acc 97.842%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.069 Acc 97.699%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.070 Acc 97.744%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.072 Acc 97.695%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.217 Acc 95.637%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.205 Acc 95.775%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.038 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.066 Acc 97.757%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.065 Acc 97.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.065 Acc 97.838%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.067 Acc 97.752%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.068 Acc 97.725%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.231 Acc 95.575%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.222 Acc 95.553%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.060 Acc 98.035%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.067 Acc 97.808%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.068 Acc 97.794%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.068 Acc 97.806%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.068 Acc 97.814%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.223 Acc 95.336%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.210 Acc 95.658%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.013 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.063 Acc 97.987%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.065 Acc 97.895%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.066 Acc 97.890%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.066 Acc 97.882%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.240 Acc 95.537%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.227 Acc 95.678%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.066 Acc 97.563%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.065 Acc 97.757%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.066 Acc 97.825%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.067 Acc 97.765%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.201 Acc 95.792%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.194 Acc 95.888%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.065 Acc 97.741%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.069 Acc 97.699%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.069 Acc 97.729%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.070 Acc 97.703%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.069 Acc 97.720%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.221 Acc 95.560%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.213 Acc 95.690%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.067 Acc 97.812%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.067 Acc 97.783%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.069 Acc 97.678%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.070 Acc 97.675%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.212 Acc 95.645%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.202 Acc 95.802%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.060 Acc 97.826%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.065 Acc 97.823%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.066 Acc 97.757%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.065 Acc 97.795%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.065 Acc 97.806%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.217 Acc 95.661%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.207 Acc 95.783%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.065 Acc 97.811%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.067 Acc 97.841%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.066 Acc 97.857%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.068 Acc 97.784%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.208 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.209 Acc 95.483%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.197 Acc 95.651%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.063 Acc 97.958%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.065 Acc 97.924%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.068 Acc 97.804%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.067 Acc 97.829%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.197 Acc 95.955%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.190 Acc 95.969%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.058 Acc 98.058%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.066 Acc 97.858%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.064 Acc 97.895%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.065 Acc 97.849%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.066 Acc 97.839%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.187 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.217 Acc 95.622%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.204 Acc 95.783%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.061 Acc 97.981%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.064 Acc 97.897%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.067 Acc 97.820%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.066 Acc 97.861%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.068 Acc 97.793%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.211 Acc 95.746%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.201 Acc 95.880%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.066 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.062 Acc 97.927%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.064 Acc 97.901%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.064 Acc 97.911%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.067 Acc 97.818%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.068 Acc 97.776%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.223 Acc 95.746%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.210 Acc 95.946%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.058 Acc 98.144%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.060 Acc 98.041%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.063 Acc 97.902%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.065 Acc 97.868%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.222 Acc 95.413%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.209 Acc 95.557%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.029 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.062 Acc 98.004%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.063 Acc 97.952%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.063 Acc 97.965%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.065 Acc 97.876%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.066 Acc 97.854%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.208 Acc 95.583%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.199 Acc 95.759%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.065 Acc 97.795%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.063 Acc 97.917%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.063 Acc 97.921%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.063 Acc 97.913%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.064 Acc 97.889%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.207 Acc 95.676%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.198 Acc 95.853%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.064 Acc 97.834%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.065 Acc 97.823%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.063 Acc 97.835%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.065 Acc 97.804%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.065 Acc 97.789%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.224 Acc 95.738%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.213 Acc 95.868%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.043%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.059 Acc 98.060%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.061 Acc 97.934%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.062 Acc 97.935%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.062 Acc 97.924%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.229 Acc 95.382%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.219 Acc 95.577%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.057 Acc 98.058%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.063 Acc 97.858%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.066 Acc 97.786%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.066 Acc 97.818%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.066 Acc 97.837%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.212 Acc 95.784%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.206 Acc 95.981%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.059 Acc 98.051%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.060 Acc 98.018%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.060 Acc 97.988%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.061 Acc 97.997%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.061 Acc 97.965%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.223 Acc 95.746%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.214 Acc 95.845%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ffe3c76f3843cb9b340569af0bcc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.309 Acc 10.156%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.213 Acc 20.227%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 1.997 Acc 28.895%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.762 Acc 37.972%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.580 Acc 44.933%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.431 Acc 50.535%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.645 Acc 78.125%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.597 Acc 81.969%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.587 Acc 82.035%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.846 Acc 75.781%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.662 Acc 79.517%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.633 Acc 80.372%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.612 Acc 81.102%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.584 Acc 81.871%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.564 Acc 82.493%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.355 Acc 89.062%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.406 Acc 88.181%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.400 Acc 88.188%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.424 Acc 88.281%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.455 Acc 85.442%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.454 Acc 85.681%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.444 Acc 86.132%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.434 Acc 86.481%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.425 Acc 86.800%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.326 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.355 Acc 89.457%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.349 Acc 89.700%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.372 Acc 85.156%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.384 Acc 88.297%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.384 Acc 88.378%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.382 Acc 88.372%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.378 Acc 88.513%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.372 Acc 88.674%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.323 Acc 91.406%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.304 Acc 91.066%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.299 Acc 91.247%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.335 Acc 89.844%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.344 Acc 89.643%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.337 Acc 89.548%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.341 Acc 89.470%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.338 Acc 89.659%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.335 Acc 89.730%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.291 Acc 91.406%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.277 Acc 92.110%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.271 Acc 92.156%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.268 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.336 Acc 89.851%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.328 Acc 90.174%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.327 Acc 90.249%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.318 Acc 90.475%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.316 Acc 90.500%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.273 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.277 Acc 91.847%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.275 Acc 91.810%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.287 Acc 91.267%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.292 Acc 91.317%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.293 Acc 91.201%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.290 Acc 91.278%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.295 Acc 91.146%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.243 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.273 Acc 92.412%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.269 Acc 92.351%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.291 Acc 91.406%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.277 Acc 91.499%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.282 Acc 91.531%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.282 Acc 91.484%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.282 Acc 91.480%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.282 Acc 91.537%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.216 Acc 88.281%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.245 Acc 92.953%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.242 Acc 92.980%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.237 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.271 Acc 91.778%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.271 Acc 91.888%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.274 Acc 91.824%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.277 Acc 91.671%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.277 Acc 91.713%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.288 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.245 Acc 93.363%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.242 Acc 93.136%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.163 Acc 91.406%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.270 Acc 91.948%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.261 Acc 92.316%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.265 Acc 92.229%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.265 Acc 92.213%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.264 Acc 92.177%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.234 Acc 93.564%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.230 Acc 93.470%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.254 Acc 92.466%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.257 Acc 92.281%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.256 Acc 92.416%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.257 Acc 92.388%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.256 Acc 92.425%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.261 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.243 Acc 93.147%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.234 Acc 93.322%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.246 Acc 90.625%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.254 Acc 92.876%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.249 Acc 92.806%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.254 Acc 92.707%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.252 Acc 92.628%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.253 Acc 92.621%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.213 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.209 Acc 94.322%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.204 Acc 94.356%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.321 Acc 93.750%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.248 Acc 92.922%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.247 Acc 92.821%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.244 Acc 92.839%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.245 Acc 92.825%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.244 Acc 92.816%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.229 Acc 93.851%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.225 Acc 93.816%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.205 Acc 94.531%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.249 Acc 92.938%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.242 Acc 93.093%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.241 Acc 93.080%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.238 Acc 93.136%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.238 Acc 93.045%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.234 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.213 Acc 94.276%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.208 Acc 94.380%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.236 Acc 93.100%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.236 Acc 93.054%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.235 Acc 93.166%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.235 Acc 93.169%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.234 Acc 93.223%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.256 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.224 Acc 93.611%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.218 Acc 93.676%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.288 Acc 90.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.233 Acc 93.232%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.232 Acc 93.260%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.231 Acc 93.374%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.228 Acc 93.466%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.231 Acc 93.368%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.194 Acc 94.763%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.188 Acc 94.831%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.311 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.234 Acc 93.286%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.224 Acc 93.482%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.220 Acc 93.605%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.222 Acc 93.571%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.225 Acc 93.494%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.211 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.220 Acc 94.067%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.214 Acc 94.255%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.208 Acc 94.036%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.216 Acc 93.905%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.219 Acc 93.792%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.217 Acc 93.773%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.216 Acc 93.781%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.232 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.200 Acc 94.678%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.194 Acc 94.796%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.183 Acc 94.531%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.214 Acc 93.704%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.215 Acc 93.789%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.216 Acc 93.708%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.216 Acc 93.746%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.218 Acc 93.748%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.200 Acc 94.748%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.196 Acc 94.726%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.201 Acc 94.005%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.209 Acc 93.991%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.209 Acc 93.950%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.209 Acc 93.958%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.214 Acc 93.836%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.186 Acc 95.111%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.181 Acc 95.118%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.198 Acc 94.261%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.200 Acc 94.263%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.203 Acc 94.189%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.208 Acc 94.048%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.208 Acc 94.034%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.169 Acc 92.188%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.203 Acc 94.423%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.198 Acc 94.512%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.195 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.208 Acc 93.889%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.210 Acc 93.925%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.208 Acc 93.906%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.207 Acc 93.943%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.207 Acc 93.962%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.199 Acc 94.593%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.196 Acc 94.551%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.196 Acc 94.423%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.199 Acc 94.333%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.198 Acc 94.269%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.203 Acc 94.163%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.201 Acc 94.190%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.194 Acc 94.856%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.188 Acc 94.951%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.236 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.202 Acc 94.485%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.195 Acc 94.422%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.198 Acc 94.269%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.200 Acc 94.268%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.202 Acc 94.191%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.171 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.187 Acc 95.073%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.182 Acc 95.114%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.194 Acc 94.454%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.193 Acc 94.446%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.196 Acc 94.448%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.194 Acc 94.447%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.197 Acc 94.357%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.213 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.198 Acc 94.655%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.193 Acc 94.660%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.192 Acc 94.438%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.199 Acc 94.376%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.197 Acc 94.435%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.196 Acc 94.409%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.196 Acc 94.396%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.186 Acc 95.042%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.181 Acc 95.106%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.183 Acc 92.969%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.196 Acc 94.346%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.198 Acc 94.306%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.191 Acc 94.518%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.194 Acc 94.442%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.195 Acc 94.444%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.186 Acc 95.243%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.351%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.182 Acc 94.848%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.187 Acc 94.671%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.187 Acc 94.599%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.187 Acc 94.543%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.188 Acc 94.561%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.190 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.191 Acc 94.895%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.184 Acc 94.994%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.184 Acc 94.686%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.189 Acc 94.586%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.188 Acc 94.518%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.189 Acc 94.584%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.189 Acc 94.553%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.184 Acc 95.258%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.178 Acc 95.254%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.219 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.183 Acc 94.833%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.185 Acc 94.671%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.184 Acc 94.695%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.188 Acc 94.582%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.186 Acc 94.623%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.177 Acc 95.250%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.184 Acc 94.616%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.188 Acc 94.586%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.191 Acc 94.599%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.188 Acc 94.627%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.187 Acc 94.640%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.187 Acc 95.042%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.182 Acc 95.002%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.176 Acc 94.887%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.831%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.180 Acc 94.861%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.180 Acc 94.843%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.181 Acc 94.812%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.175 Acc 95.410%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.174 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.177 Acc 94.926%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.182 Acc 94.955%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.181 Acc 94.962%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.181 Acc 94.890%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.181 Acc 94.891%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.187 Acc 95.119%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.181 Acc 95.130%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.173 Acc 94.957%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.179 Acc 94.873%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.180 Acc 94.804%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.180 Acc 94.761%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.179 Acc 94.754%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.184 Acc 95.166%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.178 Acc 95.340%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.180 Acc 94.918%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.180 Acc 94.846%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.843%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.181 Acc 94.872%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.180 Acc 94.873%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.173 Acc 92.188%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.539%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.192 Acc 94.648%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.327 Acc 93.750%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.174 Acc 94.895%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.181 Acc 94.873%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.177 Acc 94.960%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.176 Acc 94.985%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.175 Acc 94.987%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.184 Acc 95.390%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.178 Acc 95.367%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.171 Acc 95.196%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.169 Acc 95.118%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.170 Acc 95.092%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.172 Acc 95.034%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.173 Acc 95.047%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.183 Acc 95.065%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.178 Acc 95.239%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.137 Acc 98.438%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.163 Acc 95.080%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.174 Acc 94.928%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.171 Acc 95.022%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.173 Acc 95.112%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.173 Acc 95.085%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.173 Acc 95.413%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.167 Acc 95.623%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.418 Acc 90.625%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.167 Acc 94.995%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.168 Acc 95.083%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.169 Acc 95.058%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.170 Acc 95.042%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.172 Acc 95.010%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.176 Acc 95.266%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.164 Acc 95.135%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.168 Acc 95.095%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.074%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.170 Acc 95.125%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.171 Acc 95.118%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.421%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.171 Acc 95.390%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.199 Acc 92.969%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.173 Acc 94.949%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.168 Acc 95.103%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.168 Acc 95.079%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.137%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.167 Acc 95.146%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.182 Acc 95.359%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.177 Acc 95.421%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.165 Acc 95.374%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.165 Acc 95.359%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.170 Acc 95.253%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.170 Acc 95.196%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.169 Acc 95.213%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.187 Acc 95.243%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.179 Acc 95.351%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.114 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.162 Acc 95.266%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.159 Acc 95.476%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.160 Acc 95.416%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.162 Acc 95.377%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.165 Acc 95.341%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.190 Acc 95.374%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.184 Acc 95.367%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.155 Acc 95.475%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.164 Acc 95.250%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.160 Acc 95.341%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.161 Acc 95.318%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.162 Acc 95.291%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.176 Acc 95.475%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.172 Acc 95.425%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.163 Acc 95.413%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.168 Acc 95.176%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.165 Acc 95.266%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.163 Acc 95.344%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.164 Acc 95.345%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.170 Acc 95.591%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.163 Acc 95.744%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.160 Acc 95.421%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.157 Acc 95.507%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.159 Acc 95.437%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.160 Acc 95.414%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.161 Acc 95.414%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.088 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.179 Acc 95.336%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.417%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.164 Acc 95.243%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.164 Acc 95.246%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.161 Acc 95.287%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.163 Acc 95.266%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.161 Acc 95.339%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.182 Acc 95.351%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.177 Acc 95.363%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.155 Acc 95.506%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.154 Acc 95.546%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.157 Acc 95.489%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.157 Acc 95.484%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.159 Acc 95.461%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.102 Acc 96.875%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.178 Acc 95.336%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.173 Acc 95.402%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.089 Acc 98.438%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.148 Acc 95.753%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.155 Acc 95.569%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.155 Acc 95.564%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.157 Acc 95.542%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.157 Acc 95.540%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.185 Acc 95.266%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.152 Acc 95.630%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.152 Acc 95.666%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.154 Acc 95.593%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.158 Acc 95.488%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.158 Acc 95.531%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.172 Acc 95.676%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.165 Acc 95.763%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.156 Acc 95.421%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.155 Acc 95.449%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.154 Acc 95.538%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.153 Acc 95.624%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.153 Acc 95.646%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.180 Acc 92.969%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.192 Acc 95.096%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.186 Acc 95.095%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.142 Acc 96.009%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.146 Acc 95.833%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.146 Acc 95.832%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.151 Acc 95.727%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.150 Acc 95.777%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.177 Acc 95.459%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.172 Acc 95.522%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.171 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.151 Acc 95.730%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.154 Acc 95.763%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.155 Acc 95.699%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.154 Acc 95.712%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.155 Acc 95.660%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.165 Acc 95.869%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.161 Acc 95.915%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.151 Acc 95.612%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.151 Acc 95.614%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.153 Acc 95.622%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.152 Acc 95.621%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.182 Acc 95.545%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.174 Acc 95.553%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.144 Acc 95.978%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.150 Acc 95.697%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.151 Acc 95.640%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.150 Acc 95.700%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.150 Acc 95.765%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.128 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.176 Acc 95.707%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.172 Acc 95.666%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.140 Acc 95.900%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.145 Acc 95.965%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.144 Acc 95.871%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.149 Acc 95.764%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.149 Acc 95.707%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.135 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.174 Acc 95.484%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.147 Acc 95.947%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.148 Acc 95.934%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.149 Acc 95.806%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.147 Acc 95.763%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.149 Acc 95.780%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.138 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.184 Acc 95.343%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.178 Acc 95.375%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.141 Acc 96.009%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.144 Acc 95.839%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.148 Acc 95.743%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.149 Acc 95.648%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.174 Acc 95.707%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.658%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.299 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.134 Acc 96.248%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.136 Acc 96.137%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.142 Acc 95.907%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.144 Acc 95.872%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.145 Acc 95.807%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.172 Acc 95.467%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.168 Acc 95.499%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.201 Acc 96.094%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.147 Acc 95.900%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.149 Acc 95.829%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.147 Acc 95.832%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.143 Acc 95.911%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.145 Acc 95.893%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.171 Acc 95.684%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.168 Acc 95.756%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.142 Acc 95.962%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.143 Acc 95.861%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.143 Acc 95.881%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.144 Acc 95.887%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.145 Acc 95.858%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.560%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.170 Acc 95.600%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.191 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.722%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.139 Acc 95.977%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.142 Acc 95.920%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.144 Acc 95.874%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.146 Acc 95.847%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.183 Acc 95.591%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.176 Acc 95.588%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.141 Acc 95.885%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.143 Acc 95.833%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.142 Acc 95.785%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.143 Acc 95.850%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.143 Acc 95.879%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.181 Acc 95.374%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.174 Acc 95.557%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.152 Acc 95.885%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.148 Acc 95.814%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.144 Acc 95.876%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.144 Acc 95.903%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.142 Acc 95.910%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.165 Acc 95.869%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.160 Acc 95.864%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.131 Acc 96.233%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.136 Acc 96.051%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.141 Acc 95.967%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.178 Acc 95.668%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.175 Acc 95.592%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.131 Acc 96.241%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.136 Acc 96.012%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.136 Acc 96.125%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.138 Acc 96.029%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.139 Acc 96.033%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.181 Acc 95.722%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.174 Acc 95.794%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.141 Acc 95.978%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.138 Acc 96.028%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.141 Acc 96.006%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.143 Acc 95.928%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.141 Acc 95.986%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.179 Acc 95.684%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.174 Acc 95.565%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.146 Acc 95.715%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.138 Acc 95.892%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.136 Acc 95.938%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.137 Acc 95.963%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.138 Acc 95.988%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.170 Acc 95.748%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.136 Acc 95.978%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.135 Acc 96.067%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.137 Acc 96.022%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.139 Acc 95.936%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.115 Acc 97.656%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.179 Acc 95.622%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.172 Acc 95.752%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.066 Acc 99.219%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.134 Acc 96.264%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.134 Acc 96.230%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.134 Acc 96.234%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.136 Acc 96.107%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.136 Acc 96.102%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.168 Acc 95.643%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.095 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.130 Acc 96.152%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.134 Acc 96.083%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.134 Acc 96.065%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.136 Acc 96.081%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.167 Acc 95.885%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.162 Acc 95.927%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.072 Acc 99.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.129 Acc 96.380%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.132 Acc 96.241%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.131 Acc 96.205%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.135 Acc 96.113%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.136 Acc 96.064%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.173 Acc 95.784%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.167 Acc 95.822%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.127 Acc 96.496%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.131 Acc 96.323%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.135 Acc 96.084%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.069 Acc 97.656%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.168 Acc 95.893%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.162 Acc 95.931%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.137 Acc 96.279%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.138 Acc 96.160%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.136 Acc 96.120%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.134 Acc 96.109%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.134 Acc 96.084%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.179 Acc 95.661%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.175 Acc 95.600%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.140 Acc 97.656%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.140 Acc 96.109%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.138 Acc 96.109%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.138 Acc 96.078%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.139 Acc 96.000%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.137 Acc 96.064%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.181 Acc 95.800%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.176 Acc 95.783%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.121 Acc 96.604%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.128 Acc 96.292%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.131 Acc 96.268%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.130 Acc 96.246%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.131 Acc 96.215%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.168 Acc 95.707%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.164 Acc 95.892%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.132 Acc 96.187%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.132 Acc 96.164%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.129 Acc 96.203%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.132 Acc 96.133%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.133 Acc 96.131%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.173 Acc 95.521%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.120 Acc 96.558%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.126 Acc 96.377%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.128 Acc 96.377%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.128 Acc 96.320%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.129 Acc 96.298%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.126 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.174 Acc 95.614%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.169 Acc 95.662%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.125 Acc 96.397%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.126 Acc 96.416%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.131 Acc 96.289%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.131 Acc 96.231%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.179 Acc 95.483%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.173 Acc 95.596%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.123 Acc 96.210%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.122 Acc 96.343%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.124 Acc 96.369%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.126 Acc 96.347%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.127 Acc 96.335%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.123 Acc 96.875%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.166 Acc 96.009%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.162 Acc 96.070%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.124 Acc 96.388%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.133 Acc 96.122%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.131 Acc 96.178%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.132 Acc 96.151%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.175 Acc 95.833%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.292 Acc 94.531%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.125 Acc 96.233%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.124 Acc 96.292%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.128 Acc 96.239%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.126 Acc 96.308%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.128 Acc 96.275%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.177 Acc 95.577%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.130 Acc 96.310%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.128 Acc 96.261%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.127 Acc 96.249%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.128 Acc 96.226%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.129 Acc 96.201%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.071 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.171 Acc 95.769%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.165 Acc 95.907%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.124 Acc 96.481%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.132 Acc 96.238%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.127 Acc 96.307%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.126 Acc 96.341%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.126 Acc 96.329%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.081 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.182 Acc 95.869%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.174 Acc 95.903%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.127 Acc 96.272%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.125 Acc 96.401%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.126 Acc 96.358%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.128 Acc 96.289%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.186 Acc 95.529%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.178 Acc 95.573%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.122 Acc 96.318%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.122 Acc 96.397%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.126 Acc 96.286%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.124 Acc 96.329%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.127 Acc 96.247%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.172 Acc 95.947%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.165 Acc 96.012%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.124 Acc 96.426%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.125 Acc 96.420%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.122 Acc 96.452%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.124 Acc 96.419%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.124 Acc 96.393%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.082 Acc 96.875%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.722%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.170 Acc 95.787%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.190 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.129 Acc 96.078%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.122 Acc 96.253%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.122 Acc 96.322%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.121 Acc 96.337%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.122 Acc 96.334%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.181 Acc 95.468%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.120 Acc 96.419%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.126 Acc 96.343%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.124 Acc 96.309%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.124 Acc 96.242%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.124 Acc 96.254%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.114 Acc 97.656%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.166 Acc 95.978%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.161 Acc 95.993%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.124 Acc 96.496%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.124 Acc 96.335%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.121 Acc 96.436%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.123 Acc 96.401%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.179 Acc 95.575%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.173 Acc 95.775%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.111 Acc 96.566%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.116 Acc 96.541%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.118 Acc 96.538%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.120 Acc 96.495%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.121 Acc 96.501%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.199 Acc 95.328%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.193 Acc 95.324%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.120 Acc 96.475%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.122 Acc 96.470%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.120 Acc 96.520%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.122 Acc 96.482%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.175 Acc 95.583%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.170 Acc 95.682%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.118 Acc 96.479%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.120 Acc 96.411%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.121 Acc 96.420%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.084 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.178 Acc 95.753%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.171 Acc 95.822%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.113 Acc 96.774%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.115 Acc 96.786%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.115 Acc 96.724%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.116 Acc 96.643%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.118 Acc 96.601%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.179 Acc 95.645%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.171 Acc 95.759%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.121 Acc 96.350%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.119 Acc 96.457%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.121 Acc 96.415%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.121 Acc 96.392%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.181 Acc 95.668%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.176 Acc 95.670%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.176 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.119 Acc 96.627%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.115 Acc 96.657%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.114 Acc 96.667%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.118 Acc 96.557%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.120 Acc 96.496%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.078 Acc 98.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.171 Acc 95.908%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.165 Acc 95.911%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.114 Acc 96.426%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.118 Acc 96.416%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.118 Acc 96.457%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.116 Acc 96.552%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.117 Acc 96.513%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.180 Acc 95.668%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.174 Acc 95.725%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.112 Acc 96.689%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.116 Acc 96.692%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.115 Acc 96.711%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.117 Acc 96.608%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.119 Acc 96.571%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.087 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.184 Acc 95.622%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.178 Acc 95.647%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.124 Acc 94.531%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.109 Acc 96.542%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.108 Acc 96.549%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.111 Acc 96.623%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.113 Acc 96.585%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.115 Acc 96.579%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.183 Acc 95.575%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.178 Acc 95.608%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.113 Acc 96.558%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.114 Acc 96.661%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.111 Acc 96.763%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.112 Acc 96.686%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.114 Acc 96.633%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.096 Acc 98.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.172 Acc 95.970%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.166 Acc 96.020%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.106 Acc 96.898%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.110 Acc 96.727%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.112 Acc 96.683%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.115 Acc 96.624%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.116 Acc 96.552%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.132 Acc 97.656%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.181 Acc 95.661%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.175 Acc 95.631%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.051 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.107 Acc 96.914%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.113 Acc 96.692%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.115 Acc 96.628%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.116 Acc 96.591%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.192 Acc 95.475%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.185 Acc 95.604%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.106 Acc 96.937%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.112 Acc 96.747%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.110 Acc 96.808%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.112 Acc 96.744%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.113 Acc 96.664%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.128 Acc 97.656%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.529%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.169 Acc 95.627%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.106 Acc 96.782%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.109 Acc 96.688%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.113 Acc 96.605%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.115 Acc 96.559%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.114 Acc 96.562%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.183 Acc 95.343%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.176 Acc 95.382%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.103 Acc 96.860%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.110 Acc 96.708%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.113 Acc 96.654%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.114 Acc 96.625%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.142 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.175 Acc 95.862%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.169 Acc 95.876%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.109 Acc 96.821%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.113 Acc 96.683%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.114 Acc 96.624%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.174 Acc 95.661%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.167 Acc 95.802%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.096 Acc 97.239%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.102 Acc 97.003%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.105 Acc 96.924%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.108 Acc 96.830%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.109 Acc 96.799%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.614%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.178 Acc 95.748%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.107 Acc 97.084%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.106 Acc 96.968%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.107 Acc 96.922%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.111 Acc 96.803%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.113 Acc 96.728%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.184 Acc 95.645%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.178 Acc 95.709%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.105 Acc 96.860%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.108 Acc 96.770%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.109 Acc 96.735%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.110 Acc 96.704%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.113 Acc 96.668%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.115 Acc 96.875%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.187 Acc 95.661%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.178 Acc 95.833%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.103 Acc 96.890%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.104 Acc 96.891%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.108 Acc 96.810%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.109 Acc 96.776%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.110 Acc 96.744%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.168 Acc 95.845%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.106 Acc 96.782%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.108 Acc 96.844%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.110 Acc 96.771%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.110 Acc 96.774%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.111 Acc 96.744%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.182 Acc 95.715%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.175 Acc 95.837%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.111 Acc 96.686%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.189 Acc 95.568%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.179 Acc 95.728%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.151 Acc 96.875%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.104 Acc 96.852%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.103 Acc 96.883%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.105 Acc 96.761%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.108 Acc 96.709%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.110 Acc 96.685%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 95.784%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.165 Acc 95.880%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.126 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.106 Acc 96.968%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.107 Acc 96.906%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.108 Acc 96.911%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.107 Acc 96.879%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.108 Acc 96.817%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.123 Acc 96.875%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.182 Acc 95.545%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.175 Acc 95.623%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.105 Acc 96.829%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.103 Acc 96.922%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.106 Acc 96.870%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.107 Acc 96.865%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.109 Acc 96.820%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.179 Acc 95.715%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.172 Acc 95.837%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.123 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.101 Acc 96.813%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.103 Acc 96.747%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.107 Acc 96.711%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.106 Acc 96.700%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.108 Acc 96.650%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.180 Acc 95.893%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.172 Acc 95.861%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.100 Acc 97.037%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.100 Acc 97.011%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.104 Acc 96.901%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.105 Acc 96.869%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.107 Acc 96.834%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.183 Acc 95.715%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.176 Acc 95.713%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.094 Acc 97.161%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.103 Acc 96.957%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.105 Acc 96.932%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.106 Acc 96.857%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.107 Acc 96.834%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.187 Acc 95.328%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.181 Acc 95.515%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.152 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.104 Acc 96.790%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.106 Acc 96.770%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.105 Acc 96.823%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.105 Acc 96.834%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.107 Acc 96.792%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.102 Acc 97.656%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.185 Acc 95.637%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.178 Acc 95.771%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.100 Acc 96.976%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.095 Acc 97.042%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.101 Acc 96.901%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.105 Acc 96.828%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.106 Acc 96.791%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.189 Acc 95.405%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.182 Acc 95.608%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.098 Acc 97.246%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.097 Acc 97.287%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.098 Acc 97.168%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.102 Acc 97.058%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.102 Acc 97.008%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.076 Acc 98.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.184 Acc 95.583%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.176 Acc 95.682%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.100 Acc 95.312%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.097 Acc 97.115%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.097 Acc 97.034%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.101 Acc 96.994%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.103 Acc 96.904%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.104 Acc 96.898%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.189 Acc 95.429%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.183 Acc 95.522%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.135 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.099 Acc 97.068%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.101 Acc 97.062%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.102 Acc 96.981%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.101 Acc 96.988%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.104 Acc 96.908%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.192 Acc 95.653%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.183 Acc 95.740%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.103 Acc 96.852%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.105 Acc 96.758%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.106 Acc 96.776%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.106 Acc 96.764%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.106 Acc 96.778%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.113 Acc 96.875%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.181 Acc 95.459%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.172 Acc 95.701%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.103 Acc 97.045%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.104 Acc 96.887%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.104 Acc 96.922%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.104 Acc 96.887%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.106 Acc 96.810%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.173 Acc 95.800%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 95.868%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.100 Acc 97.014%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.098 Acc 96.980%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.100 Acc 96.888%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.103 Acc 96.832%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.102 Acc 96.861%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.054 Acc 98.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.180 Acc 95.715%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.173 Acc 95.783%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.099 Acc 96.983%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.101 Acc 96.980%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.104 Acc 96.888%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.103 Acc 96.894%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.182 Acc 96.001%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.173 Acc 96.051%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.076 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.094 Acc 97.138%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.097 Acc 97.038%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.102 Acc 96.869%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.105 Acc 96.777%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.181 Acc 95.684%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.177 Acc 95.713%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.097 Acc 97.058%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.102 Acc 96.966%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.102 Acc 96.939%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.103 Acc 96.883%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.186 Acc 95.545%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.178 Acc 95.655%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.092 Acc 97.239%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.096 Acc 97.108%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.100 Acc 96.987%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.102 Acc 96.912%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.116 Acc 97.656%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.184 Acc 95.661%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.833%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.095 Acc 97.092%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.098 Acc 96.979%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.102 Acc 96.924%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.102 Acc 96.914%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.194 Acc 95.792%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.184 Acc 95.837%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.092 Acc 97.432%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.095 Acc 97.275%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.097 Acc 97.140%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.098 Acc 97.070%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.099 Acc 97.022%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.174 Acc 95.822%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.102 Acc 96.960%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.100 Acc 96.997%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.099 Acc 97.031%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.099 Acc 97.012%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.190 Acc 95.715%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.181 Acc 95.798%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.106 Acc 96.728%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.102 Acc 96.824%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.103 Acc 96.776%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.103 Acc 96.811%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.105 Acc 96.799%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.076 Acc 97.656%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.196 Acc 95.653%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.187 Acc 95.752%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.195 Acc 92.969%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.106 Acc 96.852%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.101 Acc 97.120%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.098 Acc 97.145%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.098 Acc 97.083%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.100 Acc 97.054%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.192 Acc 95.374%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.182 Acc 95.596%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.094 Acc 97.192%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.094 Acc 97.178%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.096 Acc 97.153%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.098 Acc 97.072%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.098 Acc 97.040%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.080 Acc 98.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.187 Acc 95.521%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.181 Acc 95.651%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.091 Acc 97.215%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.097 Acc 97.108%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.097 Acc 97.057%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.097 Acc 97.117%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.099 Acc 97.051%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.194 Acc 95.467%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.186 Acc 95.643%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.095 Acc 96.898%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.098 Acc 96.987%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.097 Acc 96.994%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.098 Acc 96.961%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.182 Acc 95.643%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.094 Acc 97.200%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.097 Acc 97.069%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.100 Acc 96.982%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.098 Acc 97.043%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.073 Acc 98.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.182 Acc 95.815%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.175 Acc 95.880%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.095 Acc 96.960%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.093 Acc 97.104%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.094 Acc 97.114%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.097 Acc 97.083%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.124 Acc 97.656%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.196 Acc 95.707%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.187 Acc 95.725%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.093 Acc 96.991%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.095 Acc 97.044%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.095 Acc 97.037%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.097 Acc 97.020%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.083 Acc 97.656%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.183 Acc 95.645%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.176 Acc 95.697%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.092 Acc 97.123%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.095 Acc 97.062%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.096 Acc 97.080%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.096 Acc 97.079%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.098 Acc 97.656%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.183 Acc 95.637%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.176 Acc 95.713%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.101 Acc 98.438%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.089 Acc 97.416%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.094 Acc 97.209%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.095 Acc 97.199%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.094 Acc 97.189%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.094 Acc 97.178%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.188 Acc 95.645%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.179 Acc 95.736%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.112 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.096 Acc 96.991%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.094 Acc 97.174%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.094 Acc 97.127%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.095 Acc 97.107%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.098 Acc 97.032%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.187 Acc 95.738%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.178 Acc 95.857%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.145 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.094 Acc 97.174%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.093 Acc 97.166%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.094 Acc 97.173%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.096 Acc 97.139%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.092 Acc 96.875%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.184 Acc 95.614%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.177 Acc 95.666%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.089 Acc 97.260%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.091 Acc 97.207%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.094 Acc 97.089%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.094 Acc 97.081%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.188 Acc 95.722%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.181 Acc 95.841%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.083 Acc 97.556%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.087 Acc 97.419%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.089 Acc 97.293%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.092 Acc 97.157%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.094 Acc 97.129%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.077 Acc 98.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.189 Acc 95.560%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.177 Acc 95.740%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.087 Acc 97.287%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.090 Acc 97.210%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.092 Acc 97.113%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.092 Acc 97.146%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.177 Acc 95.810%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.087 Acc 97.370%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.092 Acc 97.349%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.093 Acc 97.259%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.096 Acc 97.146%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.096 Acc 97.125%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.177 Acc 95.705%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.088 Acc 97.401%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.091 Acc 97.341%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.092 Acc 97.285%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.091 Acc 97.241%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.093 Acc 97.185%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.097 Acc 97.656%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.196 Acc 95.606%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.188 Acc 95.635%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.092 Acc 97.037%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.090 Acc 97.170%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.093 Acc 97.046%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.095 Acc 97.029%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.096 Acc 96.987%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.125 Acc 97.656%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.207 Acc 95.336%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.196 Acc 95.484%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.090 Acc 97.138%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.090 Acc 97.104%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.091 Acc 97.137%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.092 Acc 97.120%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.093 Acc 97.115%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.192 Acc 95.552%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.186 Acc 95.651%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.085 Acc 97.316%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.086 Acc 97.330%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.090 Acc 97.184%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.092 Acc 97.146%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.090 Acc 97.171%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.077 Acc 97.656%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.197 Acc 95.506%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.187 Acc 95.666%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.076 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.093 Acc 97.115%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.091 Acc 97.159%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.092 Acc 97.153%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.092 Acc 97.146%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.093 Acc 97.129%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.190 Acc 95.692%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.180 Acc 95.853%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.088 Acc 97.299%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.093 Acc 97.158%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.094 Acc 97.095%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.095 Acc 97.051%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.200 Acc 95.336%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.190 Acc 95.538%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.089 Acc 97.239%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.092 Acc 97.143%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.092 Acc 97.168%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.093 Acc 97.087%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.093 Acc 97.092%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.089 Acc 96.875%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.193 Acc 95.583%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.182 Acc 95.763%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.082 Acc 97.463%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.093 Acc 97.109%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.092 Acc 97.154%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.083 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.189 Acc 95.661%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.182 Acc 95.728%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.099 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.090 Acc 97.099%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.091 Acc 97.077%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.090 Acc 97.140%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.088 Acc 97.167%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.090 Acc 97.149%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.191 Acc 95.738%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.087 Acc 97.177%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.088 Acc 97.194%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.090 Acc 97.212%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.090 Acc 97.245%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.091 Acc 97.188%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.199 Acc 95.490%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.186 Acc 95.728%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.185 Acc 94.531%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.089 Acc 97.228%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.091 Acc 97.224%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.092 Acc 97.181%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.198 Acc 95.568%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.190 Acc 95.697%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.091 Acc 97.061%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.090 Acc 97.097%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.090 Acc 97.202%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.090 Acc 97.209%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.133 Acc 98.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.198 Acc 95.707%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.190 Acc 95.721%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.080 Acc 97.486%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.087 Acc 97.345%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.089 Acc 97.243%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.090 Acc 97.268%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.203 Acc 95.173%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.192 Acc 95.390%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.086 Acc 97.198%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.089 Acc 97.181%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.089 Acc 97.216%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.090 Acc 97.202%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.207 Acc 95.405%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.198 Acc 95.553%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.090 Acc 97.239%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.088 Acc 97.268%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.090 Acc 97.251%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.090 Acc 97.195%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.091 Acc 97.149%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.132 Acc 97.656%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.190 Acc 95.506%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.181 Acc 95.643%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.085 Acc 97.362%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.087 Acc 97.310%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.088 Acc 97.288%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.088 Acc 97.284%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.088 Acc 97.260%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.193 Acc 95.467%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.184 Acc 95.635%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.083 Acc 97.362%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.089 Acc 97.201%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.088 Acc 97.251%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.088 Acc 97.241%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.090 Acc 97.235%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.118 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.189 Acc 95.692%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.181 Acc 95.771%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.089 Acc 97.260%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.089 Acc 97.282%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.089 Acc 97.269%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.089 Acc 97.262%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.197 Acc 95.444%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.187 Acc 95.596%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.117 Acc 94.531%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.083 Acc 97.409%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.085 Acc 97.334%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.087 Acc 97.228%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.088 Acc 97.212%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.089 Acc 97.182%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.200 Acc 95.637%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.190 Acc 95.787%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.081 Acc 97.300%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.084 Acc 97.310%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.084 Acc 97.366%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.084 Acc 97.385%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.087 Acc 97.294%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.193 Acc 95.699%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.184 Acc 95.783%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.078 Acc 97.517%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.082 Acc 97.357%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.084 Acc 97.290%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.083 Acc 97.366%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.085 Acc 97.329%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.199 Acc 95.614%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.188 Acc 95.791%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.082 Acc 97.494%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.085 Acc 97.299%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.088 Acc 97.251%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.086 Acc 97.294%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.087 Acc 97.271%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.198 Acc 95.653%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.189 Acc 95.767%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.087 Acc 97.316%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.090 Acc 97.186%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.092 Acc 97.127%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.092 Acc 97.119%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.090 Acc 97.160%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.133 Acc 96.875%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.195 Acc 95.351%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.187 Acc 95.522%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.078 Acc 97.525%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.083 Acc 97.322%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.088 Acc 97.224%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.089 Acc 97.248%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.127 Acc 98.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.196 Acc 95.684%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.186 Acc 95.931%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.082 Acc 97.409%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.084 Acc 97.338%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.085 Acc 97.358%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.086 Acc 97.346%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.123 Acc 97.656%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.199 Acc 95.336%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.191 Acc 95.487%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.081 Acc 97.478%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.084 Acc 97.419%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.088 Acc 97.301%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.086 Acc 97.323%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.086 Acc 97.319%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.205 Acc 95.722%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.194 Acc 95.759%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.085 Acc 97.215%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.085 Acc 97.275%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.087 Acc 97.225%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.085 Acc 97.329%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.086 Acc 97.294%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.201 Acc 95.421%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.191 Acc 95.596%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.083 Acc 97.478%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.084 Acc 97.388%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.084 Acc 97.433%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.085 Acc 97.360%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.086 Acc 97.324%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.135 Acc 98.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.208 Acc 95.320%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.200 Acc 95.484%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.081 Acc 97.339%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.083 Acc 97.396%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.083 Acc 97.428%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.084 Acc 97.372%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.086 Acc 97.284%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.098 Acc 97.656%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.187 Acc 95.761%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.179 Acc 95.911%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.086 Acc 97.177%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.084 Acc 97.291%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.084 Acc 97.332%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.084 Acc 97.337%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.084 Acc 97.340%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.102 Acc 97.656%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.205 Acc 95.514%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.192 Acc 95.736%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.077 Acc 97.509%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.080 Acc 97.392%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.084 Acc 97.282%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.087 Acc 97.196%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.086 Acc 97.202%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.108 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.220 Acc 95.676%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.207 Acc 95.787%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.076 Acc 97.602%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.079 Acc 97.563%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.083 Acc 97.381%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.084 Acc 97.371%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.056 Acc 98.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.201 Acc 95.490%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.190 Acc 95.759%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.187 Acc 93.750%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.088 Acc 97.198%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.086 Acc 97.265%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.088 Acc 97.234%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.114 Acc 97.656%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.208 Acc 95.467%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.196 Acc 95.565%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.203 Acc 89.844%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.080 Acc 97.277%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.079 Acc 97.338%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.081 Acc 97.399%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.083 Acc 97.329%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.084 Acc 97.291%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.107 Acc 97.656%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.201 Acc 95.568%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.192 Acc 95.779%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.080 Acc 97.532%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.081 Acc 97.493%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.083 Acc 97.448%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.082 Acc 97.441%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.081 Acc 98.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.191 Acc 95.777%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.182 Acc 95.896%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.078 Acc 97.579%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.080 Acc 97.560%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.081 Acc 97.473%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.083 Acc 97.425%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.208 Acc 95.475%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.199 Acc 95.612%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.076 Acc 97.556%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.083 Acc 97.353%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.083 Acc 97.341%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.083 Acc 97.365%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.089 Acc 97.656%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.201 Acc 95.753%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.190 Acc 95.849%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.080 Acc 97.525%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.082 Acc 97.469%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.084 Acc 97.407%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.083 Acc 97.439%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.205 Acc 95.606%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.194 Acc 95.713%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.077 Acc 97.525%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.082 Acc 97.411%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.081 Acc 97.459%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.081 Acc 97.432%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.082 Acc 97.404%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.200 Acc 95.707%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.189 Acc 95.849%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.082 Acc 97.415%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.083 Acc 97.387%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.083 Acc 97.362%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.104 Acc 97.656%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.195 Acc 95.637%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.188 Acc 95.721%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.078 Acc 97.424%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.080 Acc 97.431%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.081 Acc 97.397%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.082 Acc 97.374%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.197 Acc 95.637%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.189 Acc 95.779%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.078 Acc 97.424%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.081 Acc 97.334%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.082 Acc 97.379%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.081 Acc 97.440%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.082 Acc 97.377%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.203 Acc 95.398%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.191 Acc 95.573%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.079 Acc 97.401%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.081 Acc 97.396%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.081 Acc 97.379%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.080 Acc 97.450%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.206 Acc 95.560%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.194 Acc 95.697%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.078 Acc 97.625%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.080 Acc 97.586%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.079 Acc 97.597%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.079 Acc 97.592%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.081 Acc 97.555%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.436%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.188 Acc 95.484%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.079 Acc 97.432%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.077 Acc 97.501%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.078 Acc 97.508%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.080 Acc 97.450%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.081 Acc 97.429%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.198 Acc 95.684%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.190 Acc 95.767%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.072 Acc 97.811%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.075 Acc 97.651%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.078 Acc 97.567%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.201 Acc 95.637%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.192 Acc 95.682%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.075 Acc 97.625%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.079 Acc 97.458%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.078 Acc 97.501%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.079 Acc 97.485%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.081 Acc 97.450%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.132 Acc 96.875%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.204 Acc 95.351%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.193 Acc 95.522%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.075 Acc 97.556%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.078 Acc 97.431%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.078 Acc 97.469%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.079 Acc 97.456%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.079 Acc 97.478%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.203 Acc 95.661%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.195 Acc 95.756%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.076 Acc 97.664%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.078 Acc 97.602%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.079 Acc 97.550%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.078 Acc 97.516%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.079 Acc 97.513%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.209 Acc 95.436%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.200 Acc 95.655%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.072 Acc 97.757%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.080 Acc 97.528%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.079 Acc 97.519%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.079 Acc 97.496%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.079 Acc 97.475%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.206 Acc 95.359%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.200 Acc 95.472%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.076 Acc 97.641%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.080 Acc 97.428%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.080 Acc 97.426%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.080 Acc 97.416%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.213 Acc 95.537%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.202 Acc 95.658%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3569378e5fdb44eb92ce969047f8df3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.315 Acc 12.500%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.246 Acc 18.967%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.060 Acc 26.322%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.784 Acc 37.111%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.570 Acc 45.225%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.394 Acc 51.790%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.626 Acc 80.469%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.592 Acc 81.095%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.579 Acc 81.573%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.633 Acc 74.219%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.516 Acc 84.120%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.495 Acc 84.810%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.474 Acc 85.535%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.460 Acc 85.955%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.449 Acc 86.320%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.370 Acc 87.500%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.362 Acc 89.163%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.355 Acc 89.401%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.345 Acc 88.281%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.372 Acc 88.846%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.369 Acc 88.895%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.364 Acc 88.995%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.363 Acc 89.022%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.356 Acc 89.240%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.353 Acc 89.712%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.350 Acc 89.848%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.317 Acc 90.625%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.322 Acc 89.975%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.319 Acc 90.302%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.319 Acc 90.238%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.321 Acc 90.253%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.318 Acc 90.349%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.264 Acc 90.625%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.293 Acc 91.925%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.287 Acc 91.985%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.330 Acc 91.406%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.310 Acc 90.702%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.298 Acc 91.053%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.296 Acc 91.230%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.291 Acc 91.301%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.289 Acc 91.372%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.320 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.291 Acc 91.499%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.286 Acc 91.402%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.399 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.280 Acc 91.654%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.277 Acc 91.589%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.272 Acc 91.780%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.272 Acc 91.835%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.273 Acc 91.852%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.246 Acc 92.969%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.243 Acc 93.108%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.237 Acc 93.229%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.242 Acc 93.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.270 Acc 92.133%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.255 Acc 92.510%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.257 Acc 92.413%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.255 Acc 92.515%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.255 Acc 92.527%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.250 Acc 93.688%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.247 Acc 93.738%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.187 Acc 95.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.236 Acc 92.969%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.246 Acc 92.829%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.244 Acc 92.777%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.245 Acc 92.700%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.244 Acc 92.763%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.221 Acc 94.083%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.218 Acc 94.100%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.168 Acc 96.094%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.238 Acc 93.069%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.242 Acc 92.953%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.237 Acc 93.088%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.237 Acc 93.080%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.236 Acc 93.126%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.222 Acc 94.106%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.219 Acc 94.034%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.231 Acc 93.317%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.233 Acc 93.151%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.234 Acc 93.174%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.231 Acc 93.224%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.230 Acc 93.306%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.245 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.222 Acc 94.044%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.218 Acc 94.030%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.215 Acc 93.657%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.212 Acc 93.769%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.215 Acc 93.760%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.220 Acc 93.678%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.222 Acc 93.613%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.215 Acc 94.253%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.211 Acc 94.298%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.168 Acc 96.875%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.218 Acc 93.742%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.215 Acc 93.773%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.214 Acc 93.721%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.214 Acc 93.732%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.215 Acc 93.775%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.206 Acc 94.578%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.204 Acc 94.547%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.240 Acc 91.406%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.191 Acc 94.400%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.201 Acc 94.290%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.204 Acc 94.124%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.206 Acc 94.103%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.208 Acc 94.038%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.228 Acc 93.936%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.227 Acc 93.925%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.249 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.207 Acc 93.912%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.205 Acc 94.030%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.204 Acc 94.202%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.205 Acc 94.116%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.204 Acc 94.141%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.231 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.210 Acc 94.678%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.208 Acc 94.706%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.193 Acc 94.307%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.195 Acc 94.317%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.194 Acc 94.427%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.196 Acc 94.401%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.197 Acc 94.357%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.205 Acc 94.361%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.207 Acc 94.201%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.163 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.192 Acc 94.570%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.193 Acc 94.430%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.191 Acc 94.534%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.190 Acc 94.601%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.193 Acc 94.537%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.254 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.216 Acc 94.237%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.214 Acc 94.201%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.251 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.182 Acc 94.670%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.184 Acc 94.609%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.188 Acc 94.557%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.190 Acc 94.494%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.192 Acc 94.438%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.193 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.192 Acc 95.011%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.189 Acc 94.990%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.172 Acc 94.995%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.181 Acc 94.819%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.180 Acc 94.923%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.181 Acc 94.859%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.181 Acc 94.835%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.284 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.224 Acc 94.175%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.225 Acc 94.038%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.209 Acc 95.312%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.169 Acc 95.251%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.172 Acc 94.982%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.173 Acc 94.931%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.177 Acc 94.827%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.181 Acc 94.762%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.188 Acc 94.988%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.186 Acc 95.052%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.175 Acc 95.189%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.177 Acc 95.079%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.179 Acc 94.939%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.180 Acc 94.977%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.178 Acc 94.987%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.189 Acc 94.810%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.188 Acc 94.838%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.176 Acc 95.173%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.169 Acc 95.344%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.171 Acc 95.219%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.171 Acc 95.225%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.171 Acc 95.186%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.186 Acc 95.343%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.185 Acc 95.278%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.165 Acc 95.506%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.168 Acc 95.417%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.171 Acc 95.294%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.169 Acc 95.342%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.170 Acc 95.309%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.187 Acc 95.289%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.187 Acc 95.297%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.166 Acc 95.459%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.159 Acc 95.561%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.159 Acc 95.528%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.162 Acc 95.437%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.162 Acc 95.422%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.204 Acc 94.949%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.203 Acc 94.885%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.166 Acc 95.374%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.161 Acc 95.441%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.161 Acc 95.393%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.159 Acc 95.453%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.160 Acc 95.461%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.192 Acc 95.483%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.193 Acc 95.347%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.165 Acc 97.656%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.159 Acc 95.575%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.156 Acc 95.588%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.160 Acc 95.476%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.159 Acc 95.509%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.158 Acc 95.545%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.177 Acc 95.235%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.174 Acc 95.344%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.147 Acc 95.761%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.153 Acc 95.666%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.155 Acc 95.559%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.155 Acc 95.515%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.159 Acc 95.433%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.180 Acc 95.627%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.146 Acc 95.746%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.154 Acc 95.674%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.151 Acc 95.715%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.155 Acc 95.599%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.154 Acc 95.582%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.146 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.168 Acc 95.561%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.153 Acc 95.761%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.151 Acc 95.690%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.151 Acc 95.673%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.149 Acc 95.700%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.152 Acc 95.559%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.171 Acc 95.707%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.170 Acc 95.736%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.144 Acc 95.939%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.143 Acc 95.884%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.145 Acc 95.904%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.147 Acc 95.874%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.149 Acc 95.799%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.206 Acc 94.338%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.203 Acc 94.512%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.137 Acc 96.125%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.141 Acc 96.024%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.146 Acc 95.883%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.147 Acc 95.869%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.130 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.170 Acc 95.591%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.168 Acc 95.588%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.104 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.136 Acc 96.148%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.141 Acc 96.070%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.144 Acc 96.021%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.144 Acc 96.000%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.145 Acc 95.904%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.167 Acc 95.738%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.164 Acc 95.721%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.133 Acc 96.256%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.141 Acc 96.055%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.140 Acc 96.073%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.141 Acc 96.014%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.141 Acc 96.036%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.129 Acc 96.272%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.133 Acc 96.241%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.138 Acc 96.102%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.140 Acc 96.016%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.139 Acc 96.044%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.169 Acc 95.645%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.167 Acc 95.678%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.133 Acc 96.127%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.135 Acc 96.084%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.138 Acc 96.064%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.172 Acc 95.599%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.169 Acc 95.577%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.124 Acc 96.372%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.127 Acc 96.288%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.131 Acc 96.252%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.135 Acc 96.198%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.118 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.167 Acc 95.653%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.162 Acc 95.864%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.170 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.127 Acc 96.419%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.135 Acc 96.121%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.134 Acc 96.198%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.132 Acc 96.193%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.134 Acc 96.139%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.169 Acc 95.561%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.127 Acc 96.504%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.130 Acc 96.432%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.132 Acc 96.325%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.131 Acc 96.292%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.131 Acc 96.278%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.177 Acc 95.351%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.468%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.264 Acc 95.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.123 Acc 96.566%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.124 Acc 96.568%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.124 Acc 96.543%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.125 Acc 96.452%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.127 Acc 96.401%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.171 Acc 95.452%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.170 Acc 95.569%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.119 Acc 96.612%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.122 Acc 96.545%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.122 Acc 96.540%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.124 Acc 96.442%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.125 Acc 96.445%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.148 Acc 96.875%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.174 Acc 95.614%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.171 Acc 95.732%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.120 Acc 96.705%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.117 Acc 96.681%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.122 Acc 96.548%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.123 Acc 96.493%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.123 Acc 96.473%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.192 Acc 95.042%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.189 Acc 95.048%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.085 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.114 Acc 96.597%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.119 Acc 96.421%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.122 Acc 96.390%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.189 Acc 95.583%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.189 Acc 95.519%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.117 Acc 96.836%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.119 Acc 96.805%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.121 Acc 96.665%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.119 Acc 96.668%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.121 Acc 96.621%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.187 Acc 95.065%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.182 Acc 95.188%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.122 Acc 96.416%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.119 Acc 96.462%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.119 Acc 96.472%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.120 Acc 96.540%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.164 Acc 95.808%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.160 Acc 95.958%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.115 Acc 96.627%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.114 Acc 96.673%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.115 Acc 96.639%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.116 Acc 96.606%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.117 Acc 96.591%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.179 Acc 95.235%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.175 Acc 95.417%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.117 Acc 97.656%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.113 Acc 96.682%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.115 Acc 96.673%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.114 Acc 96.737%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.115 Acc 96.741%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.114 Acc 96.699%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.175 Acc 91.406%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.185 Acc 95.119%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.204%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.107 Acc 96.945%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.105 Acc 96.953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.109 Acc 96.841%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.111 Acc 96.772%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.112 Acc 96.750%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.181 Acc 95.514%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.507%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.110 Acc 96.805%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.108 Acc 96.815%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.110 Acc 96.748%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.111 Acc 96.728%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.194 Acc 95.142%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.191 Acc 95.145%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.109 Acc 96.666%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.113 Acc 96.572%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.111 Acc 96.665%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.112 Acc 96.725%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.113 Acc 96.694%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.184 Acc 95.297%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.182 Acc 95.417%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.099 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.105 Acc 96.945%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.108 Acc 96.859%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.111 Acc 96.800%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.111 Acc 96.778%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.110 Acc 96.746%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.167 Acc 95.748%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.106 Acc 97.037%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.107 Acc 96.964%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.106 Acc 96.966%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.106 Acc 96.982%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.105 Acc 96.962%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.180 Acc 95.421%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.176 Acc 95.569%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.224 Acc 92.969%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.101 Acc 97.061%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.102 Acc 96.945%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.105 Acc 96.894%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.106 Acc 96.877%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.467%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.176 Acc 95.456%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.100 Acc 97.027%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.104 Acc 96.885%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.105 Acc 96.856%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.105 Acc 96.858%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.171 Acc 95.616%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.228 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.095 Acc 97.277%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.099 Acc 97.116%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.101 Acc 96.974%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.104 Acc 96.961%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.103 Acc 96.983%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.182 Acc 95.390%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.179 Acc 95.328%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.098 Acc 97.138%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.098 Acc 97.050%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.097 Acc 97.083%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.099 Acc 96.998%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.100 Acc 96.976%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.467%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.174 Acc 95.553%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.091 Acc 97.236%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.097 Acc 97.088%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.098 Acc 97.019%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.099 Acc 97.026%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.098 Acc 97.231%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.098 Acc 97.170%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.097 Acc 97.158%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.097 Acc 97.152%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.097 Acc 97.109%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.178 Acc 95.475%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.175 Acc 95.480%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.089 Acc 97.236%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.091 Acc 97.166%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.095 Acc 97.120%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.096 Acc 97.071%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.178 Acc 95.560%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.174 Acc 95.526%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.085 Acc 97.525%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.092 Acc 97.197%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.095 Acc 97.074%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.097 Acc 97.068%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.186 Acc 95.483%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.181 Acc 95.557%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.086 Acc 97.300%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.093 Acc 97.186%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.091 Acc 97.246%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.092 Acc 97.233%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.093 Acc 97.201%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.180 Acc 95.514%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.176 Acc 95.484%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.087 Acc 97.334%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.089 Acc 97.199%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.091 Acc 97.183%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.093 Acc 97.117%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.175 Acc 95.599%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.173 Acc 95.581%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.082 Acc 97.494%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.087 Acc 97.314%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.087 Acc 97.295%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.089 Acc 97.235%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.092 Acc 97.178%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.176 Acc 95.429%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.173 Acc 95.499%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.056 Acc 99.219%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.082 Acc 97.540%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.084 Acc 97.431%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.086 Acc 97.334%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.088 Acc 97.315%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.089 Acc 97.321%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.178 Acc 95.515%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.048 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.090 Acc 97.246%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.089 Acc 97.213%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.090 Acc 97.184%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.091 Acc 97.169%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.092 Acc 97.176%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.189 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.173 Acc 95.637%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.173 Acc 95.682%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.081 Acc 97.517%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.085 Acc 97.442%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.087 Acc 97.368%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.089 Acc 97.263%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.179 Acc 95.530%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.079 Acc 97.478%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.084 Acc 97.376%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.086 Acc 97.397%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.086 Acc 97.389%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.087 Acc 97.341%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.185 Acc 96.094%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.183 Acc 95.405%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.182 Acc 95.355%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.079 Acc 97.672%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.083 Acc 97.439%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.084 Acc 97.368%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.084 Acc 97.374%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.085 Acc 97.360%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.483%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.180 Acc 95.522%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.082 Acc 97.471%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.084 Acc 97.417%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.086 Acc 97.395%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.086 Acc 97.383%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.232 Acc 94.431%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.227 Acc 94.465%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.083 Acc 97.386%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.084 Acc 97.428%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.084 Acc 97.422%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.085 Acc 97.376%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.176 Acc 95.545%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.173 Acc 95.678%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.080 Acc 97.463%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.077 Acc 97.520%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.078 Acc 97.511%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.079 Acc 97.502%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.082 Acc 97.436%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.180 Acc 95.503%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.071 Acc 97.757%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.077 Acc 97.579%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.080 Acc 97.475%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.179 Acc 95.537%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.177 Acc 95.398%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.071 Acc 97.679%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.075 Acc 97.700%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.077 Acc 97.643%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.078 Acc 97.616%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.184 Acc 95.367%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.182 Acc 95.324%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.077 Acc 97.494%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.078 Acc 97.532%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.078 Acc 97.545%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.078 Acc 97.528%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.080 Acc 97.482%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.175 Acc 95.637%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.172 Acc 95.604%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.074 Acc 97.676%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.076 Acc 97.591%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.079 Acc 97.495%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.079 Acc 97.471%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.188 Acc 95.157%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.059 Acc 99.219%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.069 Acc 97.788%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.075 Acc 97.568%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.076 Acc 97.598%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.076 Acc 97.603%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.176 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.187 Acc 95.250%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.074 Acc 97.509%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.074 Acc 97.563%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.076 Acc 97.534%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.077 Acc 97.525%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.194 Acc 95.297%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.191 Acc 95.344%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.073 Acc 97.741%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.074 Acc 97.680%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.072 Acc 97.739%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.074 Acc 97.680%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.075 Acc 97.645%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.196 Acc 95.390%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.192 Acc 95.460%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.070 Acc 97.881%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.068 Acc 97.963%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.070 Acc 97.882%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.072 Acc 97.773%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.074 Acc 97.681%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.498%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.177 Acc 95.585%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.071 Acc 97.703%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.072 Acc 97.652%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.072 Acc 97.664%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.074 Acc 97.602%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.177 Acc 96.875%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.190 Acc 95.575%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 95.507%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.071 Acc 97.679%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.073 Acc 97.680%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.071 Acc 97.713%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.074 Acc 97.631%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.184 Acc 95.251%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.183 Acc 95.278%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.065 Acc 97.865%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.069 Acc 97.761%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.070 Acc 97.763%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.070 Acc 97.758%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.071 Acc 97.748%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.184 Acc 95.467%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.185 Acc 95.239%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.072 Acc 97.571%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.068 Acc 97.722%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.066 Acc 97.815%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.069 Acc 97.783%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.071 Acc 97.744%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.184 Acc 95.320%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.180 Acc 95.394%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.092 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.069 Acc 97.734%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.069 Acc 97.700%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.072 Acc 97.631%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.071 Acc 97.678%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.198 Acc 95.235%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.196 Acc 95.289%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.064 Acc 97.950%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.067 Acc 97.882%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.070 Acc 97.711%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.070 Acc 97.700%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.193 Acc 95.552%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.189 Acc 95.526%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.065 Acc 97.819%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.067 Acc 97.816%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.064 Acc 97.882%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.065 Acc 97.839%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.069 Acc 97.775%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.174 Acc 95.753%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.028 Acc 100.000%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.068 Acc 97.819%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.065 Acc 97.866%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.068 Acc 97.789%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.069 Acc 97.806%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.068 Acc 97.798%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.174 Acc 95.777%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.172 Acc 95.763%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.122 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.063 Acc 97.888%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.064 Acc 97.940%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.063 Acc 97.981%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.064 Acc 97.933%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.065 Acc 97.885%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.206 Acc 95.057%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.199 Acc 95.130%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.061 Acc 98.136%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.064 Acc 97.994%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.068 Acc 97.859%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.067 Acc 97.871%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.067 Acc 97.859%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.181 Acc 95.777%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.180 Acc 95.612%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.060 Acc 98.074%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.064 Acc 97.866%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.064 Acc 97.864%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.065 Acc 97.871%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.067 Acc 97.829%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.199 Acc 95.421%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.195 Acc 95.402%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.076 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.064 Acc 98.113%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.064 Acc 97.987%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.062 Acc 98.007%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.061 Acc 98.042%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.063 Acc 97.990%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.195 Acc 95.173%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.195 Acc 95.270%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.061 Acc 98.053%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.063 Acc 97.931%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.065 Acc 97.893%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.201 Acc 94.972%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.201 Acc 94.943%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.062 Acc 97.909%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.065 Acc 97.832%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.187 Acc 95.231%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.063 Acc 97.811%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.063 Acc 97.866%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.065 Acc 97.835%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.064 Acc 97.880%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.064 Acc 97.865%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.191 Acc 95.374%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.191 Acc 95.336%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.061 Acc 98.012%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.062 Acc 97.948%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.062 Acc 97.957%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.061 Acc 97.976%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.063 Acc 97.910%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.192 Acc 95.266%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.188 Acc 95.274%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.061 Acc 97.741%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.061 Acc 97.889%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.063 Acc 97.882%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.063 Acc 97.907%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.199 Acc 94.872%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.196 Acc 94.974%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.058 Acc 98.120%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.060 Acc 98.107%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.058 Acc 98.116%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.060 Acc 98.011%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.062 Acc 97.926%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.195 Acc 95.560%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.190 Acc 95.550%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.022 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.056 Acc 98.260%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.058 Acc 98.165%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.058 Acc 98.129%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.059 Acc 98.056%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.060 Acc 98.046%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.200 Acc 95.196%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.194 Acc 95.219%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.056 Acc 98.221%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.055 Acc 98.212%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.057 Acc 98.147%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.057 Acc 98.137%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.059 Acc 98.055%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.196 Acc 95.127%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.191 Acc 95.328%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.053 Acc 98.182%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.054 Acc 98.181%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.058 Acc 98.110%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.059 Acc 98.091%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.060 Acc 98.035%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.189 Acc 95.444%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.186 Acc 95.456%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.053 Acc 98.283%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.052 Acc 98.317%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.055 Acc 98.178%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.057 Acc 98.116%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.059 Acc 98.041%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.196 Acc 95.297%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.192 Acc 95.243%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.057 Acc 98.066%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.057 Acc 98.053%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.059 Acc 97.983%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.059 Acc 98.007%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.058 Acc 98.029%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.201 Acc 95.266%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.199 Acc 95.258%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.049 Acc 98.275%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.052 Acc 98.228%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.055 Acc 98.162%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.058 Acc 98.093%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.058 Acc 98.034%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.169 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.205 Acc 95.057%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.203 Acc 95.103%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.011 Acc 100.000%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.054 Acc 98.175%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.055 Acc 98.146%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.056 Acc 98.113%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.057 Acc 98.073%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.056 Acc 98.094%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.203 Acc 95.343%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.200 Acc 95.417%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.051 Acc 98.314%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.052 Acc 98.263%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.055 Acc 98.139%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.056 Acc 98.126%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.056 Acc 98.118%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.191 Acc 95.676%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.189 Acc 95.585%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.052 Acc 98.182%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.054 Acc 98.134%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.055 Acc 98.113%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.054 Acc 98.176%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.056 Acc 98.141%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.209 Acc 95.034%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.205 Acc 95.005%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.111 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.051 Acc 98.182%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.053 Acc 98.189%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.054 Acc 98.199%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.054 Acc 98.196%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.055 Acc 98.163%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.194 Acc 95.436%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.190 Acc 95.569%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.052 Acc 98.144%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.052 Acc 98.189%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.052 Acc 98.206%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.053 Acc 98.206%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.055 Acc 98.177%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.148 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.210 Acc 95.421%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.204 Acc 95.464%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.047 Acc 98.291%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.054 Acc 98.092%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.054 Acc 98.108%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.054 Acc 98.106%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.054 Acc 98.115%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.206 Acc 94.957%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.204 Acc 95.056%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.051 Acc 98.283%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.051 Acc 98.259%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.052 Acc 98.235%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.053 Acc 98.184%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.053 Acc 98.210%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.205 Acc 95.034%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.056 Acc 98.151%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.053 Acc 98.286%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.055 Acc 98.222%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.054 Acc 98.249%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.052 Acc 98.302%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.214 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.199 Acc 95.166%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.195 Acc 95.258%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.046 Acc 98.407%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.048 Acc 98.422%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.050 Acc 98.331%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.051 Acc 98.289%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.053 Acc 98.250%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.200 Acc 95.459%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.197 Acc 95.491%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.051 Acc 98.190%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.054 Acc 98.099%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.054 Acc 98.149%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.054 Acc 98.151%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.198 Acc 95.459%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.196 Acc 95.402%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.049 Acc 98.290%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.050 Acc 98.301%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.050 Acc 98.307%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.133 Acc 96.875%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.198 Acc 95.204%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.196 Acc 95.223%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.049 Acc 98.314%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.052 Acc 98.200%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.053 Acc 98.194%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.053 Acc 98.221%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.054 Acc 98.172%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.186 Acc 95.452%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.185 Acc 95.417%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.045 Acc 98.507%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.049 Acc 98.418%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.048 Acc 98.380%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.051 Acc 98.258%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.202 Acc 95.483%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.198 Acc 95.414%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.044 Acc 98.468%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.052 Acc 98.296%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.197 Acc 95.467%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.190 Acc 95.503%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.048 Acc 98.340%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.049 Acc 98.282%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.049 Acc 98.280%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.051 Acc 98.261%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.208 Acc 95.606%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.202 Acc 95.546%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.049 Acc 98.399%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.050 Acc 98.371%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.051 Acc 98.284%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.052 Acc 98.278%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.051 Acc 98.302%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.197 Acc 95.251%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.191 Acc 95.305%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.048 Acc 98.391%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.046 Acc 98.403%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.049 Acc 98.339%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.049 Acc 98.334%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.049 Acc 98.303%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.201 Acc 95.073%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.197 Acc 95.033%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.044 Acc 98.538%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.045 Acc 98.484%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.047 Acc 98.432%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.049 Acc 98.348%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.049 Acc 98.364%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.197 Acc 95.637%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.196 Acc 95.522%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.047 Acc 98.484%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.047 Acc 98.426%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.046 Acc 98.399%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.048 Acc 98.356%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.049 Acc 98.321%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.208 Acc 95.173%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.206 Acc 95.161%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.045 Acc 98.468%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.046 Acc 98.472%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.048 Acc 98.380%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.048 Acc 98.371%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.048 Acc 98.375%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.216 Acc 94.531%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.205 Acc 95.606%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.200 Acc 95.612%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.046 Acc 98.484%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.047 Acc 98.465%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.049 Acc 98.401%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.048 Acc 98.461%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.048 Acc 98.428%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.207 Acc 95.429%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.043 Acc 98.484%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.046 Acc 98.399%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.048 Acc 98.383%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.049 Acc 98.328%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.049 Acc 98.328%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.201 Acc 95.251%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.199 Acc 95.285%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.039 Acc 98.670%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.042 Acc 98.593%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.045 Acc 98.489%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.046 Acc 98.459%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.047 Acc 98.425%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.193 Acc 95.514%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.193 Acc 95.476%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.047 Acc 98.360%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.045 Acc 98.356%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.048 Acc 98.323%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.048 Acc 98.317%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.048 Acc 98.317%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.233 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.218 Acc 95.266%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.212 Acc 95.243%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.047 Acc 98.445%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.048 Acc 98.472%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.047 Acc 98.432%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.047 Acc 98.453%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.047 Acc 98.442%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.222 Acc 95.212%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.221 Acc 95.091%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.044 Acc 98.561%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.044 Acc 98.488%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.045 Acc 98.500%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.045 Acc 98.482%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.048 Acc 98.403%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.219 Acc 94.779%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.215 Acc 94.803%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.042 Acc 98.530%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.045 Acc 98.465%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.045 Acc 98.430%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.044 Acc 98.451%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.045 Acc 98.423%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.120 Acc 97.656%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.211 Acc 95.367%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.208 Acc 95.386%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.043 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.040 Acc 98.623%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.041 Acc 98.624%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.043 Acc 98.518%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.045 Acc 98.478%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.046 Acc 98.462%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.208 Acc 95.212%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.205 Acc 95.173%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.046 Acc 98.538%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.043 Acc 98.593%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.044 Acc 98.523%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.045 Acc 98.465%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.046 Acc 98.450%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.216 Acc 94.717%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.211 Acc 94.881%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.040 Acc 98.639%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.041 Acc 98.612%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.042 Acc 98.583%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.045 Acc 98.506%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.045 Acc 98.483%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.212 Acc 95.158%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.212 Acc 95.013%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.047 Acc 98.314%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.048 Acc 98.313%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.048 Acc 98.339%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.047 Acc 98.340%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.047 Acc 98.358%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.226 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.227 Acc 95.173%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.225 Acc 95.079%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.041 Acc 98.584%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.042 Acc 98.577%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.043 Acc 98.526%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.044 Acc 98.447%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.045 Acc 98.420%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.194 Acc 95.730%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.191 Acc 95.616%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.012 Acc 99.219%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.038 Acc 98.662%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.039 Acc 98.682%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.041 Acc 98.609%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.041 Acc 98.589%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.043 Acc 98.545%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.214 Acc 95.080%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.210 Acc 95.106%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.040 Acc 98.693%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.039 Acc 98.655%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.041 Acc 98.567%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.043 Acc 98.562%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.044 Acc 98.492%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.199 Acc 95.630%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.195 Acc 95.612%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.037 Acc 98.741%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.040 Acc 98.637%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.043 Acc 98.537%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.043 Acc 98.509%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.224 Acc 94.756%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [200/204] Loss: 0.219 Acc 94.710%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.042 Acc 98.468%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.041 Acc 98.554%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.043 Acc 98.484%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.042 Acc 98.531%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.043 Acc 98.500%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.204 Acc 95.475%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.204 Acc 95.359%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.041 Acc 98.608%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.043 Acc 98.504%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.043 Acc 98.531%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.044 Acc 98.519%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.045 Acc 98.480%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.198 Acc 95.243%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.197 Acc 95.274%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.044 Acc 98.484%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.044 Acc 98.515%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.043 Acc 98.535%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.043 Acc 98.519%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.218 Acc 95.065%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.214 Acc 95.106%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.036 Acc 98.778%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.039 Acc 98.644%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.041 Acc 98.627%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.042 Acc 98.617%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.043 Acc 98.570%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.203 Acc 95.552%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.202 Acc 95.565%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.032 Acc 98.863%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.037 Acc 98.752%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.039 Acc 98.707%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.040 Acc 98.677%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.042 Acc 98.637%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.227 Acc 95.220%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.226 Acc 95.215%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.038 Acc 98.639%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.039 Acc 98.616%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.039 Acc 98.643%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.041 Acc 98.572%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.041 Acc 98.553%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.221 Acc 95.274%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.214 Acc 95.336%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.090 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.041 Acc 98.700%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.042 Acc 98.636%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.041 Acc 98.609%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.041 Acc 98.605%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.042 Acc 98.600%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.210 Acc 94.980%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.205 Acc 94.955%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.038 Acc 98.770%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.037 Acc 98.756%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.040 Acc 98.643%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.040 Acc 98.644%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.041 Acc 98.617%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.227 Acc 95.111%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.224 Acc 95.040%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.044 Acc 98.507%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.044 Acc 98.504%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.044 Acc 98.487%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.045 Acc 98.482%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.044 Acc 98.484%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.222 Acc 95.088%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.221 Acc 94.998%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.025 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.042 Acc 98.654%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.040 Acc 98.651%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.040 Acc 98.676%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.040 Acc 98.638%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.041 Acc 98.612%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.219 Acc 95.390%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.214 Acc 95.468%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.041 Acc 98.530%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.041 Acc 98.531%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.041 Acc 98.552%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.041 Acc 98.570%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.041 Acc 98.562%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.207 Acc 95.011%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.204 Acc 94.982%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.038 Acc 98.693%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.039 Acc 98.690%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.040 Acc 98.617%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.040 Acc 98.628%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.040 Acc 98.622%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.205 Acc 95.204%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.198 Acc 95.196%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.038 Acc 98.685%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.037 Acc 98.682%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.039 Acc 98.635%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.041 Acc 98.586%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.041 Acc 98.572%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.230 Acc 95.034%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.225 Acc 95.134%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.038 Acc 98.793%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.039 Acc 98.733%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.040 Acc 98.645%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.041 Acc 98.607%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.041 Acc 98.572%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.552%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.208 Acc 95.647%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.038 Acc 98.741%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.038 Acc 98.715%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.039 Acc 98.679%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.039 Acc 98.695%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.206 Acc 95.382%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.205 Acc 95.340%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.042 Acc 98.592%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.041 Acc 98.574%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.041 Acc 98.583%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.040 Acc 98.599%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.040 Acc 98.607%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.190 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.218 Acc 95.158%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.214 Acc 95.079%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.039 Acc 98.615%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.038 Acc 98.612%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.039 Acc 98.614%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.040 Acc 98.589%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.041 Acc 98.567%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.222 Acc 95.421%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.214 Acc 95.476%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.035 Acc 98.755%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.038 Acc 98.682%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.038 Acc 98.666%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.039 Acc 98.630%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.039 Acc 98.659%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.215 Acc 95.591%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.209 Acc 95.666%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.027 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.035 Acc 98.760%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.037 Acc 98.689%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.038 Acc 98.699%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.038 Acc 98.676%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.292 Acc 92.969%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.223 Acc 95.398%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.219 Acc 95.425%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.034 Acc 98.894%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.036 Acc 98.853%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.037 Acc 98.772%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.037 Acc 98.763%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.039 Acc 98.695%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.228 Acc 95.258%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.224 Acc 95.153%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.036 Acc 98.840%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.034 Acc 98.888%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.037 Acc 98.757%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.038 Acc 98.701%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.038 Acc 98.689%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.229 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.237 Acc 94.701%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.230 Acc 94.900%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.038 Acc 98.662%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.036 Acc 98.776%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.036 Acc 98.759%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.037 Acc 98.741%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.037 Acc 98.718%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.196 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.227 Acc 95.220%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.222 Acc 95.246%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.034 Acc 98.846%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.033 Acc 98.845%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.035 Acc 98.767%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.036 Acc 98.729%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.203 Acc 95.359%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.200 Acc 95.231%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.034 Acc 98.824%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.036 Acc 98.795%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.035 Acc 98.840%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.035 Acc 98.835%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.036 Acc 98.773%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.213 Acc 95.359%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.207 Acc 95.410%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.040 Acc 98.615%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.037 Acc 98.690%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.037 Acc 98.728%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.038 Acc 98.673%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.039 Acc 98.615%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.209 Acc 95.622%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.204 Acc 95.530%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.028 Acc 99.025%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.033 Acc 98.869%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.038 Acc 98.665%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.038 Acc 98.664%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.195 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.211 Acc 95.305%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.208 Acc 95.258%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.033 Acc 98.786%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.033 Acc 98.884%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.033 Acc 98.902%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.034 Acc 98.858%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.035 Acc 98.802%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.214 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.209 Acc 95.614%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.205 Acc 95.581%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.035 Acc 98.817%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.035 Acc 98.873%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.034 Acc 98.879%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.036 Acc 98.831%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.036 Acc 98.806%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.202 Acc 95.475%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.200 Acc 95.472%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.035 Acc 98.871%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.037 Acc 98.783%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.039 Acc 98.661%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.038 Acc 98.673%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.037 Acc 98.720%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.222 Acc 95.374%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.218 Acc 95.336%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.039 Acc 98.700%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.038 Acc 98.772%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.036 Acc 98.796%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.037 Acc 98.778%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.037 Acc 98.777%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.233 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.219 Acc 95.282%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [165/200]Batch [200/204] Loss: 0.218 Acc 95.363%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.039 Acc 98.608%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.038 Acc 98.706%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.038 Acc 98.665%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.038 Acc 98.665%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.193 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.222 Acc 95.088%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.217 Acc 95.052%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.038 Acc 98.708%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.037 Acc 98.768%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.038 Acc 98.731%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.038 Acc 98.730%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.037 Acc 98.726%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.211 Acc 95.026%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.211 Acc 95.044%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.032 Acc 98.832%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.033 Acc 98.826%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.033 Acc 98.816%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.034 Acc 98.800%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.035 Acc 98.751%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.214 Acc 95.467%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.212 Acc 95.476%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.031 Acc 98.847%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.031 Acc 98.846%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.033 Acc 98.772%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.034 Acc 98.773%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.036 Acc 98.710%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.234 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.202 Acc 95.220%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.202 Acc 95.126%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.032 Acc 98.948%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.032 Acc 98.923%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.032 Acc 98.918%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.033 Acc 98.874%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.034 Acc 98.844%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.206 Acc 95.336%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.202 Acc 95.367%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.034 Acc 98.770%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.035 Acc 98.791%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.036 Acc 98.757%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.036 Acc 98.739%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.037 Acc 98.695%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.237 Acc 95.173%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.231 Acc 95.188%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.032 Acc 98.871%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.034 Acc 98.865%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.034 Acc 98.855%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.034 Acc 98.808%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.035 Acc 98.757%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.211 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.214 Acc 95.166%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.214 Acc 95.227%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.037 Acc 98.755%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.036 Acc 98.702%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.035 Acc 98.752%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.034 Acc 98.776%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.036 Acc 98.735%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.215 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.224 Acc 95.243%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.223 Acc 95.239%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.034 Acc 98.847%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.036 Acc 98.780%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.036 Acc 98.778%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.037 Acc 98.728%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.038 Acc 98.706%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.227 Acc 95.575%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.227 Acc 95.553%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.032 Acc 98.824%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.034 Acc 98.776%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.035 Acc 98.798%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.035 Acc 98.814%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.035 Acc 98.815%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.238 Acc 95.135%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.235 Acc 95.176%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.033 Acc 98.886%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.034 Acc 98.803%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.033 Acc 98.863%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.033 Acc 98.847%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.034 Acc 98.837%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.228 Acc 94.926%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.227 Acc 94.998%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.031 Acc 98.948%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.031 Acc 98.892%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.032 Acc 98.900%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.033 Acc 98.882%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.034 Acc 98.829%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.242 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.232 Acc 95.111%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.232 Acc 95.072%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.036 Acc 98.855%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.034 Acc 98.857%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.035 Acc 98.829%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.035 Acc 98.796%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.035 Acc 98.820%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.214 Acc 95.336%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.211 Acc 95.398%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.031 Acc 98.863%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.031 Acc 98.818%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.032 Acc 98.842%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.033 Acc 98.843%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.034 Acc 98.834%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.212 Acc 95.490%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.213 Acc 95.382%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.030 Acc 99.002%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.031 Acc 98.947%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.032 Acc 98.874%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.032 Acc 98.860%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.033 Acc 98.834%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.223 Acc 94.825%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [180/200]Batch [200/204] Loss: 0.220 Acc 94.994%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.034 Acc 98.809%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.034 Acc 98.846%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.033 Acc 98.845%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.034 Acc 98.815%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.035 Acc 98.781%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.202 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.204 Acc 95.266%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.204 Acc 95.332%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.030 Acc 99.080%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.030 Acc 99.032%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.032 Acc 98.912%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.033 Acc 98.915%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.033 Acc 98.904%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.225 Acc 95.212%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.224 Acc 95.188%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.032 Acc 99.010%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.031 Acc 98.967%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.033 Acc 98.917%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.032 Acc 98.922%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.209 Acc 96.875%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.222 Acc 95.166%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.222 Acc 95.138%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.034 Acc 98.809%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.033 Acc 98.850%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.035 Acc 98.811%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.035 Acc 98.780%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.036 Acc 98.762%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.221 Acc 95.158%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.219 Acc 95.270%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.033 Acc 99.010%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.033 Acc 98.939%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.034 Acc 98.907%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.034 Acc 98.934%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.034 Acc 98.888%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.221 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.220 Acc 95.514%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.215 Acc 95.596%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.027 Acc 99.049%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.030 Acc 98.978%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.032 Acc 98.933%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.032 Acc 98.889%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.033 Acc 98.840%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.190 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.228 Acc 95.351%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.221 Acc 95.410%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.031 Acc 98.963%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.030 Acc 98.954%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.031 Acc 98.931%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.031 Acc 98.944%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.206 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.232 Acc 95.374%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.226 Acc 95.309%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.033 Acc 98.987%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.033 Acc 98.904%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.033 Acc 98.855%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.033 Acc 98.823%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.034 Acc 98.818%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.273 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.241 Acc 95.003%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.235 Acc 95.157%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.030 Acc 98.956%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.033 Acc 98.902%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.033 Acc 98.876%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.033 Acc 98.868%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.229 Acc 95.374%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.222 Acc 95.347%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.026 Acc 99.072%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.029 Acc 99.021%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.030 Acc 98.977%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.031 Acc 98.944%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.032 Acc 98.933%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.219 Acc 95.498%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.216 Acc 95.522%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.026 Acc 99.165%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.031 Acc 98.977%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.032 Acc 98.903%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.034 Acc 98.862%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.235 Acc 95.328%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.227 Acc 95.363%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.031 Acc 98.847%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.031 Acc 98.830%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.032 Acc 98.845%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.031 Acc 98.872%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.032 Acc 98.852%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.278 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.224 Acc 95.282%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.220 Acc 95.289%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.028 Acc 99.080%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.029 Acc 98.974%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.031 Acc 98.928%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.032 Acc 98.891%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.231 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.220 Acc 95.483%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.217 Acc 95.456%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.031 Acc 99.025%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.030 Acc 99.071%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.030 Acc 99.027%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.031 Acc 98.983%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.032 Acc 98.930%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.253 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.225 Acc 95.173%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.220 Acc 95.239%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.034 Acc 98.762%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.033 Acc 98.818%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.032 Acc 98.907%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.032 Acc 98.903%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.032 Acc 98.912%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.233 Acc 95.444%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [195/200]Batch [200/204] Loss: 0.227 Acc 95.375%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.039 Acc 97.656%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.031 Acc 99.033%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.033 Acc 98.951%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.032 Acc 98.941%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.034 Acc 98.876%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.222 Acc 95.413%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.220 Acc 95.324%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.033 Acc 98.871%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.031 Acc 98.877%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.032 Acc 98.845%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.032 Acc 98.829%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.033 Acc 98.824%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.134 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.220 Acc 94.957%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.221 Acc 94.998%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.029 Acc 99.002%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.030 Acc 98.958%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.032 Acc 98.887%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.032 Acc 98.886%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.032 Acc 98.899%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.220 Acc 95.645%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.221 Acc 95.686%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.029 Acc 98.925%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.028 Acc 98.989%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.029 Acc 98.985%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.031 Acc 98.938%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.031 Acc 98.930%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.206 Acc 95.599%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.206 Acc 95.410%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fb6ca5819447aebd82c31b799f0d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.324 Acc 10.938%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.191 Acc 21.248%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 1.849 Acc 34.558%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.530 Acc 46.699%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.315 Acc 54.781%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.158 Acc 60.474%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.597 Acc 79.688%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.482 Acc 85.118%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.472 Acc 85.432%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.409 Acc 89.062%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.450 Acc 86.077%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.438 Acc 86.431%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.423 Acc 86.921%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.414 Acc 87.243%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.409 Acc 87.498%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.307 Acc 87.500%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.342 Acc 89.411%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.332 Acc 89.875%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.216 Acc 93.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.361 Acc 89.001%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.348 Acc 89.432%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.342 Acc 89.525%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.336 Acc 89.778%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.331 Acc 89.880%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.325 Acc 85.938%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.306 Acc 91.197%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.300 Acc 91.227%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.262 Acc 92.188%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.308 Acc 90.339%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.301 Acc 90.664%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.301 Acc 90.721%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.298 Acc 90.925%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.296 Acc 90.990%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.277 Acc 91.955%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.269 Acc 92.013%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.283 Acc 91.870%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.278 Acc 91.861%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.279 Acc 91.785%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.274 Acc 91.973%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.272 Acc 92.011%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.227 Acc 92.188%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.257 Acc 92.721%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.252 Acc 92.829%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.358 Acc 92.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.255 Acc 92.427%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.256 Acc 92.475%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.251 Acc 92.644%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.254 Acc 92.560%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.203 Acc 91.406%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.224 Acc 93.742%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.219 Acc 93.816%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.157 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.226 Acc 93.425%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.236 Acc 93.097%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.238 Acc 92.974%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.238 Acc 92.945%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.240 Acc 93.005%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.256 Acc 92.188%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.246 Acc 92.837%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.241 Acc 93.050%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.230 Acc 93.309%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.230 Acc 93.311%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.233 Acc 93.143%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.232 Acc 93.218%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.232 Acc 93.257%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.280 Acc 87.500%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.285 Acc 91.731%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.278 Acc 91.989%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.263 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.214 Acc 93.765%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.219 Acc 93.719%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.218 Acc 93.732%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.223 Acc 93.569%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.225 Acc 93.472%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.203 Acc 94.199%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.198 Acc 94.531%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.208 Acc 93.912%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.209 Acc 93.855%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.208 Acc 93.908%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.210 Acc 93.853%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.214 Acc 93.792%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.217 Acc 94.059%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.211 Acc 94.003%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.205 Acc 96.094%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.199 Acc 93.905%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.200 Acc 93.948%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.206 Acc 93.986%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.207 Acc 94.029%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.206 Acc 94.046%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.363 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.287 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.283 Acc 92.965%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.269 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.202 Acc 94.083%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.200 Acc 94.143%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.199 Acc 94.150%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.200 Acc 94.202%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.199 Acc 94.269%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.224 Acc 94.075%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.220 Acc 93.898%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.242 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.191 Acc 94.640%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.193 Acc 94.555%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.198 Acc 94.344%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.195 Acc 94.410%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.195 Acc 94.400%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.209 Acc 94.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.205 Acc 94.516%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.189 Acc 94.694%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.182 Acc 94.792%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.184 Acc 94.692%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.183 Acc 94.703%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.185 Acc 94.715%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.195 Acc 94.964%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.190 Acc 95.044%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.218 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.175 Acc 94.903%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.178 Acc 94.932%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.184 Acc 94.684%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.182 Acc 94.734%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.181 Acc 94.775%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.200 Acc 94.732%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.195 Acc 94.850%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.231 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.172 Acc 95.104%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.177 Acc 94.978%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.179 Acc 94.884%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.179 Acc 94.890%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.179 Acc 94.898%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.195 Acc 94.900%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.237 Acc 93.750%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.157 Acc 95.529%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.169 Acc 95.192%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.173 Acc 95.053%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.173 Acc 95.024%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.176 Acc 94.927%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.190 Acc 94.995%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.185 Acc 95.106%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.193 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.165 Acc 95.289%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.168 Acc 95.285%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.172 Acc 95.198%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.170 Acc 95.172%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.169 Acc 95.224%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.197 Acc 94.609%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.193 Acc 94.792%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.214 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.167 Acc 95.243%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.162 Acc 95.394%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.167 Acc 95.297%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.166 Acc 95.303%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.165 Acc 95.311%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.210 Acc 94.833%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.206 Acc 94.986%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.167 Acc 95.158%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.161 Acc 95.371%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.161 Acc 95.411%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.162 Acc 95.412%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.164 Acc 95.359%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.184 Acc 95.227%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.180 Acc 95.266%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.157 Acc 95.676%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.162 Acc 95.631%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.159 Acc 95.580%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.160 Acc 95.513%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.160 Acc 95.507%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.195 Acc 94.872%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.190 Acc 94.858%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.160 Acc 95.499%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.155 Acc 95.601%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.153 Acc 95.671%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.156 Acc 95.603%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.193 Acc 94.887%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.186 Acc 94.990%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.144 Acc 95.854%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.147 Acc 95.841%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.150 Acc 95.772%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.150 Acc 95.702%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.152 Acc 95.645%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.155 Acc 97.656%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.192 Acc 95.158%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.187 Acc 95.149%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.155 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.139 Acc 96.040%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.145 Acc 95.748%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.145 Acc 95.803%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.148 Acc 95.782%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.179 Acc 95.343%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.176 Acc 95.379%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.127 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.144 Acc 95.908%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.148 Acc 95.810%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.144 Acc 95.912%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.144 Acc 95.903%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.146 Acc 95.874%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.128 Acc 98.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.193 Acc 95.034%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.187 Acc 95.165%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.190 Acc 94.531%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.139 Acc 95.907%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.143 Acc 95.834%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.142 Acc 95.874%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.144 Acc 95.866%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.180 Acc 95.142%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.173 Acc 95.231%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.129 Acc 96.403%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.130 Acc 96.238%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.134 Acc 96.120%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.137 Acc 96.068%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.138 Acc 96.033%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.191 Acc 95.073%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.183 Acc 95.227%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.132 Acc 96.334%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.133 Acc 96.253%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.136 Acc 96.166%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.137 Acc 96.148%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.137 Acc 96.180%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.175 Acc 95.285%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.124 Acc 96.450%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.127 Acc 96.315%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.129 Acc 96.268%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.131 Acc 96.265%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.131 Acc 96.234%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.194 Acc 95.003%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.189 Acc 95.192%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.121 Acc 96.527%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.127 Acc 96.447%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.129 Acc 96.426%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.131 Acc 96.302%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.132 Acc 96.304%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.174 Acc 95.421%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.170 Acc 95.522%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.124 Acc 96.442%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.126 Acc 96.366%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.128 Acc 96.301%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.127 Acc 96.347%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.128 Acc 96.284%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.187 Acc 94.748%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.181 Acc 94.963%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.122 Acc 96.542%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.124 Acc 96.393%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.124 Acc 96.475%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.122 Acc 96.481%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.124 Acc 96.440%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.130 Acc 97.656%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.177 Acc 95.359%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.170 Acc 95.484%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.064 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.120 Acc 96.388%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.119 Acc 96.451%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.121 Acc 96.436%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.123 Acc 96.487%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.124 Acc 96.441%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.173 Acc 95.537%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.113 Acc 96.836%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.113 Acc 96.758%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.115 Acc 96.670%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.117 Acc 96.659%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.119 Acc 96.597%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.191 Acc 95.096%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.186 Acc 95.258%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.108 Acc 96.643%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.111 Acc 96.731%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.114 Acc 96.688%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.115 Acc 96.698%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.118 Acc 96.675%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.184 Acc 95.104%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.179 Acc 95.266%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.113 Acc 96.708%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.111 Acc 96.779%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.115 Acc 96.694%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.115 Acc 96.668%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.156 Acc 96.875%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.203 Acc 94.493%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.197 Acc 94.597%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.112 Acc 96.705%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.112 Acc 96.642%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.115 Acc 96.669%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.186 Acc 95.150%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.180 Acc 95.270%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.100 Acc 96.860%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.103 Acc 96.929%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.107 Acc 96.870%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.109 Acc 96.815%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.110 Acc 96.791%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.146 Acc 96.875%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.189 Acc 95.135%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.183 Acc 95.320%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.101 Acc 97.042%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.102 Acc 97.041%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.106 Acc 96.902%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.108 Acc 96.863%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.162 Acc 96.875%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.174 Acc 95.537%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.168 Acc 95.709%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.100 Acc 97.076%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.102 Acc 97.003%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.106 Acc 96.942%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.105 Acc 96.906%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.107 Acc 96.850%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.170 Acc 95.599%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.166 Acc 95.674%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.081 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.101 Acc 97.006%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.098 Acc 97.030%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.098 Acc 96.981%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.101 Acc 96.942%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.177 Acc 95.599%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.172 Acc 95.608%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.095 Acc 97.254%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.097 Acc 97.163%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.098 Acc 97.168%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.100 Acc 97.062%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.103 Acc 97.031%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.118 Acc 97.656%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.173 Acc 95.487%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.061 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.102 Acc 96.995%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.102 Acc 96.992%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.101 Acc 97.025%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.102 Acc 97.017%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.202 Acc 94.933%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.195 Acc 95.083%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.088 Acc 97.401%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.093 Acc 97.240%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.095 Acc 97.184%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.098 Acc 97.087%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.099 Acc 97.065%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.190 Acc 94.833%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.183 Acc 95.068%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.090 Acc 97.231%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.093 Acc 97.173%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.095 Acc 97.120%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.180 Acc 95.483%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.088 Acc 97.393%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.088 Acc 97.353%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.093 Acc 97.282%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.094 Acc 97.214%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.094 Acc 97.199%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.178 Acc 95.464%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.090 Acc 97.339%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.088 Acc 97.341%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.089 Acc 97.303%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.089 Acc 97.290%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.091 Acc 97.224%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.186 Acc 95.135%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.180 Acc 95.262%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.086 Acc 97.393%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.085 Acc 97.415%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.085 Acc 97.410%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.088 Acc 97.335%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.090 Acc 97.290%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.184 Acc 95.266%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.176 Acc 95.402%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.174 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.088 Acc 97.378%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.087 Acc 97.330%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.089 Acc 97.225%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.088 Acc 97.245%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.089 Acc 97.227%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.112 Acc 97.656%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.195 Acc 94.817%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.189 Acc 95.002%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.084 Acc 97.345%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.086 Acc 97.267%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.087 Acc 97.230%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.089 Acc 97.199%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.191 Acc 95.080%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.184 Acc 95.316%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.121 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.072 Acc 97.695%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.077 Acc 97.551%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.081 Acc 97.485%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.084 Acc 97.444%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.085 Acc 97.429%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.122 Acc 96.875%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.183 Acc 95.382%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.177 Acc 95.503%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.079 Acc 97.625%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.080 Acc 97.571%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.081 Acc 97.519%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.081 Acc 97.498%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.084 Acc 97.419%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.089 Acc 96.875%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.183 Acc 95.196%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.178 Acc 95.320%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.077 Acc 97.602%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.077 Acc 97.497%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.079 Acc 97.534%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.082 Acc 97.483%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.084 Acc 97.415%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.182 Acc 95.653%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.075 Acc 97.648%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.078 Acc 97.568%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.079 Acc 97.543%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.081 Acc 97.466%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.109 Acc 97.656%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.180 Acc 95.490%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.173 Acc 95.581%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.076 Acc 97.471%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.075 Acc 97.629%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.079 Acc 97.576%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.079 Acc 97.561%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.080 Acc 97.508%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.185 Acc 95.189%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.180 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.076 Acc 97.803%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.074 Acc 97.827%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.075 Acc 97.724%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.077 Acc 97.666%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.078 Acc 97.638%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.184 Acc 95.150%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.177 Acc 95.289%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.078 Acc 97.618%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.078 Acc 97.625%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.078 Acc 97.580%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.080 Acc 97.525%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.191 Acc 95.382%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.185 Acc 95.495%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.077 Acc 97.803%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.075 Acc 97.668%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.075 Acc 97.677%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.076 Acc 97.619%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.125 Acc 97.656%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.192 Acc 95.064%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.073 Acc 97.695%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.074 Acc 97.594%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.074 Acc 97.597%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.074 Acc 97.637%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.075 Acc 97.633%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.188 Acc 95.289%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.180 Acc 95.515%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.071 Acc 97.672%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.073 Acc 97.661%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.074 Acc 97.604%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.075 Acc 97.555%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.207 Acc 94.856%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.197 Acc 95.013%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.066 Acc 97.811%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.067 Acc 97.909%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.070 Acc 97.794%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.072 Acc 97.779%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.073 Acc 97.742%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.194 Acc 94.995%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.190 Acc 95.087%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.064 Acc 97.896%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.067 Acc 97.862%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.067 Acc 97.887%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.069 Acc 97.843%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.070 Acc 97.817%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.172 Acc 96.875%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.205 Acc 95.019%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.194 Acc 95.243%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.071 Acc 97.873%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.070 Acc 97.781%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.071 Acc 97.748%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.070 Acc 97.750%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.194 Acc 95.065%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.186 Acc 95.239%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.064 Acc 98.028%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.064 Acc 98.014%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.068 Acc 97.838%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.070 Acc 97.795%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.072 Acc 97.730%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.189%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.177 Acc 95.355%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.065 Acc 97.913%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.066 Acc 97.908%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.066 Acc 97.925%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.068 Acc 97.846%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.211 Acc 94.670%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.201 Acc 94.881%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.058 Acc 98.175%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.062 Acc 97.998%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.063 Acc 97.991%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.064 Acc 97.941%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.065 Acc 97.926%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.118 Acc 96.875%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.193 Acc 95.367%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.184 Acc 95.550%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.059 Acc 98.082%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.061 Acc 98.033%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.063 Acc 97.970%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.066 Acc 97.901%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.210 Acc 94.817%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.198 Acc 95.083%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.065 Acc 97.896%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.065 Acc 97.998%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.065 Acc 97.944%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.066 Acc 97.865%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.196 Acc 95.080%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.189 Acc 95.204%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.068 Acc 99.219%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.058 Acc 98.229%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.060 Acc 98.092%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.061 Acc 97.999%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.062 Acc 97.938%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.209 Acc 94.841%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.195 Acc 95.064%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.056 Acc 98.229%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.059 Acc 98.123%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.061 Acc 98.074%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.061 Acc 98.024%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.063 Acc 97.993%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.193 Acc 95.119%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.186 Acc 95.309%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.053 Acc 98.221%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.057 Acc 98.146%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.060 Acc 98.040%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.060 Acc 98.021%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.061 Acc 97.995%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.200 Acc 94.872%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.188 Acc 95.161%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.052 Acc 98.260%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.053 Acc 98.266%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.057 Acc 98.129%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.059 Acc 98.058%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.060 Acc 98.029%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.195 Acc 95.196%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.184 Acc 95.394%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.031 Acc 97.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.060 Acc 97.950%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.058 Acc 98.072%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.059 Acc 98.064%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.060 Acc 98.038%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.060 Acc 98.012%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.149 Acc 97.656%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.193 Acc 95.266%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.183 Acc 95.390%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.052 Acc 98.283%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.056 Acc 98.189%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.059 Acc 98.091%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.060 Acc 98.084%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.210 Acc 94.771%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.201 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.057 Acc 98.198%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.057 Acc 98.169%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.057 Acc 98.162%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.059 Acc 98.073%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.059 Acc 98.054%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.216 Acc 94.848%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.206 Acc 94.982%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.051 Acc 98.376%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.052 Acc 98.321%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.055 Acc 98.174%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.057 Acc 98.121%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.170 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.215 Acc 94.895%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.206 Acc 95.072%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.049 Acc 98.329%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.054 Acc 98.162%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.055 Acc 98.136%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.055 Acc 98.143%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.056 Acc 98.105%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.215 Acc 94.854%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.058 Acc 96.875%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.048 Acc 98.430%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.050 Acc 98.336%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.052 Acc 98.292%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.054 Acc 98.208%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.055 Acc 98.169%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.209 Acc 94.972%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.198 Acc 95.173%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.050 Acc 98.283%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.051 Acc 98.270%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.053 Acc 98.199%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.054 Acc 98.180%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.057 Acc 98.096%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.212 Acc 94.879%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.206 Acc 94.943%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.053 Acc 98.298%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.053 Acc 98.255%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.053 Acc 98.269%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.054 Acc 98.194%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.055 Acc 98.146%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.052 Acc 98.275%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.053 Acc 98.255%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.054 Acc 98.287%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.055 Acc 98.215%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.056 Acc 98.155%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.204 Acc 95.297%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.195 Acc 95.410%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.047 Acc 98.345%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.052 Acc 98.270%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.053 Acc 98.230%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.051 Acc 98.299%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.054 Acc 98.213%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.207 Acc 95.111%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.049 Acc 98.345%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.052 Acc 98.204%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.051 Acc 98.301%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.053 Acc 98.238%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.217 Acc 95.011%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.210 Acc 95.095%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.053 Acc 98.175%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.051 Acc 98.247%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.051 Acc 98.247%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.051 Acc 98.271%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.205 Acc 94.438%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.193 Acc 94.803%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.049 Acc 98.368%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.050 Acc 98.321%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.052 Acc 98.300%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.051 Acc 98.301%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.051 Acc 98.311%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.211 Acc 94.833%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.201 Acc 94.986%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.046 Acc 98.480%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.047 Acc 98.409%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.049 Acc 98.375%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.051 Acc 98.344%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.099 Acc 96.875%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.217 Acc 94.903%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.206 Acc 95.106%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.052 Acc 98.260%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.055 Acc 98.216%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.052 Acc 98.284%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.054 Acc 98.200%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.054 Acc 98.194%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.223 Acc 94.841%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.210 Acc 95.040%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.047 Acc 98.314%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.046 Acc 98.379%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.048 Acc 98.339%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.048 Acc 98.367%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.050 Acc 98.353%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.211 Acc 94.926%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.202 Acc 95.145%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.038 Acc 96.875%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.042 Acc 98.631%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.047 Acc 98.403%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.048 Acc 98.373%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.049 Acc 98.379%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.048 Acc 98.369%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.231 Acc 94.748%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.219 Acc 94.932%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.048 Acc 98.348%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.047 Acc 98.409%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.048 Acc 98.387%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.049 Acc 98.392%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.218 Acc 95.243%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.208 Acc 95.305%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.064 Acc 96.094%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.047 Acc 98.445%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.044 Acc 98.574%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.045 Acc 98.549%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.045 Acc 98.525%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.046 Acc 98.466%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.218 Acc 94.787%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.205 Acc 94.928%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.047 Acc 98.461%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.049 Acc 98.406%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.048 Acc 98.430%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.049 Acc 98.384%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.205 Acc 95.367%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.045 Acc 98.492%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.046 Acc 98.440%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.047 Acc 98.420%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.048 Acc 98.395%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.195 Acc 95.282%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.188 Acc 95.421%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.042 Acc 98.600%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.045 Acc 98.418%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.045 Acc 98.430%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.047 Acc 98.389%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.047 Acc 98.391%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.170 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.211 Acc 95.189%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.202 Acc 95.328%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.047 Acc 98.407%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.045 Acc 98.488%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.046 Acc 98.448%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.046 Acc 98.432%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.048 Acc 98.378%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.235 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.221 Acc 95.034%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.214 Acc 95.114%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.042 Acc 98.577%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.045 Acc 98.480%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.045 Acc 98.492%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.046 Acc 98.420%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.046 Acc 98.433%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.193 Acc 95.374%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.187 Acc 95.414%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.034 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.038 Acc 98.631%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.041 Acc 98.562%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.042 Acc 98.567%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.043 Acc 98.537%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.044 Acc 98.489%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.223 Acc 94.593%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.215 Acc 94.761%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.043 Acc 98.523%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.043 Acc 98.570%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.043 Acc 98.559%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.042 Acc 98.582%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.044 Acc 98.520%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.205 Acc 95.119%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.195 Acc 95.281%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.034 Acc 97.656%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.045 Acc 98.399%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.042 Acc 98.550%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.042 Acc 98.580%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.043 Acc 98.589%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.044 Acc 98.544%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.216 Acc 95.127%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.043 Acc 98.561%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.041 Acc 98.597%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.041 Acc 98.603%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.042 Acc 98.545%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.262 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.234 Acc 95.042%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.224 Acc 94.998%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.039 Acc 98.646%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.042 Acc 98.566%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.043 Acc 98.575%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.044 Acc 98.484%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.044 Acc 98.523%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.209 Acc 95.019%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.201 Acc 95.215%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.039 Acc 98.677%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.039 Acc 98.612%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.040 Acc 98.614%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.041 Acc 98.588%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.042 Acc 98.572%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.144 Acc 96.875%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.205 Acc 95.166%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.197 Acc 95.417%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.043 Acc 98.461%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.042 Acc 98.588%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.043 Acc 98.535%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.044 Acc 98.522%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.187 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.219 Acc 95.150%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.206 Acc 95.386%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.045 Acc 98.443%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.044 Acc 98.482%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.044 Acc 98.480%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.212 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.221 Acc 95.042%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.213 Acc 95.048%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.041 Acc 98.600%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.042 Acc 98.570%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.043 Acc 98.534%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.044 Acc 98.523%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.044 Acc 98.486%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.225 Acc 95.258%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.211 Acc 95.425%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.035 Acc 98.793%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.040 Acc 98.659%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.041 Acc 98.635%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.042 Acc 98.632%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.041 Acc 98.639%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.234 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.223 Acc 95.019%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.212 Acc 95.138%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.035 Acc 98.855%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.042 Acc 98.557%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.041 Acc 98.566%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.041 Acc 98.570%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.218 Acc 94.872%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.210 Acc 94.974%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.037 Acc 98.801%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.040 Acc 98.630%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.040 Acc 98.621%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.040 Acc 98.629%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.214 Acc 96.094%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.244 Acc 94.547%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.232 Acc 94.780%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.034 Acc 98.855%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.040 Acc 98.659%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.043 Acc 98.531%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.044 Acc 98.496%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.043 Acc 98.525%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.215 Acc 94.980%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.203 Acc 95.118%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.035 Acc 98.811%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.037 Acc 98.788%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.037 Acc 98.753%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.038 Acc 98.712%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.217 Acc 95.088%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.205 Acc 95.243%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.071 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.044 Acc 98.708%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.042 Acc 98.678%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.041 Acc 98.648%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.040 Acc 98.662%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.040 Acc 98.643%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.221 Acc 94.910%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.207 Acc 95.262%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.039 Acc 98.677%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.041 Acc 98.647%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.039 Acc 98.705%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.041 Acc 98.650%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.042 Acc 98.590%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.231 Acc 94.964%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.217 Acc 95.208%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.037 Acc 98.832%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.037 Acc 98.826%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.037 Acc 98.816%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.037 Acc 98.775%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.039 Acc 98.687%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.218 Acc 95.367%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.205 Acc 95.534%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.031 Acc 98.909%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.033 Acc 98.811%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.035 Acc 98.759%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.036 Acc 98.714%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.038 Acc 98.653%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.234 Acc 94.833%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.222 Acc 95.106%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.038 Acc 98.677%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.038 Acc 98.705%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.038 Acc 98.699%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.038 Acc 98.701%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.224 Acc 95.196%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.213 Acc 95.425%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.035 Acc 98.747%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.034 Acc 98.752%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.036 Acc 98.723%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.037 Acc 98.708%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.037 Acc 98.717%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.234 Acc 95.266%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.222 Acc 95.472%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.038 Acc 98.631%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.038 Acc 98.725%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.037 Acc 98.733%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.038 Acc 98.718%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.038 Acc 98.729%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.255 Acc 94.709%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.242 Acc 94.807%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.041 Acc 98.608%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.038 Acc 98.682%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.038 Acc 98.700%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.038 Acc 98.728%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.039 Acc 98.687%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.210 Acc 95.011%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.199 Acc 95.188%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.037 Acc 98.670%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.037 Acc 98.694%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.036 Acc 98.744%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.036 Acc 98.714%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.240 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.223 Acc 95.220%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.209 Acc 95.476%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.038 Acc 98.739%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.037 Acc 98.787%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.037 Acc 98.762%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.038 Acc 98.716%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.038 Acc 98.720%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.240 Acc 94.794%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.224 Acc 95.072%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.041 Acc 98.592%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.037 Acc 98.748%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.037 Acc 98.707%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.037 Acc 98.704%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.037 Acc 98.717%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [100/204] Loss: 0.232 Acc 94.462%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.218 Acc 94.807%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.036 Acc 98.764%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.037 Acc 98.736%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.038 Acc 98.706%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.038 Acc 98.706%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.214 Acc 95.026%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.203 Acc 95.301%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.027 Acc 99.064%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.030 Acc 99.028%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.033 Acc 98.910%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.035 Acc 98.810%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.036 Acc 98.779%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.279 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.224 Acc 94.949%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.212 Acc 95.176%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.029 Acc 98.994%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.033 Acc 98.869%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.032 Acc 98.905%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.033 Acc 98.858%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.034 Acc 98.835%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.228 Acc 94.980%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.214 Acc 95.270%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.035 Acc 98.793%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.033 Acc 98.853%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.036 Acc 98.754%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.037 Acc 98.734%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.036 Acc 98.751%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.226 Acc 95.096%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.215 Acc 95.289%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.027 Acc 99.080%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.031 Acc 98.951%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.031 Acc 98.957%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.031 Acc 98.958%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.034 Acc 98.873%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.217 Acc 94.980%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.206 Acc 95.184%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.029 Acc 99.072%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.032 Acc 98.902%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.032 Acc 98.917%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.033 Acc 98.873%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.212 Acc 95.127%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.204 Acc 95.278%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.033 Acc 98.824%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.033 Acc 98.850%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.034 Acc 98.822%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.034 Acc 98.835%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.035 Acc 98.820%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.226 Acc 95.119%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.214 Acc 95.340%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.031 Acc 98.931%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.032 Acc 98.871%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.033 Acc 98.812%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.035 Acc 98.787%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.216 Acc 94.640%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.208 Acc 94.900%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.033 Acc 98.925%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.034 Acc 98.861%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.034 Acc 98.845%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.035 Acc 98.833%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.035 Acc 98.832%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.286 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.229 Acc 94.554%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.219 Acc 94.838%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.031 Acc 98.878%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.031 Acc 98.935%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.031 Acc 98.923%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.032 Acc 98.895%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.032 Acc 98.857%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.251 Acc 94.848%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.238 Acc 95.204%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.036 Acc 98.764%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.034 Acc 98.819%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.034 Acc 98.815%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.034 Acc 98.818%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.232 Acc 94.616%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.218 Acc 94.799%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.031 Acc 98.900%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.032 Acc 98.855%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.033 Acc 98.847%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.033 Acc 98.849%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.235 Acc 94.995%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.220 Acc 95.157%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.029 Acc 98.979%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.032 Acc 98.954%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.033 Acc 98.876%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.033 Acc 98.915%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.033 Acc 98.910%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.228 Acc 94.763%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.215 Acc 95.083%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.032 Acc 98.786%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.029 Acc 98.888%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.031 Acc 98.879%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.031 Acc 98.880%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.032 Acc 98.857%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.228 Acc 95.196%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.213 Acc 95.468%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.030 Acc 98.971%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.032 Acc 98.896%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.031 Acc 98.946%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.032 Acc 98.907%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.032 Acc 98.902%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.305 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.223 Acc 95.359%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.211 Acc 95.460%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.028 Acc 99.080%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.033 Acc 98.923%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.033 Acc 98.889%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.033 Acc 98.870%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.033 Acc 98.888%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.222 Acc 94.941%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.209 Acc 95.211%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.031 Acc 98.878%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.030 Acc 98.904%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.031 Acc 98.920%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.031 Acc 98.911%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.031 Acc 98.885%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.222 Acc 95.150%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.208 Acc 95.359%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.033 Acc 98.933%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.033 Acc 98.919%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.033 Acc 98.897%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.033 Acc 98.886%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.032 Acc 98.912%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.244 Acc 94.964%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.229 Acc 95.075%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.030 Acc 98.909%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.033 Acc 98.896%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.031 Acc 98.951%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.031 Acc 98.950%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.032 Acc 98.907%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.227 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.231 Acc 95.088%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.220 Acc 95.192%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.025 Acc 99.141%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.027 Acc 99.001%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.027 Acc 98.993%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.029 Acc 98.950%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.030 Acc 98.921%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.242 Acc 94.547%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.226 Acc 94.784%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.029 Acc 98.909%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.031 Acc 98.877%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.031 Acc 98.897%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.032 Acc 98.878%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.032 Acc 98.865%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.237 Acc 94.957%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.226 Acc 95.227%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.028 Acc 98.987%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.030 Acc 98.978%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.030 Acc 98.975%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.030 Acc 98.936%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.031 Acc 98.926%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.230 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.226 Acc 94.926%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.212 Acc 95.141%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.026 Acc 99.103%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.029 Acc 99.014%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.030 Acc 98.991%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.030 Acc 98.960%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.257 Acc 94.833%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.240 Acc 95.037%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.029 Acc 99.080%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.030 Acc 99.017%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.030 Acc 98.975%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.030 Acc 98.965%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.031 Acc 98.954%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.279 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.236 Acc 94.980%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.226 Acc 95.188%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.032 Acc 98.909%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.030 Acc 98.916%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.031 Acc 98.871%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.032 Acc 98.843%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.032 Acc 98.865%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.224 Acc 95.135%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.212 Acc 95.332%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.025 Acc 98.438%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.033 Acc 99.002%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.030 Acc 98.982%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.031 Acc 98.909%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.031 Acc 98.937%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.364 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.253 Acc 94.794%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.235 Acc 95.033%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.032 Acc 98.863%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.030 Acc 98.958%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.030 Acc 98.925%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.029 Acc 98.979%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.029 Acc 98.986%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.219 Acc 95.359%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.208 Acc 95.553%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.026 Acc 99.018%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.027 Acc 99.052%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.028 Acc 99.021%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.029 Acc 99.001%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.029 Acc 98.983%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.266 Acc 95.312%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.227 Acc 94.972%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.217 Acc 95.196%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.056 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.027 Acc 99.110%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.026 Acc 99.067%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.027 Acc 99.058%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.027 Acc 99.073%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.028 Acc 99.013%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.282 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.256 Acc 94.864%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.245 Acc 94.932%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.027 Acc 99.080%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.029 Acc 99.001%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.031 Acc 98.967%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.030 Acc 98.954%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.030 Acc 98.991%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [100/204] Loss: 0.215 Acc 94.910%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.200 Acc 95.274%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.028 Acc 99.018%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.027 Acc 99.040%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.028 Acc 99.022%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.029 Acc 98.972%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.254 Acc 94.825%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.241 Acc 94.970%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.030 Acc 98.925%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.030 Acc 98.912%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.030 Acc 98.907%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.031 Acc 98.913%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.031 Acc 98.904%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.223 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.233 Acc 94.964%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.220 Acc 95.165%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.027 Acc 99.103%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.029 Acc 99.032%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.030 Acc 98.998%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.030 Acc 98.987%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.030 Acc 98.983%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.236 Acc 95.189%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.219 Acc 95.507%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.031 Acc 98.948%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.030 Acc 99.005%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.030 Acc 99.019%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.030 Acc 99.006%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.030 Acc 98.968%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.190 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.232 Acc 94.988%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.220 Acc 95.161%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.012 Acc 99.219%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.026 Acc 99.103%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.026 Acc 99.106%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.026 Acc 99.114%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.027 Acc 99.074%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.230 Acc 95.166%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.218 Acc 95.258%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.029 Acc 98.987%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.030 Acc 99.009%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.028 Acc 99.037%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.028 Acc 99.059%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.028 Acc 99.036%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.216 Acc 95.212%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.202 Acc 95.515%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.013 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.022 Acc 99.203%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.025 Acc 99.172%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.025 Acc 99.169%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.025 Acc 99.158%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.027 Acc 99.113%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.192 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.242 Acc 95.026%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.228 Acc 95.169%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.019 Acc 99.319%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.024 Acc 99.122%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.026 Acc 99.076%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.026 Acc 99.078%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.027 Acc 99.066%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.224 Acc 96.094%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.235 Acc 95.498%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.223 Acc 95.666%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.025 Acc 99.049%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.028 Acc 98.989%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.029 Acc 98.957%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.029 Acc 98.975%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.028 Acc 99.029%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.204 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.232 Acc 95.096%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.222 Acc 95.250%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.030 Acc 99.118%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.030 Acc 99.040%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.028 Acc 99.118%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.028 Acc 99.069%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.028 Acc 99.055%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.245 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.254 Acc 94.895%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.241 Acc 95.060%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.023 Acc 99.226%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.029 Acc 98.985%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.029 Acc 99.004%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.029 Acc 98.996%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.229 Acc 95.050%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.213 Acc 95.417%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.025 Acc 99.226%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.026 Acc 99.114%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.027 Acc 99.092%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.027 Acc 99.060%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.234 Acc 94.848%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.220 Acc 95.138%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.027 Acc 99.134%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.028 Acc 99.044%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.027 Acc 99.040%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.026 Acc 99.049%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.027 Acc 99.010%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.254 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.249 Acc 94.756%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.232 Acc 95.114%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.031 Acc 98.987%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.027 Acc 99.075%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.030 Acc 98.980%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.029 Acc 99.006%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.029 Acc 98.988%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.230 Acc 94.995%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.216 Acc 95.320%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.026 Acc 99.145%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.026 Acc 99.154%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.026 Acc 99.133%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.027 Acc 99.102%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [165/200]Batch [100/204] Loss: 0.242 Acc 95.297%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.226 Acc 95.390%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.023 Acc 99.157%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.024 Acc 99.106%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.025 Acc 99.136%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.026 Acc 99.082%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.027 Acc 99.071%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.241 Acc 94.918%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.224 Acc 95.145%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.024 Acc 99.141%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.026 Acc 99.102%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.027 Acc 99.082%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.027 Acc 99.082%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.242 Acc 94.361%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.226 Acc 94.652%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.027 Acc 99.087%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.027 Acc 99.063%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.028 Acc 99.045%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.028 Acc 99.041%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.232 Acc 94.957%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.218 Acc 95.200%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.024 Acc 99.103%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.025 Acc 99.145%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.024 Acc 99.214%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.025 Acc 99.186%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.027 Acc 99.121%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.286 Acc 92.188%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.249 Acc 95.019%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.232 Acc 95.281%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.029 Acc 99.087%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.026 Acc 99.122%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.027 Acc 99.089%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.028 Acc 99.050%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.225 Acc 95.220%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.209 Acc 95.332%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.028 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.025 Acc 99.172%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.023 Acc 99.199%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.024 Acc 99.193%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.024 Acc 99.170%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.024 Acc 99.159%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.255 Acc 94.802%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.240 Acc 95.075%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.028 Acc 99.013%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.028 Acc 99.014%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.029 Acc 99.020%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.028 Acc 99.049%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.237 Acc 95.135%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.220 Acc 95.382%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.007 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.020 Acc 99.404%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.022 Acc 99.312%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.024 Acc 99.224%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.024 Acc 99.170%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.026 Acc 99.097%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.216 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.230 Acc 94.941%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.215 Acc 95.184%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.021 Acc 99.226%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.024 Acc 99.153%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.025 Acc 99.123%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.026 Acc 99.123%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.027 Acc 99.091%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.201 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.254 Acc 94.756%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.241 Acc 94.893%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.027 Acc 99.072%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.024 Acc 99.188%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.024 Acc 99.193%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.024 Acc 99.191%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.025 Acc 99.139%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.250 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.242 Acc 95.057%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.226 Acc 95.239%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.024 Acc 99.118%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.025 Acc 99.156%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.025 Acc 99.143%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.025 Acc 99.122%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.248 Acc 95.343%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.229 Acc 95.476%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.025 Acc 99.056%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.023 Acc 99.168%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.024 Acc 99.159%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.025 Acc 99.156%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.025 Acc 99.164%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.243 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.245 Acc 95.003%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.228 Acc 95.278%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.011 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.026 Acc 99.141%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.024 Acc 99.203%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.024 Acc 99.185%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.025 Acc 99.154%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.025 Acc 99.124%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.241 Acc 94.980%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.227 Acc 95.227%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.025 Acc 99.141%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.025 Acc 99.180%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.025 Acc 99.168%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.025 Acc 99.161%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.248 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.245 Acc 94.972%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.229 Acc 95.204%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.025 Acc 99.118%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.024 Acc 99.203%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.025 Acc 99.203%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.025 Acc 99.168%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.025 Acc 99.147%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [180/200]Batch [100/204] Loss: 0.230 Acc 95.127%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.213 Acc 95.336%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.023 Acc 99.265%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.022 Acc 99.300%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.022 Acc 99.278%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.023 Acc 99.267%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.024 Acc 99.248%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.231 Acc 95.135%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.217 Acc 95.320%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.022 Acc 99.250%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.023 Acc 99.223%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.024 Acc 99.172%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.024 Acc 99.178%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.025 Acc 99.156%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.256 Acc 96.094%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.249 Acc 94.903%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.235 Acc 95.044%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.023 Acc 99.103%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.024 Acc 99.141%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.024 Acc 99.167%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.025 Acc 99.136%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.225 Acc 94.864%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.213 Acc 95.180%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.023 Acc 99.172%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.025 Acc 99.122%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.026 Acc 99.102%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.027 Acc 99.094%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.026 Acc 99.127%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.212 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.253 Acc 95.235%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.237 Acc 95.429%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.022 Acc 99.157%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.023 Acc 99.137%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.025 Acc 99.102%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.026 Acc 99.092%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.025 Acc 99.105%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.246 Acc 95.104%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.233 Acc 95.363%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.017 Acc 99.366%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.021 Acc 99.246%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.024 Acc 99.136%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.025 Acc 99.119%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.024 Acc 99.153%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.291 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.249 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.233 Acc 95.573%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.024 Acc 99.180%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.026 Acc 99.106%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.027 Acc 99.092%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.026 Acc 99.121%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.026 Acc 99.131%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.322 Acc 93.750%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.251 Acc 95.034%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.237 Acc 95.223%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.020 Acc 99.265%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.020 Acc 99.331%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.022 Acc 99.252%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.023 Acc 99.223%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.023 Acc 99.198%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.238 Acc 94.949%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.225 Acc 95.176%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.020 Acc 99.319%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.020 Acc 99.285%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.021 Acc 99.276%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.023 Acc 99.234%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.025 Acc 99.161%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.250 Acc 95.374%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.234 Acc 95.468%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.020 Acc 99.288%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.021 Acc 99.246%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.023 Acc 99.172%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.023 Acc 99.184%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.024 Acc 99.169%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.271 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.235 Acc 95.196%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.221 Acc 95.460%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.024 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.020 Acc 99.428%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.021 Acc 99.308%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.021 Acc 99.291%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.022 Acc 99.227%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.023 Acc 99.183%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.302 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.243 Acc 95.073%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.229 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.024 Acc 99.126%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.024 Acc 99.157%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.023 Acc 99.188%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.024 Acc 99.176%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.025 Acc 99.141%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.237 Acc 95.282%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.227 Acc 95.367%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.021 Acc 99.335%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.023 Acc 99.260%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.023 Acc 99.222%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.245 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.254 Acc 94.740%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.235 Acc 95.103%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.021 Acc 99.335%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.022 Acc 99.268%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.022 Acc 99.254%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.023 Acc 99.227%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.246 Acc 96.094%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.251 Acc 94.910%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.238 Acc 95.219%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.024 Acc 99.257%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.022 Acc 99.281%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.021 Acc 99.284%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.021 Acc 99.275%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.021 Acc 99.245%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [195/200]Batch [100/204] Loss: 0.246 Acc 94.957%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.232 Acc 95.239%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.026 Acc 99.172%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.025 Acc 99.149%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.025 Acc 99.145%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.024 Acc 99.163%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.236 Acc 95.235%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.224 Acc 95.495%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.023 Acc 99.234%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.023 Acc 99.246%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.022 Acc 99.265%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.022 Acc 99.266%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.023 Acc 99.251%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.264 Acc 95.088%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.248 Acc 95.165%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.026 Acc 99.141%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.023 Acc 99.211%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.024 Acc 99.169%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.024 Acc 99.190%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.023 Acc 99.214%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.267 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.259 Acc 94.964%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.243 Acc 95.208%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.017 Acc 99.474%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.020 Acc 99.355%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.020 Acc 99.369%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.021 Acc 99.328%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.021 Acc 99.315%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.262 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.293 Acc 93.920%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.270 Acc 94.290%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba61029e3b8f4f579817542977b908d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2024ee24a84ae4bd7c9144d41029f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.303 Acc 11.719%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 8.025 Acc 15.401%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 5.146 Acc 17.339%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 4.179 Acc 17.953%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 3.695 Acc 18.214%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 3.404 Acc 18.318%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.255 Acc 17.969%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.236 Acc 18.843%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.234 Acc 19.049%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.235 Acc 19.025%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 18.939%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 18.862%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.230 Acc 15.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.237 Acc 19.067%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.235 Acc 19.080%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.235 Acc 19.093%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.315 Acc 10.938%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.235 Acc 19.640%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 19.174%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.212 Acc 21.094%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.240 Acc 18.727%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.239 Acc 18.862%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.239 Acc 18.857%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.238 Acc 18.900%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.222 Acc 17.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.230 Acc 19.276%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.234 Acc 19.080%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.235 Acc 19.007%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.169 Acc 29.688%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.242 Acc 18.487%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.241 Acc 18.404%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.238 Acc 18.690%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.238 Acc 18.732%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.204 Acc 25.781%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.239 Acc 16.406%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.242 Acc 18.533%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.236 Acc 18.854%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.238 Acc 18.851%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.254 Acc 15.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.241 Acc 18.673%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.239 Acc 19.049%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.237 Acc 19.072%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.225 Acc 19.562%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.174 Acc 26.562%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 6213550647.636 Acc 17.164%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 37551639969.051 Acc 13.402%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 25104879750.669 Acc 12.129%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 18855689582.073 Acc 11.415%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 15094789924.211 Acc 11.185%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 7.187 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 7.676 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 7.696 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 6041380.000 Acc 10.156%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 5473234.931 Acc 11.231%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 4976875.229 Acc 11.497%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 4544429.591 Acc 11.734%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 4206809.904 Acc 11.822%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 3938327.651 Acc 11.948%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 11.669 Acc 9.375%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 12.234 Acc 11.108%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 12.264 Acc 11.093%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2507511.750 Acc 10.938%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2311833.406 Acc 13.436%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2187310.575 Acc 13.623%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2092788.024 Acc 13.647%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2018538.674 Acc 13.714%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 1942253.055 Acc 13.864%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 17.163 Acc 9.375%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 17.601 Acc 11.108%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 17.640 Acc 11.093%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 1888615.250 Acc 12.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 1459795.185 Acc 14.070%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 1393741.603 Acc 14.109%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 1340408.878 Acc 14.210%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 1313410.556 Acc 14.238%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 1260194.836 Acc 14.203%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 22.430 Acc 9.375%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 22.853 Acc 11.108%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 22.899 Acc 11.093%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 908454.750 Acc 12.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 956601.303 Acc 14.202%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 930840.723 Acc 14.265%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 901913.691 Acc 14.314%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 875672.090 Acc 14.288%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 844684.134 Acc 14.310%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 27.390 Acc 9.375%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 27.907 Acc 11.108%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 27.959 Acc 11.093%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 526005.688 Acc 17.969%\n",
      "Train Epoch [ 15/200]Batch [100/573] Loss: 612044.314 Acc 14.356%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 600380.545 Acc 14.152%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 577658.191 Acc 14.091%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 563275.872 Acc 14.105%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 543114.875 Acc 14.014%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 32.159 Acc 9.375%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 32.872 Acc 11.108%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 32.929 Acc 11.093%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 447300.031 Acc 13.281%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 407633.550 Acc 14.016%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 395274.217 Acc 13.724%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 386481.198 Acc 13.652%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 373672.679 Acc 13.636%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 358889.282 Acc 13.585%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 36.693 Acc 9.375%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 37.637 Acc 11.108%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 37.699 Acc 11.093%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 292437.875 Acc 10.156%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 253033.740 Acc 13.622%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 241545.837 Acc 13.717%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 232323.333 Acc 13.806%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 222294.857 Acc 13.741%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 216782.666 Acc 13.772%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 41.517 Acc 9.375%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 42.568 Acc 11.108%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 42.636 Acc 11.093%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 160903.500 Acc 12.500%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 161151.500 Acc 13.784%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 164359.385 Acc 13.577%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 153657.264 Acc 13.632%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 156148.302 Acc 13.418%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 149851.187 Acc 13.341%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 45.191 Acc 9.375%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 46.436 Acc 11.108%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 46.506 Acc 11.093%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 63205.645 Acc 17.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 94403.536 Acc 13.390%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 88352.827 Acc 13.371%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 90885.111 Acc 13.294%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 86646.933 Acc 13.285%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 83086.624 Acc 13.217%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 46.909 Acc 9.375%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 48.046 Acc 11.108%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 48.111 Acc 11.093%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 45848.961 Acc 10.938%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 70149.331 Acc 12.972%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 61051.910 Acc 12.955%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 53685.090 Acc 12.848%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 55921.962 Acc 12.808%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 51164.849 Acc 12.782%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 44.300 Acc 9.375%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 45.207 Acc 11.108%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 45.251 Acc 11.093%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 18917.396 Acc 18.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 35828.784 Acc 12.693%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 30236.849 Acc 12.484%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 30473.959 Acc 12.453%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 29109.716 Acc 12.387%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 27399.590 Acc 12.321%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 39.009 Acc 9.375%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 39.796 Acc 11.108%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 39.818 Acc 11.093%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 11112.469 Acc 15.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 18974.805 Acc 11.974%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 20543.330 Acc 11.917%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 19506.000 Acc 12.009%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 18980.794 Acc 11.986%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 17907.474 Acc 11.981%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 32.365 Acc 9.375%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 33.266 Acc 11.108%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 33.257 Acc 11.093%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 6967.160 Acc 10.156%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 9300.033 Acc 11.603%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 8596.181 Acc 11.855%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 8409.276 Acc 12.043%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 8291.172 Acc 11.867%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 9299.169 Acc 11.911%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 25.181 Acc 9.375%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 26.245 Acc 11.108%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 26.205 Acc 11.093%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 3703.797 Acc 14.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 7592.864 Acc 12.005%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 7847.532 Acc 11.758%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 7758.796 Acc 11.760%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 12206.384 Acc 11.746%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 11231.750 Acc 11.719%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 19.585 Acc 9.375%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 20.732 Acc 11.108%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 20.670 Acc 11.093%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 1433.439 Acc 13.281%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 4798.989 Acc 11.858%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 4252.188 Acc 11.835%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 4642.637 Acc 11.724%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 4589.142 Acc 11.699%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 4551.210 Acc 11.737%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 14.822 Acc 9.375%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 15.905 Acc 11.108%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 15.842 Acc 11.093%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2972.569 Acc 12.500%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 4132.033 Acc 11.255%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 4028.600 Acc 11.544%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 3535.654 Acc 11.490%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 3507.258 Acc 11.584%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 3769.963 Acc 11.638%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 9.964 Acc 9.375%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 10.976 Acc 11.108%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 10.913 Acc 11.093%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2050.243 Acc 12.500%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 1782.913 Acc 12.028%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2166.118 Acc 11.929%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2018.950 Acc 13.427%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 1912.508 Acc 14.838%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 1785.121 Acc 15.533%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 8.076 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 8.969 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 8.913 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2006.777 Acc 18.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 1798.753 Acc 18.735%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 1725.513 Acc 18.847%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 1608.431 Acc 18.836%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 1537.532 Acc 18.756%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 1564.648 Acc 18.725%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 7.050 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 7.792 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 7.745 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 389.863 Acc 18.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2761.735 Acc 18.796%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 1745.843 Acc 18.672%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 1553.086 Acc 18.763%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 1545.196 Acc 18.649%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 1349.591 Acc 18.697%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 5.983 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 6.571 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 6.534 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 473.417 Acc 18.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 605.824 Acc 18.719%\n",
      "Train Epoch [ 30/200]Batch [200/573] Loss: 648.914 Acc 18.633%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 914.802 Acc 18.779%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 1035.822 Acc 18.768%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 970.848 Acc 18.655%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 4.877 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 5.303 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 5.276 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 22.792 Acc 21.094%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 957.913 Acc 18.464%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 1108.719 Acc 18.552%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 932.388 Acc 18.675%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 825.785 Acc 18.701%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 731.564 Acc 18.783%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 3.778 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 4.045 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 4.029 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 213.059 Acc 14.062%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 540.039 Acc 19.075%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 470.664 Acc 19.166%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 437.730 Acc 18.937%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 378.047 Acc 18.912%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 348.678 Acc 18.794%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.610 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.704 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.699 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 67.964 Acc 21.094%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 297.568 Acc 19.021%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 306.675 Acc 19.282%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 294.340 Acc 19.129%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 384.530 Acc 19.089%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 334.494 Acc 18.869%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 552.268 Acc 13.281%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 168.669 Acc 18.835%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 409.513 Acc 19.123%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 323.366 Acc 18.903%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 459.588 Acc 18.859%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 405.835 Acc 18.971%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.241 Acc 16.406%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 77.093 Acc 18.711%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 89.257 Acc 18.661%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 80.736 Acc 18.921%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 73.796 Acc 18.990%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 106.043 Acc 18.897%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.274 Acc 14.844%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 137.352 Acc 18.742%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 112.779 Acc 18.917%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 101.378 Acc 19.093%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 90.553 Acc 19.085%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 1202.635 Acc 18.931%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.223 Acc 20.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 292.400 Acc 18.866%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 276.161 Acc 18.991%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 239.156 Acc 19.059%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 243.641 Acc 19.042%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 217.404 Acc 19.021%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 431.644 Acc 15.625%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 79.793 Acc 18.541%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 54.305 Acc 18.789%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 50.986 Acc 18.677%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 53.645 Acc 18.842%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 52.200 Acc 18.876%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.272 Acc 20.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 35.276 Acc 18.557%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 28.471 Acc 18.855%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 22.003 Acc 18.971%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 34.963 Acc 19.064%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 37.115 Acc 19.015%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.241 Acc 17.188%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 53.433 Acc 19.230%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 43.128 Acc 19.131%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 10003096496.770 Acc 17.940%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 7536548727.768 Acc 16.180%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 6032569618.667 Acc 15.173%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.317 Acc 14.062%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.331 Acc 16.120%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.335 Acc 15.986%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 569269.500 Acc 5.469%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 579362.330 Acc 11.231%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 643076.310 Acc 11.692%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 526277.091 Acc 12.124%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 481483.459 Acc 12.186%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 435967.312 Acc 12.389%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.255 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.276 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.279 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 64445.195 Acc 16.406%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 149227.716 Acc 14.356%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 162712.317 Acc 14.358%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 148853.404 Acc 14.569%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 135026.937 Acc 14.807%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 129305.400 Acc 14.802%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 162876.094 Acc 17.188%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 82774.223 Acc 15.934%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 80779.525 Acc 15.909%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 81335.672 Acc 16.079%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 73378.340 Acc 16.231%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 66883.069 Acc 16.481%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 55375.816 Acc 19.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 63703.041 Acc 16.530%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 50863.328 Acc 16.768%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 48562.225 Acc 16.936%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 51873.907 Acc 17.164%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 49557.751 Acc 17.145%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 5269.593 Acc 13.281%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 184730.553 Acc 17.737%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 110343.663 Acc 17.887%\n",
      "Train Epoch [ 45/200]Batch [300/573] Loss: 84608.275 Acc 17.958%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 70553.611 Acc 18.014%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 77614.448 Acc 18.129%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 614.554 Acc 20.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 22879.371 Acc 18.533%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 24199.475 Acc 18.280%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 21720.314 Acc 18.394%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 18364.042 Acc 18.317%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 18364.888 Acc 18.373%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 16937.070 Acc 14.844%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 9163.843 Acc 18.270%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 12376.207 Acc 18.396%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 12386.037 Acc 18.387%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 14070.509 Acc 18.430%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 13757.779 Acc 18.454%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 844.195 Acc 25.781%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 11278.502 Acc 18.665%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 12148.474 Acc 18.563%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 12554.099 Acc 18.540%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 12026.046 Acc 18.635%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 10750.558 Acc 18.583%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 138.299 Acc 23.438%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 7370.496 Acc 18.843%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 7857.298 Acc 19.185%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 7251.319 Acc 18.945%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 6661.829 Acc 18.929%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 6775.552 Acc 18.806%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2710.559 Acc 15.625%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 11205.681 Acc 18.487%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 8512.851 Acc 18.509%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 6558.431 Acc 18.745%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 5883.780 Acc 18.775%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 6326.969 Acc 18.830%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 3028.367 Acc 21.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 4226.843 Acc 18.696%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 3221.334 Acc 18.614%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2778.574 Acc 18.760%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 3063.038 Acc 18.791%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2835.049 Acc 18.844%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 16252.369 Acc 16.406%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2951.769 Acc 18.843%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2902.062 Acc 18.563%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 3313.646 Acc 18.711%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2957.822 Acc 18.758%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 3180.259 Acc 18.842%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.250 Acc 15.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 5956.408 Acc 18.649%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 3933.581 Acc 19.174%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 3413.799 Acc 18.984%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 3387.115 Acc 19.029%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 3093.462 Acc 18.943%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.261 Acc 17.188%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 610.716 Acc 19.554%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 1228.969 Acc 19.310%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 1564.979 Acc 18.937%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 1476.887 Acc 18.974%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 1366.051 Acc 18.971%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.172 Acc 22.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 1317.795 Acc 19.175%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 1261.057 Acc 18.917%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 1080.701 Acc 18.823%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 1297.026 Acc 18.892%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 1262.169 Acc 18.928%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 26588.791 Acc 19.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 728.036 Acc 19.036%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 769.429 Acc 19.049%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 609.208 Acc 18.784%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 808.209 Acc 18.779%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 662.029 Acc 18.811%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 225.114 Acc 19.052%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 287.306 Acc 18.983%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 558.531 Acc 18.779%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 504.395 Acc 18.738%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 534.971 Acc 18.834%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.262 Acc 17.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 998.951 Acc 18.943%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 1092.295 Acc 18.890%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 58/200]Batch [300/573] Loss: 927.867 Acc 18.784%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 765.131 Acc 18.900%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 648.897 Acc 18.854%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2196.799 Acc 16.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 4488.168 Acc 19.694%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2384.479 Acc 18.929%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 1645.912 Acc 19.015%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 1317.479 Acc 18.824%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 1150.323 Acc 18.918%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.278 Acc 20.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 952.202 Acc 18.649%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 1113.443 Acc 18.711%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 1490.714 Acc 18.965%\n",
      "Train Epoch [ 60/200]Batch [400/573] Loss: 1189.772 Acc 18.980%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 966.603 Acc 19.034%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 799797.549 Acc 18.835%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 403273.636 Acc 19.030%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 269365.957 Acc 18.869%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 202506.780 Acc 18.925%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 167984.569 Acc 18.878%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.223 Acc 17.188%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 5.043 Acc 18.866%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 32.773 Acc 18.762%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 26.656 Acc 18.823%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 51.914 Acc 18.918%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 42.235 Acc 18.922%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.225 Acc 19.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.239 Acc 18.588%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.237 Acc 18.989%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 10.731 Acc 18.847%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 9.036 Acc 18.879%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.239 Acc 18.642%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.238 Acc 18.731%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.906 Acc 18.963%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 12.178 Acc 18.898%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 19.594 Acc 18.872%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.193 Acc 21.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.234 Acc 19.044%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.236 Acc 18.649%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.236 Acc 18.926%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.236 Acc 18.943%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 297.967 Acc 19.407%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 150.840 Acc 19.119%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 101.471 Acc 19.015%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 76.724 Acc 18.951%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 61.856 Acc 19.001%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.281 Acc 16.406%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.238 Acc 18.742%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.238 Acc 18.777%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.284 Acc 11.719%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.241 Acc 18.572%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.240 Acc 18.785%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.239 Acc 19.004%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.238 Acc 18.975%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.255 Acc 20.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.241 Acc 18.804%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.240 Acc 18.626%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 146.738 Acc 18.859%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 117.896 Acc 18.833%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.274 Acc 15.625%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.239 Acc 18.929%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.199 Acc 24.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.234 Acc 19.059%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.237 Acc 18.738%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.238 Acc 18.734%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.234 Acc 22.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.236 Acc 18.929%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.238 Acc 18.736%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.237 Acc 18.878%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.225 Acc 21.875%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.234 Acc 19.214%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.233 Acc 19.034%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 4.269 Acc 19.019%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 3.864 Acc 18.954%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.208 Acc 21.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.236 Acc 19.268%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.238 Acc 18.856%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.234 Acc 19.154%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.235 Acc 19.028%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.237 Acc 18.975%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.205 Acc 24.219%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.236 Acc 18.893%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.236 Acc 18.921%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.234 Acc 14.062%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 61.817 Acc 19.114%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 32.174 Acc 19.228%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 22.228 Acc 19.064%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 17.244 Acc 18.986%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 14.248 Acc 18.989%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.238 Acc 17.188%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.236 Acc 18.952%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.237 Acc 18.955%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.277 Acc 14.062%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.239 Acc 18.789%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.239 Acc 18.797%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.239 Acc 18.770%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.212 Acc 23.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.987%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.238 Acc 19.034%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.188 Acc 27.344%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.235 Acc 18.448%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 18.806%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.185 Acc 22.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.235 Acc 19.251%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.238 Acc 18.906%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.893%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.195 Acc 22.656%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.243 Acc 18.727%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.240 Acc 18.703%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.238 Acc 18.867%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.270 Acc 17.188%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.230 Acc 19.779%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.233 Acc 19.481%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 17.491 Acc 19.048%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 17.530 Acc 18.993%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.251 Acc 17.188%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.240 Acc 18.619%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.237 Acc 18.956%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.237 Acc 18.971%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.290 Acc 20.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.240 Acc 18.827%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.238 Acc 19.127%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.238 Acc 19.100%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.238 Acc 18.982%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.238 Acc 18.932%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.305 Acc 17.188%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 1012774983.521 Acc 19.206%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 508906833.984 Acc 18.937%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 339834796.860 Acc 18.802%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 255087965.283 Acc 18.888%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 204172712.573 Acc 18.953%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.259 Acc 18.750%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.237 Acc 18.881%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.239 Acc 18.688%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.239 Acc 18.742%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 519.081 Acc 18.961%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.161 Acc 25.000%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.242 Acc 18.835%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.238 Acc 18.972%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 849.208 Acc 18.965%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 637.994 Acc 18.881%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 511.095 Acc 18.957%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.237 Acc 18.719%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.237 Acc 18.859%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.237 Acc 18.810%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.251 Acc 14.844%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.236 Acc 18.982%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.236 Acc 19.014%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.235 Acc 18.893%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.305 Acc 15.625%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.237 Acc 19.014%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.237 Acc 19.056%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.219 Acc 21.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.240 Acc 18.781%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.237 Acc 18.799%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.270 Acc 17.969%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.240 Acc 18.889%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.238 Acc 18.952%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.238 Acc 18.879%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.219 Acc 21.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.236 Acc 18.766%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.237 Acc 18.789%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.259 Acc 13.281%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.239 Acc 18.851%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 217.008 Acc 18.830%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 163.449 Acc 18.908%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 131.272 Acc 18.851%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.269 Acc 18.750%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.246 Acc 18.317%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.241 Acc 18.766%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.240 Acc 18.906%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.238 Acc 19.005%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.213 Acc 20.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.241 Acc 18.719%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.238 Acc 19.014%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.237 Acc 18.805%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.250 Acc 14.062%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.231 Acc 19.531%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 365.787 Acc 19.500%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 245.005 Acc 19.202%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 184.466 Acc 19.050%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 148.094 Acc 18.864%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.246 Acc 21.875%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.237 Acc 18.781%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.235 Acc 18.960%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.237 Acc 18.807%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.834%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.213 Acc 25.000%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.236 Acc 18.889%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.235 Acc 19.004%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.236 Acc 18.919%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.845%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.230 Acc 12.500%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.236 Acc 18.862%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.236 Acc 18.916%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.236 Acc 19.000%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.214 Acc 21.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.240 Acc 18.588%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [103/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.236 Acc 18.962%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.236 Acc 18.934%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.203 Acc 26.562%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.240 Acc 18.502%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.239 Acc 18.812%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.237 Acc 18.727%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.236 Acc 18.956%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.237 Acc 19.005%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.277 Acc 9.375%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.236 Acc 19.175%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.234 Acc 19.259%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.238 Acc 18.872%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.243 Acc 14.844%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.240 Acc 18.824%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.238 Acc 18.900%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.282 Acc 16.406%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.236 Acc 19.174%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.237 Acc 18.964%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.242 Acc 18.557%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.238 Acc 18.794%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.237 Acc 18.806%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.210 Acc 17.969%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 109777.650 Acc 18.905%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 55163.013 Acc 19.080%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 36837.175 Acc 18.973%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 27651.406 Acc 18.836%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 22132.610 Acc 18.876%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.231 Acc 21.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.237 Acc 18.928%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.237 Acc 18.777%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.217 Acc 24.219%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.233 Acc 19.361%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.237 Acc 19.061%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.237 Acc 18.792%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.288 Acc 14.844%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.237 Acc 18.603%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.236 Acc 19.158%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.236 Acc 19.054%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.243 Acc 19.531%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.237 Acc 18.704%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.238 Acc 18.763%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.190 Acc 25.781%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.242 Acc 18.851%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.237 Acc 19.069%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.237 Acc 19.093%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 18.976%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.292 Acc 18.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.236 Acc 18.987%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.237 Acc 18.857%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.883%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.223 Acc 19.531%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.240 Acc 18.851%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.239 Acc 18.828%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.238 Acc 18.884%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.238 Acc 18.950%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.213 Acc 22.656%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.234 Acc 19.183%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [118/200]Batch [200/573] Loss: 2.235 Acc 19.209%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.234 Acc 19.160%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.241 Acc 12.500%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.238 Acc 18.796%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.244%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.238 Acc 18.880%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.238 Acc 18.820%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.236 Acc 19.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.237 Acc 18.747%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.236 Acc 19.014%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.242 Acc 19.531%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.235 Acc 18.951%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.238 Acc 18.975%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.250 Acc 17.969%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.237 Acc 19.170%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.236 Acc 19.077%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.255 Acc 19.531%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.240 Acc 18.738%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.239 Acc 18.799%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.239 Acc 18.721%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.239 Acc 18.822%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.253 Acc 18.750%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.236 Acc 18.975%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.237 Acc 18.872%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.216 Acc 17.188%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.234 Acc 19.036%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.237 Acc 18.857%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.237 Acc 18.830%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.230 Acc 17.188%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.234 Acc 19.369%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.238 Acc 18.948%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.235 Acc 19.082%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 18.917%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.234 Acc 22.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.215 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.210 Acc 21.094%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.236 Acc 19.013%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.237 Acc 19.127%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.236 Acc 19.111%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.224 Acc 17.188%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.235 Acc 19.291%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.236 Acc 19.111%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.237 Acc 18.978%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.286 Acc 17.969%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.237 Acc 19.098%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.238 Acc 18.997%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.825%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.298 Acc 15.625%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.234 Acc 18.998%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.707%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.238 Acc 18.768%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.238 Acc 18.738%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.918%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.173 Acc 25.000%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.233 Acc 19.423%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.236 Acc 19.162%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [133/200]Batch [300/573] Loss: 2.235 Acc 19.186%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.209 Acc 25.781%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.235 Acc 19.276%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.235 Acc 18.983%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.238 Acc 18.881%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.296 Acc 14.844%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.236 Acc 19.199%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.237 Acc 19.209%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.237 Acc 19.080%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.238 Acc 18.834%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.237 Acc 18.869%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.228 Acc 20.312%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.238 Acc 18.645%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.239 Acc 18.817%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.238 Acc 18.869%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.249 Acc 22.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.234 Acc 18.943%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.236 Acc 18.808%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.238 Acc 18.794%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.266 Acc 17.969%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.240 Acc 18.332%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.239 Acc 18.657%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.236 Acc 19.041%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.236 Acc 18.953%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.237 Acc 18.859%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.189 Acc 19.531%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.241 Acc 18.448%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.240 Acc 18.424%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.240 Acc 18.628%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.237 Acc 18.916%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.965%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.161 Acc 25.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.240 Acc 18.363%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.237 Acc 18.832%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.243 Acc 21.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.237 Acc 19.237%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.235 Acc 19.286%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.234 Acc 19.209%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.236 Acc 18.980%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.248 Acc 16.406%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.240 Acc 18.936%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.240 Acc 18.832%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.239 Acc 18.871%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.238 Acc 18.831%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.258 Acc 15.625%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.237 Acc 18.804%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.236 Acc 18.976%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.254 Acc 18.750%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.241 Acc 18.781%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.238 Acc 18.807%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.237 Acc 18.992%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.243 Acc 18.711%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.239 Acc 18.723%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.194 Acc 19.531%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.235 Acc 19.059%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.237 Acc 18.699%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.755%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.795%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.283 Acc 17.188%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.836%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.267 Acc 17.969%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.239 Acc 18.711%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [148/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.188 Acc 24.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.234 Acc 19.732%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.235 Acc 19.341%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.235 Acc 19.202%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.236 Acc 19.173%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.239 Acc 17.969%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.235 Acc 19.446%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.238 Acc 19.045%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.238 Acc 18.855%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.238 Acc 18.914%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.159 Acc 28.906%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.237 Acc 19.069%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.196 Acc 23.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.238 Acc 18.974%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.240 Acc 18.769%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.239 Acc 18.777%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.238 Acc 18.914%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.227 Acc 24.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.241 Acc 18.680%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.260 Acc 17.969%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.241 Acc 18.560%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.241 Acc 18.644%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.239 Acc 18.787%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.290 Acc 14.844%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.239 Acc 18.858%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.235 Acc 19.166%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.234 Acc 18.967%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.235 Acc 19.095%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.236 Acc 19.095%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.237 Acc 19.032%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.213 Acc 17.188%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.235 Acc 18.943%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.236 Acc 18.863%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.235 Acc 18.914%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.260 Acc 15.625%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.237 Acc 19.106%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.238 Acc 18.662%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.238 Acc 18.752%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.238 Acc 18.858%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.269 Acc 14.062%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.234 Acc 18.680%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.235 Acc 18.773%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.238 Acc 18.649%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.237 Acc 18.818%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.237 Acc 18.884%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.256 Acc 17.969%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.239 Acc 18.827%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.237 Acc 19.061%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.237 Acc 18.849%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.236 Acc 18.971%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.238 Acc 18.680%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.239 Acc 18.805%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.265 Acc 15.625%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.240 Acc 18.905%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.237 Acc 18.983%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.971%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.237 Acc 18.935%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.191 Acc 21.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.234 Acc 19.144%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.235 Acc 19.061%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.237 Acc 18.971%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.236 Acc 19.071%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [163/200]Batch [500/573] Loss: 2.237 Acc 19.003%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.189 Acc 26.562%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.239 Acc 18.905%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.236 Acc 18.983%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.236 Acc 19.020%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.236 Acc 19.021%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.242 Acc 17.188%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.239 Acc 18.619%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.240 Acc 18.528%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.238 Acc 18.792%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.237 Acc 18.871%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.216 Acc 17.969%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.233 Acc 18.866%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.872%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.262 Acc 20.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.240 Acc 18.781%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.839%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.236 Acc 18.957%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.237 Acc 19.001%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.239 Acc 18.738%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.238 Acc 18.937%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.238 Acc 18.842%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.233 Acc 17.969%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.236 Acc 19.206%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.238 Acc 19.026%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.238 Acc 19.020%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.220 Acc 16.406%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.235 Acc 19.018%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.237 Acc 18.993%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.204 Acc 21.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.236 Acc 18.518%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.237 Acc 18.637%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.237 Acc 18.768%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.236 Acc 18.934%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.196 Acc 20.312%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.244 Acc 17.946%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.240 Acc 18.595%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.238 Acc 18.854%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.237 Acc 19.059%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.233 Acc 19.399%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.235 Acc 19.194%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.200 Acc 22.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.238 Acc 19.059%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.237 Acc 19.127%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.276 Acc 14.844%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.243 Acc 18.294%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.237 Acc 19.046%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.238 Acc 18.886%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.236 Acc 18.869%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.237 Acc 18.981%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.257 Acc 17.188%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.237 Acc 19.284%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.235 Acc 19.232%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.238 Acc 18.955%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.877%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.238 Acc 18.926%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.204 Acc 20.312%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.235 Acc 19.315%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.239 Acc 18.929%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.238 Acc 18.952%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.238 Acc 18.832%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.247 Acc 17.969%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.242 Acc 18.533%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.241 Acc 18.738%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.240 Acc 18.869%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.238 Acc 18.873%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.235 Acc 17.969%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.239 Acc 18.796%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.236 Acc 18.886%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.222 Acc 21.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.236 Acc 19.245%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.238 Acc 18.984%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.223 Acc 16.406%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.232 Acc 19.168%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.234 Acc 18.991%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.236 Acc 18.911%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.235 Acc 18.968%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.235 Acc 18.995%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.298 Acc 14.062%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.238 Acc 19.005%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.239 Acc 18.846%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.230 Acc 15.625%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.239 Acc 18.588%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.239 Acc 21.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.239 Acc 18.552%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.238 Acc 18.579%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.238 Acc 18.701%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.238 Acc 18.839%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.245 Acc 19.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.236 Acc 19.010%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.245 Acc 17.969%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.923%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.235 Acc 22.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.238 Acc 19.137%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.236 Acc 19.294%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.237 Acc 19.064%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.196 Acc 21.875%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.236 Acc 18.936%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.239 Acc 18.769%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.237 Acc 19.000%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.176 Acc 21.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 18.777%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.237 Acc 18.907%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.229 Acc 17.188%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.230 Acc 19.624%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.237 Acc 19.100%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.235 Acc 19.173%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.235 Acc 19.091%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.236 Acc 19.035%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.272 Acc 21.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.233 Acc 19.516%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.232 Acc 19.469%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.234 Acc 19.254%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.236 Acc 19.004%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.278 Acc 12.500%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.236 Acc 19.353%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.235 Acc 19.022%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.237 Acc 18.854%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [193/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.298 Acc 11.719%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.235 Acc 19.508%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.235 Acc 19.426%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.237 Acc 19.194%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.237 Acc 19.021%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.238 Acc 18.897%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.279 Acc 15.625%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.232 Acc 19.717%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.234 Acc 19.220%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 19.243%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.237 Acc 18.856%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.272 Acc 19.531%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.237 Acc 18.835%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.236 Acc 18.878%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.237 Acc 18.911%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.343 Acc 10.938%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.239 Acc 18.603%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.239 Acc 18.684%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.238 Acc 18.871%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.237 Acc 18.967%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.248 Acc 17.188%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.238 Acc 18.804%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.237 Acc 18.987%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.223 Acc 20.312%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.238 Acc 18.895%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1759680e0042e3a502d2a7b97c3753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.326 Acc 11.719%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.245 Acc 18.077%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.244 Acc 18.447%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.233 Acc 18.906%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.184 Acc 20.852%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.076 Acc 24.880%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.586 Acc 47.656%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.498 Acc 50.534%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.496 Acc 50.389%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.369 Acc 50.781%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.109 Acc 62.856%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.979 Acc 67.868%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.874 Acc 71.732%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.800 Acc 74.232%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.744 Acc 76.084%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.484 Acc 84.375%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.564 Acc 82.163%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.555 Acc 82.533%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.568 Acc 79.688%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.452 Acc 86.363%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.451 Acc 86.178%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.436 Acc 86.597%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.429 Acc 86.836%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.421 Acc 87.088%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.469 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.410 Acc 87.508%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.409 Acc 87.376%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.468 Acc 86.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.385 Acc 88.397%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.370 Acc 88.748%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.364 Acc 89.065%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.364 Acc 89.016%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.362 Acc 89.083%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.264 Acc 91.406%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.297 Acc 91.414%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.293 Acc 91.414%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.219 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.333 Acc 90.053%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.333 Acc 90.073%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.330 Acc 90.108%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.328 Acc 90.087%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.325 Acc 90.187%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.323 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.295 Acc 91.545%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.289 Acc 91.814%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.238 Acc 92.969%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.317 Acc 90.780%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.310 Acc 90.749%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.310 Acc 90.804%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.306 Acc 90.839%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.306 Acc 90.848%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.257 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.277 Acc 91.847%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.270 Acc 92.184%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.296 Acc 92.969%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.279 Acc 91.460%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.287 Acc 91.212%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.284 Acc 91.287%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.286 Acc 91.241%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.289 Acc 91.275%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.258 Acc 90.625%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.292 Acc 91.592%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.287 Acc 91.682%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.285 Acc 89.062%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.281 Acc 91.716%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.275 Acc 91.760%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.279 Acc 91.679%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.283 Acc 91.628%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.280 Acc 91.676%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.279 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.260 Acc 92.760%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.255 Acc 92.926%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.254 Acc 89.844%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.268 Acc 92.273%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.276 Acc 92.044%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.273 Acc 91.897%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.272 Acc 91.952%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.269 Acc 92.105%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.315 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.294 Acc 91.576%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.292 Acc 91.604%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.283 Acc 91.406%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.271 Acc 92.002%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.270 Acc 92.016%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.267 Acc 92.071%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.266 Acc 92.115%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.264 Acc 92.191%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.223 Acc 94.013%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.221 Acc 94.065%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.258 Acc 92.497%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.258 Acc 92.347%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.253 Acc 92.515%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.255 Acc 92.512%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.257 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.253 Acc 92.891%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.251 Acc 93.035%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.154 Acc 96.094%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.229 Acc 93.255%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.241 Acc 92.868%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.244 Acc 92.795%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.245 Acc 92.752%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.246 Acc 92.716%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.223 Acc 93.943%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.218 Acc 93.948%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.294 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.229 Acc 93.270%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.235 Acc 93.089%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.238 Acc 93.052%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.239 Acc 92.926%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.239 Acc 92.938%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.238 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.227 Acc 93.998%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.224 Acc 93.956%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.331 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.238 Acc 93.062%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.235 Acc 93.190%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.238 Acc 93.112%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.238 Acc 93.056%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.237 Acc 93.089%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.200 Acc 92.188%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.223 Acc 93.967%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.219 Acc 94.088%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.264 Acc 96.875%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.241 Acc 93.356%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.240 Acc 93.171%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.239 Acc 93.158%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.236 Acc 93.169%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.237 Acc 93.182%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.271 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.207 Acc 94.415%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.202 Acc 94.496%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.235 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.234 Acc 93.294%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.233 Acc 93.256%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.233 Acc 93.189%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.233 Acc 93.204%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.231 Acc 93.245%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.301 Acc 91.406%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.223 Acc 93.912%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.220 Acc 93.902%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.346 Acc 90.625%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.226 Acc 93.611%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.226 Acc 93.525%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.225 Acc 93.467%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.224 Acc 93.475%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.226 Acc 93.373%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.205 Acc 94.415%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.200 Acc 94.516%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.223 Acc 92.969%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.222 Acc 93.495%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.216 Acc 93.509%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.218 Acc 93.418%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.220 Acc 93.440%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.222 Acc 93.396%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.264 Acc 89.844%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.239 Acc 93.541%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.232 Acc 93.703%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.183 Acc 96.094%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.211 Acc 93.588%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.216 Acc 93.513%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.219 Acc 93.483%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.219 Acc 93.493%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.220 Acc 93.507%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.275 Acc 91.406%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.232 Acc 93.595%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.229 Acc 93.680%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.251 Acc 92.188%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.211 Acc 93.874%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.216 Acc 93.766%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.215 Acc 93.807%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.216 Acc 93.760%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.216 Acc 93.703%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.247 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.199 Acc 94.632%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.196 Acc 94.753%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.367 Acc 90.625%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.210 Acc 93.998%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.212 Acc 93.707%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.211 Acc 93.727%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.210 Acc 93.748%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.213 Acc 93.636%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.194 Acc 95.042%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.191 Acc 95.087%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.102 Acc 97.656%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.213 Acc 93.564%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.211 Acc 93.758%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.213 Acc 93.719%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.213 Acc 93.717%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.213 Acc 93.753%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.235 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.202 Acc 94.763%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.194 Acc 94.873%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.205 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.197 Acc 94.346%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.202 Acc 94.220%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.203 Acc 94.178%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.205 Acc 94.120%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.206 Acc 94.101%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.187 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.200 Acc 94.763%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.196 Acc 94.866%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.197 Acc 94.485%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.196 Acc 94.407%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.203 Acc 94.222%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.202 Acc 94.223%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.205 Acc 94.127%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.200 Acc 94.493%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.193 Acc 94.796%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.194 Acc 94.284%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.200 Acc 94.127%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.204 Acc 94.025%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.204 Acc 94.071%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.202 Acc 94.070%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.195 Acc 94.941%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.192 Acc 94.967%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.190 Acc 94.338%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.192 Acc 94.372%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.194 Acc 94.326%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.196 Acc 94.292%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.199 Acc 94.274%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.195 Acc 94.678%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.188 Acc 94.799%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.192 Acc 94.531%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.193 Acc 94.485%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.195 Acc 94.407%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.197 Acc 94.316%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.199 Acc 94.223%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.201 Acc 94.177%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.211 Acc 94.291%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.207 Acc 94.469%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.314 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.187 Acc 94.678%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.195 Acc 94.339%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.194 Acc 94.393%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.194 Acc 94.389%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.197 Acc 94.779%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.192 Acc 94.920%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.185 Acc 94.616%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.188 Acc 94.426%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.192 Acc 94.329%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.194 Acc 94.370%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.195 Acc 94.346%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.217 Acc 94.315%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.213 Acc 94.356%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.214 Acc 94.531%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.185 Acc 94.825%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.190 Acc 94.566%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.190 Acc 94.549%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.189 Acc 94.596%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.191 Acc 94.503%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.259 Acc 92.188%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.199 Acc 94.562%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.194 Acc 94.706%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.185 Acc 94.485%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.187 Acc 94.543%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.192 Acc 94.485%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.190 Acc 94.496%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.188 Acc 94.562%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.189 Acc 95.088%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.184 Acc 95.204%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.286 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.181 Acc 94.810%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.900%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.185 Acc 94.757%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.185 Acc 94.705%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.187 Acc 94.634%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.247 Acc 92.188%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.206 Acc 94.570%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.202 Acc 94.694%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.173 Acc 95.173%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.180 Acc 94.963%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.184 Acc 94.741%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.184 Acc 94.751%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.186 Acc 94.653%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.190 Acc 94.972%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.183 Acc 95.138%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.170 Acc 94.910%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.177 Acc 94.757%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.177 Acc 94.848%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.179 Acc 94.812%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.184 Acc 94.661%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.207 Acc 92.188%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.678%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.196 Acc 94.741%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.179 Acc 94.725%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.181 Acc 94.710%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.762%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.183 Acc 94.714%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.183 Acc 94.664%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.191 Acc 95.042%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.189 Acc 95.029%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.177 Acc 94.957%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.170 Acc 94.982%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.175 Acc 94.934%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.177 Acc 94.942%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.179 Acc 94.901%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.181 Acc 95.258%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.180 Acc 95.332%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.237 Acc 92.969%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.179 Acc 94.624%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.177 Acc 94.788%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.176 Acc 94.967%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.179 Acc 94.864%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.178 Acc 94.867%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.181 Acc 95.483%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.581%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.175 Acc 94.933%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.172 Acc 94.978%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.175 Acc 94.921%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.177 Acc 94.909%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.179 Acc 94.860%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.185 Acc 95.235%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.179 Acc 95.301%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.168 Acc 95.111%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.174 Acc 94.963%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.172 Acc 94.988%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.176 Acc 94.929%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.177 Acc 94.842%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.187 Acc 94.964%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.182 Acc 95.246%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.160 Acc 95.475%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.240%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.172 Acc 95.125%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.173 Acc 95.027%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.545%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.171 Acc 95.639%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.162 Acc 95.390%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.166 Acc 95.173%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.172 Acc 95.066%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.171 Acc 95.005%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.172 Acc 95.012%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.196 Acc 94.972%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.194 Acc 94.955%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.173 Acc 95.189%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.168 Acc 95.254%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.165 Acc 95.198%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.167 Acc 95.168%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.169 Acc 95.127%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.190 Acc 90.625%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.192 Acc 94.887%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.184 Acc 95.196%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.174 Acc 94.787%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.169 Acc 95.064%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.170 Acc 95.053%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.171 Acc 95.026%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.171 Acc 95.018%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.189 Acc 95.235%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.185 Acc 95.340%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.154 Acc 95.575%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.163 Acc 95.359%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.161 Acc 95.367%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.164 Acc 95.254%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.166 Acc 95.239%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.193 Acc 91.406%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.186 Acc 95.227%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.182 Acc 95.274%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.164 Acc 95.390%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.164 Acc 95.250%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.164 Acc 95.284%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.167 Acc 95.194%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.166 Acc 95.214%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.187 Acc 95.158%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.239%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.158 Acc 95.529%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.162 Acc 95.344%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.164 Acc 95.328%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.165 Acc 95.248%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.167 Acc 95.178%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.184 Acc 95.204%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.182 Acc 92.969%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.155 Acc 95.614%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.160 Acc 95.437%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.162 Acc 95.357%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.163 Acc 95.311%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.164 Acc 95.250%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.197 Acc 95.181%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.191 Acc 95.153%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.150 Acc 95.552%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.155 Acc 95.588%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.577%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.160 Acc 95.416%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.162 Acc 95.339%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.209 Acc 94.756%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.206 Acc 94.694%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.163 Acc 95.192%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.164 Acc 95.162%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.163 Acc 95.235%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.162 Acc 95.208%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.194 Acc 94.949%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.189 Acc 95.002%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.168 Acc 95.034%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.161 Acc 95.173%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.159 Acc 95.253%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.160 Acc 95.268%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.163 Acc 95.270%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.233 Acc 92.188%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.196 Acc 95.088%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.191 Acc 95.208%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.161 Acc 95.490%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.162 Acc 95.262%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.160 Acc 95.336%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.160 Acc 95.314%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.160 Acc 95.330%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.173 Acc 95.561%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.160 Acc 95.305%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.160 Acc 95.367%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.157 Acc 95.460%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.157 Acc 95.463%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.158 Acc 95.464%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.184 Acc 95.359%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.179 Acc 95.452%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.152 Acc 92.969%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.159 Acc 95.475%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.159 Acc 95.281%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.158 Acc 95.336%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.158 Acc 95.350%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.157 Acc 95.384%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.129 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.186 Acc 95.429%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.180 Acc 95.585%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.214 Acc 92.969%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.163 Acc 95.196%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.163 Acc 95.367%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.160 Acc 95.419%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.160 Acc 95.435%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.157 Acc 95.521%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.195 Acc 95.019%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.191 Acc 95.141%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.156 Acc 95.429%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.154 Acc 95.476%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.155 Acc 95.418%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.156 Acc 95.426%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.180 Acc 95.498%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.174 Acc 95.526%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.131 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.152 Acc 95.684%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.152 Acc 95.596%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.156 Acc 95.427%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.155 Acc 95.451%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.156 Acc 95.484%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.173 Acc 95.715%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.169 Acc 95.697%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.152 Acc 95.575%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.153 Acc 95.631%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.151 Acc 95.645%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.154 Acc 95.611%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.156 Acc 95.548%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.179 Acc 95.472%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.204 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.137 Acc 96.016%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.142 Acc 95.876%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.148 Acc 95.691%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.149 Acc 95.687%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.152 Acc 95.640%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.194 Acc 94.910%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.188 Acc 95.044%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.153 Acc 95.429%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.150 Acc 95.604%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.151 Acc 95.533%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.154 Acc 95.468%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.153 Acc 95.493%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.176 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.183 Acc 95.614%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.178 Acc 95.635%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.145 Acc 95.939%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.151 Acc 95.713%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.151 Acc 95.655%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.151 Acc 95.592%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.188 Acc 95.274%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.183 Acc 95.332%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.149 Acc 95.753%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.148 Acc 95.791%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.152 Acc 95.634%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.152 Acc 95.650%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.152 Acc 95.590%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.521%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.177 Acc 95.546%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.203 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.769%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.149 Acc 95.713%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.148 Acc 95.746%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.146 Acc 95.761%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.149 Acc 95.702%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.199 Acc 94.918%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.195 Acc 94.893%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.145 Acc 95.483%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.142 Acc 95.686%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.146 Acc 95.572%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.147 Acc 95.628%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.147 Acc 95.613%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.195 Acc 94.895%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.190 Acc 94.970%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.231 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.137 Acc 95.846%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.144 Acc 95.690%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.145 Acc 95.733%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.147 Acc 95.659%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.148 Acc 95.704%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.188 Acc 95.196%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.184%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.144 Acc 95.692%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.146 Acc 95.829%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.145 Acc 95.821%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.147 Acc 95.800%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.147 Acc 95.787%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.210 Acc 92.188%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.206 Acc 94.655%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.204 Acc 94.714%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.143 Acc 95.831%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.143 Acc 95.725%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.146 Acc 95.741%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.148 Acc 95.715%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.175 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.212%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.180 Acc 95.398%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.142 Acc 95.846%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.144 Acc 95.748%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.142 Acc 95.874%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.143 Acc 95.824%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.180 Acc 95.545%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.175 Acc 95.670%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.133 Acc 96.279%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.136 Acc 96.191%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.138 Acc 96.037%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.141 Acc 95.915%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.142 Acc 95.886%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.168 Acc 95.908%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.163 Acc 95.962%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.096 Acc 95.312%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.130 Acc 96.202%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.137 Acc 96.090%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.141 Acc 95.879%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.144 Acc 95.819%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.190 Acc 95.367%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.187 Acc 95.375%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.134 Acc 96.086%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.138 Acc 96.024%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.139 Acc 95.926%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.141 Acc 95.894%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.201 Acc 94.771%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.199 Acc 94.831%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.206 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.127 Acc 96.233%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.136 Acc 96.012%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.140 Acc 95.904%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.141 Acc 95.915%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.141 Acc 95.885%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.199 Acc 95.104%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.193 Acc 95.200%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.131 Acc 96.016%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.139 Acc 95.841%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.138 Acc 95.894%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.139 Acc 95.858%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.141 Acc 95.841%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.192 Acc 95.367%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.186 Acc 95.363%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.178 Acc 92.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.138 Acc 95.978%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.137 Acc 96.004%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.140 Acc 96.018%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.140 Acc 95.957%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.140 Acc 95.985%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.181 Acc 95.359%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.176 Acc 95.394%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.128 Acc 96.171%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.135 Acc 95.927%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.135 Acc 95.998%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.138 Acc 95.981%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.140 Acc 95.919%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.192 Acc 95.196%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.188 Acc 95.215%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.126 Acc 96.086%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.134 Acc 95.981%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.135 Acc 96.013%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.139 Acc 95.928%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.139 Acc 95.886%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.188 Acc 95.351%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.181 Acc 95.472%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.138 Acc 95.753%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.138 Acc 95.958%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.135 Acc 96.104%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.136 Acc 96.047%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.137 Acc 96.025%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.189 Acc 95.235%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.184 Acc 95.320%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.130 Acc 96.101%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.132 Acc 96.016%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.136 Acc 95.938%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.136 Acc 95.965%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.136 Acc 95.964%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.139 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.784%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.174 Acc 95.802%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.127 Acc 96.140%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.131 Acc 96.000%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.134 Acc 95.954%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.136 Acc 95.918%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.138 Acc 95.899%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.188 Acc 95.413%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.185 Acc 95.437%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.125 Acc 96.303%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.135 Acc 95.993%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.136 Acc 96.018%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.136 Acc 96.020%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.136 Acc 96.020%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.186 Acc 95.243%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.181 Acc 95.402%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.132 Acc 96.127%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.133 Acc 96.088%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.134 Acc 96.078%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.282%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.096 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.131 Acc 96.364%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.127 Acc 96.358%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.127 Acc 96.309%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.131 Acc 96.174%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.133 Acc 96.125%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.189 Acc 95.343%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.183 Acc 95.363%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.127 Acc 96.372%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.132 Acc 96.125%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.130 Acc 96.159%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.133 Acc 96.070%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.132 Acc 96.103%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.183 Acc 95.498%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.178 Acc 95.530%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.130 Acc 96.129%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.129 Acc 96.169%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.130 Acc 96.130%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.180 Acc 95.452%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.174 Acc 95.585%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.128 Acc 96.241%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.128 Acc 96.339%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.132 Acc 96.146%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.132 Acc 96.109%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.135 Acc 96.020%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.202 Acc 94.879%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.201 Acc 94.904%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.176 Acc 92.969%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.133 Acc 95.985%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.131 Acc 96.070%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.133 Acc 96.000%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.134 Acc 95.961%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.134 Acc 95.961%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.160 Acc 92.969%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.186 Acc 95.320%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.183 Acc 95.379%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.128 Acc 96.210%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.126 Acc 96.284%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.129 Acc 96.249%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.129 Acc 96.211%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.131 Acc 96.142%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.190 Acc 95.119%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.187 Acc 95.262%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.126 Acc 96.148%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.130 Acc 96.144%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.129 Acc 96.182%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.127 Acc 96.238%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.130 Acc 96.175%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.180 Acc 95.692%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.175 Acc 95.682%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.258 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.126 Acc 96.296%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.130 Acc 96.178%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.199 Acc 95.212%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.191 Acc 95.297%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.116 Acc 96.767%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.123 Acc 96.467%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.126 Acc 96.382%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.128 Acc 96.296%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.130 Acc 96.236%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.191 Acc 95.220%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.184 Acc 95.386%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.169 Acc 94.531%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.127 Acc 96.303%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.126 Acc 96.245%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.125 Acc 96.172%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.127 Acc 96.213%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.128 Acc 96.178%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.204 Acc 94.918%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.198 Acc 94.963%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.123 Acc 96.296%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.127 Acc 96.179%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.127 Acc 96.209%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.128 Acc 96.223%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.198 Acc 95.080%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.193 Acc 95.169%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.120 Acc 96.364%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.120 Acc 96.447%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.123 Acc 96.333%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.125 Acc 96.201%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.127 Acc 96.178%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.265 Acc 92.188%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.191 Acc 95.351%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.188 Acc 95.215%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.127 Acc 96.334%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.124 Acc 96.416%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.124 Acc 96.343%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.126 Acc 96.304%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.436%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.181 Acc 95.476%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.146 Acc 94.531%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.131 Acc 96.109%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.130 Acc 96.105%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.129 Acc 96.159%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.127 Acc 96.238%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.126 Acc 96.268%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.201 Acc 92.188%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.189 Acc 95.343%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.188 Acc 95.262%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.112 Acc 96.651%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.122 Acc 96.369%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.124 Acc 96.326%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.201 Acc 94.771%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.200 Acc 94.788%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.122 Acc 96.171%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.129 Acc 96.082%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.128 Acc 96.159%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.127 Acc 96.158%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.127 Acc 96.220%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.189 Acc 95.374%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.186 Acc 95.359%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.129 Acc 96.133%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.123 Acc 96.278%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.123 Acc 96.263%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.124 Acc 96.247%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.183 Acc 95.429%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.179 Acc 95.519%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.134 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.125 Acc 96.241%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.121 Acc 96.479%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.123 Acc 96.395%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.123 Acc 96.402%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.123 Acc 96.395%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.183 Acc 95.599%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.178 Acc 95.631%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.139 Acc 92.969%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.120 Acc 96.457%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.119 Acc 96.498%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.122 Acc 96.447%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.125 Acc 96.345%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.125 Acc 96.276%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.180 Acc 95.792%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.174 Acc 95.868%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.120 Acc 96.697%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.118 Acc 96.568%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.118 Acc 96.540%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.118 Acc 96.571%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.121 Acc 96.449%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.194 Acc 95.142%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.190 Acc 95.219%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.119 Acc 96.620%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.117 Acc 96.560%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.120 Acc 96.501%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.121 Acc 96.454%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.121 Acc 96.452%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.176 Acc 95.692%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.172 Acc 95.822%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.118 Acc 96.542%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.118 Acc 96.510%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.119 Acc 96.473%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.122 Acc 96.433%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.121 Acc 96.429%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.125 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.201 Acc 95.011%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.195 Acc 95.204%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.180 Acc 92.969%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.116 Acc 96.525%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.119 Acc 96.417%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.122 Acc 96.306%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.194 Acc 95.158%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.188 Acc 95.227%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.118 Acc 96.529%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.120 Acc 96.441%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.170 Acc 92.188%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.191 Acc 95.599%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.186 Acc 95.585%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.154 Acc 94.531%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.112 Acc 96.658%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.114 Acc 96.502%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.118 Acc 96.400%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.117 Acc 96.433%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.118 Acc 96.432%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.188 Acc 95.367%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.183 Acc 95.526%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.269 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.124 Acc 96.233%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.124 Acc 96.253%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.123 Acc 96.239%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.120 Acc 96.376%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.121 Acc 96.356%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.182 Acc 95.552%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.178 Acc 95.577%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.116 Acc 96.542%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.112 Acc 96.700%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.116 Acc 96.527%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.118 Acc 96.439%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.117 Acc 96.434%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.172 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.202 Acc 95.382%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.195 Acc 95.417%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.108 Acc 96.581%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.115 Acc 96.459%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.119 Acc 96.418%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.116 Acc 96.485%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.119 Acc 96.448%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.193 Acc 95.359%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.187 Acc 95.515%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.113 Acc 96.457%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.117 Acc 96.409%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.117 Acc 96.429%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.116 Acc 96.452%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.116 Acc 96.459%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.199 Acc 95.034%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.194 Acc 95.114%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.111 Acc 96.581%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.111 Acc 96.599%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.113 Acc 96.587%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.117 Acc 96.495%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.117 Acc 96.496%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.182 Acc 95.676%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.178 Acc 95.647%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.109 Acc 96.527%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.112 Acc 96.521%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.115 Acc 96.444%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.116 Acc 96.421%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.116 Acc 96.429%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.117 Acc 93.750%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.186 Acc 95.390%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.181 Acc 95.515%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.114 Acc 96.529%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.115 Acc 96.567%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.116 Acc 96.574%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.184 Acc 95.483%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.177 Acc 95.449%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.117 Acc 96.581%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.118 Acc 96.498%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.113 Acc 96.569%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.114 Acc 96.505%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.114 Acc 96.485%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.189 Acc 95.436%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.180 Acc 95.643%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.115 Acc 96.488%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.109 Acc 96.801%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.115 Acc 96.618%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.117 Acc 96.528%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.118 Acc 96.501%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.194 Acc 95.243%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.187 Acc 95.336%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.125 Acc 93.750%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.108 Acc 96.597%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.109 Acc 96.556%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.110 Acc 96.639%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.112 Acc 96.561%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.114 Acc 96.538%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.198 Acc 95.336%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.192 Acc 95.437%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.108 Acc 96.682%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.110 Acc 96.646%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.111 Acc 96.662%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.113 Acc 96.612%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.114 Acc 96.562%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.193 Acc 95.475%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.189 Acc 95.445%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.117 Acc 96.535%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.115 Acc 96.723%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.113 Acc 96.670%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.115 Acc 96.554%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.117 Acc 96.485%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.199 Acc 92.969%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.201 Acc 94.794%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.200 Acc 94.772%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.110 Acc 96.732%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.112 Acc 96.596%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.112 Acc 96.619%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.179 Acc 95.475%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.175 Acc 95.530%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.151 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.109 Acc 96.720%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.104 Acc 96.848%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.108 Acc 96.693%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.109 Acc 96.674%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.111 Acc 96.652%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.195 Acc 95.282%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.190 Acc 95.289%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.131 Acc 93.750%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.114 Acc 96.488%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.112 Acc 96.595%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.113 Acc 96.545%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.115 Acc 96.444%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.115 Acc 96.466%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.184 Acc 95.444%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.178 Acc 95.561%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.113 Acc 96.545%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.111 Acc 96.569%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.112 Acc 96.612%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.112 Acc 96.605%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.169 Acc 92.969%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.206 Acc 95.065%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.112 Acc 96.357%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.108 Acc 96.599%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.110 Acc 96.571%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.110 Acc 96.618%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.112 Acc 96.580%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.180 Acc 95.684%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.176 Acc 95.655%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.100 Acc 96.991%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.104 Acc 96.739%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.109 Acc 96.566%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.111 Acc 96.517%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.111 Acc 96.519%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.193 Acc 95.498%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.191 Acc 95.472%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.110 Acc 96.658%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.113 Acc 96.549%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.111 Acc 96.608%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.110 Acc 96.657%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.111 Acc 96.607%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.191 Acc 95.514%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.187 Acc 95.507%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.112 Acc 96.496%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.111 Acc 96.583%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.111 Acc 96.597%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.111 Acc 96.612%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.111 Acc 96.605%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.206 Acc 94.779%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.205 Acc 94.862%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.105 Acc 96.767%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.107 Acc 96.603%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.111 Acc 96.488%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.110 Acc 96.563%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.109 Acc 96.627%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.188 Acc 95.441%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.101 Acc 96.798%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.102 Acc 96.817%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.106 Acc 96.753%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.108 Acc 96.655%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.107 Acc 96.666%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.197 Acc 95.196%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.194 Acc 95.215%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.112 Acc 96.558%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.108 Acc 96.665%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.111 Acc 96.577%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.109 Acc 96.641%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.110 Acc 96.625%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.195 Acc 95.328%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.188 Acc 95.487%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.124 Acc 93.750%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.118 Acc 96.488%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.110 Acc 96.739%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.109 Acc 96.709%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.110 Acc 96.661%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.111 Acc 96.636%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.140 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.193 Acc 95.521%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.188 Acc 95.569%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.103 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.108 Acc 96.689%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.106 Acc 96.762%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.108 Acc 96.714%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.108 Acc 96.735%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.109 Acc 96.722%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.182 Acc 95.467%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.538%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.104 Acc 96.821%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.109 Acc 96.675%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.109 Acc 96.709%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.108 Acc 96.713%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.179 Acc 95.721%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.098 Acc 97.014%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.101 Acc 96.844%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.103 Acc 96.797%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.105 Acc 96.743%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.106 Acc 96.702%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.177 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.195 Acc 95.343%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.192 Acc 95.375%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.111 Acc 96.665%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.108 Acc 96.680%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.108 Acc 96.743%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.108 Acc 96.755%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.199 Acc 94.995%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.194 Acc 95.087%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.094 Acc 97.130%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.103 Acc 96.857%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.108 Acc 96.700%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.108 Acc 96.696%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.195 Acc 95.475%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.190 Acc 95.534%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.130 Acc 99.219%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.095 Acc 96.983%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.104 Acc 96.769%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.105 Acc 96.793%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.104 Acc 96.799%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.206 Acc 95.142%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.203 Acc 95.110%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.100 Acc 97.030%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.103 Acc 96.867%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.105 Acc 96.826%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.106 Acc 96.811%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.091 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.169 Acc 95.903%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.097 Acc 96.821%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.096 Acc 96.953%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.100 Acc 96.872%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.104 Acc 96.776%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.103 Acc 96.780%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.187 Acc 95.599%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.182 Acc 95.647%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.101 Acc 96.798%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.101 Acc 96.894%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.104 Acc 96.826%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.105 Acc 96.771%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.104 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.180 Acc 95.862%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.175 Acc 95.818%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.095 Acc 96.798%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.101 Acc 96.770%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.103 Acc 96.771%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.105 Acc 96.741%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.105 Acc 96.730%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.182 Acc 95.452%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.177 Acc 95.596%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.096 Acc 97.146%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.098 Acc 96.988%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.100 Acc 96.950%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.103 Acc 96.863%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.104 Acc 96.841%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.198 Acc 95.336%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.194 Acc 95.289%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.080 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.097 Acc 96.952%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.097 Acc 97.108%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.099 Acc 97.009%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.101 Acc 96.937%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.206 Acc 95.003%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.204 Acc 95.052%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.105 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.103 Acc 96.766%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.102 Acc 96.846%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.103 Acc 96.794%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.194 Acc 95.498%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.192 Acc 95.464%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.100 Acc 96.844%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.101 Acc 96.844%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.103 Acc 96.841%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.105 Acc 96.786%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.189 Acc 95.421%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.183 Acc 95.468%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.102 Acc 96.798%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.099 Acc 96.879%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.102 Acc 96.802%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.103 Acc 96.797%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.104 Acc 96.777%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.207 Acc 95.080%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.203 Acc 95.083%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.106 Acc 96.770%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.106 Acc 96.723%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.105 Acc 96.761%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.192 Acc 95.367%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.189 Acc 95.355%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.103 Acc 96.921%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.098 Acc 96.995%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.100 Acc 96.924%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.100 Acc 96.939%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.101 Acc 96.845%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.158 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.192 Acc 95.386%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.127 Acc 94.531%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.095 Acc 96.995%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.099 Acc 96.857%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.101 Acc 96.807%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.101 Acc 96.794%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.206 Acc 95.196%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.201 Acc 95.285%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.100 Acc 96.952%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.099 Acc 96.871%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.100 Acc 96.805%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.102 Acc 96.801%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.102 Acc 96.819%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.217 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.204 Acc 95.127%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.200 Acc 95.157%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.100 Acc 96.774%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.098 Acc 96.879%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.098 Acc 96.849%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.100 Acc 96.822%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.102 Acc 96.806%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.192 Acc 95.398%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.098 Acc 97.037%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.098 Acc 97.003%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.098 Acc 96.998%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.098 Acc 96.990%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.191 Acc 92.188%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.211 Acc 95.142%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.093 Acc 97.130%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.093 Acc 97.034%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.101 Acc 96.856%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.101 Acc 96.863%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.203 Acc 95.080%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.196 Acc 95.281%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.098 Acc 96.929%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.096 Acc 96.972%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.099 Acc 96.937%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.099 Acc 96.928%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.100 Acc 96.931%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.187 Acc 95.630%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.178 Acc 95.787%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.101 Acc 97.068%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.100 Acc 97.059%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.100 Acc 96.996%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.189 Acc 95.784%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.183 Acc 95.845%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.093 Acc 97.006%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.093 Acc 97.027%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.091 Acc 97.080%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.094 Acc 96.992%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.095 Acc 96.984%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.200 Acc 95.328%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.194 Acc 95.355%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.089 Acc 97.208%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.091 Acc 97.209%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.097 Acc 96.941%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.100 Acc 96.894%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.197 Acc 95.343%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.187 Acc 95.530%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.093 Acc 97.023%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.097 Acc 96.930%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.095 Acc 97.004%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.098 Acc 96.950%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 95.413%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.184 Acc 95.503%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.099 Acc 96.805%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.101 Acc 96.821%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.098 Acc 96.958%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.098 Acc 96.970%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.097 Acc 96.997%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.207 Acc 94.918%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.202 Acc 95.056%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.139 Acc 93.750%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.094 Acc 97.092%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.090 Acc 97.093%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.095 Acc 97.049%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.097 Acc 96.939%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.247 Acc 91.406%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.213 Acc 94.740%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.209 Acc 94.955%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.089 Acc 97.169%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.093 Acc 97.120%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.093 Acc 97.059%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.096 Acc 97.002%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.098 Acc 96.922%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.200 Acc 95.289%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.193 Acc 95.425%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.127 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.086 Acc 97.378%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.095 Acc 97.065%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.097 Acc 96.989%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.096 Acc 97.025%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.096 Acc 97.023%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.195 Acc 95.390%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.187 Acc 95.534%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.092 Acc 97.108%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.095 Acc 97.039%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.097 Acc 96.959%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.098 Acc 96.920%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.192 Acc 95.421%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.135 Acc 94.531%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.088 Acc 97.200%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.092 Acc 97.089%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.095 Acc 97.026%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.095 Acc 97.043%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.095 Acc 97.022%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.160 Acc 92.188%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.192 Acc 95.405%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.185 Acc 95.550%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.094 Acc 97.053%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.093 Acc 97.067%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.095 Acc 97.035%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.095 Acc 97.034%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.194 Acc 95.390%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.189 Acc 95.452%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.088 Acc 97.208%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.088 Acc 97.213%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.092 Acc 97.083%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.093 Acc 97.050%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.095 Acc 97.028%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.209 Acc 95.026%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.204 Acc 95.149%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.175 Acc 93.750%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.088 Acc 97.030%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.091 Acc 97.065%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.095 Acc 96.994%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.096 Acc 96.996%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.095 Acc 97.053%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.198 Acc 95.343%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.191 Acc 95.503%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.082 Acc 97.393%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.088 Acc 97.155%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.092 Acc 97.106%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.095 Acc 97.002%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.094 Acc 97.048%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.157 Acc 93.750%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.206 Acc 95.173%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.203 Acc 95.332%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.092 Acc 97.014%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.095 Acc 97.038%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.093 Acc 97.101%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.095 Acc 97.041%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.095 Acc 97.011%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.204 Acc 95.150%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.200 Acc 95.285%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.089 Acc 97.285%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.091 Acc 97.145%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.093 Acc 97.109%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.093 Acc 97.096%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.152 Acc 92.969%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.204 Acc 95.220%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.199 Acc 95.293%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.083 Acc 97.293%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.091 Acc 97.011%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.094 Acc 96.930%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.092 Acc 96.996%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.093 Acc 96.961%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.188 Acc 95.552%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.185 Acc 95.503%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.092 Acc 97.331%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.093 Acc 97.279%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.093 Acc 97.197%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.094 Acc 97.132%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.095 Acc 97.062%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.196 Acc 95.429%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.191 Acc 95.585%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.095 Acc 96.968%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.096 Acc 96.980%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.092 Acc 97.070%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.092 Acc 97.101%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.091 Acc 97.106%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.186 Acc 95.436%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.178 Acc 95.635%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.087 Acc 97.184%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.087 Acc 97.252%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.091 Acc 97.140%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.094 Acc 97.068%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.202 Acc 95.026%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.195 Acc 95.258%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.084 Acc 97.277%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.092 Acc 97.108%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.092 Acc 97.097%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.092 Acc 97.117%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.202 Acc 95.336%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.194 Acc 95.519%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.082 Acc 97.478%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.088 Acc 97.213%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.089 Acc 97.179%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.092 Acc 97.073%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.191 Acc 95.583%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.187 Acc 95.713%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.095 Acc 96.898%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.091 Acc 97.151%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.092 Acc 97.064%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.091 Acc 97.097%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.092 Acc 97.103%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.190 Acc 95.730%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.179 Acc 95.829%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.085 Acc 97.300%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.086 Acc 97.310%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.089 Acc 97.176%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.090 Acc 97.175%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.089 Acc 97.185%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.201 Acc 95.421%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.194 Acc 95.522%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.087 Acc 97.215%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.089 Acc 97.201%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.088 Acc 97.231%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.090 Acc 97.175%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.090 Acc 97.179%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.201 Acc 95.080%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.193 Acc 95.258%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.084 Acc 97.324%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.086 Acc 97.283%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.087 Acc 97.238%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.088 Acc 97.177%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.090 Acc 97.148%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.199 Acc 95.088%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.192 Acc 95.270%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.090 Acc 97.077%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.091 Acc 97.088%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.090 Acc 97.144%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.090 Acc 97.151%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.200 Acc 95.212%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.193 Acc 95.332%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.086 Acc 97.192%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.085 Acc 97.353%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.088 Acc 97.262%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.089 Acc 97.232%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.089 Acc 97.196%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.231 Acc 94.779%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.224 Acc 94.881%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.091 Acc 96.937%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.089 Acc 97.042%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.086 Acc 97.173%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.085 Acc 97.198%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.089 Acc 97.118%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.206 Acc 95.382%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.202 Acc 95.336%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.085 Acc 97.246%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.086 Acc 97.268%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.089 Acc 97.173%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.090 Acc 97.152%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.091 Acc 97.149%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.190 Acc 95.560%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.188 Acc 95.592%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.088 Acc 97.386%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.087 Acc 97.287%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.087 Acc 97.298%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.088 Acc 97.237%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.088 Acc 97.209%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.198 Acc 95.583%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.189 Acc 95.721%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.087 Acc 97.300%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.086 Acc 97.407%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.087 Acc 97.324%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.089 Acc 97.253%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.088 Acc 97.263%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.220 Acc 95.235%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.212 Acc 95.421%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.082 Acc 97.239%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.085 Acc 97.288%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.086 Acc 97.265%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.088 Acc 97.185%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.219 Acc 94.957%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.215 Acc 95.029%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.085 Acc 97.386%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.085 Acc 97.252%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.090 Acc 97.142%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.206 Acc 95.282%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.202 Acc 95.246%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.084 Acc 97.401%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.086 Acc 97.194%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.088 Acc 97.202%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.087 Acc 97.217%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.359%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.406%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.061 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.084 Acc 97.393%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.086 Acc 97.341%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.087 Acc 97.288%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.088 Acc 97.284%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.088 Acc 97.255%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.208 Acc 95.537%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.202 Acc 95.557%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.080 Acc 97.393%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.083 Acc 97.353%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.085 Acc 97.392%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.085 Acc 97.364%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.087 Acc 97.337%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.205 Acc 95.336%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.199 Acc 95.460%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.081 Acc 97.347%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.085 Acc 97.330%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.089 Acc 97.212%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.089 Acc 97.185%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.088 Acc 97.215%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.214 Acc 95.003%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.209 Acc 95.239%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.253 Acc 93.750%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.091 Acc 97.324%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.087 Acc 97.373%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.085 Acc 97.324%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.086 Acc 97.286%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.086 Acc 97.255%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.215 Acc 94.918%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.212 Acc 95.013%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.087 Acc 97.260%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.086 Acc 97.207%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.088 Acc 97.183%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.091 Acc 97.100%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.269 Acc 93.750%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.225 Acc 94.926%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.216 Acc 95.017%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.082 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.086 Acc 97.169%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.086 Acc 97.147%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.087 Acc 97.145%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.085 Acc 97.212%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.087 Acc 97.184%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.405%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.191 Acc 95.546%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.086 Acc 97.123%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.086 Acc 97.143%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.084 Acc 97.272%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.083 Acc 97.339%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.084 Acc 97.305%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.211 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.211 Acc 95.196%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.202 Acc 95.367%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.080 Acc 97.370%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.084 Acc 97.279%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.088 Acc 97.202%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.087 Acc 97.235%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.086 Acc 97.270%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.211 Acc 95.181%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.205 Acc 95.258%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.079 Acc 97.424%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.083 Acc 97.376%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.084 Acc 97.335%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.084 Acc 97.299%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.199 Acc 95.490%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.193 Acc 95.588%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.082 Acc 97.401%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.085 Acc 97.221%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.084 Acc 97.257%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.085 Acc 97.241%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.086 Acc 97.215%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.192 Acc 95.459%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.185 Acc 95.666%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.083 Acc 97.386%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.082 Acc 97.396%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.082 Acc 97.340%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.082 Acc 97.337%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.083 Acc 97.305%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.206 Acc 95.150%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.200 Acc 95.305%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.083 Acc 97.401%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.085 Acc 97.415%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.085 Acc 97.345%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.085 Acc 97.327%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.195 Acc 95.390%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.189 Acc 95.573%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.082 Acc 97.392%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.084 Acc 97.350%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.086 Acc 97.343%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.087 Acc 97.301%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.211 Acc 95.336%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.205 Acc 95.359%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c34f402dcd4576b71fc37be7f33b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.363 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 3.402 Acc 17.976%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.826 Acc 18.151%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.631 Acc 18.452%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.533 Acc 18.538%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.474 Acc 18.700%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.226 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.230 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.231 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.185 Acc 27.344%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.239 Acc 18.982%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.236 Acc 18.781%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 18.965%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.238 Acc 18.906%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.221 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.295 Acc 17.188%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.235 Acc 18.920%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.235 Acc 18.929%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.237 Acc 18.802%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.315 Acc 11.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 19.022%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 19.027%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.271 Acc 15.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.231 Acc 19.647%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.237 Acc 18.896%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.261 Acc 16.406%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.243 Acc 18.325%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.201 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.269 Acc 15.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.233 Acc 19.562%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.234 Acc 19.345%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.236 Acc 19.134%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.248 Acc 17.969%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.237 Acc 18.897%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.240 Acc 18.649%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.238 Acc 18.776%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.235 Acc 19.052%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.236 Acc 18.913%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.236 Acc 18.950%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.234 Acc 19.066%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.234 Acc 18.981%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.220 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.221 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.189 Acc 25.781%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.234 Acc 18.998%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.234 Acc 18.940%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.234 Acc 18.859%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.234 Acc 18.805%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.233 Acc 18.920%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.222 Acc 21.094%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 2.234 Acc 18.905%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 2.232 Acc 18.921%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 2.230 Acc 19.196%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 2.230 Acc 18.974%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 2.232 Acc 18.985%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 2.217 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 2.216 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 2.218 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 2.221 Acc 18.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 2.225 Acc 18.835%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 2.222 Acc 19.154%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 2.232 Acc 18.924%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 2.234 Acc 18.822%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 2.234 Acc 18.879%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2.213 Acc 21.875%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2.235 Acc 19.578%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2.238 Acc 18.940%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2.237 Acc 18.856%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 2.238 Acc 18.828%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 2.272 Acc 14.062%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 2.234 Acc 19.346%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 2.235 Acc 19.076%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 2.237 Acc 18.926%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 2.261 Acc 17.969%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 2.239 Acc 18.777%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 2.239 Acc 18.879%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 2.238 Acc 18.895%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 2.163 Acc 28.125%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 2.240 Acc 19.137%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 2.238 Acc 19.111%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 2.236 Acc 19.098%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 2.238 Acc 18.953%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 2.283 Acc 14.062%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 2.237 Acc 18.719%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 2.236 Acc 18.952%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 2.237 Acc 18.766%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 2.238 Acc 18.865%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 2.244 Acc 17.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 2.234 Acc 18.611%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 2.234 Acc 18.874%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 2.265 Acc 11.719%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 2.241 Acc 18.827%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 2.239 Acc 18.622%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 2.239 Acc 18.625%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 2.238 Acc 18.865%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 2.283 Acc 14.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 2.235 Acc 19.067%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 2.238 Acc 18.637%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 2.238 Acc 18.711%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 2.238 Acc 18.723%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 2.238 Acc 18.865%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 2.279 Acc 15.625%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 2.497 Acc 19.160%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 2.367 Acc 19.162%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 2.324 Acc 19.074%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 2.303 Acc 18.968%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 2.290 Acc 18.884%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 2.207 Acc 22.656%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 2.235 Acc 19.021%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 2.236 Acc 19.088%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 2.219 Acc 18.750%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 2.237 Acc 19.034%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 2.256 Acc 20.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 2.234 Acc 19.261%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 2.232 Acc 14.062%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 2.237 Acc 19.139%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2.205 Acc 24.219%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 2.235 Acc 19.512%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 2.236 Acc 19.272%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 2.236 Acc 19.077%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 2.236 Acc 18.987%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2.230 Acc 19.531%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 2.234 Acc 19.245%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 2.236 Acc 18.922%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2.249 Acc 19.531%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 2.239 Acc 18.673%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 2.239 Acc 18.747%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 2.237 Acc 19.014%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 2.211 Acc 18.750%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2.233 Acc 19.129%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 2.236 Acc 18.914%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 2.237 Acc 18.842%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 2.283 Acc 16.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 2.240 Acc 18.394%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 2.237 Acc 18.902%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 2.237 Acc 18.907%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 2.209 Acc 24.219%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 2.235 Acc 18.928%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 2.235 Acc 18.933%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 2.248 Acc 25.000%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 2.239 Acc 18.824%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 2.238 Acc 18.779%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 2.265 Acc 16.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 2.239 Acc 19.108%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 2.236 Acc 19.225%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 2.237 Acc 19.124%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 2.238 Acc 18.950%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 2.287 Acc 11.719%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 2.238 Acc 19.052%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 2.238 Acc 19.038%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 2.237 Acc 18.978%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 2.238 Acc 18.896%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.201 Acc 22.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 2.239 Acc 18.908%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.251 Acc 15.625%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 2.237 Acc 18.580%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 2.236 Acc 18.933%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 2.236 Acc 18.953%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.204 Acc 20.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 2.241 Acc 18.557%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 2.238 Acc 19.090%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 2.237 Acc 18.962%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 2.284 Acc 18.750%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 2.233 Acc 19.230%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 2.238 Acc 18.786%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 2.237 Acc 19.005%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.233 Acc 22.656%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 2.239 Acc 18.676%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 2.237 Acc 18.797%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.294 Acc 14.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 2.236 Acc 18.940%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 2.238 Acc 18.854%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 2.238 Acc 18.806%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 2.161 Acc 22.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 2.240 Acc 18.920%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 2.236 Acc 19.279%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 2.243 Acc 20.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 2.238 Acc 19.067%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 2.237 Acc 19.255%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 2.238 Acc 19.007%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 2.236 Acc 19.040%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 2.170 Acc 30.469%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 2.236 Acc 19.129%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 2.236 Acc 19.236%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 2.237 Acc 19.168%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 2.238 Acc 18.937%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 2.221 Acc 19.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 2.237 Acc 18.684%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 2.238 Acc 18.911%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 2.238 Acc 18.869%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 2.234 Acc 20.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 2.234 Acc 19.446%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 2.235 Acc 19.181%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 2.236 Acc 18.872%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 2.217 Acc 17.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 2.241 Acc 18.758%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 2.244 Acc 19.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 2.240 Acc 18.626%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 2.240 Acc 18.591%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 2.202 Acc 17.969%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 2.229 Acc 19.624%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 2.235 Acc 18.960%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 2.235 Acc 18.924%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 2.236 Acc 18.912%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2.260 Acc 17.969%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 2.239 Acc 18.951%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 2.224 Acc 17.188%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 2.234 Acc 19.647%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 2.239 Acc 18.972%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 2.236 Acc 19.056%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 2.194 Acc 18.750%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2.234 Acc 19.021%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 2.238 Acc 18.825%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2.237 Acc 18.853%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.253 Acc 15.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 2.234 Acc 19.237%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 2.235 Acc 19.224%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 2.237 Acc 18.953%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.225 Acc 17.969%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 2.238 Acc 18.711%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 2.237 Acc 18.950%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 2.237 Acc 18.904%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 2.238 Acc 18.883%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.242 Acc 18.750%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 2.234 Acc 19.361%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 2.235 Acc 19.290%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 2.237 Acc 18.881%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 2.236 Acc 19.006%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 2.298 Acc 13.281%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 2.239 Acc 18.441%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 2.238 Acc 18.680%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 2.236 Acc 18.851%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.227 Acc 17.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 2.231 Acc 19.144%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 2.237 Acc 18.856%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.235 Acc 18.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 2.238 Acc 18.657%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 2.239 Acc 18.707%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 2.237 Acc 18.975%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2.231 Acc 15.625%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 2.235 Acc 18.897%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2.237 Acc 18.777%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.295 Acc 14.062%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 2.232 Acc 19.407%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 2.235 Acc 19.061%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 2.237 Acc 18.923%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 2.238 Acc 18.864%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.212 Acc 21.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.273 Acc 16.406%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 2.240 Acc 18.951%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 2.236 Acc 19.110%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.256 Acc 20.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.233 Acc 18.982%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.235 Acc 18.870%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.236 Acc 18.854%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.234 Acc 19.106%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.234 Acc 19.213%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.235 Acc 19.173%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 2.236 Acc 18.997%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.241 Acc 22.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.240 Acc 18.858%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.182 Acc 24.219%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 2.238 Acc 18.878%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 2.238 Acc 18.893%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 2.237 Acc 18.964%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.234 Acc 18.858%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.235 Acc 18.859%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.236 Acc 18.864%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.237 Acc 18.840%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.219 Acc 19.531%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.235 Acc 19.183%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.236 Acc 18.895%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.217 Acc 17.188%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.238 Acc 18.472%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.239 Acc 18.707%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.238 Acc 18.755%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.249 Acc 18.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.234 Acc 18.765%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.237 Acc 18.668%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.238 Acc 18.620%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.237 Acc 18.768%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.187 Acc 23.438%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.232 Acc 19.152%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.235 Acc 19.049%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.235 Acc 19.215%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.236 Acc 19.054%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.211 Acc 17.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.236 Acc 18.765%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 19.084%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.237 Acc 18.871%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.267 Acc 18.750%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.229 Acc 19.624%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.234 Acc 19.100%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 2.237 Acc 18.861%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 2.237 Acc 18.876%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.214 Acc 20.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.238 Acc 18.692%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.204 Acc 21.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.241 Acc 18.742%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.239 Acc 18.867%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.238 Acc 18.886%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.264 Acc 17.969%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.239 Acc 18.912%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.237 Acc 18.750%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.236 Acc 18.830%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.238 Acc 18.756%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.837%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.179 Acc 25.000%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 2.243 Acc 18.533%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 2.238 Acc 18.746%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 2.237 Acc 18.923%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.235 Acc 21.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.236 Acc 18.991%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.227 Acc 20.312%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.241 Acc 18.564%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.240 Acc 18.614%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.239 Acc 18.864%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.236 Acc 18.984%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.239 Acc 18.595%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.238 Acc 18.784%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.237 Acc 18.828%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.238 Acc 18.844%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.221 Acc 23.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.236 Acc 19.284%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.240 Acc 18.890%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.236 Acc 19.013%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.273 Acc 14.844%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.242 Acc 18.394%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.239 Acc 18.864%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.848%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.234 Acc 15.625%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.238 Acc 18.371%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.236 Acc 18.908%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.237 Acc 18.982%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.228 Acc 21.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.239 Acc 19.137%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.235 Acc 19.158%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 2.236 Acc 19.068%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 2.237 Acc 18.965%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.271 Acc 16.406%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.239 Acc 18.645%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.239 Acc 18.724%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.238 Acc 18.845%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.262 Acc 19.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.237 Acc 18.975%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.248 Acc 18.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 2.239 Acc 18.672%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 2.237 Acc 18.858%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.199 Acc 20.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.238 Acc 18.699%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.239 Acc 18.675%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.791%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.218 Acc 20.312%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.242 Acc 18.626%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.237 Acc 18.944%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 2.238 Acc 18.892%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 2.238 Acc 18.923%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.241 Acc 18.750%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.235 Acc 18.773%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.235 Acc 19.076%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.239 Acc 18.629%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.238 Acc 18.792%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.249 Acc 15.625%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.236 Acc 19.144%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.236 Acc 19.123%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.238 Acc 18.881%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.217 Acc 18.750%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.234 Acc 19.307%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.236 Acc 19.056%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.196 Acc 26.562%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.237 Acc 18.942%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.236 Acc 19.079%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.887%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.184 Acc 19.531%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.237 Acc 19.098%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.238 Acc 18.817%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.239 Acc 18.692%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.834%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.222 Acc 19.531%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.241 Acc 18.781%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.240 Acc 18.816%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.239 Acc 18.779%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.254 Acc 17.969%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.242 Acc 18.216%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.239 Acc 18.490%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 2.238 Acc 18.768%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 2.237 Acc 18.848%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.209 Acc 26.562%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.233 Acc 19.137%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.235 Acc 18.758%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.237 Acc 18.714%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.237 Acc 18.832%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.884%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.241 Acc 16.406%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.233 Acc 19.446%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.235 Acc 19.092%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.238 Acc 18.854%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.237 Acc 18.844%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.229 Acc 16.406%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.241 Acc 18.858%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 2.239 Acc 19.038%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.244 Acc 17.188%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.242 Acc 18.278%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.240 Acc 18.610%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.243 Acc 20.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.240 Acc 18.765%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.235 Acc 19.057%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.236 Acc 19.004%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.186 Acc 26.562%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.237 Acc 19.009%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.198 Acc 23.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.243 Acc 18.835%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 2.242 Acc 18.637%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.239 Acc 18.771%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.246 Acc 17.188%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.241 Acc 18.699%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.204 Acc 23.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.239 Acc 18.464%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.241 Acc 18.233%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.239 Acc 18.490%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.252 Acc 20.312%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.235 Acc 18.991%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.236 Acc 18.941%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.251 Acc 17.188%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.234 Acc 19.400%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.234 Acc 19.442%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.236 Acc 19.155%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.273 Acc 17.969%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.238 Acc 18.984%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.238 Acc 18.828%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.206 Acc 23.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.233 Acc 19.516%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.235 Acc 19.263%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.236 Acc 19.072%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.232 Acc 20.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 2.235 Acc 19.044%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 2.238 Acc 18.995%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 2.237 Acc 18.976%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 2.238 Acc 18.941%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 2.237 Acc 18.981%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.190 Acc 24.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.232 Acc 19.717%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.236 Acc 19.286%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 19.142%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.236 Acc 19.116%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.215 Acc 18.750%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.237 Acc 19.090%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.238 Acc 18.975%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.238 Acc 18.950%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.254 Acc 17.969%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.235 Acc 19.044%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.236 Acc 18.766%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.237 Acc 18.708%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 18.785%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.240 Acc 15.625%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.232 Acc 19.663%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.236 Acc 19.317%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.236 Acc 19.017%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.269 Acc 16.406%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.237 Acc 18.834%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 18.859%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.256 Acc 18.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.240 Acc 18.758%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.229 Acc 21.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.238 Acc 18.964%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.238 Acc 18.815%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.238 Acc 18.805%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 2.235 Acc 19.178%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.237 Acc 18.957%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.286 Acc 13.281%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.235 Acc 18.866%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.018%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.243 Acc 19.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.239 Acc 18.750%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.238 Acc 18.913%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.237 Acc 19.004%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 19.091%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.236 Acc 19.071%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.283 Acc 17.188%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.240 Acc 18.820%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.238 Acc 18.890%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.236 Acc 18.990%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.195 Acc 16.406%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.235 Acc 19.261%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.236 Acc 19.135%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.236 Acc 19.243%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.238 Acc 19.036%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.237 Acc 18.978%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.254 Acc 21.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.240 Acc 18.448%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.239 Acc 18.633%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.238 Acc 18.953%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.246 Acc 17.969%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.238 Acc 19.106%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.238 Acc 18.797%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.238 Acc 18.858%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.220 Acc 17.188%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.235 Acc 19.154%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.235 Acc 19.222%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.235 Acc 19.192%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.236 Acc 19.001%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.243 Acc 18.750%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.234 Acc 19.106%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.235 Acc 18.991%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.236 Acc 18.895%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.231 Acc 18.750%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.238 Acc 18.998%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 19.018%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.240 Acc 16.406%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.240 Acc 18.680%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.238 Acc 18.836%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.238 Acc 18.879%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.238 Acc 18.920%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.213 Acc 21.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.240 Acc 18.688%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.240 Acc 18.692%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.239 Acc 18.768%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.239 Acc 18.758%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.278 Acc 17.969%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.239 Acc 18.882%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.238 Acc 18.931%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.224 Acc 18.750%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 18.939%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.833%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.240 Acc 17.969%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.909%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.239 Acc 18.779%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.177 Acc 23.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.232 Acc 19.129%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.235 Acc 19.010%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 2.235 Acc 19.056%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.235 Acc 18.955%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.238 Acc 19.531%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.232 Acc 19.330%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.234 Acc 19.216%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.235 Acc 19.120%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.236 Acc 19.035%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.235 Acc 19.202%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.236 Acc 19.027%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.210 Acc 19.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.235 Acc 19.018%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.238 Acc 18.876%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.222 Acc 17.188%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.237 Acc 18.750%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.238 Acc 18.792%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.263 Acc 16.406%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.237 Acc 18.882%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.237 Acc 18.841%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.237 Acc 18.861%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.238 Acc 18.850%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.228 Acc 18.750%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.238 Acc 18.549%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.195 Acc 25.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.235 Acc 19.349%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.237 Acc 19.121%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.276 Acc 17.188%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.241 Acc 18.456%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.238 Acc 18.847%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.236 Acc 19.082%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.222 Acc 15.625%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.239 Acc 18.874%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.239 Acc 18.773%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.238 Acc 18.917%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.214 Acc 21.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.234 Acc 19.199%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.234 Acc 19.127%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.235 Acc 19.043%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.271 Acc 14.844%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.769%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.238 Acc 18.762%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.238 Acc 18.792%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.208 Acc 21.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.234 Acc 19.284%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.236 Acc 19.080%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.235 Acc 19.189%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.237 Acc 19.058%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.247 Acc 20.312%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.244 Acc 18.263%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.995%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.222 Acc 20.312%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.233 Acc 19.191%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.235 Acc 18.972%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.237 Acc 18.727%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.237 Acc 18.920%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.238 Acc 18.963%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 2.238 Acc 18.890%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.216 Acc 23.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.241 Acc 18.704%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.236 Acc 18.847%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.236 Acc 18.932%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.237 Acc 18.855%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.186 Acc 24.219%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.233 Acc 19.114%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.237 Acc 18.968%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.292 Acc 13.281%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 2.235 Acc 18.881%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.238 Acc 19.061%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.236 Acc 19.126%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.222 Acc 18.750%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.244 Acc 18.564%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.241 Acc 18.664%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.239 Acc 18.750%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.238 Acc 18.861%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.240 Acc 21.094%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.237 Acc 18.665%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.236 Acc 18.851%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.236 Acc 18.901%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.238 Acc 18.862%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.267 Acc 14.062%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.240 Acc 18.742%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.236 Acc 18.967%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.251 Acc 14.062%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.234 Acc 19.237%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.236 Acc 19.131%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.236 Acc 19.121%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.237 Acc 19.095%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.237 Acc 18.957%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.188 Acc 18.750%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.240 Acc 18.448%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.236 Acc 18.762%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.235 Acc 19.041%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.247 Acc 15.625%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.240 Acc 18.711%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.239 Acc 18.785%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.236 Acc 18.910%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.255 Acc 20.312%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.234 Acc 19.267%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.237 Acc 19.051%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.227 Acc 23.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.238 Acc 18.936%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.237 Acc 19.049%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.236 Acc 18.946%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.211 Acc 25.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.241 Acc 18.509%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.241 Acc 18.623%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.238 Acc 18.826%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.259 Acc 18.750%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.240 Acc 19.052%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.239 Acc 18.952%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.942%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.238 Acc 18.951%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.198 Acc 20.312%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.237 Acc 19.253%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.239 Acc 18.937%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.239 Acc 18.763%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 2.238 Acc 18.839%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.255 Acc 15.625%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.237 Acc 18.917%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.992%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.226 Acc 21.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.243 Acc 18.572%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.239 Acc 18.653%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.174 Acc 21.875%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.237 Acc 18.967%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.911%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.236 Acc 18.943%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.215 Acc 16.406%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.917%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.235 Acc 19.033%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.236 Acc 19.018%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.229 Acc 17.188%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.242 Acc 18.673%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.238 Acc 19.003%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.235 Acc 19.083%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.236 Acc 19.015%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.276 Acc 18.750%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.234 Acc 19.624%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.235 Acc 19.236%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.236 Acc 19.019%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.214 Acc 24.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.237 Acc 19.144%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.236 Acc 19.033%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.221 Acc 20.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.241 Acc 18.256%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.240 Acc 18.576%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.239 Acc 18.697%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.242 Acc 15.625%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.235 Acc 18.976%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.939%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.250 Acc 15.625%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.239 Acc 18.711%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.237 Acc 19.073%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.237 Acc 18.991%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.238 Acc 18.886%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.191 Acc 22.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.235 Acc 19.052%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.234 Acc 19.306%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.235 Acc 19.272%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.235 Acc 19.149%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.236 Acc 19.006%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.279 Acc 19.531%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.233 Acc 19.462%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.234 Acc 19.251%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.238 Acc 18.893%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.281 Acc 14.062%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.233 Acc 19.377%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.235 Acc 19.119%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.237 Acc 18.968%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.250 Acc 17.188%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.239 Acc 18.595%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.239 Acc 18.638%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.738%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.294 Acc 13.281%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.236 Acc 19.100%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.223 Acc 17.969%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.236 Acc 19.237%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.233 Acc 19.399%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.236 Acc 19.155%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.249 Acc 17.188%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.241 Acc 18.536%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.237 Acc 18.885%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.259 Acc 20.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.240 Acc 18.611%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.237 Acc 18.797%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.281 Acc 16.406%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.237 Acc 18.936%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.236 Acc 19.248%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.237 Acc 19.121%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.237 Acc 18.957%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.226 Acc 17.188%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.238 Acc 18.897%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.895%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.237 Acc 18.786%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.238 Acc 18.658%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.231 Acc 19.531%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.235 Acc 18.959%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.235 Acc 19.088%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.235 Acc 19.082%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.237 Acc 18.926%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.283 Acc 19.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.233 Acc 19.384%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.236 Acc 19.216%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.237 Acc 19.147%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.237 Acc 19.042%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.236 Acc 14.062%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.005%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.237 Acc 18.723%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.237 Acc 18.952%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.273 Acc 14.062%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.242 Acc 18.448%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.241 Acc 18.870%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.238 Acc 18.906%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.226 Acc 23.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.240 Acc 18.526%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.235 Acc 19.057%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.237 Acc 18.838%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.231 Acc 17.969%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 18.917%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.236 Acc 18.970%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.233 Acc 17.188%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.235 Acc 19.245%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.236 Acc 19.053%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.239 Acc 18.890%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.263 Acc 19.531%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.238 Acc 18.913%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.236 Acc 18.963%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.182 Acc 22.656%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.232 Acc 18.912%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.236 Acc 18.987%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.236 Acc 18.815%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.760%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.236 Acc 19.162%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.236 Acc 18.997%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.253 Acc 18.750%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.234 Acc 19.083%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.234 Acc 18.952%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 18.916%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.294 Acc 14.062%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.235 Acc 18.843%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.239 Acc 18.684%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.239 Acc 18.908%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 2.239 Acc 18.867%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.245 Acc 21.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.240 Acc 18.715%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.239 Acc 18.877%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.238 Acc 18.887%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.236 Acc 14.062%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.234 Acc 17.969%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.236 Acc 18.979%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.236 Acc 19.074%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf8a61684ab45849204ce483e439362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.316 Acc 8.594%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 4.569 Acc 16.793%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 3.410 Acc 18.066%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 3.022 Acc 18.285%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.826 Acc 18.317%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.709 Acc 18.443%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.228 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.225 Acc 20.266%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.233 Acc 19.356%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 19.069%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 19.070%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 19.007%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.259 Acc 15.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.235 Acc 18.704%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.236 Acc 18.874%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.235 Acc 18.978%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.273 Acc 15.625%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.238 Acc 18.796%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.239 Acc 18.762%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 19.040%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.948%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.260 Acc 14.844%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.235 Acc 18.889%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.236 Acc 18.587%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.236 Acc 18.690%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.236 Acc 18.816%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.235 Acc 18.744%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.196 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.214 Acc 19.531%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.238 Acc 18.363%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.232 Acc 18.913%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.234 Acc 18.929%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.233 Acc 18.869%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.233 Acc 18.948%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.191 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.218 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.219 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.221 Acc 20.312%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.223 Acc 19.438%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.226 Acc 19.007%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.226 Acc 18.914%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.223 Acc 18.958%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.214 Acc 19.431%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 1.984 Acc 38.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.006 Acc 31.405%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.011 Acc 31.110%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.061 Acc 32.031%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.009 Acc 29.308%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 1.903 Acc 34.161%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 1.782 Acc 38.800%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 1.644 Acc 43.990%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 1.514 Acc 48.728%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.747 Acc 77.344%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.795 Acc 75.472%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.792 Acc 75.649%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.725 Acc 74.219%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.726 Acc 77.027%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.686 Acc 78.327%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.651 Acc 79.384%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.628 Acc 80.243%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.607 Acc 80.930%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.495 Acc 82.031%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.497 Acc 85.063%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.497 Acc 85.005%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.477 Acc 85.938%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.493 Acc 84.855%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.470 Acc 85.588%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.462 Acc 85.930%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.457 Acc 86.105%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.448 Acc 86.391%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.477 Acc 87.500%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.479 Acc 86.703%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.476 Acc 86.633%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.297 Acc 88.281%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.403 Acc 87.670%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.394 Acc 88.099%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.393 Acc 88.164%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.392 Acc 88.186%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.393 Acc 88.138%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.388 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.371 Acc 88.869%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.367 Acc 88.977%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.413 Acc 88.281%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.363 Acc 89.032%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.363 Acc 89.117%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.364 Acc 89.140%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.362 Acc 89.135%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.363 Acc 89.089%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.362 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.371 Acc 89.565%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.361 Acc 89.754%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.268 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.345 Acc 89.581%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.351 Acc 89.443%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.351 Acc 89.519%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.349 Acc 89.555%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.347 Acc 89.594%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.319 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.350 Acc 89.689%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.344 Acc 89.879%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.218 Acc 92.969%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.327 Acc 89.991%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.321 Acc 90.170%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.328 Acc 90.072%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.330 Acc 90.062%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.332 Acc 90.043%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.287 Acc 89.844%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.297 Acc 91.793%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.288 Acc 91.939%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.344 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.330 Acc 89.937%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.327 Acc 90.034%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.324 Acc 90.207%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.321 Acc 90.327%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.321 Acc 90.360%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.355 Acc 88.281%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.314 Acc 91.677%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.310 Acc 91.756%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.348 Acc 89.844%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.303 Acc 90.865%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.306 Acc 90.897%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.317 Acc 90.677%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.318 Acc 90.522%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.317 Acc 90.570%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.304 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.276 Acc 91.932%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.267 Acc 92.067%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.289 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.294 Acc 91.275%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.297 Acc 91.157%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.300 Acc 91.030%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.301 Acc 90.991%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.301 Acc 90.991%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.312 Acc 93.750%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.275 Acc 92.280%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.265 Acc 92.413%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.259 Acc 92.188%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.283 Acc 91.414%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.301 Acc 91.018%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.296 Acc 91.274%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.296 Acc 91.307%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.296 Acc 91.336%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.311 Acc 89.844%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.254 Acc 93.031%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.246 Acc 93.124%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.211 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.286 Acc 91.267%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.284 Acc 91.449%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.294 Acc 91.206%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.297 Acc 91.174%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.297 Acc 91.208%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.285 Acc 88.281%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.246 Acc 93.023%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.240 Acc 93.276%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.173 Acc 92.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.268 Acc 91.940%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.280 Acc 91.589%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.282 Acc 91.596%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.285 Acc 91.613%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.284 Acc 91.614%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.247 Acc 92.984%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.239 Acc 93.206%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.159 Acc 96.875%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.286 Acc 92.048%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.280 Acc 91.912%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.285 Acc 91.707%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.283 Acc 91.771%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.281 Acc 91.798%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.279 Acc 89.844%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.248 Acc 93.301%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.240 Acc 93.319%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.249 Acc 90.625%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.270 Acc 92.296%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.268 Acc 92.343%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.273 Acc 92.055%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.274 Acc 92.045%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.273 Acc 92.060%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.331 Acc 90.625%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.262 Acc 92.884%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.251 Acc 93.132%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.244 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.265 Acc 92.443%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.267 Acc 92.292%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.270 Acc 92.265%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.270 Acc 92.262%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.273 Acc 92.177%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.248 Acc 93.201%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.242 Acc 93.233%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.257 Acc 92.242%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.260 Acc 92.425%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.269 Acc 92.307%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.266 Acc 92.373%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.265 Acc 92.414%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.245 Acc 93.038%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.241 Acc 93.155%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.266 Acc 92.188%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.264 Acc 92.351%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.266 Acc 92.312%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.266 Acc 92.242%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.265 Acc 92.309%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.219 Acc 94.230%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.211 Acc 94.372%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.244 Acc 91.406%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.263 Acc 92.497%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.268 Acc 92.222%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.264 Acc 92.419%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.263 Acc 92.464%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.263 Acc 92.484%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.332 Acc 89.844%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.227 Acc 93.719%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.222 Acc 94.045%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.252 Acc 92.946%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.256 Acc 92.712%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.257 Acc 92.595%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.258 Acc 92.571%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.260 Acc 92.517%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.184 Acc 91.406%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.207 Acc 94.407%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.201 Acc 94.566%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.221 Acc 91.406%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.245 Acc 92.822%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.245 Acc 92.852%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.248 Acc 92.771%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.249 Acc 92.749%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.249 Acc 92.705%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.216 Acc 94.330%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.206 Acc 94.457%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.230 Acc 92.969%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.247 Acc 92.891%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.252 Acc 92.724%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.246 Acc 92.896%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.248 Acc 92.836%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.248 Acc 92.833%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.220 Acc 94.075%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.211 Acc 94.263%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.338 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.243 Acc 93.093%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.242 Acc 93.109%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.244 Acc 93.021%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.248 Acc 92.963%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.250 Acc 92.833%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.344 Acc 90.625%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.230 Acc 94.377%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.224 Acc 94.450%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.235 Acc 93.123%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.243 Acc 92.918%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.241 Acc 93.041%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.241 Acc 93.064%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.242 Acc 93.081%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.230 Acc 93.657%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.221 Acc 93.886%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.231 Acc 93.209%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.234 Acc 93.237%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.236 Acc 93.200%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.234 Acc 93.154%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.238 Acc 93.050%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.234 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.227 Acc 93.839%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.161 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.228 Acc 93.603%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.235 Acc 93.291%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.234 Acc 93.231%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.236 Acc 93.230%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.234 Acc 93.232%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.326 Acc 90.625%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.217 Acc 94.307%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.208 Acc 94.422%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.344 Acc 91.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.228 Acc 93.139%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.229 Acc 93.218%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.231 Acc 93.233%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.229 Acc 93.325%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.229 Acc 93.370%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.240 Acc 93.595%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.229 Acc 93.894%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.255 Acc 94.531%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.234 Acc 93.178%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.236 Acc 93.167%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.236 Acc 93.182%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.237 Acc 93.210%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.235 Acc 93.262%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.234 Acc 92.188%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.187 Acc 95.003%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.180 Acc 95.204%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.150 Acc 94.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.217 Acc 93.881%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.226 Acc 93.521%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.228 Acc 93.343%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.230 Acc 93.339%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.230 Acc 93.337%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.252 Acc 93.116%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.244 Acc 93.249%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.223 Acc 93.588%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.227 Acc 93.400%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.223 Acc 93.553%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.229 Acc 93.397%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.228 Acc 93.455%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.198 Acc 94.694%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.189 Acc 94.998%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.242 Acc 92.188%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.229 Acc 93.170%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.226 Acc 93.505%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.225 Acc 93.532%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.226 Acc 93.520%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.228 Acc 93.479%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.234 Acc 94.028%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.229 Acc 94.111%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.213 Acc 93.704%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.213 Acc 93.762%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.217 Acc 93.638%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.217 Acc 93.752%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.218 Acc 93.706%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.211 Acc 94.392%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.205 Acc 94.504%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.222 Acc 93.735%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.219 Acc 93.633%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.218 Acc 93.662%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.225 Acc 93.551%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.222 Acc 93.647%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.255 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.201 Acc 94.933%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.192 Acc 95.048%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.210 Acc 94.044%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.214 Acc 93.886%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.214 Acc 93.893%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.215 Acc 93.828%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.219 Acc 93.720%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.283 Acc 92.188%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.223 Acc 94.067%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.215 Acc 94.232%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.280 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.196 Acc 94.222%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.207 Acc 94.030%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.213 Acc 93.867%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.217 Acc 93.793%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.217 Acc 93.758%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.199 Acc 94.524%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.191 Acc 94.912%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.204 Acc 94.524%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.211 Acc 94.119%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.212 Acc 94.030%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.214 Acc 93.964%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.213 Acc 93.971%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.182 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.192 Acc 94.841%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.186 Acc 94.970%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.194 Acc 94.338%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.213 Acc 93.933%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.213 Acc 93.869%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.214 Acc 93.857%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.214 Acc 93.900%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.217 Acc 94.763%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.209 Acc 94.943%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.225 Acc 93.696%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.219 Acc 93.812%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.218 Acc 93.856%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.218 Acc 93.867%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.215 Acc 93.914%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.280 Acc 90.625%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.231 Acc 93.425%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.224 Acc 93.680%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.203 Acc 94.160%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.204 Acc 94.146%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.209 Acc 93.994%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.211 Acc 93.994%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.214 Acc 93.842%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.193 Acc 95.173%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.185 Acc 95.320%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.202 Acc 92.188%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.216 Acc 93.634%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.218 Acc 93.723%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.217 Acc 93.797%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.216 Acc 93.814%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.214 Acc 93.839%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.218 Acc 94.531%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.213 Acc 94.558%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.202 Acc 92.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.217 Acc 93.974%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.209 Acc 93.968%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.212 Acc 93.994%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.209 Acc 94.009%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.208 Acc 94.048%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.208 Acc 94.779%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.203 Acc 94.827%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.165 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.199 Acc 94.315%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.196 Acc 94.508%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.196 Acc 94.435%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.203 Acc 94.186%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.206 Acc 94.098%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.200 Acc 94.794%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.194 Acc 95.021%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.200 Acc 94.315%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.204 Acc 94.111%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.208 Acc 94.017%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.206 Acc 94.179%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.205 Acc 94.085%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.197 Acc 94.972%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.188 Acc 95.235%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.199 Acc 94.338%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.203 Acc 94.127%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.203 Acc 94.121%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.205 Acc 94.122%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.207 Acc 94.095%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.198 Acc 95.119%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.192 Acc 95.169%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.192 Acc 94.732%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.197 Acc 94.446%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.203 Acc 94.326%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.199 Acc 94.401%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.198 Acc 94.375%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 95.057%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 95.114%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.206 Acc 93.765%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.211 Acc 93.781%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.207 Acc 93.901%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.207 Acc 93.976%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.206 Acc 94.024%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.195 Acc 95.127%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.187 Acc 95.188%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.201 Acc 94.044%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.201 Acc 94.069%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.199 Acc 94.207%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.203 Acc 94.159%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.203 Acc 94.162%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.192 Acc 95.034%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.138%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.201 Acc 94.694%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.203 Acc 94.426%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.200 Acc 94.461%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.200 Acc 94.403%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.198 Acc 94.371%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.196 Acc 94.640%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.193 Acc 94.768%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.185 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.208 Acc 94.183%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.208 Acc 94.135%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.201 Acc 94.334%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.201 Acc 94.270%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.203 Acc 94.196%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.164 Acc 92.188%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.203 Acc 94.717%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.197 Acc 94.904%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.186 Acc 94.655%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.186 Acc 94.621%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.191 Acc 94.573%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.192 Acc 94.525%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.194 Acc 94.452%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.187 Acc 95.490%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.180 Acc 95.565%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.148 Acc 94.531%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.194 Acc 94.330%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.196 Acc 94.271%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.200 Acc 94.103%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.199 Acc 94.159%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.198 Acc 94.169%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.259 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.213 Acc 94.508%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.206 Acc 94.729%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.179 Acc 92.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.188 Acc 94.485%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.192 Acc 94.329%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.197 Acc 94.298%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.197 Acc 94.327%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.196 Acc 94.361%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.199 Acc 95.080%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.192 Acc 95.075%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.195 Acc 91.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.190 Acc 94.230%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.192 Acc 94.240%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.196 Acc 94.163%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.195 Acc 94.227%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.195 Acc 94.254%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.202 Acc 94.910%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.196 Acc 95.114%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.377 Acc 90.625%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.192 Acc 94.205%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.194 Acc 94.220%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.192 Acc 94.307%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.194 Acc 94.263%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.190 Acc 95.173%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.184 Acc 95.301%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.153 Acc 95.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.181 Acc 94.810%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.186 Acc 94.784%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.187 Acc 94.653%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.187 Acc 94.642%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.188 Acc 94.591%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.195 Acc 94.972%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.190 Acc 95.029%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.134 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.188 Acc 94.632%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.189 Acc 94.504%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.193 Acc 94.456%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.195 Acc 94.380%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.197 Acc 94.841%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.190 Acc 94.974%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.183 Acc 94.732%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.181 Acc 94.749%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.185 Acc 94.661%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.186 Acc 94.656%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.190 Acc 94.558%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.227%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.173%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.179 Acc 94.856%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.182 Acc 94.900%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.181 Acc 94.869%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.738%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.188 Acc 94.711%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.187 Acc 95.406%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.197 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.181 Acc 94.771%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.183 Acc 94.648%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.183 Acc 94.643%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.184 Acc 94.596%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.188 Acc 94.545%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.188 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.189 Acc 95.104%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.183 Acc 95.262%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.177 Acc 94.949%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.181 Acc 94.726%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.188 Acc 94.565%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.186 Acc 94.644%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.188 Acc 94.595%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.173 Acc 95.588%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.178 Acc 94.841%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.691%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.186 Acc 94.721%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.189 Acc 94.545%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.125 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.193 Acc 95.421%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.189 Acc 95.402%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.221 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.178 Acc 94.787%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.186 Acc 94.617%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.189 Acc 94.536%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.193 Acc 94.539%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.190 Acc 94.573%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.188 Acc 95.305%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.184 Acc 95.441%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.165 Acc 92.969%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.190 Acc 94.500%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.178 Acc 94.838%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.179 Acc 94.840%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.183 Acc 94.732%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.183 Acc 94.767%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.179 Acc 95.622%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.175 Acc 95.670%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.187 Acc 94.709%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.181 Acc 94.858%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.183 Acc 94.793%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.185 Acc 94.722%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.187 Acc 94.633%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.183 Acc 95.382%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.178 Acc 95.484%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.342 Acc 92.188%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.172 Acc 94.879%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.178 Acc 94.656%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.185 Acc 94.521%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.188 Acc 94.442%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.185 Acc 94.544%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.182 Acc 95.444%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.179 Acc 95.515%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.166 Acc 95.127%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.180 Acc 94.768%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.182 Acc 94.791%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.182 Acc 94.833%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.181 Acc 94.838%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.186 Acc 95.483%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.184 Acc 95.437%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.283 Acc 94.531%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.182 Acc 94.647%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.182 Acc 94.803%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.180 Acc 94.858%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.182 Acc 94.742%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.184 Acc 94.667%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.178 Acc 95.800%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.173 Acc 95.775%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.173 Acc 95.050%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.174 Acc 94.974%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.181 Acc 94.868%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.180 Acc 94.865%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.211 Acc 94.701%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.208 Acc 94.667%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.172 Acc 95.065%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.176 Acc 95.029%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.179 Acc 94.936%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.180 Acc 94.915%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.181 Acc 94.877%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.530%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.183 Acc 93.750%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.166 Acc 94.964%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.172 Acc 94.866%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.178 Acc 94.773%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.180 Acc 94.751%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.182 Acc 94.737%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.202 Acc 95.251%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.188 Acc 95.460%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.171 Acc 94.910%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.178 Acc 94.885%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.178 Acc 94.892%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.176 Acc 94.880%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.177 Acc 94.860%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.179 Acc 95.449%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.203 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.172 Acc 94.972%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.173 Acc 94.947%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.178 Acc 94.830%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.181 Acc 94.790%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.180 Acc 94.796%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.178 Acc 95.645%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.224 Acc 92.969%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.175 Acc 95.065%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.172 Acc 95.040%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.174 Acc 95.037%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.175 Acc 94.927%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.175 Acc 94.951%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.233 Acc 92.969%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.202 Acc 95.343%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.194 Acc 95.421%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.243 Acc 92.969%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.169 Acc 95.266%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.172 Acc 95.083%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.173 Acc 95.056%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.173 Acc 95.067%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.175 Acc 95.015%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.188 Acc 95.405%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.185 Acc 95.468%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.173 Acc 95.065%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.170 Acc 95.029%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.173 Acc 95.032%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.176 Acc 94.968%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.177 Acc 94.901%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.213 Acc 94.446%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.204 Acc 94.648%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.178 Acc 94.787%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.175 Acc 94.908%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.173 Acc 94.949%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.173 Acc 95.020%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.173 Acc 95.060%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.190 Acc 95.405%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.184 Acc 95.456%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.173 Acc 94.887%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.175 Acc 94.694%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.178 Acc 94.687%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.177 Acc 94.777%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.176 Acc 94.876%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.197 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.186 Acc 95.583%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.184 Acc 95.655%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.178 Acc 94.903%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.174 Acc 94.924%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.172 Acc 94.936%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.173 Acc 94.931%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.173 Acc 94.930%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.209 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.189 Acc 95.382%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.186 Acc 95.484%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.171 Acc 95.065%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.166 Acc 95.204%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.172 Acc 95.087%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.172 Acc 95.024%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.171 Acc 95.030%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.110 Acc 95.312%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.176 Acc 95.838%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.173 Acc 95.903%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.191 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.181 Acc 94.825%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.173 Acc 94.963%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.174 Acc 94.970%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.172 Acc 94.995%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.171 Acc 95.019%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.203 Acc 94.995%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.197 Acc 95.130%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.095 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.169 Acc 94.670%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.166 Acc 94.963%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.166 Acc 95.061%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.168 Acc 95.049%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.171 Acc 95.005%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.224 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.211 Acc 94.980%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.175 Acc 94.794%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.176 Acc 94.846%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.177 Acc 94.879%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.177 Acc 94.866%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.177 Acc 94.863%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.175 Acc 92.188%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.184 Acc 95.529%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.181 Acc 95.550%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.359%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.166 Acc 95.184%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.172 Acc 95.048%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.173 Acc 94.975%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.175 Acc 94.913%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.676%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.173 Acc 95.662%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.160 Acc 95.413%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.166 Acc 95.239%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.169 Acc 95.178%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.172 Acc 95.133%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.172 Acc 95.052%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.250 Acc 91.406%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.204 Acc 94.941%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.200 Acc 94.974%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.164 Acc 95.135%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.166 Acc 95.270%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.168 Acc 95.188%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.169 Acc 95.139%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.168 Acc 95.167%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.190 Acc 95.220%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.187 Acc 95.270%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.211 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.149 Acc 95.568%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.163 Acc 95.320%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.165 Acc 95.224%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.166 Acc 95.190%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.168 Acc 95.111%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.092 Acc 97.656%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.173 Acc 95.506%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.169 Acc 95.709%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.159 Acc 92.188%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.167 Acc 94.903%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.167 Acc 95.021%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.164 Acc 95.100%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.165 Acc 95.092%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.167 Acc 95.079%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.177 Acc 95.885%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.127 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.157 Acc 95.429%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.166 Acc 95.118%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.169 Acc 95.001%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.170 Acc 94.964%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.170 Acc 94.971%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.191 Acc 95.630%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.186 Acc 95.728%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.165 Acc 95.212%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.165 Acc 95.122%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.166 Acc 95.110%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.168 Acc 95.118%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.168 Acc 95.033%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.117 Acc 96.875%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.205 Acc 94.872%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.199 Acc 94.939%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.166 Acc 95.150%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.166 Acc 95.122%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.167 Acc 95.185%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.169 Acc 95.125%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.168 Acc 95.124%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.188 Acc 95.498%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.185 Acc 95.414%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.259 Acc 92.188%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.155 Acc 95.367%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.160 Acc 95.208%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.164 Acc 95.203%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.164 Acc 95.170%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.166 Acc 95.105%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.192 Acc 95.429%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.190 Acc 95.394%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.090 Acc 98.438%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.166 Acc 95.266%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.167 Acc 95.122%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.161 Acc 95.287%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.165 Acc 95.211%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.167 Acc 95.079%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.209 Acc 93.750%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.204 Acc 95.158%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.199 Acc 95.274%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.157 Acc 95.490%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.161 Acc 95.433%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.160 Acc 95.429%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.164 Acc 95.262%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.165 Acc 95.255%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.185 Acc 95.568%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.184 Acc 95.565%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.398%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.160 Acc 95.309%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.164 Acc 95.271%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.163 Acc 95.274%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.164 Acc 95.255%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.211 Acc 94.895%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.208 Acc 95.149%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.250 Acc 91.406%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.172 Acc 94.848%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.165 Acc 95.075%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.163 Acc 95.227%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.163 Acc 95.229%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.164 Acc 95.219%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.190 Acc 95.421%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.186 Acc 95.480%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.159 Acc 95.421%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.157 Acc 95.476%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.163 Acc 95.162%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.164 Acc 95.149%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.164 Acc 95.155%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.202 Acc 95.282%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.198 Acc 95.309%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.160 Acc 95.382%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.160 Acc 95.464%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.159 Acc 95.424%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.162 Acc 95.357%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.163 Acc 95.292%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.225 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.206 Acc 95.034%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.200 Acc 95.169%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.149 Acc 95.545%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.159 Acc 95.219%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.162 Acc 95.188%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.160 Acc 95.274%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.162 Acc 95.241%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.188 Acc 95.606%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.168 Acc 95.073%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.164 Acc 95.122%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.161 Acc 95.248%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.163 Acc 95.237%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.161 Acc 95.292%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.182 Acc 95.552%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.174 Acc 95.635%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.160 Acc 95.328%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.161 Acc 95.367%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.161 Acc 95.341%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.160 Acc 95.340%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.160 Acc 95.350%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.187 Acc 95.367%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.185 Acc 95.355%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.161 Acc 95.343%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.159 Acc 95.379%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.158 Acc 95.375%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.157 Acc 95.455%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.160 Acc 95.364%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.213 Acc 95.413%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.208 Acc 95.309%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.213 Acc 95.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.164 Acc 95.127%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.159 Acc 95.347%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.160 Acc 95.367%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.158 Acc 95.394%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.160 Acc 95.337%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.214 Acc 94.732%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.212 Acc 94.799%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.221 Acc 95.312%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.152 Acc 95.220%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.159 Acc 95.188%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.159 Acc 95.263%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.156 Acc 95.355%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.157 Acc 95.376%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.172 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.199 Acc 95.467%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.188 Acc 95.557%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.148 Acc 95.614%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.153 Acc 95.445%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.158 Acc 95.310%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.160 Acc 95.248%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.163 Acc 95.247%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.202 Acc 91.406%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.176 Acc 95.441%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.152 Acc 95.413%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.155 Acc 95.398%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.157 Acc 95.333%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.159 Acc 95.340%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.159 Acc 95.341%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.191 Acc 95.614%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.187 Acc 95.686%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.165 Acc 95.073%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.158 Acc 95.293%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.158 Acc 95.232%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.159 Acc 95.311%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.161 Acc 95.252%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.191 Acc 95.405%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.187 Acc 95.515%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.145 Acc 95.637%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.155 Acc 95.600%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.154 Acc 95.614%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.154 Acc 95.527%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.158 Acc 95.414%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.189 Acc 95.475%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.185 Acc 95.491%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.143 Acc 95.924%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.143 Acc 95.903%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.149 Acc 95.767%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.153 Acc 95.622%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.155 Acc 95.548%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.203 Acc 95.483%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.197 Acc 95.515%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.183 Acc 92.969%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.149 Acc 95.483%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.154 Acc 95.437%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.155 Acc 95.468%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.159 Acc 95.404%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.158 Acc 95.414%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.248 Acc 93.750%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.231 Acc 94.183%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.224 Acc 94.282%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.160 Acc 95.173%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.152 Acc 95.472%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.154 Acc 95.460%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.154 Acc 95.496%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.155 Acc 95.448%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.176 Acc 95.676%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.171 Acc 95.763%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.188 Acc 91.406%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.157 Acc 95.227%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.153 Acc 95.437%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.154 Acc 95.411%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.157 Acc 95.340%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.158 Acc 95.309%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.170 Acc 96.875%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.196 Acc 95.158%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.193 Acc 95.188%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.156 Acc 95.429%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.150 Acc 95.421%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.151 Acc 95.450%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.154 Acc 95.390%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.157 Acc 95.317%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.174 Acc 95.763%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.150 Acc 95.701%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.152 Acc 95.632%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.152 Acc 95.566%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.155 Acc 95.481%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.228 Acc 94.957%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.226 Acc 94.862%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.160 Acc 95.104%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.157 Acc 95.157%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.156 Acc 95.328%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.159 Acc 95.309%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.161 Acc 95.298%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.185 Acc 95.487%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.160 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.144 Acc 95.614%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.151 Acc 95.538%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.153 Acc 95.536%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.154 Acc 95.501%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.157 Acc 95.394%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.191 Acc 95.344%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.128 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.142 Acc 95.908%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.150 Acc 95.569%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.150 Acc 95.629%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.150 Acc 95.620%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.152 Acc 95.542%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.156 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.211 Acc 95.057%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.207 Acc 95.239%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.162 Acc 95.235%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.150 Acc 95.592%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.150 Acc 95.588%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.152 Acc 95.544%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.154 Acc 95.504%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.191 Acc 95.413%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.186 Acc 95.484%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.144 Acc 95.606%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.150 Acc 95.429%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.151 Acc 95.424%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.154 Acc 95.369%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.154 Acc 95.381%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.195 Acc 95.003%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.188 Acc 95.188%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.154 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.152 Acc 95.475%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.157 Acc 95.476%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.154 Acc 95.489%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.153 Acc 95.527%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.153 Acc 95.529%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.184 Acc 95.568%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.179 Acc 95.647%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.307 Acc 91.406%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.148 Acc 95.552%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.151 Acc 95.484%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.152 Acc 95.486%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.152 Acc 95.455%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.154 Acc 95.392%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.184 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.193 Acc 95.761%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.186 Acc 95.767%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.158 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.146 Acc 95.869%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.151 Acc 95.732%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.151 Acc 95.621%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.151 Acc 95.564%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.152 Acc 95.518%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.192 Acc 95.436%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.184 Acc 95.581%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.136 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.157 Acc 95.441%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.156 Acc 95.481%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.158 Acc 95.379%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.157 Acc 95.383%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.181 Acc 95.258%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.182 Acc 95.359%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.144 Acc 93.750%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.150 Acc 95.436%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.147 Acc 95.612%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.147 Acc 95.645%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.150 Acc 95.578%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.191 Acc 95.150%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.186 Acc 95.359%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.145 Acc 95.662%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.149 Acc 95.549%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.154 Acc 95.449%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.154 Acc 95.429%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.177 Acc 95.814%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.129 Acc 96.101%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.137 Acc 96.012%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.145 Acc 95.704%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.150 Acc 95.599%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.147 Acc 95.621%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.179 Acc 96.094%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.196 Acc 95.351%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.194 Acc 95.386%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.150 Acc 95.537%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.152 Acc 95.491%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.152 Acc 95.453%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.154 Acc 95.427%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.153 Acc 95.473%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.188 Acc 95.476%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.156 Acc 95.475%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.150 Acc 95.569%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.151 Acc 95.519%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.152 Acc 95.518%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.307 Acc 93.750%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.216 Acc 95.220%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.207 Acc 95.309%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.147 Acc 95.560%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.151 Acc 95.592%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.148 Acc 95.559%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.147 Acc 95.620%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.150 Acc 95.576%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.128 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.188 Acc 95.692%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.180 Acc 95.748%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.136 Acc 95.924%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.143 Acc 95.658%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.143 Acc 95.671%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.147 Acc 95.576%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.148 Acc 95.557%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.215 Acc 95.142%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.211 Acc 95.169%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.157 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.135 Acc 96.086%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.137 Acc 95.965%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.142 Acc 95.894%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.144 Acc 95.825%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.147 Acc 95.737%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.213 Acc 95.034%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.207 Acc 95.118%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.203 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.128 Acc 96.086%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.139 Acc 95.736%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.144 Acc 95.723%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.145 Acc 95.661%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.147 Acc 95.595%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.199 Acc 95.243%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.194 Acc 95.390%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.144 Acc 95.815%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.144 Acc 95.709%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.147 Acc 95.632%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.147 Acc 95.649%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.201 Acc 95.166%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.199 Acc 95.285%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.146 Acc 95.529%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.146 Acc 95.612%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.144 Acc 95.665%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.145 Acc 95.630%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.148 Acc 95.574%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.202 Acc 95.537%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.196 Acc 95.635%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.141 Acc 95.599%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.144 Acc 95.655%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.150 Acc 95.494%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.151 Acc 95.406%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.153 Acc 95.381%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.210 Acc 94.864%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.204 Acc 95.013%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.147 Acc 95.777%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.144 Acc 95.767%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.146 Acc 95.637%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.146 Acc 95.646%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.146 Acc 95.693%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.206 Acc 95.483%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.202 Acc 95.484%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.142 Acc 95.568%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.141 Acc 95.577%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.142 Acc 95.678%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.145 Acc 95.620%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.148 Acc 95.546%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.203 Acc 95.073%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.192 Acc 95.246%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.155 Acc 95.444%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.149 Acc 95.631%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.149 Acc 95.569%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.148 Acc 95.577%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.148 Acc 95.571%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.188 Acc 96.875%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.193 Acc 95.552%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.189 Acc 95.542%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.169 Acc 94.531%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.142 Acc 95.769%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.147 Acc 95.581%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.147 Acc 95.541%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.146 Acc 95.548%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.147 Acc 95.531%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.205 Acc 95.452%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.203 Acc 95.534%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.182 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.142 Acc 95.869%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.145 Acc 95.806%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.144 Acc 95.839%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.144 Acc 95.784%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.144 Acc 95.751%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.176 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.178 Acc 95.616%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.141 Acc 95.715%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.145 Acc 95.635%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.145 Acc 95.614%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.146 Acc 95.603%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.147 Acc 95.574%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.199 Acc 95.390%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.197 Acc 95.351%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.156 Acc 95.498%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.152 Acc 95.515%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.150 Acc 95.588%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.148 Acc 95.630%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.147 Acc 95.624%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.185 Acc 95.692%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.185 Acc 95.794%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.137 Acc 95.614%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.140 Acc 95.705%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.142 Acc 95.647%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.145 Acc 95.562%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.146 Acc 95.554%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.221 Acc 94.833%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.217 Acc 94.967%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.222 Acc 91.406%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.150 Acc 95.459%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.143 Acc 95.709%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.142 Acc 95.746%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.144 Acc 95.696%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.145 Acc 95.670%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.212 Acc 95.645%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.204 Acc 95.709%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.135 Acc 95.831%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.137 Acc 95.802%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.143 Acc 95.697%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.145 Acc 95.663%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.146 Acc 95.635%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.194 Acc 95.614%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.189 Acc 95.658%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.132 Acc 96.109%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.141 Acc 95.849%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.141 Acc 95.967%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.143 Acc 95.885%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.145 Acc 95.766%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.201 Acc 95.119%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.197 Acc 95.095%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.335 Acc 92.969%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.143 Acc 95.738%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.147 Acc 95.647%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.147 Acc 95.694%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.145 Acc 95.716%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.146 Acc 95.690%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.197 Acc 95.606%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.191 Acc 95.573%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.172 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.136 Acc 95.908%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.139 Acc 95.864%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.144 Acc 95.723%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.145 Acc 95.700%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.148 Acc 95.645%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.202 Acc 95.111%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.195 Acc 95.145%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.145 Acc 95.583%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.143 Acc 95.616%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.146 Acc 95.551%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.147 Acc 95.566%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.149 Acc 95.550%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.217 Acc 95.181%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.208 Acc 95.250%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.140 Acc 95.823%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.136 Acc 95.934%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.145 Acc 95.720%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.146 Acc 95.727%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.146 Acc 95.696%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.207 Acc 95.382%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.205 Acc 95.429%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.130 Acc 96.210%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.136 Acc 96.032%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.138 Acc 95.941%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.138 Acc 95.942%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.140 Acc 95.893%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.203 Acc 95.243%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.199 Acc 95.239%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.129 Acc 95.962%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.135 Acc 95.969%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.141 Acc 95.839%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.141 Acc 95.849%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.192 Acc 95.599%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.185 Acc 95.728%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.147 Acc 95.537%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.138 Acc 95.845%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.139 Acc 95.800%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.141 Acc 95.766%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.143 Acc 95.727%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.212 Acc 94.794%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.203 Acc 94.967%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.147 Acc 95.744%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.145 Acc 95.764%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.144 Acc 95.726%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.144 Acc 95.735%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.203 Acc 95.715%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.195 Acc 95.759%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.131 Acc 96.264%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.137 Acc 96.047%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.140 Acc 95.933%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.142 Acc 95.800%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.140 Acc 95.819%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.193 Acc 95.498%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.187 Acc 95.569%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.124 Acc 96.171%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.126 Acc 96.168%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.129 Acc 96.148%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.134 Acc 96.082%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.134 Acc 96.047%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.207 Acc 95.490%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.200 Acc 95.627%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.140 Acc 95.761%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.139 Acc 95.814%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.142 Acc 95.694%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.141 Acc 95.710%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.146 Acc 95.601%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.277 Acc 92.969%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.223 Acc 95.220%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.216 Acc 95.390%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.139 Acc 95.815%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.140 Acc 95.791%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.144 Acc 95.738%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.144 Acc 95.724%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.144 Acc 95.705%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.276 Acc 92.188%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.210 Acc 95.490%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.573%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.141 Acc 95.919%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.143 Acc 95.816%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.143 Acc 95.757%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.143 Acc 95.715%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.257 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.223 Acc 95.173%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.218 Acc 95.208%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.134 Acc 95.970%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.137 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.139 Acc 95.852%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.142 Acc 95.745%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.141 Acc 95.782%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.246 Acc 92.188%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.214 Acc 95.320%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.204 Acc 95.371%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.274 Acc 92.969%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.132 Acc 96.047%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.135 Acc 96.050%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.138 Acc 95.965%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.140 Acc 95.913%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.203 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.218 Acc 95.498%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.213 Acc 95.476%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.179 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.139 Acc 95.831%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.142 Acc 95.826%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.137 Acc 95.915%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.140 Acc 95.868%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.141 Acc 95.838%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.260 Acc 91.406%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.198 Acc 95.189%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.138 Acc 95.939%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.139 Acc 95.896%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.141 Acc 95.720%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.140 Acc 95.729%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.140 Acc 95.746%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.382%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.191 Acc 95.390%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.138 Acc 95.800%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.136 Acc 95.958%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.139 Acc 95.909%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.140 Acc 95.825%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.140 Acc 95.807%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.193 Acc 95.475%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.191 Acc 95.484%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.134 Acc 96.024%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.138 Acc 95.920%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.140 Acc 95.846%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.140 Acc 95.846%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.188 Acc 95.792%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.181 Acc 95.841%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.203 Acc 95.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.122 Acc 96.558%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.132 Acc 96.107%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.134 Acc 96.049%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.135 Acc 96.020%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.186 Acc 95.693%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.140 Acc 95.893%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.138 Acc 95.892%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.136 Acc 95.917%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.138 Acc 95.876%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.138 Acc 95.907%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.198 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.187 Acc 95.846%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.184 Acc 95.818%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.131 Acc 95.970%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.137 Acc 95.903%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.140 Acc 95.764%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.138 Acc 95.848%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.141 Acc 95.771%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.239 Acc 92.188%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.190 Acc 95.707%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.185 Acc 95.814%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.128 Acc 96.032%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.131 Acc 95.985%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.133 Acc 95.993%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.137 Acc 95.881%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.136 Acc 95.847%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.214 Acc 95.367%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.208 Acc 95.324%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.108 Acc 93.750%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.134 Acc 96.086%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.135 Acc 96.063%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.134 Acc 95.990%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.135 Acc 95.998%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.136 Acc 95.899%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.199 Acc 95.506%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.194 Acc 95.530%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.173 Acc 92.969%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.132 Acc 96.194%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.137 Acc 95.973%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.137 Acc 95.951%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.137 Acc 95.952%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.138 Acc 95.952%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.192 Acc 95.498%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.188 Acc 95.670%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.127 Acc 96.202%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.139 Acc 95.829%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.137 Acc 95.865%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.135 Acc 95.963%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.135 Acc 95.980%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.201 Acc 95.312%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.211 Acc 95.305%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.205 Acc 95.414%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.149 Acc 95.483%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.141 Acc 95.616%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.137 Acc 95.728%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.138 Acc 95.747%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.140 Acc 95.734%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.215 Acc 95.297%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.204 Acc 95.456%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.134 Acc 94.531%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.130 Acc 96.105%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.132 Acc 96.013%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.135 Acc 95.909%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.138 Acc 95.829%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.224 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.201 Acc 95.452%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.193 Acc 95.503%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.123 Acc 96.303%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.131 Acc 96.016%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.134 Acc 95.934%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.134 Acc 95.963%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.220 Acc 94.887%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.208 Acc 95.072%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.140 Acc 94.531%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.136 Acc 95.846%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.142 Acc 95.752%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.139 Acc 95.852%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.137 Acc 95.920%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.137 Acc 95.904%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.219 Acc 95.026%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.215 Acc 95.106%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.131 Acc 96.040%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.136 Acc 95.931%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.135 Acc 95.922%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.136 Acc 95.848%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.139 Acc 95.841%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.205 Acc 95.506%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.198 Acc 95.612%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.131 Acc 96.086%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.135 Acc 95.938%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.135 Acc 95.974%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.137 Acc 95.965%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.135 Acc 95.974%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.198 Acc 95.831%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.193 Acc 95.864%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.124 Acc 96.326%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.130 Acc 96.191%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.134 Acc 96.034%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.133 Acc 96.022%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.132 Acc 96.003%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.286 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.214 Acc 95.398%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.210 Acc 95.421%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.130 Acc 95.838%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.132 Acc 95.896%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.136 Acc 95.808%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.139 Acc 95.790%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.138 Acc 95.818%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.235 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.217 Acc 95.699%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.211 Acc 95.728%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.130 Acc 96.098%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.135 Acc 95.967%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.135 Acc 95.957%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.135 Acc 95.986%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.699%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.195 Acc 95.861%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.135 Acc 95.959%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.133 Acc 95.990%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.134 Acc 95.941%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.257 Acc 94.640%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.245 Acc 94.834%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.259 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.131 Acc 95.955%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.133 Acc 95.958%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.132 Acc 96.016%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.134 Acc 95.940%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.135 Acc 95.904%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.200 Acc 95.490%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.195 Acc 95.542%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.202 Acc 91.406%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.130 Acc 95.800%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.129 Acc 96.067%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.132 Acc 96.031%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.134 Acc 95.979%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.134 Acc 95.975%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.246 Acc 94.601%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.240 Acc 94.698%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.129 Acc 96.016%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.133 Acc 95.958%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.133 Acc 95.972%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.135 Acc 95.961%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.135 Acc 95.955%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.210 Acc 95.792%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.208 Acc 95.713%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.135 Acc 95.861%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.133 Acc 95.956%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.136 Acc 95.961%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.136 Acc 95.971%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.165 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.188 Acc 95.784%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.183 Acc 95.740%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.133 Acc 96.031%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.135 Acc 95.973%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.135 Acc 95.952%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.163 Acc 96.875%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.205 Acc 95.614%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.198 Acc 95.643%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.139 Acc 95.779%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.141 Acc 95.751%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.137 Acc 95.840%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.137 Acc 95.838%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.203 Acc 95.459%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.195 Acc 95.616%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.123 Acc 96.334%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.127 Acc 96.273%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.126 Acc 96.320%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.127 Acc 96.267%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.127 Acc 96.259%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.214 Acc 95.282%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.210 Acc 95.293%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.181 Acc 93.750%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.131 Acc 95.931%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.130 Acc 96.024%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.132 Acc 96.018%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.134 Acc 96.006%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.136 Acc 95.946%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.213 Acc 95.552%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.209 Acc 95.616%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.126 Acc 96.303%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.128 Acc 96.102%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.128 Acc 96.195%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.130 Acc 96.137%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.129 Acc 96.091%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.223 Acc 95.297%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.212 Acc 95.445%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.168 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.126 Acc 96.156%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.129 Acc 96.067%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.130 Acc 96.063%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.132 Acc 96.024%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.131 Acc 96.070%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.193 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.218 Acc 95.351%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.215 Acc 95.414%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.168 Acc 92.188%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.140 Acc 95.761%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.131 Acc 96.024%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.130 Acc 96.050%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.129 Acc 96.068%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.132 Acc 95.991%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.112 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.201 Acc 95.575%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.193 Acc 95.651%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.067 Acc 95.312%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.121 Acc 96.419%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.125 Acc 96.276%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.129 Acc 96.115%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.130 Acc 95.990%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.132 Acc 95.977%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.223 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.224 Acc 95.351%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.218 Acc 95.414%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad4f8d2f1d7456492633adccc45219f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.305 Acc 13.281%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.249 Acc 18.758%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.246 Acc 18.598%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.242 Acc 18.805%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.241 Acc 18.805%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.240 Acc 18.854%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.228 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.253 Acc 22.656%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.239 Acc 18.897%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.235 Acc 19.022%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.236 Acc 18.940%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.220 Acc 17.969%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.240 Acc 18.580%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.238 Acc 18.738%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.235 Acc 18.934%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.896%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.236 Acc 18.903%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.218 Acc 21.875%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.236 Acc 18.906%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 18.916%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.973%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.247 Acc 20.312%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.239 Acc 18.502%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.238 Acc 18.839%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.180 Acc 21.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.240 Acc 18.912%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.238 Acc 19.111%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.237 Acc 19.064%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.217 Acc 18.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.246 Acc 18.325%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.240 Acc 18.734%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.237 Acc 19.030%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.236 Acc 19.132%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.219 Acc 20.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.238 Acc 19.098%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.239 Acc 18.793%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.239 Acc 18.802%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.239 Acc 18.840%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.238 Acc 18.890%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.235 Acc 18.959%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.238 Acc 18.903%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.239 Acc 18.764%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.238 Acc 18.831%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.266 Acc 19.531%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.241 Acc 18.765%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.238 Acc 18.731%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.239 Acc 18.768%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.237 Acc 18.957%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.273 Acc 11.719%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 2.234 Acc 19.168%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 2.236 Acc 19.014%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 2.236 Acc 19.051%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 2.297 Acc 14.844%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 2.237 Acc 19.199%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 2.235 Acc 19.143%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 2.238 Acc 18.900%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2.233 Acc 20.312%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2.236 Acc 19.214%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2.237 Acc 19.123%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2.237 Acc 18.991%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 2.256 Acc 18.750%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 2.235 Acc 18.870%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 2.235 Acc 18.888%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 2.236 Acc 18.937%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 2.246 Acc 18.750%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 2.233 Acc 19.361%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 2.234 Acc 19.080%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 2.236 Acc 18.940%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 2.256 Acc 17.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 2.240 Acc 18.704%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 2.236 Acc 19.103%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 2.236 Acc 19.058%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 2.236 Acc 19.085%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 2.234 Acc 19.407%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 2.235 Acc 19.127%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 2.234 Acc 19.150%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 2.236 Acc 18.958%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 2.246 Acc 17.188%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 2.234 Acc 19.052%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 2.234 Acc 19.069%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 2.235 Acc 19.048%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 2.267 Acc 14.062%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 2.241 Acc 18.533%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 2.240 Acc 18.738%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 2.238 Acc 18.863%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 2.211 Acc 23.438%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 2.233 Acc 19.021%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 2.238 Acc 18.746%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 2.238 Acc 18.867%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 2.237 Acc 14.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 2.236 Acc 19.019%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 2.234 Acc 16.406%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 2.238 Acc 18.456%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 2.238 Acc 18.618%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 2.238 Acc 18.628%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 2.238 Acc 18.754%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 2.238 Acc 18.862%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 2.246 Acc 15.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 2.239 Acc 18.715%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 2.239 Acc 18.859%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 2.194 Acc 21.875%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 2.238 Acc 18.619%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 2.236 Acc 19.018%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 2.236 Acc 18.991%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 2.278 Acc 14.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 2.240 Acc 18.889%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 2.238 Acc 19.045%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 2.238 Acc 18.949%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 2.238 Acc 18.959%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 2.244 Acc 17.969%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 2.240 Acc 18.572%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 2.238 Acc 18.937%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 2.236 Acc 19.330%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 2.236 Acc 19.174%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2.275 Acc 15.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 2.234 Acc 18.881%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 2.238 Acc 18.781%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2.258 Acc 14.844%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 2.240 Acc 18.937%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 2.238 Acc 18.960%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 2.237 Acc 18.883%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 2.294 Acc 14.062%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2.241 Acc 18.858%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 2.239 Acc 18.902%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 2.239 Acc 18.810%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 2.239 Acc 18.816%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 2.210 Acc 21.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 2.237 Acc 18.805%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 2.237 Acc 18.838%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 2.276 Acc 13.281%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 2.240 Acc 18.982%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 2.239 Acc 18.740%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 2.237 Acc 18.995%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 2.236 Acc 17.188%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 2.236 Acc 19.137%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 2.236 Acc 18.855%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 2.237 Acc 18.854%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 2.237 Acc 18.855%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 2.238 Acc 18.879%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 2.184 Acc 23.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 2.233 Acc 19.245%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 2.236 Acc 19.022%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 2.236 Acc 18.908%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 2.242 Acc 17.188%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 2.235 Acc 18.881%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 2.234 Acc 19.007%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 2.235 Acc 18.999%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 2.236 Acc 19.032%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.212 Acc 19.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 2.230 Acc 19.423%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 2.234 Acc 19.216%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 2.236 Acc 19.001%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 2.238 Acc 18.879%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.264 Acc 17.969%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 2.237 Acc 18.878%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.230 Acc 21.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 2.237 Acc 19.076%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 2.239 Acc 17.188%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 2.235 Acc 19.346%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 2.239 Acc 18.785%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 2.235 Acc 19.157%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 2.236 Acc 19.057%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.257 Acc 17.188%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 2.244 Acc 18.255%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 2.241 Acc 18.567%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 2.240 Acc 18.644%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 2.238 Acc 18.918%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 2.238 Acc 18.943%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.260 Acc 14.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 2.236 Acc 19.129%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 2.237 Acc 19.135%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 2.237 Acc 19.103%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 2.213 Acc 24.219%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 2.232 Acc 19.369%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 2.236 Acc 19.116%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 2.238 Acc 18.941%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 2.225 Acc 23.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 2.232 Acc 19.570%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 2.235 Acc 19.263%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 2.238 Acc 19.007%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 2.237 Acc 19.068%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 2.241 Acc 18.970%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 2.187 Acc 18.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 2.238 Acc 19.160%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 2.239 Acc 19.003%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 2.238 Acc 18.825%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 2.227 Acc 22.656%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 2.256 Acc 16.406%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 2.243 Acc 18.611%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 2.241 Acc 18.785%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 2.239 Acc 18.984%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 2.237 Acc 19.056%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 2.251 Acc 15.625%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 2.238 Acc 18.742%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 2.235 Acc 19.088%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 2.238 Acc 18.889%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 2.265 Acc 17.188%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 2.236 Acc 18.898%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 2.238 Acc 18.784%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 2.238 Acc 18.873%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 2.234 Acc 17.188%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 2.237 Acc 19.013%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 2.235 Acc 19.185%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 2.236 Acc 19.046%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 2.214 Acc 17.188%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 2.236 Acc 18.996%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2.238 Acc 14.844%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 2.235 Acc 19.067%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 2.233 Acc 19.170%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 2.235 Acc 19.087%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 2.236 Acc 19.021%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 2.206 Acc 19.531%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 2.237 Acc 18.595%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 2.237 Acc 18.676%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2.237 Acc 18.810%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 2.274 Acc 14.844%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2.237 Acc 19.014%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 2.236 Acc 19.186%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2.235 Acc 19.157%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 2.235 Acc 19.191%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 2.236 Acc 19.045%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 2.237 Acc 19.080%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 2.236 Acc 19.132%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.257 Acc 10.938%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 2.237 Acc 19.129%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 2.235 Acc 19.115%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 2.234 Acc 19.212%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.253 Acc 15.625%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 2.241 Acc 18.727%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 2.237 Acc 19.043%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 2.236 Acc 19.058%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 2.306 Acc 14.844%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 2.240 Acc 18.765%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 2.240 Acc 18.657%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 2.239 Acc 18.667%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 2.238 Acc 18.690%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 2.237 Acc 18.872%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.214 Acc 20.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 2.241 Acc 18.394%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 2.239 Acc 18.715%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 2.240 Acc 18.755%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 2.238 Acc 18.842%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 2.238 Acc 18.945%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.227 Acc 17.188%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 2.240 Acc 18.502%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 2.237 Acc 19.162%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2.227 Acc 16.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 2.237 Acc 19.299%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 2.238 Acc 18.766%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 2.238 Acc 18.857%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 2.238 Acc 18.942%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.191 Acc 25.000%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 2.232 Acc 19.508%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 2.236 Acc 19.076%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 2.236 Acc 19.038%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 2.236 Acc 18.995%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.278 Acc 16.406%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 2.238 Acc 18.776%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 2.238 Acc 18.844%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 2.237 Acc 18.945%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.227 Acc 21.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.333 Acc 6.250%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.239 Acc 18.696%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.236 Acc 18.839%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.238 Acc 18.779%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.229 Acc 21.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.234 Acc 19.191%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.235 Acc 19.038%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.234 Acc 19.017%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.191 Acc 21.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.236 Acc 19.049%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.185 Acc 25.781%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 2.234 Acc 19.407%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 2.233 Acc 19.411%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 2.234 Acc 19.168%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 2.235 Acc 19.130%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.313 Acc 13.281%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.241 Acc 19.307%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.242 Acc 18.874%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.239 Acc 18.797%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.264 Acc 14.844%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.236 Acc 19.392%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.236 Acc 19.178%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.237 Acc 19.087%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.313 Acc 13.281%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.240 Acc 18.665%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.238 Acc 19.003%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.239 Acc 18.810%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.279 Acc 17.188%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.235 Acc 19.524%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.239 Acc 18.856%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.255 Acc 17.188%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.241 Acc 18.464%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.239 Acc 18.653%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.238 Acc 18.886%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.235 Acc 18.920%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.238 Acc 18.849%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.236 Acc 18.959%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.206 Acc 20.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.234 Acc 19.384%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.237 Acc 19.073%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.238 Acc 18.934%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 2.237 Acc 18.799%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.264 Acc 16.406%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.238 Acc 18.765%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.235 Acc 19.049%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.238 Acc 18.865%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.236 Acc 17.969%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.235 Acc 19.384%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.236 Acc 19.088%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.238 Acc 18.862%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.239 Acc 18.857%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.238 Acc 18.925%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.263 Acc 14.062%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.238 Acc 18.456%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.237 Acc 18.633%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.237 Acc 18.680%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.185 Acc 25.000%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 2.235 Acc 19.259%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 2.236 Acc 19.046%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.181 Acc 27.344%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.239 Acc 18.754%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.237 Acc 18.880%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.238 Acc 18.847%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.192 Acc 17.188%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.231 Acc 19.322%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.236 Acc 18.916%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.236 Acc 18.980%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.244 Acc 20.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.240 Acc 19.152%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.238 Acc 18.916%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.238 Acc 18.840%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.202 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.190 Acc 25.000%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.236 Acc 18.967%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.236 Acc 19.205%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 19.017%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.271 Acc 17.188%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.234 Acc 19.206%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.238 Acc 18.911%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.237 Acc 18.904%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.270 Acc 15.625%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.233 Acc 19.462%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.234 Acc 19.181%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.236 Acc 18.882%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.236 Acc 18.992%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.204 Acc 21.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.236 Acc 18.936%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.239 Acc 18.664%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.237 Acc 18.901%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.276 Acc 15.625%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.237 Acc 18.510%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.238 Acc 18.637%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.239 Acc 18.786%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.232 Acc 14.844%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.241 Acc 18.549%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.238 Acc 19.018%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.239 Acc 18.911%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.261 Acc 21.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 2.238 Acc 18.541%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 2.236 Acc 18.727%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 2.235 Acc 18.939%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 2.235 Acc 18.939%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.229 Acc 14.844%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.240 Acc 18.974%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.240 Acc 18.913%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.240 Acc 18.841%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.237 Acc 19.175%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.236 Acc 19.119%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 2.236 Acc 19.072%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.244 Acc 15.625%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.238 Acc 19.059%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.239 Acc 18.869%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.239 Acc 18.845%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.201 Acc 21.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.241 Acc 19.044%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.239 Acc 19.076%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.237 Acc 18.989%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.238 Acc 18.927%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.238 Acc 18.915%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.233 Acc 19.299%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.235 Acc 19.092%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.236 Acc 19.080%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.205 Acc 21.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.238 Acc 18.665%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.236 Acc 18.892%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.239 Acc 18.672%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.236 Acc 18.976%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.236 Acc 18.992%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.261 Acc 16.406%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.240 Acc 18.510%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.240 Acc 18.509%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.239 Acc 18.618%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.238 Acc 18.783%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.233 Acc 17.188%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.235 Acc 19.152%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.237 Acc 18.653%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 2.236 Acc 18.750%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 2.237 Acc 18.717%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 2.236 Acc 18.878%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.203 Acc 20.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.235 Acc 19.021%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.234 Acc 19.185%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.235 Acc 19.126%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.236 Acc 19.050%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.208 Acc 18.750%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.239 Acc 18.664%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.238 Acc 18.802%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.228 Acc 18.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.237 Acc 19.052%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 2.235 Acc 19.158%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 2.236 Acc 18.939%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.233 Acc 19.245%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.236 Acc 18.870%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.951%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.231 Acc 20.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.237 Acc 19.106%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.236 Acc 19.128%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.192 Acc 22.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.235 Acc 18.858%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.237 Acc 18.941%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.247 Acc 18.750%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.238 Acc 19.067%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.238 Acc 18.915%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.238 Acc 21.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.236 Acc 19.183%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.240 Acc 18.793%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.212 Acc 23.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.238 Acc 18.611%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.212 Acc 21.094%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.237 Acc 18.897%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.238 Acc 18.806%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.227 Acc 25.000%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.233 Acc 19.222%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.233 Acc 19.213%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.235 Acc 19.183%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.236 Acc 19.050%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.200 Acc 20.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.238 Acc 18.866%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.240 Acc 18.820%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.238 Acc 18.923%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.237 Acc 18.918%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.267 Acc 18.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.239 Acc 18.633%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.238 Acc 18.783%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.257 Acc 21.094%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 2.237 Acc 18.812%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 2.237 Acc 18.864%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.143 Acc 21.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.238 Acc 19.088%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.231 Acc 21.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.241 Acc 18.611%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.238 Acc 18.785%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.236 Acc 18.893%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.237 Acc 18.849%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.236 Acc 18.950%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.215 Acc 17.188%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.233 Acc 19.090%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.219 Acc 21.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.234 Acc 19.267%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.236 Acc 19.285%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.236 Acc 19.147%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.236 Acc 19.048%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.212 Acc 21.875%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.236 Acc 19.095%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 19.009%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.152 Acc 26.562%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.233 Acc 18.912%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.235 Acc 19.135%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.234 Acc 19.007%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.236 Acc 18.847%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.236 Acc 21.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.232 Acc 19.446%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.232 Acc 19.376%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.234 Acc 19.129%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.236 Acc 19.052%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.237 Acc 19.034%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.228 Acc 17.188%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.236 Acc 19.031%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.225 Acc 21.094%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.236 Acc 19.137%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.150%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.236 Acc 19.217%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.237 Acc 19.101%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.228 Acc 21.094%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.236 Acc 19.361%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.238 Acc 18.916%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.262 Acc 14.062%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.242 Acc 18.642%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.237 Acc 18.976%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.237 Acc 18.879%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.261 Acc 17.969%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.238 Acc 19.098%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.236 Acc 19.185%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.237 Acc 18.926%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.238 Acc 18.873%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.280 Acc 15.625%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.239 Acc 18.789%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.238 Acc 19.038%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.237 Acc 18.941%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.254 Acc 19.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.234 Acc 19.083%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.248 Acc 19.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.237 Acc 18.955%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.252 Acc 20.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.240 Acc 18.433%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.238 Acc 18.602%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.165 Acc 25.000%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.235 Acc 19.485%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 18.995%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.238 Acc 19.004%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.236 Acc 19.068%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.227 Acc 18.750%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.241 Acc 18.680%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.238 Acc 19.069%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.238 Acc 19.011%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.238 Acc 18.920%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.241 Acc 25.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.233 Acc 19.670%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.239 Acc 18.817%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.238 Acc 18.849%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.238 Acc 18.864%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.214 Acc 24.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.237 Acc 18.944%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.236 Acc 19.012%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.236 Acc 18.921%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.236 Acc 19.012%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.248 Acc 15.625%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.232 Acc 19.469%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.234 Acc 19.329%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.237 Acc 19.002%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 18.873%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.848%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.228 Acc 21.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.886%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.252 Acc 15.625%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.234 Acc 19.438%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.236 Acc 19.209%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.237 Acc 18.935%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.298 Acc 13.281%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.233 Acc 19.061%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.236 Acc 18.856%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.247 Acc 18.750%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.240 Acc 18.619%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.238 Acc 18.752%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.238 Acc 18.803%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.252 Acc 18.750%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.240 Acc 18.526%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.307 Acc 14.844%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.235 Acc 18.987%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.237 Acc 18.973%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.199 Acc 23.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.238 Acc 18.869%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.238 Acc 18.872%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.256 Acc 14.844%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.236 Acc 18.881%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.236 Acc 18.906%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.236 Acc 18.877%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.268 Acc 17.969%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.236 Acc 19.245%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.234 Acc 19.213%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.236 Acc 19.060%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.236 Acc 19.020%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.248 Acc 18.750%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.241 Acc 18.943%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.238 Acc 18.940%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.237 Acc 18.885%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.237 Acc 18.976%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.251 Acc 16.406%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.243 Acc 18.472%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.240 Acc 18.777%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.240 Acc 18.683%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.236 Acc 18.959%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.201 Acc 23.438%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.235 Acc 19.276%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.239 Acc 18.802%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.237 Acc 18.881%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.236 Acc 18.970%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.194 Acc 22.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.243 Acc 18.588%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.239 Acc 18.937%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.239 Acc 18.911%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.238 Acc 18.949%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.238 Acc 18.895%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.277 Acc 15.625%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.239 Acc 18.881%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.239 Acc 18.645%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.875%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.200 Acc 21.875%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.236 Acc 18.696%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.236 Acc 18.962%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.267 Acc 16.406%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.238 Acc 18.735%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.237 Acc 18.688%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.238 Acc 18.638%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.243 Acc 21.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.237 Acc 18.889%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.236 Acc 19.139%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 19.017%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.246 Acc 18.750%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.242 Acc 18.649%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.238 Acc 18.714%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.236 Acc 18.939%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.235 Acc 19.139%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.236 Acc 19.048%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.237 Acc 19.052%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.210 Acc 23.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.236 Acc 18.932%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.237 Acc 18.882%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.237 Acc 18.926%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.261 Acc 15.625%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.236 Acc 18.827%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.236 Acc 18.933%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.238 Acc 18.740%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.238 Acc 18.845%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.238 Acc 18.873%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.273 Acc 15.625%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.240 Acc 18.789%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.239 Acc 18.849%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.195 Acc 18.750%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.236 Acc 19.299%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.237 Acc 19.146%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.236 Acc 19.024%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.265 Acc 16.406%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.241 Acc 18.564%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.240 Acc 18.972%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.239 Acc 19.033%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.220 Acc 20.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.239 Acc 18.874%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.238 Acc 18.979%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.179 Acc 24.219%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.240 Acc 18.824%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.238 Acc 18.990%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.238 Acc 18.981%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.249 Acc 17.969%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.245 Acc 18.239%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.243 Acc 18.416%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.240 Acc 18.540%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.239 Acc 18.651%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.238 Acc 18.803%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.264 Acc 18.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.237 Acc 18.580%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.236 Acc 18.960%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.189 Acc 21.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.239 Acc 19.152%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.238 Acc 18.926%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.236 Acc 19.073%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.236 Acc 19.038%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.239 Acc 20.312%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.242 Acc 18.680%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.239 Acc 18.882%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.206 Acc 22.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.236 Acc 18.696%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.235 Acc 19.064%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.287 Acc 14.062%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.233 Acc 19.415%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.235 Acc 19.132%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.263 Acc 14.844%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.239 Acc 18.533%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.236 Acc 18.948%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.237 Acc 19.046%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.236 Acc 18.929%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.210 Acc 18.750%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.241 Acc 18.796%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 2.239 Acc 18.863%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.817%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.238 Acc 18.881%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.239 Acc 18.936%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.874%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.161 Acc 22.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.235 Acc 18.936%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.237 Acc 18.816%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.236 Acc 18.937%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.220 Acc 20.312%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.238 Acc 18.990%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.237 Acc 19.065%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.237 Acc 19.009%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.236 Acc 18.957%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.255 Acc 17.188%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.239 Acc 18.665%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.237 Acc 18.901%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.238 Acc 18.830%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.223 Acc 14.844%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.237 Acc 18.673%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.235 Acc 18.981%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.235 Acc 19.013%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.208 Acc 20.312%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.239 Acc 18.773%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.239 Acc 18.792%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.195 Acc 23.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.241 Acc 18.588%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.236 Acc 18.750%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.239 Acc 18.557%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.237 Acc 18.754%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.237 Acc 18.685%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.237 Acc 18.844%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.182 Acc 25.000%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.231 Acc 19.090%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.234 Acc 18.909%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.237 Acc 18.784%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.291 Acc 12.500%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.240 Acc 18.758%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.241 Acc 18.587%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.240 Acc 18.792%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.238 Acc 18.962%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.263 Acc 17.969%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.237 Acc 18.804%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.239 Acc 18.737%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.879%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.238 Acc 18.929%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.213 Acc 17.188%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.237 Acc 19.075%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.238 Acc 18.804%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.236 Acc 18.924%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.293 Acc 11.719%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.234 Acc 19.049%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.234 Acc 19.090%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.235 Acc 19.058%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.247 Acc 17.969%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.232 Acc 19.369%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.236 Acc 19.142%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 19.054%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.202 Acc 22.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.240 Acc 18.557%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.236 Acc 19.042%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 2.238 Acc 18.981%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.236 Acc 18.992%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.188 Acc 20.312%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.238 Acc 18.832%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.237 Acc 18.924%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.237 Acc 18.927%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.236 Acc 18.939%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.207 Acc 21.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.235 Acc 18.912%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.238 Acc 18.707%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.238 Acc 18.649%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.240 Acc 18.490%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.240 Acc 18.594%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.239 Acc 18.682%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.238 Acc 18.738%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.270 Acc 17.969%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.236 Acc 18.965%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.305 Acc 10.938%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.241 Acc 18.758%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.240 Acc 18.847%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.239 Acc 18.822%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.243 Acc 17.969%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.655%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.234 Acc 19.380%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.237 Acc 19.025%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.238 Acc 18.896%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.202 Acc 22.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.234 Acc 19.454%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.236 Acc 19.092%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.237 Acc 19.030%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.237 Acc 19.070%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.184 Acc 23.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.240 Acc 18.139%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.238 Acc 18.839%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.238 Acc 18.836%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.243 Acc 18.750%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.238 Acc 18.893%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.812%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.234 Acc 19.160%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.251 Acc 14.844%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.240 Acc 18.634%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.240 Acc 18.754%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.239 Acc 18.688%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.238 Acc 18.927%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.296 Acc 15.625%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.236 Acc 18.797%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.237 Acc 18.729%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.850%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.243 Acc 17.969%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.234 Acc 19.183%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.235 Acc 19.178%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.264 Acc 17.188%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.235 Acc 19.205%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 19.207%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.235 Acc 19.124%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.236 Acc 19.017%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.189 Acc 19.531%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.241 Acc 18.348%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.238 Acc 18.692%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.238 Acc 18.830%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 2.239 Acc 18.816%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.197 Acc 22.656%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.240 Acc 18.513%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.237 Acc 18.737%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.238 Acc 18.851%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.251 Acc 20.312%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.240 Acc 18.602%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.239 Acc 18.807%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.238 Acc 18.823%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.151 Acc 26.562%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.237 Acc 19.531%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.237 Acc 18.873%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e5de7d6634418e9223fe21922c8340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.309 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.246 Acc 18.843%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.244 Acc 18.874%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.240 Acc 18.916%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.234 Acc 19.065%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.941 Acc 25.000%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.934 Acc 25.681%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.937 Acc 25.342%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.772 Acc 37.500%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.450 Acc 50.487%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.210 Acc 59.624%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.033 Acc 66.022%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.914 Acc 70.122%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.837 Acc 72.873%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.897 Acc 80.469%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.850 Acc 81.946%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.852 Acc 81.810%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.494 Acc 85.938%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.433 Acc 87.044%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.433 Acc 87.088%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.424 Acc 87.370%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.413 Acc 87.568%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.409 Acc 87.725%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.540 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.543 Acc 88.072%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.539 Acc 88.134%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.320 Acc 88.281%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.350 Acc 89.488%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.351 Acc 89.478%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.351 Acc 89.428%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.350 Acc 89.468%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.347 Acc 89.566%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.611 Acc 89.844%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.615 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.611 Acc 89.327%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.210 Acc 93.750%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.320 Acc 90.300%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.324 Acc 90.365%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.322 Acc 90.443%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.320 Acc 90.506%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.318 Acc 90.570%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.316 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.332 Acc 91.553%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.324 Acc 91.764%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.198 Acc 92.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.296 Acc 91.414%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.294 Acc 91.418%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.296 Acc 91.282%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.296 Acc 91.338%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.294 Acc 91.356%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.309 Acc 92.969%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.359 Acc 91.491%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.353 Acc 91.655%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.274 Acc 91.855%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.274 Acc 91.822%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.279 Acc 91.705%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.277 Acc 91.827%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.280 Acc 91.801%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.310 Acc 93.750%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.348 Acc 92.149%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.343 Acc 92.289%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.267 Acc 92.188%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.284 Acc 91.669%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.271 Acc 91.923%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.272 Acc 91.886%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.272 Acc 91.960%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.272 Acc 91.982%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.601 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.552 Acc 90.524%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.551 Acc 90.582%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.337 Acc 89.062%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.243 Acc 92.744%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.259 Acc 92.428%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.256 Acc 92.616%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.258 Acc 92.544%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.260 Acc 92.448%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.368 Acc 91.406%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.342 Acc 93.131%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.336 Acc 93.284%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.270 Acc 92.188%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.247 Acc 92.969%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.238 Acc 93.039%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.245 Acc 92.862%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.250 Acc 92.776%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.252 Acc 92.708%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.291 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.310 Acc 92.984%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.307 Acc 93.089%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.246 Acc 92.984%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.244 Acc 92.840%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.240 Acc 92.901%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.243 Acc 92.877%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.242 Acc 92.920%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.359 Acc 93.750%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.395 Acc 93.549%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.391 Acc 93.661%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.215 Acc 93.518%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.227 Acc 93.350%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.234 Acc 93.210%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.233 Acc 93.218%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.235 Acc 93.242%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.336 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.338 Acc 92.226%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.334 Acc 92.292%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.235 Acc 93.456%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.229 Acc 93.622%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.224 Acc 93.553%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.228 Acc 93.425%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.229 Acc 93.437%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.358 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.381 Acc 92.528%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.376 Acc 92.704%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.395 Acc 89.062%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.223 Acc 93.402%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.220 Acc 93.447%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.227 Acc 93.358%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.228 Acc 93.388%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.228 Acc 93.357%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.355 Acc 93.750%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.373 Acc 92.860%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.367 Acc 93.050%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.236 Acc 93.750%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.203 Acc 94.121%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.215 Acc 93.649%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.217 Acc 93.654%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.215 Acc 93.731%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.217 Acc 93.700%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.486 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.508 Acc 91.538%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.503 Acc 91.682%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.310 Acc 91.406%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.220 Acc 93.533%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.221 Acc 93.653%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.215 Acc 93.823%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.217 Acc 93.781%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.216 Acc 93.830%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.353 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.364 Acc 93.990%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.359 Acc 94.170%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.354 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.203 Acc 94.168%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.203 Acc 94.104%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.209 Acc 94.025%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.209 Acc 94.040%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.209 Acc 94.054%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.348 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.372 Acc 92.938%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.367 Acc 93.046%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.213 Acc 93.750%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.201 Acc 94.106%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.204 Acc 94.007%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.211 Acc 93.867%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.206 Acc 93.958%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.206 Acc 94.040%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.289 Acc 93.796%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.284 Acc 93.560%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.260 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.198 Acc 94.214%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.201 Acc 94.158%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.203 Acc 94.119%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.204 Acc 94.140%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.207 Acc 94.053%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.288 Acc 92.907%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.282 Acc 92.992%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.121 Acc 95.312%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.184 Acc 94.562%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.188 Acc 94.617%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.194 Acc 94.412%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.196 Acc 94.323%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.197 Acc 94.336%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.306 Acc 95.312%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.362 Acc 93.758%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.358 Acc 93.762%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.187 Acc 94.624%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.186 Acc 94.632%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.191 Acc 94.521%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.197 Acc 94.338%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.198 Acc 94.389%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.263 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.300 Acc 93.232%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.294 Acc 93.377%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.427 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.196 Acc 94.392%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.194 Acc 94.407%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.190 Acc 94.562%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.193 Acc 94.436%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.193 Acc 94.427%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.286 Acc 94.531%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.324 Acc 92.752%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.317 Acc 92.938%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.198 Acc 93.750%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.194 Acc 94.315%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.190 Acc 94.450%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.189 Acc 94.485%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.192 Acc 94.418%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.191 Acc 94.433%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.397 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.424 Acc 92.102%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.418 Acc 92.335%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.309 Acc 92.969%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.170 Acc 95.196%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.184 Acc 94.757%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.182 Acc 94.799%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.184 Acc 94.742%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.182 Acc 94.798%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.319 Acc 92.188%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.346 Acc 93.054%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.339 Acc 93.295%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.190 Acc 92.969%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.180 Acc 94.879%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.184 Acc 94.593%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.189 Acc 94.500%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.186 Acc 94.520%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.204 Acc 96.094%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.272 Acc 94.160%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.267 Acc 94.080%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.176 Acc 94.988%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.181 Acc 94.978%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.182 Acc 94.830%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.182 Acc 94.816%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.181 Acc 94.813%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.349 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.395 Acc 93.224%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.390 Acc 93.354%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.165 Acc 95.243%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.173 Acc 95.044%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.176 Acc 94.931%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.177 Acc 94.905%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.180 Acc 94.824%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.293 Acc 94.075%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.288 Acc 94.181%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.172 Acc 95.080%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.169 Acc 95.130%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.173 Acc 94.983%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.173 Acc 94.991%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.174 Acc 94.965%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.298 Acc 93.859%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.170 Acc 94.817%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.166 Acc 95.087%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.171 Acc 94.960%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.169 Acc 95.022%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.172 Acc 94.999%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.312 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.339 Acc 93.085%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.332 Acc 93.295%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.235 Acc 93.750%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.162 Acc 95.243%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.166 Acc 95.130%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.169 Acc 95.084%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.173 Acc 95.020%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.174 Acc 94.955%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.283 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.316 Acc 93.727%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.312 Acc 93.839%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.167 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.169 Acc 95.498%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.166 Acc 95.328%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.166 Acc 95.227%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.165 Acc 95.266%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.165 Acc 95.258%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.416 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.412 Acc 92.327%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.409 Acc 92.265%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.160 Acc 95.266%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.163 Acc 95.239%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.166 Acc 95.167%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.166 Acc 95.147%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.167 Acc 95.133%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.295 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.330 Acc 93.688%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.327 Acc 93.657%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.154 Acc 95.490%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.158 Acc 95.386%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.161 Acc 95.255%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.160 Acc 95.293%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.163 Acc 95.224%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.347 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.351 Acc 93.123%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.348 Acc 92.984%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.165 Acc 95.158%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.158 Acc 95.332%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.162 Acc 95.248%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.213%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.165 Acc 95.220%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.310 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.355 Acc 93.417%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.352 Acc 93.408%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.146 Acc 95.560%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.152 Acc 95.476%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.154 Acc 95.510%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.157 Acc 95.523%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.159 Acc 95.459%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.381 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.446 Acc 91.832%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.442 Acc 91.970%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.160 Acc 95.452%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.159 Acc 95.424%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.159 Acc 95.427%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.159 Acc 95.380%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.283 Acc 95.312%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.300 Acc 94.175%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.298 Acc 94.080%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.151 Acc 95.398%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.157 Acc 95.262%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.157 Acc 95.315%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.158 Acc 95.303%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.158 Acc 95.390%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.508 Acc 90.625%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.529 Acc 91.027%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.525 Acc 91.021%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.199 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.150 Acc 95.722%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.152 Acc 95.600%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.154 Acc 95.531%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.152 Acc 95.566%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.154 Acc 95.578%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.343 Acc 93.185%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.340 Acc 93.159%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.143 Acc 95.854%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.145 Acc 95.713%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.149 Acc 95.636%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.152 Acc 95.542%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.250 Acc 96.094%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.299 Acc 93.348%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.297 Acc 93.326%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.151 Acc 95.746%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.144 Acc 95.837%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.147 Acc 95.663%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.151 Acc 95.579%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.151 Acc 95.560%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.378 Acc 91.406%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.401 Acc 92.257%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.394 Acc 92.479%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.136 Acc 95.955%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.142 Acc 95.872%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.144 Acc 95.790%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.149 Acc 95.581%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.150 Acc 95.554%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.277 Acc 94.299%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.274 Acc 94.368%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.134 Acc 96.264%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.143 Acc 96.004%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.144 Acc 95.912%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.147 Acc 95.809%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.147 Acc 95.787%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.247 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.268 Acc 93.959%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.262 Acc 94.022%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.143 Acc 95.506%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.144 Acc 95.612%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.143 Acc 95.676%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.142 Acc 95.743%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.147 Acc 95.648%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.278 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.292 Acc 93.688%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.287 Acc 93.828%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.139 Acc 95.792%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.138 Acc 95.763%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.137 Acc 95.824%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.142 Acc 95.794%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.280 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.295 Acc 93.735%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.293 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.118 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.141 Acc 95.862%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.137 Acc 95.973%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.143 Acc 95.816%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.141 Acc 95.868%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.143 Acc 95.780%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.332 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.360 Acc 93.386%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.356 Acc 93.412%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.181 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.132 Acc 95.908%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.138 Acc 95.822%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.142 Acc 95.793%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.141 Acc 95.837%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.142 Acc 95.821%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.523 Acc 90.625%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.520 Acc 90.555%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.517 Acc 90.683%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.144 Acc 95.730%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.142 Acc 95.810%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.140 Acc 95.847%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.141 Acc 95.864%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.142 Acc 95.854%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.362 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.377 Acc 92.683%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.372 Acc 92.736%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.136 Acc 95.877%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.137 Acc 95.923%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.138 Acc 95.930%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.138 Acc 95.938%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.138 Acc 95.924%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.489 Acc 91.406%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.488 Acc 91.584%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.482 Acc 91.772%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.130 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.142 Acc 95.676%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.139 Acc 95.783%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.138 Acc 95.790%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.135 Acc 95.879%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.136 Acc 95.880%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.303 Acc 93.510%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.302 Acc 93.490%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.133 Acc 95.973%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.137 Acc 95.912%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.138 Acc 95.895%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.137 Acc 95.879%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.299 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.315 Acc 93.642%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.313 Acc 93.618%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.128 Acc 95.931%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.130 Acc 95.985%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.136 Acc 95.839%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.136 Acc 95.852%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.138 Acc 95.804%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.281 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.322 Acc 93.325%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.315 Acc 93.490%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.129 Acc 96.117%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.129 Acc 96.125%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.137 Acc 95.955%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.136 Acc 95.946%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.375 Acc 92.188%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.358 Acc 93.209%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.354 Acc 93.315%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.144 Acc 92.969%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.134 Acc 95.862%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.129 Acc 96.059%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.132 Acc 95.933%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.131 Acc 95.989%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.132 Acc 95.996%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.324 Acc 93.139%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.318 Acc 93.140%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.120 Acc 96.380%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.125 Acc 96.245%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.125 Acc 96.229%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.128 Acc 96.176%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.129 Acc 96.097%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.323 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.335 Acc 93.642%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.331 Acc 93.703%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.252 Acc 96.094%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.137 Acc 96.063%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.135 Acc 96.024%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.134 Acc 96.065%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.132 Acc 96.041%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.134 Acc 96.053%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.285 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.311 Acc 93.193%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.307 Acc 93.319%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.209 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.114 Acc 96.364%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.123 Acc 96.175%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.123 Acc 96.187%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.123 Acc 96.242%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.123 Acc 96.253%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.403 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.374 Acc 93.023%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.366 Acc 93.175%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.126 Acc 96.117%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.128 Acc 96.078%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.128 Acc 96.115%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.130 Acc 96.151%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.320 Acc 90.625%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.313 Acc 93.270%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.309 Acc 93.330%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.125 Acc 96.256%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.122 Acc 96.319%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.122 Acc 96.275%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.125 Acc 96.193%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.127 Acc 96.142%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.321 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.361 Acc 92.737%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.355 Acc 92.879%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.115 Acc 96.426%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.123 Acc 96.288%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.121 Acc 96.314%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.123 Acc 96.298%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.124 Acc 96.286%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.282 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.286 Acc 93.773%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.282 Acc 93.839%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.122 Acc 96.238%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.122 Acc 96.249%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.123 Acc 96.271%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.124 Acc 96.270%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.343 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.356 Acc 93.077%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.350 Acc 93.186%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.256 Acc 92.188%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.109 Acc 96.689%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.116 Acc 96.436%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.117 Acc 96.356%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.120 Acc 96.304%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.123 Acc 96.226%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.352 Acc 92.969%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.337 Acc 93.247%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.331 Acc 93.357%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.116 Acc 96.558%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.117 Acc 96.545%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.120 Acc 96.351%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.122 Acc 96.341%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.123 Acc 96.300%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.286 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.318 Acc 92.752%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.311 Acc 93.008%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.118 Acc 96.426%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.119 Acc 96.374%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.119 Acc 96.372%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.119 Acc 96.359%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.513 Acc 91.406%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.542 Acc 89.735%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.539 Acc 89.941%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.136 Acc 97.656%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.115 Acc 96.511%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.116 Acc 96.424%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.118 Acc 96.447%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.120 Acc 96.390%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.406 Acc 92.969%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.418 Acc 91.429%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.412 Acc 91.682%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.117 Acc 96.388%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.111 Acc 96.498%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.119 Acc 96.377%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.118 Acc 96.404%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.118 Acc 96.393%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.340 Acc 92.969%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.380 Acc 92.342%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.374 Acc 92.440%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.112 Acc 96.566%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.116 Acc 96.529%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.114 Acc 96.496%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.116 Acc 96.448%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.119 Acc 96.396%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.413 Acc 91.406%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.403 Acc 91.747%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.397 Acc 91.764%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.104 Acc 96.759%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.108 Acc 96.587%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.116 Acc 96.397%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.117 Acc 96.361%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.118 Acc 96.321%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.271 Acc 92.969%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.318 Acc 92.613%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.313 Acc 92.747%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.121 Acc 96.395%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.117 Acc 96.432%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.122 Acc 96.252%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.122 Acc 96.281%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.120 Acc 96.281%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.308 Acc 91.406%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.320 Acc 92.876%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.314 Acc 93.081%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.141 Acc 93.750%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.119 Acc 96.349%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.121 Acc 96.362%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.121 Acc 96.397%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.120 Acc 96.409%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.120 Acc 96.384%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.353 Acc 92.188%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.366 Acc 92.265%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.357 Acc 92.545%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.111 Acc 96.701%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.112 Acc 96.610%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.113 Acc 96.538%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.321 Acc 92.188%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.326 Acc 92.976%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.322 Acc 93.132%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.100 Acc 96.945%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.111 Acc 96.605%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.110 Acc 96.604%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.111 Acc 96.625%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.286 Acc 93.023%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.279 Acc 93.334%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.066 Acc 96.875%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.097 Acc 96.999%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.105 Acc 96.755%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.108 Acc 96.608%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.108 Acc 96.602%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.110 Acc 96.587%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.385 Acc 92.188%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.410 Acc 91.136%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.404 Acc 91.181%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.109 Acc 96.558%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.107 Acc 96.642%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.108 Acc 96.602%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.109 Acc 96.614%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.110 Acc 96.571%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.456 Acc 89.062%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.415 Acc 92.033%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.409 Acc 91.993%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.105 Acc 96.728%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.106 Acc 96.751%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.108 Acc 96.676%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.109 Acc 96.646%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.415 Acc 90.625%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.456 Acc 90.749%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.450 Acc 90.897%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.107 Acc 96.635%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.112 Acc 96.556%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.112 Acc 96.582%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.111 Acc 96.593%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.112 Acc 96.537%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.398 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.377 Acc 92.520%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.370 Acc 92.549%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.103 Acc 96.450%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.105 Acc 96.611%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.107 Acc 96.613%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.109 Acc 96.554%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.110 Acc 96.551%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.394 Acc 89.062%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.391 Acc 92.249%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.386 Acc 92.421%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.092 Acc 96.960%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.100 Acc 96.817%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.100 Acc 96.808%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.104 Acc 96.725%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.106 Acc 96.643%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.302 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.316 Acc 92.690%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.310 Acc 92.926%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.105 Acc 96.767%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.106 Acc 96.743%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.109 Acc 96.662%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.109 Acc 96.647%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.109 Acc 96.574%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.322 Acc 92.489%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.317 Acc 92.506%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.100 Acc 96.821%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.104 Acc 96.599%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.110 Acc 96.429%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.110 Acc 96.483%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.110 Acc 96.513%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.433 Acc 91.406%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.373 Acc 92.543%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.366 Acc 92.864%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.106 Acc 96.767%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.105 Acc 96.700%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.105 Acc 96.711%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.105 Acc 96.700%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.107 Acc 96.644%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.415 Acc 91.406%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.407 Acc 91.863%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.402 Acc 92.044%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.098 Acc 96.774%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.102 Acc 96.774%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.102 Acc 96.792%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.103 Acc 96.793%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.105 Acc 96.738%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.387 Acc 89.844%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.356 Acc 91.917%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.348 Acc 92.094%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.107 Acc 96.589%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.104 Acc 96.696%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.109 Acc 96.592%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.107 Acc 96.649%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.107 Acc 96.664%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.419 Acc 90.625%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.333 Acc 92.946%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.329 Acc 93.054%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.094 Acc 97.146%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.095 Acc 97.057%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.098 Acc 96.974%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.100 Acc 96.911%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.271 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.305 Acc 93.131%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.299 Acc 93.171%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.100 Acc 96.929%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.105 Acc 96.820%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.105 Acc 96.809%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.104 Acc 96.805%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.384 Acc 92.188%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.367 Acc 92.667%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.361 Acc 92.774%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.110 Acc 96.465%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.104 Acc 96.688%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.103 Acc 96.717%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.103 Acc 96.715%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.103 Acc 96.750%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.387 Acc 91.406%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.374 Acc 91.375%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.369 Acc 91.531%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.097 Acc 97.045%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.097 Acc 97.023%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.099 Acc 97.026%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.101 Acc 96.895%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.417 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.387 Acc 91.646%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.382 Acc 91.857%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.097 Acc 96.968%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.095 Acc 97.108%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.098 Acc 96.992%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.099 Acc 96.972%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.100 Acc 96.937%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.329 Acc 92.969%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.358 Acc 92.311%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.353 Acc 92.541%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.100 Acc 96.805%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.102 Acc 96.739%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.104 Acc 96.701%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.105 Acc 96.694%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.105 Acc 96.688%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.515 Acc 89.062%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.452 Acc 90.726%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.448 Acc 90.745%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.097 Acc 96.929%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.099 Acc 96.854%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.098 Acc 96.895%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.379 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.332 Acc 92.288%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.327 Acc 92.463%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.094 Acc 96.929%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.099 Acc 96.805%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.098 Acc 96.898%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.098 Acc 96.893%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.100 Acc 96.799%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.385 Acc 92.188%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.374 Acc 91.940%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.371 Acc 91.939%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.101 Acc 96.860%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.099 Acc 96.918%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.098 Acc 96.927%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.100 Acc 96.869%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.099 Acc 96.897%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.382 Acc 90.625%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.358 Acc 91.847%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.355 Acc 91.760%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.090 Acc 97.084%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.091 Acc 97.077%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.095 Acc 97.023%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.097 Acc 96.912%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.097 Acc 96.902%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.318 Acc 91.406%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.315 Acc 92.791%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.311 Acc 92.891%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.090 Acc 97.006%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.091 Acc 97.054%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.098 Acc 96.880%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.102 Acc 96.746%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.101 Acc 96.767%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.290 Acc 91.406%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.308 Acc 93.069%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.303 Acc 93.144%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.090 Acc 97.092%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.096 Acc 96.957%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.097 Acc 96.880%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.099 Acc 96.865%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.101 Acc 96.805%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.376 Acc 92.188%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.364 Acc 92.574%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.363 Acc 92.452%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.085 Acc 97.200%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.090 Acc 97.151%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.089 Acc 97.148%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.094 Acc 97.062%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.326 Acc 92.296%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.321 Acc 92.397%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.092 Acc 96.999%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.092 Acc 97.019%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.093 Acc 96.989%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.095 Acc 96.961%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.097 Acc 96.922%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.491 Acc 92.188%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.499 Acc 90.602%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.495 Acc 90.726%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.114 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.094 Acc 97.061%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.097 Acc 97.003%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.098 Acc 96.968%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.098 Acc 96.943%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.098 Acc 96.955%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.378 Acc 91.406%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.375 Acc 91.824%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.370 Acc 92.048%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.086 Acc 97.254%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.087 Acc 97.209%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.086 Acc 97.218%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.089 Acc 97.152%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.091 Acc 97.092%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.327 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.322 Acc 92.613%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.316 Acc 92.825%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.110 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.082 Acc 97.300%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.091 Acc 97.054%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.091 Acc 97.062%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.094 Acc 96.986%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.094 Acc 96.978%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.321 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.315 Acc 92.837%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.310 Acc 93.062%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.088 Acc 96.983%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.090 Acc 97.073%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.092 Acc 97.018%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.093 Acc 96.998%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.094 Acc 96.959%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.581 Acc 87.500%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.526 Acc 89.101%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.521 Acc 89.303%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.099 Acc 96.813%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.095 Acc 96.972%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.096 Acc 96.950%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.368 Acc 92.188%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.352 Acc 91.878%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.346 Acc 92.051%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.082 Acc 97.362%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.083 Acc 97.264%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.089 Acc 97.155%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.090 Acc 97.134%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.381 Acc 90.625%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.383 Acc 91.298%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.377 Acc 91.461%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.091 Acc 97.155%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.093 Acc 97.127%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.093 Acc 97.078%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.093 Acc 97.057%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.339 Acc 92.188%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.356 Acc 92.288%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.352 Acc 92.425%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.088 Acc 97.178%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.090 Acc 97.116%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.090 Acc 97.120%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.090 Acc 97.103%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.437 Acc 89.844%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.473 Acc 88.885%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.465 Acc 89.082%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.087 Acc 97.233%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.088 Acc 97.199%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.087 Acc 97.165%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.089 Acc 97.096%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.411 Acc 92.188%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.387 Acc 91.530%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.384 Acc 91.569%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.087 Acc 97.213%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.091 Acc 97.111%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.091 Acc 97.107%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.092 Acc 97.076%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.383 Acc 90.903%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.379 Acc 91.134%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.087 Acc 97.192%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.083 Acc 97.244%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.088 Acc 97.127%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.088 Acc 97.161%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.088 Acc 97.139%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.323 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.323 Acc 92.644%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.320 Acc 92.743%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.134 Acc 94.531%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.078 Acc 97.362%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.081 Acc 97.295%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.086 Acc 97.119%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.086 Acc 97.132%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.088 Acc 97.081%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.391 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.397 Acc 90.664%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.390 Acc 90.691%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.084 Acc 97.262%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.084 Acc 97.265%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.086 Acc 97.209%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.317 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.332 Acc 92.845%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.328 Acc 92.903%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.086 Acc 97.138%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.084 Acc 97.271%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.088 Acc 97.171%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.089 Acc 97.128%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.090 Acc 97.118%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.507 Acc 89.062%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.524 Acc 88.730%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.521 Acc 88.950%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.086 Acc 97.068%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.088 Acc 97.170%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.089 Acc 97.098%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.089 Acc 97.074%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.091 Acc 97.020%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.349 Acc 92.969%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.370 Acc 91.600%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.365 Acc 91.869%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.086 Acc 97.285%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.086 Acc 97.283%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.089 Acc 97.202%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.088 Acc 97.228%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.088 Acc 97.213%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.382 Acc 90.625%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.357 Acc 91.855%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.351 Acc 91.958%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.094 Acc 96.960%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.086 Acc 97.174%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.085 Acc 97.155%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.085 Acc 97.173%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.086 Acc 97.140%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.361 Acc 91.406%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.320 Acc 92.551%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.318 Acc 92.724%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.086 Acc 97.306%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.085 Acc 97.316%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.087 Acc 97.255%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.086 Acc 97.299%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.387 Acc 92.188%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.381 Acc 91.832%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.376 Acc 91.896%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.077 Acc 97.401%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.080 Acc 97.404%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.083 Acc 97.334%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.086 Acc 97.224%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.088 Acc 97.148%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.330 Acc 90.625%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.362 Acc 91.979%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.351 Acc 92.230%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.081 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.084 Acc 97.231%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.085 Acc 97.236%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.085 Acc 97.225%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.085 Acc 97.243%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.088 Acc 97.196%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.461 Acc 90.625%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.523 Acc 87.353%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.520 Acc 87.247%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.082 Acc 97.316%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.085 Acc 97.236%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.085 Acc 97.207%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.088 Acc 97.120%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.088 Acc 97.095%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.354 Acc 91.406%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.360 Acc 92.079%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.356 Acc 91.954%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.077 Acc 97.517%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.081 Acc 97.392%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.079 Acc 97.423%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.079 Acc 97.440%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.083 Acc 97.344%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.266 Acc 92.188%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.286 Acc 93.549%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.284 Acc 93.416%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.079 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.079 Acc 97.432%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.083 Acc 97.295%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.084 Acc 97.280%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.083 Acc 97.309%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.084 Acc 97.284%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.441 Acc 87.500%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.418 Acc 90.300%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.411 Acc 90.559%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.076 Acc 97.432%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.080 Acc 97.419%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.084 Acc 97.306%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.086 Acc 97.245%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.086 Acc 97.251%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.346 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.396 Acc 90.733%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.391 Acc 90.913%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.077 Acc 97.396%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.080 Acc 97.355%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.084 Acc 97.261%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.085 Acc 97.266%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.477 Acc 90.625%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.412 Acc 90.277%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.411 Acc 90.454%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.082 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.083 Acc 97.308%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.085 Acc 97.244%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.086 Acc 97.210%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.087 Acc 97.191%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.086 Acc 97.190%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.290 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.303 Acc 92.992%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.301 Acc 92.961%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.080 Acc 97.509%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.080 Acc 97.470%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.078 Acc 97.480%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.079 Acc 97.450%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.081 Acc 97.427%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.388 Acc 89.844%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.358 Acc 92.110%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.353 Acc 92.020%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.070 Acc 97.757%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.077 Acc 97.520%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.081 Acc 97.374%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.082 Acc 97.358%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.360 Acc 91.406%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.366 Acc 91.399%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.361 Acc 91.709%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.085 Acc 97.208%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.080 Acc 97.369%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.083 Acc 97.343%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.083 Acc 97.321%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.409 Acc 92.969%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.376 Acc 90.811%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.368 Acc 91.099%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.079 Acc 97.308%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.077 Acc 97.349%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.082 Acc 97.295%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.083 Acc 97.300%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.084 Acc 97.255%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.417 Acc 91.406%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.364 Acc 92.025%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.360 Acc 92.067%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.081 Acc 97.416%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.079 Acc 97.458%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.080 Acc 97.443%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.084 Acc 97.313%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.084 Acc 97.340%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.311 Acc 90.625%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.329 Acc 91.855%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.326 Acc 91.985%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.081 Acc 97.369%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.083 Acc 97.257%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.085 Acc 97.257%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.084 Acc 97.293%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.417 Acc 92.188%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.395 Acc 91.236%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.391 Acc 91.367%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.079 Acc 97.462%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.078 Acc 97.532%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.080 Acc 97.430%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.081 Acc 97.380%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.356 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.378 Acc 91.692%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.372 Acc 91.869%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.078 Acc 97.316%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.077 Acc 97.427%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.077 Acc 97.438%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.078 Acc 97.399%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.079 Acc 97.358%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.389 Acc 92.188%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.430 Acc 89.496%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.424 Acc 89.871%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.067 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.072 Acc 97.741%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.076 Acc 97.571%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.082 Acc 97.368%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.082 Acc 97.399%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.082 Acc 97.366%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.391 Acc 90.625%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.366 Acc 91.894%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.363 Acc 91.970%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.077 Acc 97.486%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.079 Acc 97.462%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.081 Acc 97.433%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.082 Acc 97.407%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.085 Acc 97.319%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.385 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.389 Acc 91.553%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.385 Acc 91.725%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.077 Acc 97.516%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.076 Acc 97.522%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.078 Acc 97.457%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.285 Acc 93.750%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.311 Acc 92.907%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.307 Acc 93.070%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.075 Acc 97.548%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.078 Acc 97.442%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.080 Acc 97.402%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.080 Acc 97.395%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.081 Acc 97.371%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.379 Acc 91.406%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.389 Acc 91.515%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.384 Acc 91.632%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.080 Acc 96.094%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.074 Acc 97.447%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.077 Acc 97.388%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.077 Acc 97.410%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.079 Acc 97.372%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.079 Acc 97.424%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.298 Acc 92.188%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.320 Acc 92.064%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.313 Acc 92.238%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.078 Acc 97.370%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.080 Acc 97.306%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.082 Acc 97.363%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.081 Acc 97.377%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.572 Acc 85.156%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.530 Acc 88.498%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.523 Acc 88.526%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.078 Acc 97.331%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.079 Acc 97.380%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.078 Acc 97.449%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.079 Acc 97.421%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.079 Acc 97.427%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.365 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.368 Acc 91.778%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.365 Acc 91.803%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.076 Acc 97.509%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.075 Acc 97.450%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.078 Acc 97.373%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.076 Acc 97.421%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.078 Acc 97.402%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.467 Acc 89.062%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.447 Acc 90.331%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.445 Acc 90.590%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.076 Acc 97.618%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.079 Acc 97.498%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.079 Acc 97.483%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.079 Acc 97.461%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.328 Acc 92.450%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.326 Acc 92.456%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.075 Acc 97.587%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.080 Acc 97.361%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.078 Acc 97.358%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.081 Acc 97.345%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.080 Acc 97.355%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.354 Acc 90.625%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.415 Acc 89.813%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.410 Acc 89.960%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.077 Acc 97.567%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.079 Acc 97.485%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.078 Acc 97.504%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.078 Acc 97.458%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.385 Acc 91.406%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.422 Acc 90.478%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.420 Acc 90.516%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.078 Acc 97.393%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.078 Acc 97.458%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.079 Acc 97.428%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.080 Acc 97.383%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.398 Acc 89.844%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.405 Acc 90.617%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.400 Acc 90.691%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.077 Acc 97.497%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.078 Acc 97.454%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.077 Acc 97.461%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.077 Acc 97.460%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.290 Acc 92.188%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.317 Acc 92.427%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.314 Acc 92.428%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.078 Acc 97.454%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.077 Acc 97.449%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.080 Acc 97.415%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.081 Acc 97.358%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.392 Acc 89.844%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.400 Acc 91.043%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.398 Acc 91.192%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.077 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.066 Acc 97.780%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.071 Acc 97.672%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.072 Acc 97.613%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.075 Acc 97.544%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.342 Acc 92.528%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.338 Acc 92.440%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.068 Acc 97.687%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.074 Acc 97.512%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.072 Acc 97.555%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.072 Acc 97.588%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.073 Acc 97.594%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.380 Acc 90.625%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.354 Acc 92.141%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.348 Acc 92.281%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.079 Acc 97.455%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.075 Acc 97.645%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.074 Acc 97.638%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.075 Acc 97.600%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.077 Acc 97.561%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.362 Acc 91.406%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.367 Acc 91.128%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.361 Acc 91.367%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.084 Acc 97.246%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.081 Acc 97.427%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.080 Acc 97.506%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.078 Acc 97.520%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.078 Acc 97.505%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.306 Acc 92.930%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.301 Acc 92.926%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.079 Acc 97.494%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.076 Acc 97.551%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.075 Acc 97.588%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.075 Acc 97.535%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.329 Acc 92.188%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.327 Acc 92.574%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.325 Acc 92.607%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.075 Acc 97.610%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.075 Acc 97.563%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.078 Acc 97.506%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.079 Acc 97.463%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.330 Acc 93.750%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.340 Acc 92.489%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.336 Acc 92.460%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.076 Acc 97.525%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.074 Acc 97.586%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.077 Acc 97.529%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.079 Acc 97.438%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.078 Acc 97.472%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.344 Acc 90.625%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.323 Acc 92.458%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.319 Acc 92.428%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.028 Acc 97.656%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.073 Acc 97.749%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.073 Acc 97.612%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.075 Acc 97.532%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.075 Acc 97.503%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.300 Acc 92.969%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.297 Acc 92.512%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.289 Acc 92.693%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.069 Acc 97.888%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.072 Acc 97.785%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.073 Acc 97.698%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.074 Acc 97.666%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.362 Acc 89.844%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.309 Acc 92.528%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.306 Acc 92.491%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.074 Acc 97.563%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.073 Acc 97.664%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.076 Acc 97.547%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.075 Acc 97.570%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.343 Acc 90.625%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.379 Acc 91.004%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.373 Acc 91.181%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.070 Acc 97.633%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.070 Acc 97.695%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.071 Acc 97.668%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.072 Acc 97.661%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.380 Acc 89.844%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.389 Acc 90.911%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.382 Acc 91.025%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.080 Acc 97.347%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.083 Acc 97.271%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.079 Acc 97.415%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.078 Acc 97.426%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.077 Acc 97.446%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.420 Acc 91.406%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.416 Acc 90.950%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.413 Acc 90.874%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.063 Acc 97.989%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.062 Acc 97.944%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.067 Acc 97.835%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.070 Acc 97.736%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.438 Acc 90.625%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.402 Acc 90.563%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.397 Acc 90.676%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.072 Acc 97.679%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.075 Acc 97.582%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.073 Acc 97.620%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.073 Acc 97.639%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.073 Acc 97.631%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.341 Acc 92.969%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.314 Acc 92.868%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.312 Acc 92.755%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.072 Acc 97.587%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.067 Acc 97.691%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.070 Acc 97.612%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.071 Acc 97.586%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.072 Acc 97.603%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.494 Acc 89.062%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.479 Acc 88.181%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.476 Acc 88.305%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.069 Acc 97.788%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.075 Acc 97.516%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.077 Acc 97.450%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.076 Acc 97.471%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.297 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.299 Acc 92.412%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.298 Acc 92.514%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.076 Acc 97.409%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.074 Acc 97.547%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.075 Acc 97.552%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.076 Acc 97.535%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.076 Acc 97.513%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.358 Acc 92.969%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.358 Acc 91.453%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.356 Acc 91.558%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.070 Acc 97.772%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.070 Acc 97.668%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.072 Acc 97.597%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.073 Acc 97.555%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.073 Acc 97.567%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.370 Acc 89.062%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.398 Acc 90.517%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.395 Acc 90.555%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.074 Acc 97.455%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.070 Acc 97.660%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.074 Acc 97.547%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.076 Acc 97.489%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.075 Acc 97.483%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.477 Acc 89.062%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.478 Acc 88.722%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.469 Acc 88.981%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.059 Acc 97.888%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.065 Acc 97.905%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.065 Acc 97.903%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.069 Acc 97.703%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.071 Acc 97.673%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.433 Acc 88.281%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.410 Acc 90.439%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.404 Acc 90.470%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.069 Acc 97.755%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.070 Acc 97.738%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.070 Acc 97.728%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.335 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.343 Acc 91.855%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.338 Acc 91.935%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.057 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.070 Acc 97.556%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.068 Acc 97.648%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.070 Acc 97.643%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.071 Acc 97.606%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.072 Acc 97.597%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.424 Acc 91.406%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.427 Acc 90.316%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.422 Acc 90.435%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.065 Acc 97.834%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.066 Acc 97.800%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.068 Acc 97.690%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.071 Acc 97.584%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.072 Acc 97.580%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.345 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.403 Acc 90.710%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.400 Acc 90.777%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.070 Acc 97.757%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.067 Acc 97.718%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.069 Acc 97.633%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.069 Acc 97.647%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.069 Acc 97.661%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.249 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.291 Acc 92.984%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.288 Acc 93.050%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.064 Acc 97.757%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.066 Acc 97.742%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.069 Acc 97.625%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.071 Acc 97.563%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.073 Acc 97.539%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.355 Acc 90.625%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.368 Acc 91.174%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.365 Acc 91.492%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.079 Acc 97.355%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.073 Acc 97.565%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.073 Acc 97.578%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.073 Acc 97.600%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.386 Acc 91.406%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.359 Acc 91.917%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.353 Acc 91.915%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.069 Acc 97.834%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.073 Acc 97.641%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.072 Acc 97.646%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.069 Acc 97.730%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.070 Acc 97.658%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.518 Acc 87.500%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.492 Acc 89.279%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.491 Acc 89.144%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.072 Acc 97.660%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.073 Acc 97.633%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.073 Acc 97.596%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.073 Acc 97.645%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.373 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.320 Acc 92.721%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.314 Acc 92.786%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.070 Acc 97.800%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.069 Acc 97.825%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.072 Acc 97.700%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.298 Acc 93.363%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.291 Acc 93.342%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.061 Acc 97.904%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.061 Acc 97.967%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.063 Acc 97.898%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.065 Acc 97.851%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.065 Acc 97.843%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.460 Acc 89.844%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.431 Acc 90.989%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.427 Acc 91.080%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.072 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.068 Acc 97.808%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.068 Acc 97.830%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.067 Acc 97.818%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.069 Acc 97.723%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.439 Acc 89.062%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.392 Acc 91.321%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.389 Acc 91.383%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.076 Acc 97.424%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.073 Acc 97.637%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.075 Acc 97.617%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.073 Acc 97.639%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.073 Acc 97.617%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.422 Acc 91.406%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.391 Acc 91.190%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.388 Acc 91.165%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.064 Acc 97.795%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.066 Acc 97.726%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.068 Acc 97.659%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.068 Acc 97.687%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.069 Acc 97.658%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.419 Acc 90.625%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.392 Acc 91.197%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.390 Acc 91.185%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.065 Acc 97.803%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.065 Acc 97.870%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.068 Acc 97.778%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.068 Acc 97.756%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.068 Acc 97.781%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.336 Acc 91.406%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.353 Acc 92.087%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.346 Acc 92.215%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.068 Acc 97.726%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.069 Acc 97.737%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.070 Acc 97.680%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.070 Acc 97.681%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.363 Acc 90.625%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.377 Acc 91.174%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.373 Acc 91.274%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.061 Acc 97.942%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.062 Acc 97.983%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.064 Acc 97.913%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.067 Acc 97.845%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.337 Acc 92.188%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.348 Acc 92.041%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.346 Acc 91.985%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.063 Acc 98.113%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.069 Acc 97.831%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.069 Acc 97.787%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.070 Acc 97.736%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.355 Acc 93.750%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.396 Acc 91.499%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.390 Acc 91.597%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.070 Acc 97.668%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.070 Acc 97.682%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.070 Acc 97.691%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.070 Acc 97.697%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.365 Acc 89.062%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.387 Acc 91.298%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.382 Acc 91.519%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.068 Acc 97.788%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.070 Acc 97.648%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.070 Acc 97.620%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.070 Acc 97.662%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.070 Acc 97.672%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.335 Acc 89.844%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.351 Acc 91.932%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.342 Acc 91.888%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.062 Acc 98.058%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.068 Acc 97.750%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.070 Acc 97.680%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.071 Acc 97.662%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.475 Acc 87.500%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.482 Acc 89.101%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.481 Acc 89.257%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.061 Acc 97.896%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.065 Acc 97.843%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.067 Acc 97.781%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.067 Acc 97.798%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.066 Acc 97.806%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.356 Acc 91.538%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.350 Acc 91.651%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.063 Acc 98.012%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.066 Acc 97.843%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.065 Acc 97.843%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.065 Acc 97.845%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.066 Acc 97.831%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.419 Acc 89.062%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.421 Acc 90.138%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.414 Acc 90.431%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.059 Acc 98.028%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.058 Acc 98.099%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.061 Acc 97.988%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.064 Acc 97.933%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.064 Acc 97.907%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.343 Acc 92.188%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.353 Acc 92.273%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.349 Acc 92.230%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.064 Acc 98.035%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.065 Acc 97.936%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.066 Acc 97.877%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.067 Acc 97.867%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.068 Acc 97.801%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.371 Acc 90.625%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.405 Acc 90.463%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.400 Acc 90.714%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.061 Acc 97.850%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.060 Acc 97.952%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.062 Acc 97.937%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.061 Acc 97.978%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.064 Acc 97.923%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.424 Acc 90.625%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.363 Acc 91.592%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.359 Acc 91.807%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.213 Acc 94.531%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.066 Acc 97.927%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.068 Acc 97.812%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.066 Acc 97.848%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.068 Acc 97.763%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.068 Acc 97.769%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.424 Acc 90.625%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.349 Acc 91.832%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.346 Acc 91.877%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.066 Acc 97.950%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.068 Acc 97.886%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.067 Acc 97.841%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.068 Acc 97.808%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.067 Acc 97.820%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.403 Acc 90.625%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.420 Acc 89.921%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.415 Acc 89.964%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.063 Acc 97.912%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.068 Acc 97.816%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.067 Acc 97.830%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.066 Acc 97.839%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.067 Acc 97.787%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.393 Acc 88.281%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.391 Acc 90.068%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.383 Acc 90.427%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.069 Acc 97.703%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.064 Acc 97.892%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.066 Acc 97.878%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.065 Acc 97.882%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.430 Acc 89.062%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.340 Acc 91.754%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.334 Acc 91.904%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.159 Acc 96.094%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.067 Acc 97.718%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.064 Acc 97.874%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.065 Acc 97.864%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.065 Acc 97.830%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.064 Acc 97.900%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.427 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.395 Acc 90.718%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.390 Acc 90.808%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.066 Acc 97.772%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.069 Acc 97.827%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.067 Acc 97.916%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.068 Acc 97.834%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.070 Acc 97.770%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.349 Acc 90.625%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.362 Acc 91.615%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.352 Acc 91.795%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.059 Acc 98.060%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.064 Acc 97.884%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.066 Acc 97.825%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.419 Acc 92.188%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.358 Acc 92.002%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.350 Acc 91.954%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.064 Acc 97.834%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.061 Acc 97.975%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.064 Acc 97.952%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.065 Acc 97.917%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.064 Acc 97.921%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.343 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.330 Acc 92.536%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.324 Acc 92.720%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.051%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.062 Acc 97.936%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.063 Acc 97.916%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.062 Acc 97.906%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.063 Acc 97.885%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.298 Acc 92.969%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.372 Acc 90.981%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.366 Acc 91.220%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.065 Acc 97.935%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.063 Acc 97.998%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.063 Acc 97.963%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.064 Acc 97.941%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.065 Acc 97.893%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.468 Acc 87.500%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.459 Acc 90.207%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.448 Acc 90.345%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.057 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.065 Acc 97.857%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.062 Acc 97.901%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.064 Acc 97.879%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.328 Acc 92.188%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.327 Acc 92.613%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.321 Acc 92.553%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7182ba086a1347cb8025eb0c928105cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.305 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 3.068 Acc 15.934%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.657 Acc 17.211%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.516 Acc 17.943%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.446 Acc 18.191%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.404 Acc 18.335%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.196 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.213 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.214 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.292 Acc 14.844%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.229 Acc 18.943%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.221 Acc 18.972%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.146 Acc 22.314%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.971 Acc 29.489%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.781 Acc 36.940%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.928 Acc 73.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.863 Acc 72.223%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.857 Acc 72.252%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.735 Acc 76.562%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.647 Acc 79.780%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.589 Acc 81.685%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.550 Acc 82.903%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.524 Acc 83.765%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.504 Acc 84.398%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.570 Acc 83.594%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.486 Acc 84.901%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.477 Acc 85.102%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.398 Acc 87.740%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.380 Acc 88.371%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.375 Acc 88.637%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.373 Acc 88.681%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.374 Acc 88.680%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.426 Acc 86.719%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.351 Acc 89.349%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.344 Acc 89.626%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.411 Acc 83.594%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.328 Acc 89.728%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.333 Acc 89.883%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.333 Acc 89.839%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.334 Acc 89.891%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.333 Acc 90.004%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.441 Acc 89.844%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.366 Acc 90.942%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.363 Acc 91.072%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.310 Acc 90.610%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.306 Acc 90.668%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.309 Acc 90.558%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.309 Acc 90.641%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.308 Acc 90.706%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.546 Acc 82.031%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.467 Acc 85.218%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.459 Acc 85.483%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.466 Acc 90.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.290 Acc 91.515%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.287 Acc 91.527%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.295 Acc 91.331%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.300 Acc 91.149%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.298 Acc 91.199%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.330 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.312 Acc 92.837%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.307 Acc 93.101%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.321 Acc 92.188%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.290 Acc 91.437%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.286 Acc 91.500%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.282 Acc 91.604%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.279 Acc 91.683%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.281 Acc 91.653%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.271 Acc 89.844%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.281 Acc 92.489%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.279 Acc 92.576%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.284 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.269 Acc 91.971%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.265 Acc 92.153%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.273 Acc 91.928%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.270 Acc 92.045%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.272 Acc 92.033%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.331 Acc 87.500%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.308 Acc 92.126%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.303 Acc 92.312%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.209 Acc 92.969%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.264 Acc 92.025%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.259 Acc 92.324%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.259 Acc 92.322%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.260 Acc 92.357%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.263 Acc 92.300%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.365 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.310 Acc 91.979%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.305 Acc 92.277%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.272 Acc 92.188%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.253 Acc 92.698%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.256 Acc 92.572%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.257 Acc 92.457%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.260 Acc 92.412%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.262 Acc 92.361%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.227 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.266 Acc 92.667%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.258 Acc 92.938%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.290 Acc 93.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.260 Acc 92.853%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.261 Acc 92.413%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.257 Acc 92.447%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.255 Acc 92.538%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.255 Acc 92.546%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.313 Acc 92.404%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.307 Acc 92.631%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.236 Acc 93.054%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.242 Acc 92.980%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.246 Acc 92.813%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.251 Acc 92.700%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.252 Acc 92.679%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.414 Acc 88.281%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.364 Acc 89.148%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.356 Acc 89.269%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.384 Acc 91.406%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.252 Acc 92.737%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.242 Acc 93.070%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.241 Acc 93.156%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.241 Acc 93.142%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.241 Acc 93.058%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.323 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.307 Acc 91.437%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.302 Acc 91.639%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.232 Acc 93.317%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.233 Acc 93.272%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.235 Acc 93.187%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.235 Acc 93.187%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.235 Acc 93.207%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.396 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.349 Acc 92.311%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.342 Acc 92.627%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.228 Acc 93.680%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.237 Acc 93.210%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.236 Acc 93.278%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.236 Acc 93.280%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.233 Acc 93.309%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.353 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.375 Acc 91.955%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.369 Acc 92.226%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.315 Acc 86.719%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.208 Acc 93.912%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.215 Acc 93.762%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.219 Acc 93.607%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.226 Acc 93.577%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.226 Acc 93.555%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.521 Acc 90.625%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.486 Acc 91.708%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.483 Acc 91.842%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.216 Acc 93.750%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.212 Acc 93.990%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.207 Acc 93.995%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.215 Acc 93.825%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.216 Acc 93.777%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.216 Acc 93.811%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.377 Acc 85.938%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.348 Acc 90.989%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.343 Acc 91.146%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.135 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.216 Acc 94.028%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.212 Acc 94.100%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.213 Acc 94.033%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.213 Acc 93.988%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.214 Acc 93.943%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.278 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.260 Acc 94.152%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.256 Acc 94.286%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.165 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.210 Acc 94.005%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.211 Acc 94.065%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.212 Acc 93.978%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.212 Acc 93.955%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.213 Acc 93.931%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.307 Acc 89.062%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.275 Acc 93.317%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.273 Acc 93.155%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.220 Acc 91.406%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.195 Acc 94.477%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.198 Acc 94.185%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.199 Acc 94.145%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.205 Acc 94.071%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.205 Acc 94.109%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.253 Acc 93.889%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.247 Acc 94.018%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.112 Acc 94.531%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.192 Acc 94.353%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.197 Acc 94.224%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.201 Acc 94.186%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.202 Acc 94.202%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.201 Acc 94.221%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.326 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.280 Acc 92.830%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.272 Acc 93.183%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.179 Acc 94.632%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.183 Acc 94.764%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.191 Acc 94.583%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.194 Acc 94.562%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.198 Acc 94.491%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.247 Acc 93.727%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.244 Acc 93.913%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.199 Acc 94.253%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.192 Acc 94.582%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.192 Acc 94.573%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.194 Acc 94.465%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.194 Acc 94.497%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.360 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.359 Acc 93.015%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.354 Acc 93.155%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.181 Acc 95.057%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.178 Acc 95.005%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.185 Acc 94.788%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.189 Acc 94.714%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.189 Acc 94.711%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.300 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.278 Acc 94.021%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.273 Acc 93.987%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.215 Acc 92.969%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.171 Acc 94.910%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.175 Acc 94.932%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.181 Acc 94.817%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.184 Acc 94.714%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.186 Acc 94.633%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.245 Acc 94.052%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.239 Acc 94.228%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.174 Acc 95.019%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.178 Acc 94.963%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.181 Acc 94.845%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.183 Acc 94.839%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.187 Acc 94.729%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.270 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.247 Acc 94.508%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.240 Acc 94.792%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.226 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.183 Acc 94.980%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.178 Acc 95.044%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.180 Acc 94.957%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.181 Acc 94.903%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.179 Acc 94.966%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.237 Acc 93.804%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.232 Acc 93.905%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.174 Acc 95.150%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.172 Acc 95.064%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.174 Acc 95.092%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.174 Acc 95.079%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.174 Acc 95.079%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.226 Acc 94.833%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.223 Acc 94.683%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.162 Acc 95.351%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.170 Acc 95.209%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.169 Acc 95.221%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.171 Acc 95.183%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.290 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.282 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.278 Acc 93.116%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.169 Acc 95.343%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.164 Acc 95.359%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.169 Acc 95.203%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.168 Acc 95.188%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.203 Acc 94.477%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.197 Acc 94.741%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.169 Acc 95.398%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.162 Acc 95.476%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.160 Acc 95.546%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.163 Acc 95.416%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.166 Acc 95.305%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.232 Acc 94.415%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.227 Acc 94.457%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.152 Acc 95.730%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.154 Acc 95.674%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.155 Acc 95.629%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.157 Acc 95.556%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.160 Acc 95.448%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.249 Acc 96.094%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.265 Acc 93.858%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.261 Acc 93.952%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.150 Acc 95.761%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.158 Acc 95.588%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.161 Acc 95.512%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.158 Acc 95.583%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.159 Acc 95.464%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.223 Acc 95.135%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.217 Acc 95.332%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.116 Acc 94.531%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.157 Acc 95.498%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.158 Acc 95.456%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.156 Acc 95.567%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.155 Acc 95.607%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.157 Acc 95.501%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.263 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.272 Acc 94.206%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.268 Acc 94.259%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.154 Acc 95.668%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.153 Acc 95.565%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.154 Acc 95.551%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.157 Acc 95.463%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.160 Acc 95.412%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.221 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.203 Acc 95.111%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.197 Acc 95.316%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.149 Acc 95.862%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.152 Acc 95.763%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.151 Acc 95.764%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.153 Acc 95.720%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.155 Acc 95.642%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.204 Acc 95.312%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.249 Acc 94.438%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.247 Acc 94.512%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.199 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.151 Acc 95.838%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.147 Acc 95.771%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.145 Acc 95.795%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.144 Acc 95.819%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.145 Acc 95.777%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.276 Acc 92.188%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.236 Acc 93.781%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.233 Acc 93.781%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.141 Acc 95.668%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.142 Acc 95.752%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.147 Acc 95.710%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.147 Acc 95.720%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.146 Acc 95.723%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.205 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.223 Acc 94.578%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.219 Acc 94.776%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.130 Acc 96.310%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.135 Acc 96.152%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.141 Acc 95.956%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.145 Acc 95.877%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.145 Acc 95.872%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.240 Acc 94.539%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.236 Acc 94.446%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.151 Acc 95.668%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.146 Acc 95.787%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.139 Acc 95.961%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.142 Acc 95.866%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.142 Acc 95.843%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.217 Acc 94.578%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.214 Acc 94.593%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.136 Acc 95.877%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.137 Acc 95.946%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.140 Acc 95.829%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.143 Acc 95.821%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.142 Acc 95.874%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.182 Acc 96.875%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.225 Acc 94.624%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.219 Acc 94.834%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.165 Acc 92.969%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.138 Acc 95.857%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.140 Acc 95.860%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.141 Acc 95.846%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.140 Acc 95.858%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.215 Acc 95.444%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.208 Acc 95.538%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.138 Acc 95.955%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.139 Acc 95.923%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.142 Acc 95.878%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.141 Acc 95.967%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.142 Acc 95.911%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.206 Acc 94.872%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.200 Acc 94.967%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.129 Acc 96.426%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.139 Acc 95.956%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.139 Acc 95.975%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.139 Acc 96.010%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.211 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.213 Acc 94.825%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.209 Acc 94.846%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.126 Acc 96.233%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.128 Acc 96.199%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.130 Acc 96.187%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.134 Acc 96.107%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.134 Acc 96.123%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.188 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.238 Acc 94.547%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.230 Acc 94.562%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.163 Acc 96.094%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.130 Acc 96.214%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.130 Acc 96.231%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.132 Acc 96.183%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.132 Acc 96.169%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.193 Acc 95.050%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.188 Acc 95.153%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.099 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.131 Acc 96.310%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.132 Acc 96.179%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.135 Acc 96.031%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.134 Acc 96.108%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.211 Acc 94.446%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.205 Acc 94.578%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.123 Acc 96.241%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.122 Acc 96.339%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.124 Acc 96.364%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.124 Acc 96.345%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.127 Acc 96.279%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.208 Acc 95.104%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.199 Acc 95.211%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.121 Acc 96.426%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.124 Acc 96.304%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.124 Acc 96.317%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.124 Acc 96.312%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.124 Acc 96.343%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.207 Acc 96.094%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.262 Acc 94.384%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.255 Acc 94.481%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.115 Acc 96.597%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.122 Acc 96.288%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.123 Acc 96.325%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.122 Acc 96.357%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.124 Acc 96.318%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.215 Acc 95.034%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.211 Acc 94.982%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.113 Acc 96.589%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.116 Acc 96.537%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.121 Acc 96.418%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.124 Acc 96.308%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.124 Acc 96.290%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.244 Acc 94.779%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.239 Acc 94.854%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.060 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.116 Acc 96.607%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.115 Acc 96.519%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.117 Acc 96.442%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.120 Acc 96.392%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.277 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.303 Acc 93.982%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.295 Acc 94.154%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.106 Acc 96.604%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.111 Acc 96.716%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.116 Acc 96.567%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.115 Acc 96.602%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.298 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.279 Acc 94.469%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.274 Acc 94.496%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.120 Acc 96.473%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.121 Acc 96.397%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.118 Acc 96.499%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.117 Acc 96.493%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.118 Acc 96.512%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.185 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.218 Acc 95.150%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.212 Acc 95.204%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.221 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.109 Acc 96.666%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.117 Acc 96.401%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.117 Acc 96.413%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.120 Acc 96.347%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.122 Acc 96.300%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.233 Acc 94.570%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.230 Acc 94.625%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.110 Acc 96.739%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.111 Acc 96.714%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.115 Acc 96.583%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.199 Acc 96.875%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.218 Acc 94.640%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.213 Acc 94.694%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.100 Acc 96.937%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.105 Acc 96.832%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.111 Acc 96.724%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.114 Acc 96.630%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.116 Acc 96.572%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.268 Acc 93.851%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.265 Acc 93.937%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.111 Acc 96.607%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.112 Acc 96.604%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.112 Acc 96.590%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.242 Acc 94.152%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.233 Acc 94.251%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.058 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.102 Acc 96.894%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.104 Acc 96.805%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.107 Acc 96.768%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.109 Acc 96.749%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.253 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.290 Acc 93.673%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.284 Acc 93.793%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.106 Acc 96.728%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.102 Acc 96.836%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.103 Acc 96.849%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.105 Acc 96.830%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.107 Acc 96.724%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.220 Acc 94.957%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.214 Acc 95.060%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.116 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.099 Acc 97.045%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.108 Acc 96.807%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.108 Acc 96.785%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.220 Acc 94.446%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.213 Acc 94.737%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.105 Acc 96.852%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.107 Acc 96.852%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.107 Acc 96.869%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.280 Acc 89.844%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.281 Acc 93.912%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.276 Acc 94.127%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.175 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.102 Acc 97.030%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.103 Acc 96.935%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.106 Acc 96.857%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.109 Acc 96.725%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.287 Acc 92.188%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.256 Acc 94.245%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.249 Acc 94.259%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.101 Acc 96.689%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.108 Acc 96.537%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.108 Acc 96.631%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.110 Acc 96.633%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.107 Acc 96.688%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.371 Acc 90.625%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.287 Acc 93.843%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.284 Acc 93.929%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.094 Acc 97.092%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.103 Acc 96.896%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.105 Acc 96.754%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.105 Acc 96.775%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.239 Acc 91.406%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.227 Acc 94.663%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.221 Acc 94.807%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.092 Acc 97.169%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.100 Acc 96.887%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.102 Acc 96.865%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.104 Acc 96.817%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.104 Acc 96.791%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.225 Acc 94.547%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.220 Acc 94.597%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.096 Acc 97.053%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.103 Acc 96.878%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.105 Acc 96.824%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.107 Acc 96.780%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.254 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.259 Acc 94.090%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.252 Acc 94.232%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.094 Acc 97.153%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.097 Acc 97.034%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.095 Acc 97.101%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.099 Acc 96.964%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.190 Acc 93.750%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.221 Acc 94.686%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.212 Acc 94.873%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.093 Acc 97.076%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.091 Acc 97.174%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.101 Acc 96.933%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.101 Acc 96.906%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.240 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.239 Acc 94.052%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.232 Acc 94.224%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.123 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.103 Acc 96.829%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.101 Acc 96.848%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.103 Acc 96.805%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.103 Acc 96.830%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.102 Acc 96.870%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.254 Acc 94.075%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.250 Acc 94.189%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.091 Acc 97.248%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.093 Acc 97.137%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.097 Acc 97.043%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.266 Acc 94.160%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.263 Acc 94.240%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.096 Acc 97.061%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.097 Acc 97.058%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.096 Acc 97.129%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.096 Acc 97.113%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.099 Acc 96.990%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.222 Acc 96.875%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.256 Acc 93.781%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.245 Acc 93.975%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.089 Acc 97.308%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.095 Acc 96.992%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.098 Acc 96.932%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.097 Acc 96.969%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.097 Acc 97.012%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.208 Acc 95.204%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.200 Acc 95.340%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.092 Acc 97.192%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.090 Acc 97.240%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.093 Acc 97.202%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.095 Acc 97.136%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.095 Acc 97.112%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.253 Acc 93.502%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.248 Acc 93.641%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.089 Acc 97.184%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.094 Acc 96.972%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.098 Acc 96.885%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.100 Acc 96.826%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.099 Acc 96.859%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.234 Acc 92.969%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.252 Acc 94.701%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.246 Acc 94.803%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.092 Acc 97.030%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.089 Acc 97.155%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.092 Acc 97.082%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.093 Acc 97.023%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.310 Acc 92.969%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.328 Acc 92.822%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.322 Acc 92.907%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.087 Acc 97.269%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.091 Acc 97.155%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.095 Acc 97.076%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.098 Acc 96.947%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.227 Acc 91.406%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.247 Acc 94.114%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.239 Acc 94.201%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.083 Acc 97.246%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.083 Acc 97.279%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.087 Acc 97.173%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.088 Acc 97.150%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.091 Acc 97.064%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.236 Acc 94.655%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.230 Acc 94.636%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.085 Acc 97.525%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.087 Acc 97.345%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.092 Acc 97.191%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.092 Acc 97.185%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.203 Acc 90.625%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.234 Acc 94.299%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.225 Acc 94.512%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.089 Acc 97.269%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.088 Acc 97.287%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.090 Acc 97.262%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.089 Acc 97.282%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.092 Acc 97.173%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.268 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.245 Acc 94.400%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.237 Acc 94.535%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.094 Acc 97.073%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.093 Acc 97.103%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.094 Acc 97.126%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.094 Acc 97.084%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.228 Acc 94.740%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.223 Acc 94.796%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.084 Acc 97.440%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.086 Acc 97.415%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.089 Acc 97.303%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.089 Acc 97.294%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.091 Acc 97.226%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.262 Acc 94.168%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.254 Acc 94.251%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.086 Acc 97.115%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.088 Acc 97.100%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.089 Acc 97.129%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.089 Acc 97.152%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.349 Acc 90.625%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.312 Acc 93.007%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.307 Acc 93.151%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.075 Acc 97.687%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.082 Acc 97.431%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.083 Acc 97.381%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.087 Acc 97.278%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.090 Acc 97.199%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.230 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.266 Acc 94.067%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.260 Acc 94.216%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.087 Acc 97.300%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.085 Acc 97.341%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.087 Acc 97.249%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.088 Acc 97.233%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.088 Acc 97.245%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.259 Acc 94.261%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.254 Acc 94.298%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.083 Acc 97.361%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.086 Acc 97.263%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.086 Acc 97.262%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.259 Acc 92.188%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.274 Acc 94.121%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.267 Acc 94.178%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.083 Acc 97.392%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.085 Acc 97.334%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.088 Acc 97.259%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.088 Acc 97.240%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.242 Acc 94.291%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.236 Acc 94.368%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.085 Acc 97.215%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.086 Acc 97.287%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.089 Acc 97.194%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.091 Acc 97.185%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.092 Acc 97.165%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.229 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.243 Acc 94.175%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.234 Acc 94.333%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.091 Acc 97.208%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.086 Acc 97.209%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.089 Acc 97.194%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.087 Acc 97.237%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.088 Acc 97.248%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.275 Acc 94.052%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.268 Acc 94.205%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.073 Acc 97.610%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.080 Acc 97.446%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.081 Acc 97.385%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.082 Acc 97.391%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.251 Acc 93.967%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.242 Acc 94.325%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.083 Acc 97.556%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.078 Acc 97.660%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.081 Acc 97.539%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.082 Acc 97.477%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.084 Acc 97.376%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.247 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.282 Acc 93.680%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.272 Acc 93.828%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.083 Acc 97.262%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.086 Acc 97.271%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.086 Acc 97.262%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.087 Acc 97.274%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.086 Acc 97.271%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.227 Acc 94.694%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.215 Acc 94.854%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.087 Acc 97.161%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.084 Acc 97.330%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.086 Acc 97.292%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.086 Acc 97.280%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.222 Acc 92.969%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.265 Acc 94.253%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.259 Acc 94.271%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.081 Acc 97.409%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.079 Acc 97.407%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.082 Acc 97.334%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.082 Acc 97.352%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.082 Acc 97.380%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.319 Acc 92.188%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.306 Acc 93.170%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.299 Acc 93.264%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.079 Acc 97.415%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.080 Acc 97.495%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.083 Acc 97.450%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.233 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.304 Acc 93.085%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.294 Acc 93.221%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.075 Acc 97.424%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.078 Acc 97.516%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.079 Acc 97.498%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.083 Acc 97.372%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.082 Acc 97.405%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.230 Acc 91.406%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.279 Acc 93.386%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.267 Acc 93.560%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.087 Acc 97.192%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.084 Acc 97.355%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.084 Acc 97.323%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.084 Acc 97.338%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.244 Acc 92.188%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.279 Acc 94.044%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.271 Acc 94.096%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.073 Acc 97.711%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.077 Acc 97.569%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.080 Acc 97.489%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.234 Acc 94.392%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.228 Acc 94.477%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.074 Acc 97.730%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.076 Acc 97.659%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.080 Acc 97.520%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.080 Acc 97.499%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.262 Acc 88.281%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.262 Acc 93.595%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.252 Acc 93.851%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.074 Acc 97.579%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.078 Acc 97.520%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.079 Acc 97.443%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.197 Acc 94.531%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.261 Acc 93.928%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.251 Acc 94.135%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.072 Acc 97.649%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.076 Acc 97.555%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.078 Acc 97.493%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.080 Acc 97.463%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.081 Acc 97.439%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.275 Acc 93.170%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.267 Acc 93.458%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.075 Acc 97.641%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.076 Acc 97.558%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.252 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.235 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.227 Acc 94.628%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.070 Acc 97.812%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.071 Acc 97.794%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.073 Acc 97.719%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.075 Acc 97.627%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.249 Acc 93.851%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.240 Acc 94.158%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.075 Acc 97.638%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.076 Acc 97.611%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.077 Acc 97.555%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.149 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.239 Acc 94.291%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.230 Acc 94.523%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.079 Acc 97.440%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.081 Acc 97.450%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.079 Acc 97.493%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.079 Acc 97.489%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.079 Acc 97.493%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.217 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.239 Acc 94.423%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.229 Acc 94.430%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.063 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.071 Acc 97.803%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.075 Acc 97.563%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.075 Acc 97.552%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.075 Acc 97.582%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.077 Acc 97.485%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.240 Acc 93.943%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.233 Acc 94.119%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.068 Acc 97.842%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.070 Acc 97.785%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.073 Acc 97.721%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.075 Acc 97.691%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.076 Acc 97.684%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.270 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.280 Acc 93.472%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.274 Acc 93.672%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.067 Acc 97.850%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.071 Acc 97.715%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.073 Acc 97.589%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.075 Acc 97.553%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.077 Acc 97.536%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.252 Acc 94.191%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.243 Acc 94.395%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.094 Acc 97.022%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.085 Acc 97.299%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.081 Acc 97.433%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.080 Acc 97.475%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.219 Acc 91.406%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.247 Acc 93.758%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.238 Acc 94.053%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.071 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.071 Acc 97.532%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.072 Acc 97.590%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.072 Acc 97.599%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.075 Acc 97.535%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.075 Acc 97.544%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.220 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.254 Acc 93.696%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.249 Acc 93.921%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.071 Acc 97.695%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.073 Acc 97.677%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.072 Acc 97.662%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.072 Acc 97.659%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.268 Acc 94.531%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.263 Acc 93.959%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.252 Acc 94.135%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.075 Acc 97.842%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.077 Acc 97.672%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.074 Acc 97.726%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.073 Acc 97.713%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.075 Acc 97.672%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.289 Acc 92.188%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.283 Acc 93.626%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.272 Acc 93.797%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.072 Acc 97.772%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.076 Acc 97.565%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.076 Acc 97.547%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.076 Acc 97.578%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.270 Acc 91.406%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.286 Acc 93.394%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.280 Acc 93.544%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.071 Acc 97.587%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.069 Acc 97.750%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.070 Acc 97.742%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.071 Acc 97.748%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.071 Acc 97.717%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.228 Acc 92.188%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.222 Acc 94.554%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.214 Acc 94.764%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.064 Acc 97.873%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.074 Acc 97.597%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.077 Acc 97.541%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.077 Acc 97.531%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.237 Acc 94.028%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.232 Acc 94.216%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.067 Acc 97.826%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.073 Acc 97.602%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.072 Acc 97.669%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.070 Acc 97.745%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.291 Acc 92.188%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.279 Acc 93.518%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.273 Acc 93.723%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.072 Acc 97.734%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.073 Acc 97.683%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.071 Acc 97.755%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.071 Acc 97.730%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.071 Acc 97.723%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.269 Acc 93.634%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.261 Acc 93.874%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.072 Acc 97.679%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.075 Acc 97.536%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.074 Acc 97.560%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.073 Acc 97.582%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.074 Acc 97.549%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.202 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.233 Acc 94.570%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.226 Acc 94.726%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.067 Acc 97.695%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.071 Acc 97.648%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.072 Acc 97.620%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.074 Acc 97.600%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.075 Acc 97.600%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.238 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.270 Acc 93.495%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.265 Acc 93.571%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.078 Acc 97.618%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.075 Acc 97.746%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.074 Acc 97.750%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.073 Acc 97.722%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.073 Acc 97.714%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.223 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.260 Acc 93.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.254 Acc 93.952%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.036 Acc 97.656%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.068 Acc 97.780%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.256 Acc 92.188%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.282 Acc 93.255%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.275 Acc 93.381%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.086 Acc 97.370%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.077 Acc 97.582%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.074 Acc 97.659%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.074 Acc 97.703%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.074 Acc 97.672%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.279 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.285 Acc 93.495%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.278 Acc 93.742%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.064 Acc 98.089%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.067 Acc 97.878%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.065 Acc 97.921%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.067 Acc 97.855%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.067 Acc 97.857%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.238 Acc 94.361%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.231 Acc 94.500%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.061 Acc 97.973%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.063 Acc 98.057%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.066 Acc 97.918%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.068 Acc 97.857%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.068 Acc 97.832%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.217 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.274 Acc 93.023%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.267 Acc 93.167%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.068 Acc 97.870%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.069 Acc 97.856%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.070 Acc 97.793%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.071 Acc 97.804%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.249 Acc 93.905%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.245 Acc 93.937%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.063 Acc 97.935%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.062 Acc 98.006%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.060 Acc 98.085%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.059 Acc 98.104%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.062 Acc 98.029%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.278 Acc 93.572%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.272 Acc 93.719%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.070 Acc 97.919%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.071 Acc 97.761%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.072 Acc 97.750%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.074 Acc 97.717%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.074 Acc 97.695%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.245 Acc 94.531%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.224 Acc 94.593%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.218 Acc 94.702%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.067 Acc 97.877%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.068 Acc 97.851%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.070 Acc 97.801%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.271 Acc 93.425%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.264 Acc 93.493%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.071 Acc 97.765%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.068 Acc 97.846%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.074 Acc 97.650%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.237 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.258 Acc 93.912%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.246 Acc 94.123%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.065 Acc 97.950%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.063 Acc 98.018%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.067 Acc 97.882%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.071 Acc 97.756%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.069 Acc 97.803%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.241 Acc 94.338%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.233 Acc 94.419%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.067 Acc 97.726%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.069 Acc 97.707%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.068 Acc 97.806%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.250 Acc 94.199%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.240 Acc 94.407%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.057 Acc 98.182%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.064 Acc 97.948%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.069 Acc 97.776%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.068 Acc 97.802%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.069 Acc 97.772%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.200 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.241 Acc 94.245%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.236 Acc 94.298%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.060 Acc 98.159%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.068 Acc 97.901%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.068 Acc 97.856%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.069 Acc 97.832%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.069 Acc 97.809%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.268 Acc 93.858%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.263 Acc 94.003%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.071 Acc 97.664%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.069 Acc 97.792%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.069 Acc 97.820%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.067 Acc 97.876%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.066 Acc 97.895%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.267 Acc 93.472%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.257 Acc 93.707%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.114 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.073 Acc 97.672%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.073 Acc 97.625%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.070 Acc 97.716%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.071 Acc 97.759%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.261 Acc 93.472%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.255 Acc 93.711%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.067 Acc 97.896%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.069 Acc 97.893%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.068 Acc 97.916%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.067 Acc 97.931%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.068 Acc 97.903%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.239 Acc 94.175%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.232 Acc 94.360%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.065 Acc 97.850%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.067 Acc 97.804%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.067 Acc 97.832%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.066 Acc 97.850%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.238 Acc 94.199%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.231 Acc 94.352%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.058 Acc 98.136%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.064 Acc 97.967%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.064 Acc 97.916%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.066 Acc 97.843%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.066 Acc 97.868%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.342 Acc 90.625%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.299 Acc 93.193%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.292 Acc 93.357%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.063 Acc 97.865%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.064 Acc 97.847%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.067 Acc 97.729%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.067 Acc 97.728%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.068 Acc 97.730%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.187 Acc 92.188%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.238 Acc 94.431%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.233 Acc 94.508%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.064 Acc 97.811%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.063 Acc 97.866%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.063 Acc 97.921%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.063 Acc 97.898%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.064 Acc 97.929%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.247 Acc 92.969%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.274 Acc 93.394%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.268 Acc 93.431%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.139 Acc 97.656%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.068 Acc 97.850%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.068 Acc 97.831%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.067 Acc 97.877%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.068 Acc 97.869%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.068 Acc 97.879%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.227 Acc 94.670%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.225 Acc 94.683%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.070 Acc 97.649%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.069 Acc 97.769%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.068 Acc 97.791%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.067 Acc 97.828%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.066 Acc 97.845%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.264 Acc 93.974%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.258 Acc 93.995%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.055 Acc 98.058%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.065 Acc 97.913%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.064 Acc 97.892%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.064 Acc 97.896%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.067 Acc 97.823%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.269 Acc 93.735%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.263 Acc 93.719%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.062 Acc 98.043%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.065 Acc 97.994%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.065 Acc 97.937%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.066 Acc 97.931%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.068 Acc 97.867%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.270 Acc 93.703%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.073 Acc 96.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.059 Acc 98.105%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.061 Acc 98.068%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.063 Acc 98.038%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.061 Acc 98.044%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.063 Acc 98.026%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.224 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.269 Acc 93.502%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.262 Acc 93.552%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.056 Acc 98.089%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.062 Acc 97.983%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.064 Acc 97.916%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.068 Acc 97.857%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.068 Acc 97.826%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.272 Acc 93.943%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.264 Acc 93.944%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.041 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.063 Acc 98.051%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.067 Acc 97.870%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.065 Acc 97.885%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.063 Acc 97.943%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.064 Acc 97.909%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.333 Acc 92.188%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.282 Acc 93.317%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.279 Acc 93.458%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.063 Acc 97.973%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.064 Acc 97.991%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.061 Acc 98.038%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.064 Acc 97.964%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.065 Acc 97.900%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.377 Acc 90.625%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.289 Acc 92.775%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.280 Acc 92.930%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.056 Acc 98.120%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.057 Acc 98.111%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.060 Acc 97.994%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.063 Acc 97.882%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.065 Acc 97.864%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.253 Acc 93.851%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.245 Acc 94.092%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.062 Acc 98.057%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.063 Acc 97.978%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.062 Acc 98.003%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.062 Acc 98.040%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.270 Acc 93.448%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.267 Acc 93.501%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.059 Acc 98.151%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.065 Acc 97.979%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.065 Acc 97.921%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.066 Acc 97.919%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.067 Acc 97.892%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.305 Acc 93.116%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.296 Acc 93.198%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.064 Acc 97.857%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.062 Acc 97.889%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.063 Acc 97.900%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.063 Acc 97.931%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.064 Acc 97.896%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.244 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.251 Acc 93.765%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.244 Acc 94.014%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.138 Acc 92.969%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.054 Acc 98.352%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.055 Acc 98.290%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.057 Acc 98.183%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.059 Acc 98.085%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.060 Acc 98.046%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.245 Acc 92.969%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.247 Acc 94.137%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.239 Acc 94.282%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.056 Acc 98.198%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.055 Acc 98.200%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.059 Acc 98.069%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.062 Acc 97.993%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.261 Acc 93.727%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.252 Acc 93.731%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.065 Acc 97.942%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.068 Acc 97.835%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.069 Acc 97.833%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.067 Acc 97.892%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.067 Acc 97.876%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.280 Acc 92.188%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.268 Acc 93.479%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.263 Acc 93.703%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.058 Acc 98.012%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.062 Acc 98.029%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.061 Acc 98.033%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.063 Acc 98.005%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.064 Acc 97.999%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.244 Acc 94.152%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.237 Acc 94.248%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.053 Acc 98.345%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.057 Acc 98.165%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.060 Acc 98.053%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.060 Acc 98.063%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.059 Acc 98.098%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.239 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.263 Acc 93.557%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.257 Acc 93.773%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.062 Acc 97.989%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.066 Acc 97.882%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.065 Acc 97.874%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.066 Acc 97.882%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.065 Acc 97.928%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.260 Acc 93.433%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.253 Acc 93.703%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.058 Acc 97.997%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.059 Acc 98.088%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.062 Acc 97.999%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.062 Acc 98.006%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.313 Acc 92.969%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.262 Acc 93.680%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.260 Acc 93.630%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.053 Acc 98.252%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.057 Acc 98.103%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.057 Acc 98.110%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.060 Acc 98.005%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.061 Acc 97.998%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.199 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.228 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.222 Acc 94.469%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.061 Acc 98.043%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.062 Acc 97.979%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.063 Acc 97.937%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.061 Acc 98.045%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.303 Acc 94.531%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.251 Acc 94.075%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.248 Acc 94.127%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.050 Acc 98.407%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.056 Acc 98.193%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.057 Acc 98.178%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.059 Acc 98.118%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.059 Acc 98.091%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.243 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.269 Acc 93.673%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.261 Acc 93.711%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.059 Acc 98.144%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.058 Acc 98.208%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.059 Acc 98.129%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.059 Acc 98.100%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.061 Acc 98.048%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.257 Acc 92.188%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.269 Acc 93.518%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.264 Acc 93.579%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.113 Acc 94.531%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.064 Acc 97.865%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.062 Acc 97.924%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.064 Acc 97.910%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.063 Acc 97.937%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.337 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.278 Acc 93.472%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.270 Acc 93.606%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.020 Acc 98.438%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.054 Acc 98.260%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.056 Acc 98.197%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.057 Acc 98.188%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.058 Acc 98.145%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.059 Acc 98.094%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.215 Acc 92.188%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.253 Acc 94.369%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.244 Acc 94.364%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [100/573] Loss: 0.062 Acc 98.012%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.061 Acc 98.014%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.060 Acc 97.986%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.061 Acc 97.986%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.062 Acc 97.992%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.249 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.249 Acc 94.268%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.238 Acc 94.446%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.056 Acc 98.105%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.060 Acc 98.018%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.062 Acc 97.955%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.063 Acc 97.956%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.062 Acc 97.953%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.252 Acc 92.188%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.276 Acc 93.680%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.269 Acc 93.707%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.064 Acc 97.989%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.061 Acc 98.041%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.061 Acc 98.069%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.059 Acc 98.149%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.059 Acc 98.119%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.258 Acc 93.967%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.253 Acc 93.921%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.057 Acc 98.136%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.055 Acc 98.173%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.060 Acc 98.048%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.061 Acc 98.030%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.060 Acc 98.049%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.285 Acc 91.406%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.301 Acc 93.193%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.289 Acc 93.291%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.062 Acc 98.097%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.059 Acc 98.146%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.062 Acc 98.072%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.061 Acc 98.102%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.062 Acc 98.073%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.245 Acc 94.361%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.238 Acc 94.368%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.058 Acc 98.267%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.057 Acc 98.165%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.057 Acc 98.170%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.057 Acc 98.190%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.056 Acc 98.236%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.233 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.224 Acc 94.694%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.064 Acc 97.927%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.061 Acc 98.010%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.060 Acc 98.100%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.061 Acc 98.052%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.248 Acc 92.969%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.245 Acc 94.121%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.239 Acc 94.166%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.056 Acc 98.244%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.057 Acc 98.158%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.057 Acc 98.183%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.058 Acc 98.128%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.059 Acc 98.088%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.205 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.253 Acc 93.588%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.247 Acc 93.614%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.062 Acc 98.151%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.060 Acc 98.103%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.059 Acc 98.110%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.060 Acc 98.087%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.060 Acc 98.069%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.249 Acc 92.969%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.297 Acc 93.054%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.293 Acc 93.120%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.056 Acc 98.205%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.060 Acc 98.057%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.058 Acc 98.149%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.059 Acc 98.188%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.059 Acc 98.158%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.262 Acc 93.680%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.256 Acc 93.793%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.059 Acc 98.035%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.060 Acc 98.025%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.061 Acc 97.968%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.061 Acc 98.011%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.062 Acc 97.965%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.245 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.261 Acc 93.472%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.256 Acc 93.672%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.060 Acc 98.028%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.058 Acc 98.130%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.057 Acc 98.139%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.057 Acc 98.147%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.058 Acc 98.101%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.199 Acc 92.969%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.235 Acc 94.268%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.233 Acc 94.267%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.054 Acc 98.430%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.056 Acc 98.301%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.057 Acc 98.238%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.056 Acc 98.241%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.056 Acc 98.224%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.292 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.303 Acc 92.853%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.297 Acc 92.965%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.069 Acc 97.966%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.067 Acc 98.033%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.067 Acc 97.965%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.065 Acc 98.032%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.064 Acc 98.079%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.258 Acc 93.998%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.253 Acc 93.983%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.056 Acc 98.173%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.055 Acc 98.206%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.057 Acc 98.159%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.058 Acc 98.127%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.243 Acc 94.183%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.235 Acc 94.360%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.058 Acc 98.314%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [200/573] Loss: 0.053 Acc 98.356%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.056 Acc 98.269%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.057 Acc 98.231%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.058 Acc 98.190%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.388 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.358 Acc 91.468%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.355 Acc 91.612%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.053 Acc 98.314%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.053 Acc 98.270%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.053 Acc 98.274%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.055 Acc 98.213%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.056 Acc 98.186%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.228 Acc 90.625%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.263 Acc 93.959%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.256 Acc 94.104%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.058 Acc 98.097%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.059 Acc 98.095%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.058 Acc 98.108%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.057 Acc 98.116%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.058 Acc 98.115%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.245 Acc 94.446%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.240 Acc 94.403%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.061 Acc 98.128%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.060 Acc 98.134%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.060 Acc 98.123%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.060 Acc 98.110%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.060 Acc 98.093%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.244 Acc 94.237%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.237 Acc 94.317%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.067 Acc 97.989%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.058 Acc 98.127%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.059 Acc 98.116%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.059 Acc 98.118%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.060 Acc 98.090%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.252 Acc 93.835%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.244 Acc 93.964%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.062 Acc 98.051%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.062 Acc 98.025%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.059 Acc 98.136%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.060 Acc 98.104%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.061 Acc 98.071%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.294 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.275 Acc 93.533%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.270 Acc 93.707%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.057 Acc 98.082%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.059 Acc 98.084%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.057 Acc 98.110%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.060 Acc 98.071%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.058 Acc 98.129%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.253 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.253 Acc 94.230%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.244 Acc 94.279%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.161 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.058 Acc 98.205%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.056 Acc 98.212%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.061 Acc 98.131%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.060 Acc 98.106%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.060 Acc 98.098%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.306 Acc 91.406%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.269 Acc 93.920%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.260 Acc 94.088%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.049 Acc 98.468%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.054 Acc 98.344%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.054 Acc 98.323%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.054 Acc 98.323%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.056 Acc 98.246%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.249 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.244 Acc 94.044%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.237 Acc 94.158%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.040 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.048 Acc 98.345%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.056 Acc 98.193%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.056 Acc 98.178%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.057 Acc 98.143%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.055 Acc 98.230%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.232 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.272 Acc 93.588%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.266 Acc 93.505%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.052 Acc 98.182%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.055 Acc 98.158%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.056 Acc 98.121%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.057 Acc 98.089%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.060 Acc 98.054%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.275 Acc 89.844%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.295 Acc 93.046%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.284 Acc 93.249%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.044 Acc 98.646%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.049 Acc 98.504%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.049 Acc 98.463%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.051 Acc 98.422%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.053 Acc 98.339%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.257 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.246 Acc 93.995%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.058 Acc 98.113%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.057 Acc 98.181%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.054 Acc 98.292%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.055 Acc 98.287%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.056 Acc 98.229%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.252 Acc 94.392%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.244 Acc 94.465%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.051 Acc 98.391%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.050 Acc 98.418%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.051 Acc 98.373%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.052 Acc 98.350%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.054 Acc 98.275%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.223 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.257 Acc 93.820%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.251 Acc 94.049%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.164 Acc 96.094%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.059 Acc 98.291%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.059 Acc 98.208%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.060 Acc 98.165%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.059 Acc 98.171%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.060 Acc 98.146%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.273 Acc 90.625%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.254 Acc 94.175%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.244 Acc 94.349%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.092 Acc 95.312%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.054 Acc 98.236%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.055 Acc 98.212%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [300/573] Loss: 0.058 Acc 98.142%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.059 Acc 98.102%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.058 Acc 98.129%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.363 Acc 92.188%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.367 Acc 91.136%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.357 Acc 91.585%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.052 Acc 98.321%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.051 Acc 98.356%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.052 Acc 98.295%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.051 Acc 98.336%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.052 Acc 98.319%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.289 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.260 Acc 94.013%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.252 Acc 94.181%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.051 Acc 98.391%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.053 Acc 98.329%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.053 Acc 98.308%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.053 Acc 98.297%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.053 Acc 98.325%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.276 Acc 92.969%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.246 Acc 94.593%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.238 Acc 94.613%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.049 Acc 98.422%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.049 Acc 98.476%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.052 Acc 98.365%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.053 Acc 98.344%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.054 Acc 98.294%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.227 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.262 Acc 93.773%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.257 Acc 93.898%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0 \n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "for lr in tqdm_notebook(LRS):\n",
    "    for norm in tqdm_notebook(NORMS):\n",
    "        net =  WideResNet(depth=16, num_classes=10, widen_factor=2,dropout_rate=0.3,norm=norm).cuda()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "        train_loss_log =[]\n",
    "        train_acc_log = []\n",
    "        test_loss_log =[]\n",
    "        test_acc_log =[]\n",
    "\n",
    "        for epoch in tqdm_notebook(range(NUM_EPOCH)):\n",
    "            train(epoch)\n",
    "            test(epoch)\n",
    "\n",
    "        np.save(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr), train_loss_log)  \n",
    "        np.save(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr), test_loss_log)    \n",
    "        np.save(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr), train_acc_log)    \n",
    "        np.save(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr), test_acc_log)   \n",
    "        del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9992d213705843e8999f5a3833c42be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8cafc144d14878a070486c1541f0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd11adb7c01143179e1843cc017d3333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "LRS = [0.0001, 0.001]\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook([None,'BN', 'SN', 'MSN'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "        \n",
    "        ax = plt.subplot(3,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(3,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(3,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "                \n",
    "        ax = plt.subplot(3,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Act_Norm_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e9afc0159e42318196e7290dedb03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6f1029d90342f49a54fcc62022a725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dff9db951a44a2bc2a83ca1e125c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef64f969d2334d0ba08cc9054e369353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1080 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook(['WN', 'SN', 'MSN'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "        \n",
    "        ax = plt.subplot(3,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(3,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(3,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "                \n",
    "        ax = plt.subplot(3,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Weight_reparam_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373b6bc7ca9c41bf94978167e16ce496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057e3deafc894efda224216f92774883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49264db767eb4f5c829ded2ec3613762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook(['MSNTReLU', 'WNTReLU'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "\n",
    "        ax = plt.subplot(3,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(3,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(3,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(3,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Weight_reparam_act_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Weight_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa01599f2701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWideResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiden_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'WN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Anand/NeuralBlocks/models/wresnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, depth, num_classes, widen_factor, dropout_rate, norm)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/models/wresnet.py\u001b[0m in \u001b[0;36m_wideLayer\u001b[0;34m(self, out_planes, num_blocks, dropout_rate, stride)\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         \u001b[0mout_planes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                         \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                         stride=stride, padding=1, norm=self.norm, conv_last=True))\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_planes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_planes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/resblock.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, norm, kernel_size, stride, padding, reflection_pad, dropout_rate, conv_last)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodules\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         modules.append(ConvNormRelu(in_channels, out_channels, norm=norm, kernel_size=kernel_size,\n\u001b[0;32m---> 13\u001b[0;31m                              stride=1, padding=padding, conv_last=conv_last))\n\u001b[0m\u001b[1;32m     14\u001b[0m         modules.append(ConvNorm(out_channels, out_channels, norm=norm, kernel_size=kernel_size,\n\u001b[1;32m     15\u001b[0m                              stride=stride, padding=padding, conv_last= conv_last))\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/convnormrelu.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, norm, groups_size, conv_last, act)\u001b[0m\n\u001b[1;32m     46\u001b[0m             conv2d = WeightNormConv2d(in_channels, out_channels, kernel_size,\n\u001b[1;32m     47\u001b[0m                                           \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                                           bias, padding_mode)\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MWN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/weightnorm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeightNormConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         self.conv = Weight_norm(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n\u001b[0m\u001b[1;32m     11\u001b[0m                               \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                               bias=bias, padding_mode=padding_mode))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Weight_norm' is not defined"
     ]
    }
   ],
   "source": [
    "WideResNet(depth=16, num_classes=10, widen_factor=2,dropout_rate=0.3,norm='WN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
