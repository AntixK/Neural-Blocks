{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm_notebook\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "PATH = '/home/antixk/Anand/' #'/home/robot/Anand/'\n",
    "sys.path.append(PATH)\n",
    "\n",
    "from NeuralBlocks.models.wresnet import WideResNet\n",
    "# from NeuralBlocks.models.densenet import DenseNet\n",
    "\n",
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# net1 = DenseNet(3, 10, norm='BN')\n",
    "# net2 = WideResNet(depth=22, num_classes=10, widen_factor=5,dropout_rate=0.3,norm='BN')\n",
    "\n",
    "# print(count_parameters(net1), count_parameters(net2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2456)\n",
    "# cudnn.deterministic = True\n",
    "cudnn.benchmark = True\n",
    "np.random.seed(2456)\n",
    "\n",
    "NUM_EPOCH = 200\n",
    "BATCH_SIZE = 128\n",
    "CHECKPOINT_INTERVAL = 100\n",
    "LRS = [0.0001, 0.001, 0.01]\n",
    "NORMS =[None,'BN', 'SN', 'WN', 'MWN', 'MSN', 'MSNTReLU', 'MWNTReLU']\n",
    "DATA_PATH = PATH+\"NeuralBlocks/data_utils/datasets/SVHN/\"\n",
    "SAVE_PATH = PATH+\"NeuralBlocks/experiments/SVHN/\"\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/robot-i9/Anand/NeuralBlocks/data_utils/datasets/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: /home/robot-i9/Anand/NeuralBlocks/data_utils/datasets/SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "trainset = torchvision.datasets.SVHN(root=DATA_PATH, download=True, transform=transform, split='train')\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.SVHN(root=DATA_PATH, download=True, transform=transform, split='test')\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        train_loss_log.append(train_loss/(batch_idx+1))\n",
    "        train_acc_log.append( 100.*correct/total)\n",
    "        \n",
    "        if(batch_idx%CHECKPOINT_INTERVAL==0):\n",
    "             print(\"Train Epoch [{:3d}/{:3d}]Batch [{:3d}/{:3d}] Loss: {:.3f} Acc {:.3f}%\".format(epoch, NUM_EPOCH,batch_idx, len(trainloader),\n",
    "                train_loss/(batch_idx+1), 100.*correct/total))\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            test_loss_log.append(test_loss/(batch_idx+1))\n",
    "            test_acc_log.append( 100.*correct/total)\n",
    "        \n",
    "            if(batch_idx%CHECKPOINT_INTERVAL==0):\n",
    "                print(\"Test Epoch [{:3d}/{:3d}]Batch [{:3d}/{:3d}] Loss: {:.3f} Acc {:.3f}%\".format(epoch, NUM_EPOCH,batch_idx, len(testloader),\n",
    "                test_loss/(batch_idx+1), 100.*correct/total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(SAVE_PATH+'checkpoint'):\n",
    "            os.mkdir(SAVE_PATH+'checkpoint')\n",
    "        torch.save(state, SAVE_PATH+'checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e667392f59584e1089d7db22b3990b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2e4dc1fc9042fba664f8a127202f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9ce565b0c94430bb7913a692321138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.317 Acc 4.688%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.242 Acc 18.464%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.242 Acc 18.676%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.240 Acc 18.732%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.240 Acc 18.742%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.239 Acc 18.777%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Saving..\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.253 Acc 12.500%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.233 Acc 19.013%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.234 Acc 18.921%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.226 Acc 19.651%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.195 Acc 21.160%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.139 Acc 23.408%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.670 Acc 36.719%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.589 Acc 45.591%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.589 Acc 45.725%\n",
      "Saving..\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.674 Acc 43.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.609 Acc 45.042%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.553 Acc 47.054%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.513 Acc 48.572%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.467 Acc 50.251%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.429 Acc 51.608%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 1.143 Acc 61.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 1.065 Acc 64.635%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 1.062 Acc 64.681%\n",
      "Saving..\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.229 Acc 61.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 1.174 Acc 60.721%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 1.143 Acc 61.762%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 1.124 Acc 62.593%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 1.101 Acc 63.558%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 1.082 Acc 64.236%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.901 Acc 67.969%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.846 Acc 72.502%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.841 Acc 72.466%\n",
      "Saving..\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.988 Acc 67.188%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.929 Acc 69.802%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.909 Acc 70.557%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.892 Acc 71.229%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.879 Acc 71.735%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.868 Acc 72.165%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.812 Acc 75.781%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.739 Acc 76.145%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.731 Acc 76.073%\n",
      "Saving..\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.838 Acc 71.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.757 Acc 75.665%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.759 Acc 75.618%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.751 Acc 75.968%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.740 Acc 76.368%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.729 Acc 76.870%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.597 Acc 83.594%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.578 Acc 81.521%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.569 Acc 81.825%\n",
      "Saving..\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.667 Acc 80.469%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.661 Acc 79.069%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.659 Acc 79.275%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.654 Acc 79.376%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.648 Acc 79.584%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.643 Acc 79.753%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.547 Acc 82.812%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.516 Acc 83.888%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.509 Acc 84.021%\n",
      "Saving..\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.490 Acc 88.281%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.588 Acc 81.706%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.579 Acc 81.751%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.574 Acc 82.021%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.572 Acc 82.097%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.568 Acc 82.250%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.532 Acc 86.719%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.483 Acc 84.800%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.476 Acc 85.075%\n",
      "Saving..\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.719 Acc 78.906%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.543 Acc 83.060%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.540 Acc 83.069%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.536 Acc 83.303%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.527 Acc 83.607%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.523 Acc 83.795%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.437 Acc 88.281%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.417 Acc 87.167%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.411 Acc 87.212%\n",
      "Saving..\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.402 Acc 86.719%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.489 Acc 84.901%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.499 Acc 84.523%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.492 Acc 84.699%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.488 Acc 84.860%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.485 Acc 84.968%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.478 Acc 86.719%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.407 Acc 87.399%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.399 Acc 87.601%\n",
      "Saving..\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.558 Acc 83.594%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.464 Acc 85.504%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.455 Acc 85.961%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.455 Acc 85.932%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.452 Acc 85.941%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.451 Acc 86.036%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.399 Acc 89.062%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.367 Acc 88.800%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.360 Acc 88.899%\n",
      "Saving..\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.588 Acc 81.250%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.417 Acc 87.260%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.429 Acc 86.804%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.426 Acc 86.996%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.429 Acc 86.849%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.426 Acc 86.903%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.425 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.359 Acc 89.271%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.352 Acc 89.230%\n",
      "Saving..\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.292 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.428 Acc 86.649%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.419 Acc 86.952%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.419 Acc 87.041%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.413 Acc 87.188%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.409 Acc 87.330%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.410 Acc 89.062%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.345 Acc 89.681%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.337 Acc 89.817%\n",
      "Saving..\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.385 Acc 87.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.400 Acc 87.848%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.398 Acc 87.935%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.397 Acc 87.788%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.398 Acc 87.734%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.393 Acc 87.901%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.366 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.318 Acc 90.849%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.310 Acc 90.889%\n",
      "Saving..\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.540 Acc 85.938%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.384 Acc 88.513%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.382 Acc 88.398%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.381 Acc 88.416%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.377 Acc 88.517%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.376 Acc 88.464%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.389 Acc 92.188%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.318 Acc 90.803%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.311 Acc 90.711%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.339 Acc 90.625%\n",
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.364 Acc 88.869%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.364 Acc 88.740%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.366 Acc 88.777%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.363 Acc 88.862%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.363 Acc 88.882%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.415 Acc 89.062%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.316 Acc 91.027%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.308 Acc 91.107%\n",
      "Saving..\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.384 Acc 85.156%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.356 Acc 89.310%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.354 Acc 89.171%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.349 Acc 89.314%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.344 Acc 89.524%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.346 Acc 89.457%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.378 Acc 89.844%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.310 Acc 90.927%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.303 Acc 90.959%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.335 Acc 89.844%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.334 Acc 89.681%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.338 Acc 89.688%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.337 Acc 89.634%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.335 Acc 89.707%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.338 Acc 89.650%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.374 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.295 Acc 91.406%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.288 Acc 91.515%\n",
      "Saving..\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.370 Acc 86.719%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.334 Acc 89.790%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.327 Acc 90.042%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.328 Acc 90.028%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.332 Acc 89.877%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.329 Acc 89.972%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.339 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.276 Acc 92.087%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.268 Acc 92.230%\n",
      "Saving..\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.334 Acc 91.406%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.338 Acc 90.138%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.318 Acc 90.427%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.318 Acc 90.472%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.320 Acc 90.354%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.320 Acc 90.333%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.268 Acc 92.141%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.260 Acc 92.463%\n",
      "Saving..\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.409 Acc 88.281%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.310 Acc 90.370%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.309 Acc 90.505%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.312 Acc 90.503%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.308 Acc 90.607%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.313 Acc 90.461%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.321 Acc 92.188%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.271 Acc 92.443%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.262 Acc 92.522%\n",
      "Saving..\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.315 Acc 91.406%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.304 Acc 90.726%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.313 Acc 90.528%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.308 Acc 90.692%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.305 Acc 90.771%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.304 Acc 90.818%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.294 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.262 Acc 92.830%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.253 Acc 92.903%\n",
      "Saving..\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.311 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.283 Acc 91.213%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.290 Acc 91.282%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.294 Acc 91.149%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.297 Acc 91.007%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.298 Acc 91.001%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.341 Acc 90.625%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.257 Acc 92.675%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.251 Acc 92.763%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.303 Acc 89.844%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.284 Acc 91.615%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.292 Acc 91.262%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.291 Acc 91.310%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.288 Acc 91.381%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.291 Acc 91.349%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.305 Acc 92.188%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.252 Acc 93.000%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.242 Acc 93.206%\n",
      "Saving..\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.302 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.294 Acc 91.329%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.288 Acc 91.449%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.286 Acc 91.450%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.287 Acc 91.500%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.284 Acc 91.517%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.260 Acc 92.698%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.252 Acc 92.821%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.393 Acc 89.062%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.280 Acc 91.522%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.282 Acc 91.453%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.284 Acc 91.476%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.278 Acc 91.619%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.280 Acc 91.603%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.253 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.238 Acc 93.502%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.230 Acc 93.641%\n",
      "Saving..\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.277 Acc 91.638%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.282 Acc 91.651%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.277 Acc 91.772%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.276 Acc 91.833%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.274 Acc 91.893%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.249 Acc 92.915%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.243 Acc 93.050%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.369 Acc 89.844%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.272 Acc 92.102%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.268 Acc 92.199%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.270 Acc 92.060%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.270 Acc 92.018%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.271 Acc 91.949%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.311 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.239 Acc 93.379%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.234 Acc 93.560%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.265 Acc 90.625%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.268 Acc 91.754%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.269 Acc 91.869%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.269 Acc 91.962%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.269 Acc 91.924%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.268 Acc 91.991%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.303 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.242 Acc 93.680%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.234 Acc 93.692%\n",
      "Saving..\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.351 Acc 88.281%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.264 Acc 92.126%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.258 Acc 92.265%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.258 Acc 92.286%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.259 Acc 92.273%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.237 Acc 93.502%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.231 Acc 93.567%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.190 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.257 Acc 92.713%\n",
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.255 Acc 92.568%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.258 Acc 92.382%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.257 Acc 92.443%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.258 Acc 92.403%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.300 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.231 Acc 93.827%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.224 Acc 93.886%\n",
      "Saving..\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.285 Acc 91.406%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.262 Acc 92.396%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.253 Acc 92.483%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.255 Acc 92.416%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.256 Acc 92.441%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.256 Acc 92.398%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.230 Acc 92.188%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.217 Acc 94.199%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.210 Acc 94.209%\n",
      "Saving..\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.235 Acc 92.969%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.247 Acc 92.667%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.247 Acc 92.580%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.252 Acc 92.553%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.251 Acc 92.571%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.253 Acc 92.526%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.311 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.243 Acc 93.433%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.237 Acc 93.408%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.254 Acc 92.188%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.236 Acc 92.567%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.242 Acc 92.615%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.243 Acc 92.574%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.246 Acc 92.593%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.249 Acc 92.560%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.225 Acc 94.044%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.217 Acc 94.045%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.268 Acc 89.844%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.262 Acc 92.118%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.250 Acc 92.510%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.246 Acc 92.678%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.245 Acc 92.754%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.245 Acc 92.705%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.224 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.221 Acc 94.214%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.216 Acc 94.205%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.195 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.243 Acc 92.860%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.243 Acc 92.918%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.243 Acc 92.888%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.243 Acc 92.885%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.244 Acc 92.883%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.215 Acc 94.261%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.208 Acc 94.325%\n",
      "Saving..\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.238 Acc 93.100%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.241 Acc 92.895%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.239 Acc 92.979%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.238 Acc 92.957%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.238 Acc 92.997%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.235 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.224 Acc 93.851%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.219 Acc 93.812%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.227 Acc 93.154%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.240 Acc 92.868%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.240 Acc 92.886%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.237 Acc 93.006%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.237 Acc 93.000%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.212 Acc 94.570%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.205 Acc 94.547%\n",
      "Saving..\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.218 Acc 93.301%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.224 Acc 93.225%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.236%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.230 Acc 93.216%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.231 Acc 93.167%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.215 Acc 94.384%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.208 Acc 94.380%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.359 Acc 86.719%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.223 Acc 93.216%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.230 Acc 93.116%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.228 Acc 93.221%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.230 Acc 93.150%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.230 Acc 93.162%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.231 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.225 Acc 94.013%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.219 Acc 94.045%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.217 Acc 93.541%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.223 Acc 93.311%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.223 Acc 93.407%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.225 Acc 93.366%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.228 Acc 93.329%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.237 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.216 Acc 94.338%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.209 Acc 94.306%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.389 Acc 93.750%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.237 Acc 93.340%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.235 Acc 93.315%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.229 Acc 93.428%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.229 Acc 93.337%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.228 Acc 93.309%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.206 Acc 94.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.201 Acc 94.535%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.177 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.226 Acc 93.626%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.224 Acc 93.513%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.224 Acc 93.610%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.222 Acc 93.643%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.223 Acc 93.521%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.218 Acc 92.969%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.212 Acc 94.392%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.205 Acc 94.547%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.203 Acc 94.199%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.211 Acc 93.979%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.214 Acc 93.794%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.216 Acc 93.719%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.219 Acc 93.633%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.234 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.202 Acc 94.879%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.197 Acc 94.741%\n",
      "Saving..\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.278 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.220 Acc 93.209%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.219 Acc 93.373%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.219 Acc 93.511%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.222 Acc 93.534%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.220 Acc 93.536%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.195 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.208 Acc 94.609%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.203 Acc 94.632%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.292 Acc 90.625%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.222 Acc 93.464%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.219 Acc 93.711%\n",
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.216 Acc 93.758%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.214 Acc 93.748%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.216 Acc 93.703%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.266 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.208 Acc 94.616%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.203 Acc 94.590%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.205 Acc 94.144%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.212 Acc 93.902%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.210 Acc 93.908%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.212 Acc 93.869%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.214 Acc 93.873%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.198 Acc 94.732%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.194 Acc 94.796%\n",
      "Saving..\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.207 Acc 93.858%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.204 Acc 94.014%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.211 Acc 93.911%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.212 Acc 93.816%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.211 Acc 93.840%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.215 Acc 94.438%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.210 Acc 94.454%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.207 Acc 93.851%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.210 Acc 93.808%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.210 Acc 93.781%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.212 Acc 93.762%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.212 Acc 93.725%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.200 Acc 94.748%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.193 Acc 94.885%\n",
      "Saving..\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.203 Acc 94.090%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.206 Acc 93.917%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.208 Acc 93.926%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.208 Acc 93.859%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.199 Acc 94.887%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.193 Acc 94.939%\n",
      "Saving..\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.219 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.208 Acc 93.982%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.207 Acc 94.007%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.210 Acc 93.849%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.208 Acc 93.947%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.207 Acc 93.959%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.197 Acc 95.065%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.191 Acc 94.998%\n",
      "Saving..\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.285 Acc 91.406%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.207 Acc 93.967%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.208 Acc 93.863%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.208 Acc 93.836%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.207 Acc 93.857%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.206 Acc 93.948%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.195 Acc 94.879%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.189 Acc 94.873%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.194 Acc 94.230%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.198 Acc 94.139%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.200 Acc 94.121%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.202 Acc 94.130%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.202 Acc 94.074%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.200 Acc 94.833%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.195 Acc 94.885%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.197 Acc 94.431%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.210 Acc 94.061%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.204 Acc 94.126%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.205 Acc 94.145%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.205 Acc 94.134%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.240 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.206 Acc 94.957%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.200 Acc 95.064%\n",
      "Saving..\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.200 Acc 94.322%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.195 Acc 94.485%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.196 Acc 94.363%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.200 Acc 94.227%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.200 Acc 94.224%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.197 Acc 94.879%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.191 Acc 94.862%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.189 Acc 94.268%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.194 Acc 94.181%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.197 Acc 94.321%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.196 Acc 94.286%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.196 Acc 94.286%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.193 Acc 95.204%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.185 Acc 95.235%\n",
      "Saving..\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.191 Acc 94.601%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.195 Acc 94.376%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.198 Acc 94.326%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.197 Acc 94.344%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.196 Acc 94.360%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.199 Acc 95.011%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.191 Acc 95.095%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.169 Acc 91.406%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.189 Acc 94.570%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.192 Acc 94.562%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.192 Acc 94.529%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.194 Acc 94.479%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.195 Acc 94.405%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.237 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.206 Acc 95.011%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.200 Acc 95.017%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.192 Acc 94.493%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.191 Acc 94.625%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.191 Acc 94.612%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.193 Acc 94.535%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.194 Acc 94.455%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.241 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.191 Acc 95.220%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.185 Acc 95.235%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.300 Acc 90.625%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.192 Acc 94.431%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.191 Acc 94.438%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.191 Acc 94.498%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.191 Acc 94.442%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.191 Acc 94.453%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.195 Acc 95.119%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.190 Acc 95.211%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.280 Acc 89.844%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.180 Acc 94.856%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.180 Acc 94.920%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.184 Acc 94.767%\n",
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.188 Acc 94.631%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.189 Acc 94.592%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.211 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.186 Acc 95.289%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.179 Acc 95.386%\n",
      "Saving..\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.185 Acc 94.655%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.189 Acc 94.617%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.193 Acc 94.534%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.193 Acc 94.484%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.192 Acc 94.500%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.185 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.181 Acc 95.382%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.175 Acc 95.491%\n",
      "Saving..\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.182 Acc 94.678%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.178 Acc 94.893%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.184 Acc 94.801%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.185 Acc 94.761%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.186 Acc 94.712%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.225 Acc 93.750%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.195 Acc 95.019%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.189 Acc 95.099%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.269 Acc 91.406%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.191 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.189 Acc 94.605%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.187 Acc 94.651%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.188 Acc 94.598%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.191 Acc 95.243%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.320%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.191 Acc 94.593%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.186 Acc 94.718%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.633%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.185 Acc 94.658%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.229 Acc 93.750%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.181 Acc 95.464%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.176 Acc 96.094%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.185 Acc 94.779%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.185 Acc 94.803%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.186 Acc 94.684%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.184 Acc 94.771%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.184 Acc 94.753%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.193 Acc 95.104%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.187 Acc 95.219%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.266 Acc 92.969%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.178 Acc 94.933%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.176 Acc 94.951%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.181 Acc 94.778%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.184 Acc 94.734%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.182 Acc 94.803%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.259 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.211 Acc 94.879%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.202 Acc 94.939%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.175 Acc 95.026%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.176 Acc 94.951%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.179 Acc 94.879%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.179 Acc 94.851%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.181 Acc 94.771%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.183 Acc 95.394%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.175 Acc 94.632%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.180 Acc 94.710%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.181 Acc 94.773%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.181 Acc 94.812%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.181 Acc 94.813%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.227 Acc 92.969%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.200 Acc 95.042%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.193 Acc 95.095%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.179 Acc 94.957%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.178 Acc 94.916%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.173 Acc 95.027%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.174 Acc 95.016%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.177 Acc 94.940%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.186 Acc 95.266%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.180 Acc 95.355%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.212 Acc 93.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.176 Acc 94.578%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.173 Acc 94.819%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.172 Acc 94.980%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.172 Acc 94.960%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.173 Acc 94.971%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.182 Acc 95.475%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.176 Acc 95.534%\n",
      "Saving..\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.165 Acc 95.220%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.167 Acc 95.254%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.172 Acc 95.089%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.173 Acc 95.038%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.174 Acc 95.016%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.191 Acc 95.227%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.182 Acc 95.351%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.174 Acc 95.026%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.173 Acc 95.052%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.174 Acc 95.037%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.175 Acc 95.016%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.175 Acc 94.990%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.193 Acc 95.328%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.185 Acc 95.328%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.215 Acc 94.531%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.166 Acc 95.235%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.177 Acc 94.858%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.174 Acc 95.024%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.176 Acc 94.966%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.196 Acc 95.328%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.188 Acc 95.425%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.167 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.166 Acc 95.212%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.170 Acc 95.099%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 95.030%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.173 Acc 95.083%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.173 Acc 95.015%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.192 Acc 95.343%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.183 Acc 95.534%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.164 Acc 95.212%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.162 Acc 95.219%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.164 Acc 95.229%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.167 Acc 95.170%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.170 Acc 95.114%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.183 Acc 95.405%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.491%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.162 Acc 97.656%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.176 Acc 94.817%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.171 Acc 94.943%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.172 Acc 94.954%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.171 Acc 95.036%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.171 Acc 95.074%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.191 Acc 95.212%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.185 Acc 95.250%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.163 Acc 95.537%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.169 Acc 95.320%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.167 Acc 95.271%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.169 Acc 95.164%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.170 Acc 95.143%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.195 Acc 95.189%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 95.169%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.170 Acc 95.212%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.169 Acc 95.159%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.167 Acc 95.217%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.169 Acc 95.157%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.189 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.188 Acc 95.305%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.182 Acc 95.437%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.095 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.168 Acc 95.266%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.173%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.168 Acc 95.183%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.167 Acc 95.198%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.167 Acc 95.211%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.208 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.289%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.178 Acc 95.460%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.158 Acc 95.475%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.161 Acc 95.382%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.164 Acc 95.255%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.165 Acc 95.281%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.676%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Saving..\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.130 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.165 Acc 95.196%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.164 Acc 95.239%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.165 Acc 95.310%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.164 Acc 95.285%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.166 Acc 95.231%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.181 Acc 95.746%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.173 Acc 95.884%\n",
      "Saving..\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.171 Acc 95.282%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.164 Acc 95.301%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.164 Acc 95.341%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.163 Acc 95.299%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.163 Acc 95.317%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.231 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.193 Acc 95.382%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.185 Acc 95.437%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.111 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.164 Acc 95.065%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.161 Acc 95.254%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.164 Acc 95.165%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.165 Acc 95.198%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.165 Acc 95.241%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.222 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.188 Acc 95.398%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.180 Acc 95.546%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.179 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.153 Acc 95.561%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.157 Acc 95.414%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.159 Acc 95.412%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.161 Acc 95.327%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.177 Acc 95.421%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.171 Acc 95.546%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.169 Acc 95.297%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.167 Acc 95.223%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.161 Acc 95.333%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.159 Acc 95.390%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.158 Acc 95.423%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.189 Acc 95.444%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.181 Acc 95.561%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.183 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.163 Acc 95.297%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.160 Acc 95.464%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.157 Acc 95.531%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.159 Acc 95.482%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.161 Acc 95.425%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.187 Acc 95.599%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.181 Acc 95.600%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.154 Acc 95.514%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.156 Acc 95.565%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.156 Acc 95.569%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.157 Acc 95.568%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.157 Acc 95.512%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.174 Acc 95.746%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.167 Acc 95.814%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.154 Acc 95.552%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.156 Acc 95.577%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.156 Acc 95.458%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.157 Acc 95.420%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.158 Acc 95.394%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.197 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.183 Acc 95.568%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.175 Acc 95.627%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.196 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.152 Acc 95.738%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.152 Acc 95.627%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.157 Acc 95.536%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.155 Acc 95.591%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.157 Acc 95.511%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.186 Acc 95.568%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.179 Acc 95.534%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.115 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.152 Acc 95.676%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.155 Acc 95.487%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.156 Acc 95.531%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.154 Acc 95.560%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.156 Acc 95.482%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.174 Acc 95.653%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.168 Acc 95.705%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.147 Acc 95.606%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.150 Acc 95.620%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.154 Acc 95.546%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.155 Acc 95.538%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.155 Acc 95.560%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.189 Acc 95.645%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.181 Acc 95.756%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.200 Acc 92.188%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.152 Acc 95.583%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.153 Acc 95.604%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.155 Acc 95.528%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.155 Acc 95.540%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.154 Acc 95.579%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.193 Acc 95.529%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.186 Acc 95.515%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.184 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.153 Acc 95.568%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.151 Acc 95.569%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.152 Acc 95.554%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.154 Acc 95.581%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.154 Acc 95.579%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.177 Acc 95.717%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.154 Acc 95.552%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.147 Acc 95.690%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.150 Acc 95.684%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.149 Acc 95.690%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.151 Acc 95.620%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.183 Acc 95.506%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.177 Acc 95.662%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.144 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.157 Acc 95.444%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.635%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.149 Acc 95.686%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.150 Acc 95.706%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.151 Acc 95.679%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.187 Acc 95.684%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.179 Acc 95.767%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.157 Acc 95.429%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.152 Acc 95.655%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.156 Acc 95.567%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.155 Acc 95.607%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.153 Acc 95.610%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.191 Acc 95.645%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.183 Acc 95.725%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.160 Acc 95.475%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.153 Acc 95.697%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.153 Acc 95.629%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.153 Acc 95.589%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.150 Acc 95.681%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.180 Acc 95.838%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.171 Acc 95.899%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.123 Acc 93.750%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.140 Acc 95.915%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.148 Acc 95.702%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.149 Acc 95.699%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.185 Acc 95.606%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.176 Acc 95.728%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.143 Acc 95.823%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.150 Acc 95.647%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.148 Acc 95.621%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.149 Acc 95.650%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.149 Acc 95.648%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.199 Acc 95.367%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.191 Acc 95.511%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.140 Acc 96.032%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.148 Acc 95.794%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.148 Acc 95.767%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.147 Acc 95.768%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.148 Acc 95.740%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.178 Acc 95.483%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.170 Acc 95.686%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.141 Acc 96.001%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.140 Acc 95.981%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.141 Acc 95.943%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.142 Acc 95.915%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.146 Acc 95.821%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.190 Acc 95.653%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.181 Acc 95.826%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.194 Acc 97.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.143 Acc 95.846%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.151 Acc 95.709%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.148 Acc 95.738%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.148 Acc 95.749%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.146 Acc 95.765%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.183 Acc 95.668%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.175 Acc 95.841%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.218 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.139 Acc 95.885%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.137 Acc 95.977%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.142 Acc 95.894%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.144 Acc 95.844%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.146 Acc 95.796%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.179 Acc 95.808%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.172 Acc 95.907%\n",
      "Saving..\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.136 Acc 95.939%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.137 Acc 95.981%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.138 Acc 95.954%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.141 Acc 95.897%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.143 Acc 95.857%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.164 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.198 Acc 95.204%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.189 Acc 95.278%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.190 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.142 Acc 95.753%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.142 Acc 95.857%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.144 Acc 95.816%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.142 Acc 95.805%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.143 Acc 95.808%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.180 Acc 95.784%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.171 Acc 95.864%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.139 Acc 95.707%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.141 Acc 95.759%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.140 Acc 95.787%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.141 Acc 95.813%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.143 Acc 95.841%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.178 Acc 95.775%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.136 Acc 96.063%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.134 Acc 96.008%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.141 Acc 95.946%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.140 Acc 95.872%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.142 Acc 95.850%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.184 Acc 95.577%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.143 Acc 95.738%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.144 Acc 95.767%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.139 Acc 95.902%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.141 Acc 95.922%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.140 Acc 95.960%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.189 Acc 95.568%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.181 Acc 95.697%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.134 Acc 96.140%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.141 Acc 95.993%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.141 Acc 95.977%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.142 Acc 95.959%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.142 Acc 95.942%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.185 Acc 95.521%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.177 Acc 95.616%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.132 Acc 95.869%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.130 Acc 96.082%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.137 Acc 95.964%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.139 Acc 95.924%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.141 Acc 95.866%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.192 Acc 95.668%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.183 Acc 95.798%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.139 Acc 96.040%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.139 Acc 95.958%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.140 Acc 95.920%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.141 Acc 95.934%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.141 Acc 95.985%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.179 Acc 95.639%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.138 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.136 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.137 Acc 96.055%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.137 Acc 96.014%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.137 Acc 95.994%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.187 Acc 95.560%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.179 Acc 95.713%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.136 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.128 Acc 96.403%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.134 Acc 96.218%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.137 Acc 96.028%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.189 Acc 95.645%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.183 Acc 95.666%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.128 Acc 96.310%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.130 Acc 96.234%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.133 Acc 96.125%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.136 Acc 96.086%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.181 Acc 95.568%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.174 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.139 Acc 95.955%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.135 Acc 96.140%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.134 Acc 96.125%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.136 Acc 96.016%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.138 Acc 95.961%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.173 Acc 95.919%\n",
      "Saving..\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.137 Acc 96.047%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.134 Acc 95.969%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.133 Acc 96.127%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.134 Acc 96.084%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.134 Acc 96.097%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.188 Acc 95.722%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.181 Acc 95.787%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.130 Acc 96.349%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.134 Acc 96.195%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.134 Acc 96.120%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.138 Acc 96.043%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.137 Acc 96.091%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.179 Acc 95.947%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 96.012%\n",
      "Saving..\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.140 Acc 95.838%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.132 Acc 96.150%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.133 Acc 96.133%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.193 Acc 95.653%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.184 Acc 95.740%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.128 Acc 96.140%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.131 Acc 96.160%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.133 Acc 96.159%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.133 Acc 96.152%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.133 Acc 96.145%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.179 Acc 95.769%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.169 Acc 95.829%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.126 Acc 96.411%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.128 Acc 96.319%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.131 Acc 96.262%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.131 Acc 96.242%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.132 Acc 96.172%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.184 Acc 95.777%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.174 Acc 95.829%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.125 Acc 96.381%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.129 Acc 96.288%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.129 Acc 96.341%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.130 Acc 96.286%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.186 Acc 95.599%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.179 Acc 95.705%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.125 Acc 96.256%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.135 Acc 96.068%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.133 Acc 96.129%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.132 Acc 96.136%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.195 Acc 95.429%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.186 Acc 95.639%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.130 Acc 96.225%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.131 Acc 96.226%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.130 Acc 96.172%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.128 Acc 96.228%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.130 Acc 96.203%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.178 Acc 95.784%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.170 Acc 95.829%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.058 Acc 100.000%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.122 Acc 96.357%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.124 Acc 96.343%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.126 Acc 96.283%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.128 Acc 96.214%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.189 Acc 95.591%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.182 Acc 95.701%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.124 Acc 96.331%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.128 Acc 96.229%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.129 Acc 96.228%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.131 Acc 96.192%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.187 Acc 95.606%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.179 Acc 95.651%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.127 Acc 96.291%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.130 Acc 96.226%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.129 Acc 96.247%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.200 Acc 95.537%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.190 Acc 95.643%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.125 Acc 96.287%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.129 Acc 96.199%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.129 Acc 96.229%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.129 Acc 96.209%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.129 Acc 96.209%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.192 Acc 95.583%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.183 Acc 95.701%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.121 Acc 96.612%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.124 Acc 96.405%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.124 Acc 96.330%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.125 Acc 96.363%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.127 Acc 96.262%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.182 Acc 95.599%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.173 Acc 95.705%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.247 Acc 92.188%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.127 Acc 96.148%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.123 Acc 96.265%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.124 Acc 96.255%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.127 Acc 96.181%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.128 Acc 96.183%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.193 Acc 95.838%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.184 Acc 95.884%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.212 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.117 Acc 96.697%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.122 Acc 96.576%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.126 Acc 96.379%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.127 Acc 96.329%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.128 Acc 96.304%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.190 Acc 95.645%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.182 Acc 95.783%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.124 Acc 96.372%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.125 Acc 96.323%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.127 Acc 96.338%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.126 Acc 96.333%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.127 Acc 96.290%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.120 Acc 97.656%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.196 Acc 95.715%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.187 Acc 95.880%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.123 Acc 96.403%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.125 Acc 96.401%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.123 Acc 96.387%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.126 Acc 96.394%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.125 Acc 96.365%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.192 Acc 95.521%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.183 Acc 95.616%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.146 Acc 94.531%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.129 Acc 96.117%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.129 Acc 96.137%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.128 Acc 96.159%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.126 Acc 96.259%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.125 Acc 96.287%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.188 Acc 95.684%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.179 Acc 95.783%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.178 Acc 94.531%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.124 Acc 96.210%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.126 Acc 96.280%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.125 Acc 96.371%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.123 Acc 96.406%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [134/200]Batch [100/204] Loss: 0.194 Acc 95.537%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.186 Acc 95.627%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.119 Acc 96.457%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.121 Acc 96.354%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.120 Acc 96.408%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.121 Acc 96.396%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.123 Acc 96.325%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.189 Acc 95.514%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.178 Acc 95.690%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.123 Acc 96.419%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.123 Acc 96.331%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.122 Acc 96.333%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.123 Acc 96.287%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.123 Acc 96.304%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.203 Acc 95.622%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.193 Acc 95.725%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.072 Acc 96.094%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.128 Acc 96.234%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.124 Acc 96.325%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.122 Acc 96.363%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.122 Acc 96.395%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.201 Acc 95.568%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.193 Acc 95.643%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.119 Acc 96.364%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.122 Acc 96.276%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.123 Acc 96.270%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.121 Acc 96.351%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.121 Acc 96.384%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.185 Acc 95.815%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.177 Acc 95.892%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.094 Acc 95.312%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.114 Acc 96.481%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.124 Acc 96.405%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.122 Acc 96.506%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.121 Acc 96.509%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.120 Acc 96.533%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.190 Acc 95.800%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.182 Acc 95.798%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.113 Acc 96.651%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.116 Acc 96.533%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.119 Acc 96.447%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.118 Acc 96.458%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.120 Acc 96.452%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.186 Acc 95.637%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.177 Acc 95.864%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.065 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.118 Acc 96.504%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.119 Acc 96.501%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.120 Acc 96.493%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.121 Acc 96.445%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.175 Acc 95.312%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.195 Acc 95.614%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.186 Acc 95.631%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.241 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.118 Acc 96.635%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.120 Acc 96.638%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.119 Acc 96.636%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.117 Acc 96.672%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.119 Acc 96.563%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.189 Acc 95.684%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.177 Acc 95.837%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.116 Acc 96.650%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.119 Acc 96.553%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.119 Acc 96.521%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.186 Acc 95.722%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.118 Acc 96.511%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.116 Acc 96.514%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.116 Acc 96.558%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.184 Acc 95.529%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.174 Acc 95.736%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.110 Acc 96.705%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.112 Acc 96.692%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.112 Acc 96.597%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.114 Acc 96.571%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.116 Acc 96.529%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.194 Acc 95.722%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.185 Acc 95.810%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.115 Acc 96.634%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.113 Acc 96.657%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.114 Acc 96.621%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.190 Acc 95.808%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.180 Acc 95.977%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.115 Acc 96.388%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.116 Acc 96.482%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.115 Acc 96.512%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.114 Acc 96.598%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.115 Acc 96.568%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.191 Acc 95.328%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.184 Acc 95.491%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.106 Acc 96.720%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.112 Acc 96.642%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.113 Acc 96.654%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.117 Acc 96.562%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.194 Acc 95.746%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.185 Acc 95.876%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.061 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.117 Acc 96.720%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.116 Acc 96.599%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.117 Acc 96.587%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.116 Acc 96.622%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.115 Acc 96.574%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.203 Acc 95.622%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [149/200]Batch [200/204] Loss: 0.191 Acc 95.725%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.111 Acc 96.615%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.110 Acc 96.670%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.110 Acc 96.698%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.112 Acc 96.655%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.186 Acc 95.699%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.154 Acc 96.875%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.112 Acc 96.674%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.108 Acc 96.833%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.111 Acc 96.752%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.115 Acc 96.604%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.199 Acc 95.514%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.189 Acc 95.658%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.110 Acc 96.805%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.112 Acc 96.688%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.114 Acc 96.671%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.183 Acc 95.815%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.174 Acc 95.903%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.109 Acc 96.589%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.109 Acc 96.657%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.111 Acc 96.667%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.112 Acc 96.645%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.111 Acc 96.643%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.182 Acc 95.661%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.174 Acc 95.798%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.127 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.111 Acc 96.635%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.116 Acc 96.552%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.112 Acc 96.631%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.112 Acc 96.649%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.111 Acc 96.710%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.192 Acc 95.730%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.946%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.110 Acc 96.751%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.109 Acc 96.723%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.112 Acc 96.657%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.113 Acc 96.631%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.112 Acc 96.685%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 95.862%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.181 Acc 95.934%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.103 Acc 97.068%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.107 Acc 96.856%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.108 Acc 96.779%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.109 Acc 96.783%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.108 Acc 96.778%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.189 Acc 95.792%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.179 Acc 95.876%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.099 Acc 97.092%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.105 Acc 96.949%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.110 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.110 Acc 96.749%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.186 Acc 95.653%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.176 Acc 95.806%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.102 Acc 96.890%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.109 Acc 96.821%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.109 Acc 96.750%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.109 Acc 96.741%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.110 Acc 96.711%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.188 Acc 95.900%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.178 Acc 95.942%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.140 Acc 93.750%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.107 Acc 96.759%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.108 Acc 96.766%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.109 Acc 96.753%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.112 Acc 96.668%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.110 Acc 96.708%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.185 Acc 95.730%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.176 Acc 95.884%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.101 Acc 96.960%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.107 Acc 96.859%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.109 Acc 96.714%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.111 Acc 96.688%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.110 Acc 96.758%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.202 Acc 95.529%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.192 Acc 95.612%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.109 Acc 96.712%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.112 Acc 96.623%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.113 Acc 96.625%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.110 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.195 Acc 95.722%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.184 Acc 95.872%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.111 Acc 96.612%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.107 Acc 96.743%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.106 Acc 96.771%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.108 Acc 96.756%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.108 Acc 96.738%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.189 Acc 95.753%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.180 Acc 95.899%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.063 Acc 96.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.105 Acc 96.937%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.106 Acc 96.859%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.108 Acc 96.793%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.108 Acc 96.755%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.197 Acc 95.869%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.188 Acc 95.950%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.104 Acc 97.177%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.108 Acc 96.964%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.108 Acc 96.904%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.107 Acc 96.877%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.195 Acc 95.815%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.183 Acc 95.981%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.098 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.101 Acc 97.084%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.106 Acc 96.922%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.103 Acc 96.901%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.104 Acc 96.838%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.115 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.194 Acc 95.838%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.185 Acc 95.884%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.157 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.108 Acc 96.883%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.101 Acc 96.937%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.103 Acc 96.909%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.104 Acc 96.920%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.191 Acc 95.699%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.183 Acc 95.748%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.097 Acc 97.084%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.106 Acc 96.871%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.106 Acc 96.846%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.105 Acc 96.877%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.105 Acc 96.887%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.201 Acc 95.900%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.192 Acc 95.977%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.103 Acc 96.832%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.104 Acc 96.779%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.104 Acc 96.846%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.103 Acc 96.867%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.777%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.186 Acc 95.767%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.106 Acc 96.674%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.102 Acc 96.883%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.104 Acc 96.849%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.103 Acc 96.908%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.105 Acc 96.813%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.195 Acc 95.838%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.186 Acc 95.872%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.105 Acc 96.879%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.106 Acc 96.865%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.107 Acc 96.797%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.106 Acc 96.816%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.194 Acc 95.908%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.183 Acc 96.012%\n",
      "Saving..\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.102 Acc 97.022%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.104 Acc 96.953%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.105 Acc 96.803%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.105 Acc 96.769%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.211 Acc 95.514%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.201 Acc 95.674%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.097 Acc 97.014%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.103 Acc 96.836%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.102 Acc 96.880%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.103 Acc 96.893%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.104 Acc 96.883%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.205 Acc 95.761%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.195 Acc 95.763%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.102 Acc 97.022%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.102 Acc 96.953%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.102 Acc 96.935%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.103 Acc 96.898%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.191 Acc 95.676%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.181 Acc 95.853%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.175 Acc 93.750%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.102 Acc 96.991%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.102 Acc 96.871%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.103 Acc 96.820%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.104 Acc 96.826%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.104 Acc 96.839%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.202 Acc 95.614%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.191 Acc 95.678%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.097 Acc 97.068%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.101 Acc 97.007%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.099 Acc 97.058%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.100 Acc 97.045%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.183 Acc 95.896%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.094 Acc 97.045%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.096 Acc 97.042%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.097 Acc 97.000%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.102 Acc 96.877%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.102 Acc 96.900%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.208 Acc 95.583%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.198 Acc 95.705%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.091 Acc 97.362%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.094 Acc 97.221%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.095 Acc 97.186%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.096 Acc 97.159%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.098 Acc 97.075%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.201 Acc 95.722%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.189 Acc 95.818%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.039 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.103 Acc 96.790%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.095 Acc 96.937%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.097 Acc 96.987%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.099 Acc 96.912%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.100 Acc 96.914%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.190 Acc 95.761%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.180 Acc 95.880%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.099 Acc 96.926%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.100 Acc 96.939%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.100 Acc 96.953%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.203 Acc 95.537%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.190 Acc 95.655%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.095 Acc 97.030%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.100 Acc 96.896%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.100 Acc 96.887%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.101 Acc 96.905%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.203 Acc 95.854%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.193 Acc 95.899%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.098 Acc 97.107%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.099 Acc 97.046%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.100 Acc 96.994%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.101 Acc 96.949%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.100 Acc 96.955%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.216 Acc 95.606%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.203 Acc 95.775%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.092 Acc 97.409%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.100 Acc 97.081%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.099 Acc 97.057%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.099 Acc 97.027%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.100 Acc 97.020%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.212 Acc 95.583%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.201 Acc 95.701%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.218 Acc 92.188%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.092 Acc 97.107%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.095 Acc 97.059%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.096 Acc 97.039%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.097 Acc 97.059%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.197 Acc 95.583%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.187 Acc 95.721%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.093 Acc 97.153%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.097 Acc 97.077%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.097 Acc 97.072%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.096 Acc 97.066%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.096 Acc 97.075%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.206 Acc 95.645%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.194 Acc 95.833%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.095 Acc 97.208%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.092 Acc 97.256%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.094 Acc 97.129%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.097 Acc 97.070%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.099 Acc 97.020%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.196 Acc 95.746%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.186 Acc 95.868%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.101 Acc 97.053%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.099 Acc 97.093%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.098 Acc 97.101%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.096 Acc 97.109%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.201 Acc 95.661%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.814%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.178 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.092 Acc 97.161%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.096 Acc 97.108%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.096 Acc 97.096%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.096 Acc 97.064%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.201 Acc 95.784%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.192 Acc 95.849%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.188 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.096 Acc 97.208%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.096 Acc 97.128%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.095 Acc 97.155%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.098 Acc 97.032%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.203 Acc 95.769%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.190 Acc 95.907%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.095 Acc 97.132%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.095 Acc 97.111%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.096 Acc 97.086%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.198 Acc 95.661%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.187 Acc 95.787%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.095 Acc 97.184%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.092 Acc 97.209%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.094 Acc 97.179%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.095 Acc 97.113%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.095 Acc 97.109%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.222 Acc 95.537%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.209 Acc 95.647%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.099 Acc 97.107%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.093 Acc 97.264%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.092 Acc 97.249%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.094 Acc 97.237%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.096 Acc 97.135%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.203 Acc 95.684%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.191 Acc 95.756%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.093 Acc 97.221%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.094 Acc 97.155%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.095 Acc 97.083%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.096 Acc 97.087%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.661%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.186 Acc 95.822%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.092 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.098 Acc 97.053%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.096 Acc 97.132%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.096 Acc 97.083%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.096 Acc 97.089%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.207 Acc 95.838%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.195 Acc 95.954%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.097 Acc 97.050%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.096 Acc 97.106%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.096 Acc 97.083%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.096 Acc 97.064%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.208 Acc 95.637%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.196 Acc 95.763%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [195/200]Batch [100/573] Loss: 0.097 Acc 97.037%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.094 Acc 97.104%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.095 Acc 97.088%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.095 Acc 97.056%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.096 Acc 97.076%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.215 Acc 95.738%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.202 Acc 95.888%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.141 Acc 93.750%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.092 Acc 96.929%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.091 Acc 97.108%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.091 Acc 97.173%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.091 Acc 97.173%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.202 Acc 95.676%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.192 Acc 95.728%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.089 Acc 97.268%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.092 Acc 97.236%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.094 Acc 97.113%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.095 Acc 97.053%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.195 Acc 95.653%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.184 Acc 95.736%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.173 Acc 91.406%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.085 Acc 97.393%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.089 Acc 97.299%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.091 Acc 97.218%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.092 Acc 97.167%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.093 Acc 97.148%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.202 Acc 95.653%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.190 Acc 95.775%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.090 Acc 97.030%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.091 Acc 97.120%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.093 Acc 97.083%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.093 Acc 97.101%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.094 Acc 97.117%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.214 Acc 95.668%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.202 Acc 95.728%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c21fffee2d744ddb5bee0a3bfae6e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.337 Acc 9.375%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.309 Acc 8.988%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.266 Acc 15.683%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.215 Acc 19.721%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.164 Acc 22.695%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.117 Acc 24.975%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.655 Acc 41.406%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.703 Acc 39.550%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.704 Acc 39.657%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.838 Acc 35.156%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.781 Acc 38.459%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.732 Acc 40.668%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.683 Acc 42.951%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.635 Acc 45.355%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.592 Acc 47.452%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.155 Acc 57.812%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.172 Acc 61.912%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.169 Acc 61.870%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.294 Acc 61.719%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.276 Acc 61.100%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.243 Acc 62.345%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.216 Acc 63.442%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.187 Acc 64.596%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.158 Acc 65.703%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.833 Acc 71.094%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.847 Acc 73.940%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.847 Acc 73.993%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.051 Acc 73.438%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.956 Acc 74.095%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.931 Acc 75.101%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.912 Acc 75.867%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.886 Acc 76.757%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.863 Acc 77.660%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.547 Acc 84.375%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.567 Acc 84.777%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.569 Acc 84.608%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.738 Acc 84.375%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.695 Acc 83.470%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.685 Acc 83.633%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.668 Acc 84.105%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.651 Acc 84.467%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.637 Acc 84.685%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.424 Acc 88.281%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.429 Acc 87.771%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.430 Acc 87.675%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.466 Acc 89.062%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.543 Acc 86.595%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.528 Acc 86.851%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.522 Acc 87.033%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.509 Acc 87.276%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.500 Acc 87.422%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.327 Acc 89.844%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.358 Acc 89.952%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.359 Acc 89.785%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.412 Acc 90.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.443 Acc 88.274%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.445 Acc 88.235%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.435 Acc 88.603%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.429 Acc 88.762%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.424 Acc 88.838%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.299 Acc 90.625%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.307 Acc 91.066%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.308 Acc 90.905%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.409 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.398 Acc 89.016%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.388 Acc 89.424%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.382 Acc 89.610%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.378 Acc 89.668%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.375 Acc 89.710%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.271 Acc 90.625%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.279 Acc 91.785%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.277 Acc 91.877%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.425 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.342 Acc 90.586%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.340 Acc 90.501%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.344 Acc 90.389%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.344 Acc 90.329%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.342 Acc 90.332%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.230 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.256 Acc 92.420%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.258 Acc 92.246%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.349 Acc 90.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.315 Acc 91.143%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.321 Acc 90.948%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.322 Acc 90.929%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.321 Acc 91.009%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.320 Acc 90.965%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.253 Acc 88.281%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.244 Acc 93.023%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.243 Acc 92.922%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.271 Acc 92.188%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.304 Acc 91.190%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.306 Acc 91.212%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.308 Acc 91.154%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.306 Acc 91.241%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.304 Acc 91.286%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.232 Acc 90.625%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.244 Acc 92.891%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.243 Acc 92.728%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.243 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.288 Acc 91.723%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.291 Acc 91.554%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.286 Acc 91.715%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.286 Acc 91.689%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.287 Acc 91.668%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.275 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.238 Acc 93.108%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.237 Acc 92.988%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.452 Acc 85.938%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.277 Acc 92.157%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.274 Acc 92.188%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.277 Acc 92.040%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.276 Acc 91.963%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.275 Acc 91.950%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.239 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.237 Acc 93.309%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.236 Acc 93.210%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.394 Acc 89.844%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.279 Acc 91.847%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.273 Acc 92.071%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.268 Acc 92.245%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.269 Acc 92.168%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.266 Acc 92.242%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.229 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.229 Acc 93.317%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.229 Acc 93.350%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.257 Acc 92.683%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.259 Acc 92.526%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.257 Acc 92.525%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.259 Acc 92.451%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.259 Acc 92.462%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.210 Acc 92.188%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.216 Acc 93.796%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.215 Acc 93.723%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.240 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.247 Acc 93.054%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.254 Acc 92.782%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.249 Acc 92.893%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.250 Acc 92.803%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.251 Acc 92.730%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.282 Acc 89.844%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.223 Acc 93.626%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.221 Acc 93.544%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.379 Acc 91.406%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.247 Acc 92.845%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.249 Acc 92.763%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.248 Acc 92.761%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.248 Acc 92.768%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.246 Acc 92.827%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.185 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.209 Acc 94.067%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.208 Acc 94.014%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.302 Acc 89.062%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.248 Acc 92.744%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.234 Acc 93.148%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.237 Acc 93.073%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.240 Acc 92.971%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.241 Acc 92.920%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.185 Acc 91.406%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.204 Acc 94.369%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.201 Acc 94.232%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.306 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.236 Acc 93.139%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.233 Acc 93.280%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.233 Acc 93.223%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.235 Acc 93.156%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.236 Acc 93.101%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.232 Acc 89.844%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.204 Acc 94.322%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.203 Acc 94.263%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.281 Acc 89.062%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.234 Acc 93.185%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.230 Acc 93.276%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.233 Acc 93.184%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.231 Acc 93.265%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.232 Acc 93.207%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.237 Acc 91.406%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.201 Acc 94.384%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.199 Acc 94.434%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.101 Acc 98.438%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.230 Acc 93.216%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.223 Acc 93.513%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.226 Acc 93.501%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.227 Acc 93.423%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.228 Acc 93.398%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.199 Acc 94.454%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.199 Acc 94.298%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.215 Acc 92.188%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.215 Acc 93.665%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.220 Acc 93.544%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.224 Acc 93.457%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.224 Acc 93.442%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.228 Acc 93.318%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.138 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.203 Acc 94.462%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.201 Acc 94.446%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.291 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.214 Acc 93.533%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.217 Acc 93.614%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.217 Acc 93.633%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.217 Acc 93.635%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.220 Acc 93.588%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.194 Acc 94.701%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.191 Acc 94.601%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.152 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.215 Acc 93.758%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.217 Acc 93.653%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.214 Acc 93.758%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.214 Acc 93.771%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.215 Acc 93.744%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.191 Acc 94.686%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.188 Acc 94.694%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.206 Acc 93.858%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.208 Acc 93.925%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.210 Acc 93.919%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.211 Acc 93.886%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.211 Acc 93.881%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.193 Acc 91.406%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.193 Acc 94.524%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.191 Acc 94.652%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.299 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.207 Acc 93.874%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.204 Acc 94.115%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.207 Acc 94.010%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.208 Acc 93.945%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.208 Acc 93.950%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.187 Acc 94.895%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.185 Acc 94.943%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.207 Acc 93.998%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.207 Acc 94.022%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.206 Acc 94.038%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.207 Acc 93.968%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.207 Acc 93.957%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.187 Acc 95.011%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.186 Acc 95.005%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.169 Acc 92.969%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.192 Acc 94.330%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.196 Acc 94.279%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.196 Acc 94.233%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.201 Acc 94.130%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.203 Acc 94.095%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.194 Acc 94.593%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.195 Acc 94.543%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.199 Acc 93.959%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.201 Acc 94.042%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.202 Acc 94.059%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.203 Acc 94.031%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.202 Acc 94.059%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.192 Acc 94.640%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.191 Acc 94.675%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.291 Acc 90.625%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.194 Acc 94.454%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.199 Acc 94.263%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.198 Acc 94.251%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.201 Acc 94.177%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.202 Acc 94.163%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.221 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.181 Acc 95.158%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.179 Acc 95.126%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.191 Acc 94.578%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.196 Acc 94.286%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.196 Acc 94.295%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.197 Acc 94.221%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.196 Acc 94.261%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.183 Acc 95.227%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.181 Acc 95.122%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.248 Acc 93.750%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.201 Acc 94.183%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.194 Acc 94.380%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.197 Acc 94.347%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.197 Acc 94.362%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.196 Acc 94.343%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.185 Acc 94.926%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.185 Acc 94.908%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.142 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.191 Acc 94.462%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.197 Acc 94.395%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.193 Acc 94.381%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.194 Acc 94.319%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.195 Acc 94.288%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.178 Acc 95.212%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.176 Acc 95.231%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.300 Acc 90.625%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.182 Acc 94.779%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.187 Acc 94.621%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.188 Acc 94.625%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.189 Acc 94.601%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.191 Acc 94.495%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.179 Acc 95.282%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.189 Acc 94.640%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.191 Acc 94.500%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.186 Acc 94.609%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.186 Acc 94.629%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.199 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.189 Acc 95.050%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.186 Acc 95.040%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.280 Acc 93.750%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.189 Acc 94.601%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.187 Acc 94.656%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.184 Acc 94.658%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.187 Acc 94.558%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.173 Acc 95.459%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.171 Acc 95.530%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.180 Acc 94.941%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.186 Acc 94.745%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.186 Acc 94.682%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.187 Acc 94.621%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.186 Acc 94.581%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.174 Acc 95.367%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.172 Acc 95.359%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.207 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.179 Acc 94.856%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.182 Acc 94.788%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.181 Acc 94.884%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.183 Acc 94.765%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.184 Acc 94.717%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.177 Acc 95.328%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.172 Acc 95.433%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.204 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.179 Acc 94.879%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.178 Acc 94.842%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.179 Acc 94.825%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.180 Acc 94.779%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.180 Acc 94.782%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.178 Acc 95.243%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.174 Acc 95.278%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.181 Acc 92.969%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.185 Acc 94.701%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.179 Acc 94.819%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.178 Acc 94.858%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.179 Acc 94.818%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.179 Acc 94.812%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.107 Acc 96.875%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.168 Acc 95.537%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.165 Acc 95.658%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.182 Acc 94.841%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.181 Acc 94.842%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.179 Acc 94.845%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.179 Acc 94.865%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.172 Acc 95.599%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.169 Acc 95.721%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.148 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.166 Acc 95.189%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.168 Acc 95.025%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.168 Acc 95.087%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.173 Acc 94.983%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.175 Acc 94.899%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.175 Acc 95.529%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.172 Acc 95.449%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.192 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.168 Acc 95.042%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.173 Acc 95.130%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.174 Acc 95.017%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.176 Acc 94.907%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.176 Acc 94.918%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.189 Acc 94.957%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.187 Acc 94.920%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.213 Acc 92.188%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.168 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.170 Acc 95.122%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.173 Acc 94.980%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.172 Acc 95.022%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.171 Acc 95.091%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.177 Acc 95.436%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.175 Acc 95.441%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.189 Acc 92.969%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.173 Acc 95.220%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.170 Acc 95.165%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.169 Acc 95.123%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.172 Acc 95.085%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.172 Acc 95.091%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.169 Acc 95.645%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.168 Acc 95.643%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.198 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.167 Acc 95.196%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.167 Acc 95.138%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.171 Acc 95.061%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.171 Acc 95.028%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.174 Acc 94.976%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.162 Acc 95.684%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.162 Acc 95.674%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.165 Acc 95.142%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.166 Acc 95.103%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.164 Acc 95.167%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.166 Acc 95.092%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.169 Acc 95.079%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.163 Acc 95.653%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.160 Acc 95.686%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.163 Acc 95.088%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.171 Acc 95.126%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.168 Acc 95.185%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.167 Acc 95.155%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.170 Acc 95.072%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.176 Acc 95.498%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.174 Acc 95.487%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.169 Acc 95.243%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.161 Acc 95.355%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.166 Acc 95.264%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.167 Acc 95.233%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.182 Acc 95.258%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.180 Acc 95.347%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.168 Acc 95.243%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.168 Acc 95.165%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.164 Acc 95.300%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.165 Acc 95.258%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.165 Acc 95.292%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.178 Acc 95.382%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.174 Acc 95.429%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.150 Acc 95.692%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.157 Acc 95.511%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.160 Acc 95.419%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.162 Acc 95.346%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.165 Acc 95.258%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.163 Acc 95.777%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.161 Acc 95.888%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.162 Acc 95.227%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.163 Acc 95.118%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.163 Acc 95.167%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.162 Acc 95.258%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.164 Acc 95.253%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.176 Acc 95.429%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.174 Acc 95.476%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.165 Acc 95.270%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.166 Acc 95.300%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.165 Acc 95.299%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.164 Acc 95.345%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.166 Acc 95.676%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.163 Acc 95.728%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.147 Acc 95.738%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.152 Acc 95.713%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.154 Acc 95.621%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.158 Acc 95.552%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.160 Acc 95.515%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.170 Acc 95.552%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.168 Acc 95.569%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.214 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.152 Acc 95.674%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.152 Acc 95.691%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.155 Acc 95.599%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.160 Acc 95.472%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.167 Acc 95.699%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.162 Acc 95.752%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.320 Acc 92.188%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.154 Acc 95.498%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.156 Acc 95.410%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.159 Acc 95.331%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.159 Acc 95.375%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.159 Acc 95.362%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.169 Acc 95.583%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.165 Acc 95.573%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.157 Acc 95.575%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.157 Acc 95.612%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.157 Acc 95.528%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.157 Acc 95.488%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.156 Acc 95.506%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.173 Acc 95.568%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.171 Acc 95.542%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.149 Acc 95.436%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.155 Acc 95.340%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.155 Acc 95.450%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.155 Acc 95.451%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.157 Acc 95.439%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.170 Acc 95.599%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.166 Acc 95.713%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.161 Acc 95.452%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.155 Acc 95.581%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.157 Acc 95.541%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.157 Acc 95.560%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.159 Acc 95.501%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.169 Acc 95.498%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.149 Acc 95.645%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.150 Acc 95.666%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.153 Acc 95.653%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.154 Acc 95.566%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.156 Acc 95.545%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.168 Acc 95.738%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.164 Acc 95.814%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.153 Acc 95.591%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.155 Acc 95.484%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.152 Acc 95.608%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.153 Acc 95.642%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.154 Acc 95.590%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.168 Acc 95.599%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.162 Acc 95.791%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.152 Acc 95.800%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.155 Acc 95.655%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.152 Acc 95.629%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.152 Acc 95.611%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.152 Acc 95.589%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.192 Acc 95.166%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.187 Acc 95.114%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.145 Acc 95.877%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.145 Acc 95.837%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.148 Acc 95.738%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.150 Acc 95.667%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.151 Acc 95.613%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.164 Acc 95.769%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.158 Acc 95.923%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.174 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.142 Acc 95.800%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.147 Acc 95.748%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.150 Acc 95.689%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.150 Acc 95.675%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.149 Acc 95.724%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.164 Acc 95.877%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.160 Acc 95.896%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.143 Acc 95.924%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.145 Acc 95.767%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.147 Acc 95.736%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.149 Acc 95.749%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.150 Acc 95.721%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.163 Acc 95.777%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.161 Acc 95.826%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.135 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.146 Acc 95.947%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.145 Acc 95.911%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.148 Acc 95.787%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.148 Acc 95.784%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.149 Acc 95.768%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.161 Acc 96.024%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.158 Acc 95.997%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.137 Acc 95.970%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.144 Acc 95.860%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.146 Acc 95.799%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.194 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.177 Acc 95.511%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.141 Acc 96.194%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.143 Acc 95.896%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.141 Acc 95.907%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.141 Acc 95.899%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.144 Acc 95.802%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.174 Acc 95.568%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.168 Acc 95.670%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.141 Acc 95.962%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.142 Acc 95.885%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.144 Acc 95.874%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.180 Acc 95.521%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.569%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.129 Acc 96.334%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.137 Acc 96.024%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.139 Acc 95.982%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.141 Acc 95.913%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.142 Acc 95.888%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.171 Acc 95.620%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.148 Acc 95.862%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.142 Acc 95.973%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.144 Acc 95.922%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.142 Acc 95.952%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.140 Acc 95.989%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.134 Acc 96.071%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.139 Acc 96.039%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.142 Acc 95.918%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.144 Acc 95.833%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.163 Acc 95.869%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.161 Acc 95.880%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.141 Acc 96.016%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.142 Acc 95.893%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.142 Acc 95.880%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.171 Acc 95.722%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.787%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.136 Acc 95.947%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.134 Acc 96.140%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.135 Acc 96.044%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.137 Acc 96.107%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.139 Acc 96.045%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.169 Acc 95.560%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 95.592%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.143 Acc 95.777%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.139 Acc 96.051%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.140 Acc 96.003%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.138 Acc 96.078%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.140 Acc 96.002%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.170 Acc 95.709%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.136 Acc 96.035%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.139 Acc 95.967%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.137 Acc 96.045%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.140 Acc 95.966%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.169 Acc 95.684%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.165 Acc 95.775%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.131 Acc 96.101%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.132 Acc 96.140%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.135 Acc 96.057%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.138 Acc 96.049%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.159 Acc 95.931%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.155 Acc 95.977%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.128 Acc 96.272%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.133 Acc 96.257%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.137 Acc 96.138%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.137 Acc 96.129%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.137 Acc 96.130%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.158 Acc 95.893%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.158 Acc 95.962%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.127 Acc 96.504%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.133 Acc 96.137%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.138 Acc 95.926%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.138 Acc 95.966%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.168 Acc 95.838%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.131 Acc 96.195%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.132 Acc 96.166%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.133 Acc 96.154%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.134 Acc 96.095%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.178 Acc 96.094%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.171 Acc 95.692%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.806%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.203 Acc 93.750%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.136 Acc 95.934%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.136 Acc 95.977%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.135 Acc 96.033%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.136 Acc 96.010%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.171 Acc 95.738%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.133 Acc 96.442%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.133 Acc 96.261%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.134 Acc 96.190%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.136 Acc 96.166%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.135 Acc 96.145%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.146 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.175 Acc 95.831%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.171 Acc 95.787%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.133 Acc 96.194%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.137 Acc 96.105%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.136 Acc 96.107%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.135 Acc 96.148%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.133 Acc 96.128%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.158 Acc 95.993%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.157 Acc 96.004%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.125 Acc 96.380%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.126 Acc 96.314%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.129 Acc 96.244%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.132 Acc 96.114%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.168 Acc 95.947%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.164 Acc 95.950%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.203 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.128 Acc 96.304%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.130 Acc 96.265%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.135 Acc 96.125%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.134 Acc 96.117%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.166 Acc 95.885%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.161 Acc 95.989%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.121 Acc 98.438%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.129 Acc 96.132%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.125 Acc 96.296%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.125 Acc 96.395%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.126 Acc 96.349%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.129 Acc 96.273%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.166 Acc 95.738%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.163 Acc 95.853%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.128 Acc 96.241%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.128 Acc 96.253%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.131 Acc 96.234%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.131 Acc 96.211%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.091 Acc 95.312%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.155 Acc 96.148%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.153 Acc 96.175%\n",
      "Saving..\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.127 Acc 96.465%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.129 Acc 96.265%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.126 Acc 96.353%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.126 Acc 96.363%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.129 Acc 96.314%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.163 Acc 95.893%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.158 Acc 96.024%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.124 Acc 96.875%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.124 Acc 96.388%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.125 Acc 96.315%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.125 Acc 96.377%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.126 Acc 96.367%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.127 Acc 96.321%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.170 Acc 95.869%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.165 Acc 95.919%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.124 Acc 96.511%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.126 Acc 96.358%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.128 Acc 96.353%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.128 Acc 96.386%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.128 Acc 96.396%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.167 Acc 96.055%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.162 Acc 96.137%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.119 Acc 96.519%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.121 Acc 96.498%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.125 Acc 96.390%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.128 Acc 96.259%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.128 Acc 96.268%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.169 Acc 95.763%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.122 Acc 96.467%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.124 Acc 96.353%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.125 Acc 96.359%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.127 Acc 96.334%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.164 Acc 95.962%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.158 Acc 96.035%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.124 Acc 96.504%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.126 Acc 96.405%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.127 Acc 96.353%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.128 Acc 96.324%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.128 Acc 96.292%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.173 Acc 95.645%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.171 Acc 95.705%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.124 Acc 96.473%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.121 Acc 96.506%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.122 Acc 96.468%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.124 Acc 96.464%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.126 Acc 96.376%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.176 Acc 95.575%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.171 Acc 95.767%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.121 Acc 96.511%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.124 Acc 96.447%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.124 Acc 96.387%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.124 Acc 96.409%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.127 Acc 96.339%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.168 Acc 95.792%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.165 Acc 95.872%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.110 Acc 96.651%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.114 Acc 96.634%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.119 Acc 96.480%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.123 Acc 96.370%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.167 Acc 95.900%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.165 Acc 95.954%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.119 Acc 96.612%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.119 Acc 96.556%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.123 Acc 96.403%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.123 Acc 96.406%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.169 Acc 95.771%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.129 Acc 99.219%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.114 Acc 96.682%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.118 Acc 96.552%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.122 Acc 96.418%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.124 Acc 96.367%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.160 Acc 96.156%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.159 Acc 96.195%\n",
      "Saving..\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.119 Acc 96.542%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.121 Acc 96.556%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.124 Acc 96.468%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.123 Acc 96.478%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.123 Acc 96.457%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.166 Acc 95.916%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.162 Acc 96.016%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.111 Acc 96.790%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.114 Acc 96.813%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.120 Acc 96.548%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.119 Acc 96.596%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.120 Acc 96.498%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.171 Acc 95.692%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.166 Acc 95.775%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.117 Acc 96.705%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.115 Acc 96.770%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.115 Acc 96.724%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.117 Acc 96.655%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.120 Acc 96.537%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.162 Acc 95.993%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.158 Acc 96.070%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.171 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.121 Acc 96.364%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.125 Acc 96.234%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.125 Acc 96.317%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.124 Acc 96.367%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.124 Acc 96.342%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.167 Acc 95.970%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.166 Acc 95.962%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.118 Acc 96.720%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.120 Acc 96.661%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.119 Acc 96.602%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.122 Acc 96.548%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.122 Acc 96.507%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.163 Acc 96.063%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.159 Acc 96.156%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.182 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.115 Acc 96.604%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.116 Acc 96.580%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.117 Acc 96.566%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.120 Acc 96.462%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.121 Acc 96.431%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.166 Acc 95.939%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.163 Acc 96.012%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.114 Acc 96.767%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.112 Acc 96.758%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.115 Acc 96.605%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.119 Acc 96.509%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.121 Acc 96.456%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.163 Acc 96.035%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.120 Acc 96.457%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.119 Acc 96.471%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.120 Acc 96.499%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.120 Acc 96.470%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [105/200]Batch [500/573] Loss: 0.119 Acc 96.510%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.166 Acc 95.985%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.163 Acc 96.008%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.120 Acc 96.517%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.121 Acc 96.525%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.119 Acc 96.546%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.119 Acc 96.538%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.167 Acc 95.823%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.162 Acc 95.946%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.121 Acc 95.312%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.119 Acc 96.566%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.119 Acc 96.673%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.117 Acc 96.704%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.117 Acc 96.647%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.119 Acc 96.569%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.170 Acc 95.854%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.165 Acc 95.973%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.118 Acc 96.627%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.119 Acc 96.549%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.118 Acc 96.493%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.117 Acc 96.517%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.118 Acc 96.502%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.172 Acc 95.699%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.168 Acc 95.787%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.113 Acc 96.697%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.113 Acc 96.708%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.112 Acc 96.735%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.111 Acc 96.766%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.114 Acc 96.668%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.173 Acc 95.746%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.169 Acc 95.833%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.112 Acc 96.751%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.114 Acc 96.745%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.115 Acc 96.696%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.117 Acc 96.635%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.166 Acc 95.884%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.118 Acc 96.560%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.119 Acc 96.548%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.117 Acc 96.589%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.117 Acc 96.548%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.176 Acc 95.514%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.173 Acc 95.713%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.113 Acc 94.531%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.121 Acc 96.442%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.116 Acc 96.603%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.115 Acc 96.608%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.115 Acc 96.602%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.115 Acc 96.593%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.169 Acc 96.009%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.109 Acc 96.798%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.112 Acc 96.667%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.113 Acc 96.672%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.113 Acc 96.686%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.172 Acc 95.862%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.106 Acc 96.798%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.109 Acc 96.828%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.109 Acc 96.803%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.111 Acc 96.730%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.164 Acc 95.908%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.163 Acc 95.997%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.115 Acc 96.635%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.114 Acc 96.595%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.115 Acc 96.643%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.114 Acc 96.668%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 95.893%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.169 Acc 95.934%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.110 Acc 96.759%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.110 Acc 96.782%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.109 Acc 96.867%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.110 Acc 96.834%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.111 Acc 96.761%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.175 Acc 95.730%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.171 Acc 95.853%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.107 Acc 96.786%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.108 Acc 96.826%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.112 Acc 96.705%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.169 Acc 95.792%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.167 Acc 95.880%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.121 Acc 96.395%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.116 Acc 96.704%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.113 Acc 96.771%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.111 Acc 96.762%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.112 Acc 96.756%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.169 Acc 95.854%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.165 Acc 95.962%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.104 Acc 96.860%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.109 Acc 96.782%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.110 Acc 96.766%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.110 Acc 96.776%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.109 Acc 96.767%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.166 Acc 95.955%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.163 Acc 96.059%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.108 Acc 99.219%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.108 Acc 96.983%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.112 Acc 96.727%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.114 Acc 96.696%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.112 Acc 96.709%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.113 Acc 96.680%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.175 Acc 95.854%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.170 Acc 95.958%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.102 Acc 96.852%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.106 Acc 96.909%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.106 Acc 96.879%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.166 Acc 95.924%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.162 Acc 95.989%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.102 Acc 97.192%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.105 Acc 96.941%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.108 Acc 96.805%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.108 Acc 96.815%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.108 Acc 96.814%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.176 Acc 95.606%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.110 Acc 96.712%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.110 Acc 96.649%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.110 Acc 96.668%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.111 Acc 96.668%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.175 Acc 95.769%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.170 Acc 95.853%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.105 Acc 96.824%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.108 Acc 96.737%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.109 Acc 96.696%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.108 Acc 96.752%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.172 Acc 95.838%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.168 Acc 95.868%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.107 Acc 96.999%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.106 Acc 97.023%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.106 Acc 97.015%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.106 Acc 96.941%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.107 Acc 96.880%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.168 Acc 96.024%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.164 Acc 96.109%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.107 Acc 96.782%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.105 Acc 96.854%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.107 Acc 96.811%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.108 Acc 96.746%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.924%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.169 Acc 96.032%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.103 Acc 97.037%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.104 Acc 96.914%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.106 Acc 96.852%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.107 Acc 96.830%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.107 Acc 96.783%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.168 Acc 96.140%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.162 Acc 96.171%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.099 Acc 96.929%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.105 Acc 96.755%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.104 Acc 96.800%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.105 Acc 96.811%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.106 Acc 96.811%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.168 Acc 95.993%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.104 Acc 97.022%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.103 Acc 96.894%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.104 Acc 96.898%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.104 Acc 96.918%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.106 Acc 96.834%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.144 Acc 93.750%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.164 Acc 96.024%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.181 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.100 Acc 97.123%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.101 Acc 97.015%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.101 Acc 97.031%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.104 Acc 96.992%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.106 Acc 96.894%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.167 Acc 95.978%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.163 Acc 96.035%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.105 Acc 96.829%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.103 Acc 96.863%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.106 Acc 96.848%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.106 Acc 96.814%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.171 Acc 95.862%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.169 Acc 95.876%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.110 Acc 96.929%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.109 Acc 96.898%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.108 Acc 96.917%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.106 Acc 96.965%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.106 Acc 96.972%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.181 Acc 95.838%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.175 Acc 95.798%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.108 Acc 96.914%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.102 Acc 97.062%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.102 Acc 97.096%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.103 Acc 97.043%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.103 Acc 97.032%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.171 Acc 96.032%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.950%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.101 Acc 96.921%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.102 Acc 96.940%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.101 Acc 97.013%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.102 Acc 96.965%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.168 Acc 96.086%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.166 Acc 96.098%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.093 Acc 97.130%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.097 Acc 97.163%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.097 Acc 97.194%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.099 Acc 97.066%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.101 Acc 97.029%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.838%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.173 Acc 95.791%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.105 Acc 96.857%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.104 Acc 96.906%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.142 Acc 96.875%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.175 Acc 95.978%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.168 Acc 96.117%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.191 Acc 92.969%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.096 Acc 97.246%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.097 Acc 97.151%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.100 Acc 97.015%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.103 Acc 96.918%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.103 Acc 96.906%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.165 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.175 Acc 95.900%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.171 Acc 95.946%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.137 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.096 Acc 97.022%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.097 Acc 97.062%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.100 Acc 97.000%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.102 Acc 96.956%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.168 Acc 95.934%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.091 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.105 Acc 96.941%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.105 Acc 96.948%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.103 Acc 96.957%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.103 Acc 96.920%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.108 Acc 96.875%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.931%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 96.078%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.096 Acc 97.208%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.098 Acc 97.065%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.100 Acc 97.031%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.101 Acc 97.058%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.101 Acc 97.028%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.177 Acc 95.800%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.169 Acc 96.016%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.090 Acc 97.262%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.099 Acc 97.050%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.100 Acc 97.059%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.100 Acc 97.050%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.101 Acc 97.000%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.167 Acc 96.040%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.162 Acc 96.168%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.096 Acc 97.053%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.097 Acc 97.101%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.099 Acc 97.066%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.101 Acc 97.026%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.174 Acc 95.985%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.167 Acc 96.129%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.099 Acc 97.006%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.096 Acc 97.058%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.097 Acc 97.044%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.100 Acc 96.961%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.100 Acc 96.967%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.182 Acc 95.591%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.176 Acc 95.767%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.089 Acc 97.393%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.096 Acc 97.030%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.099 Acc 97.029%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.169 Acc 95.993%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.163 Acc 96.133%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.099 Acc 96.960%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.093 Acc 97.225%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.095 Acc 97.186%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.095 Acc 97.152%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.097 Acc 97.101%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.177 Acc 95.823%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.171 Acc 95.962%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.097 Acc 97.169%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.101 Acc 96.957%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.100 Acc 97.009%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.182 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.181 Acc 95.808%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.176 Acc 95.826%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.096 Acc 97.184%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.093 Acc 97.229%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.096 Acc 97.148%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.097 Acc 97.037%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.173 Acc 95.939%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.169 Acc 95.981%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.168 Acc 95.312%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.097 Acc 97.153%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.098 Acc 97.100%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.099 Acc 97.116%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.099 Acc 97.099%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.099 Acc 97.110%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.175 Acc 95.684%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.172 Acc 95.779%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.103 Acc 96.728%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.098 Acc 97.011%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.096 Acc 97.114%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.097 Acc 97.089%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.098 Acc 97.078%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.939%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 96.000%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.097 Acc 96.883%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.097 Acc 96.999%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.096 Acc 97.023%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.097 Acc 97.029%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.097 Acc 97.062%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.182 Acc 95.777%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.178 Acc 95.861%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.098 Acc 96.867%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.096 Acc 97.028%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.098 Acc 97.037%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.169 Acc 96.032%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.165 Acc 96.039%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.094 Acc 97.099%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.094 Acc 97.167%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.096 Acc 97.101%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.097 Acc 97.052%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.099 Acc 97.045%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.198 Acc 95.475%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.190 Acc 95.588%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.034 Acc 100.000%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.099 Acc 96.852%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.100 Acc 96.929%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.100 Acc 96.909%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.100 Acc 96.984%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.099 Acc 97.004%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.171 Acc 95.993%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.168 Acc 96.012%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.087 Acc 97.285%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.091 Acc 97.167%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.093 Acc 97.163%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.093 Acc 97.136%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.094 Acc 97.148%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.180 Acc 95.792%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.176 Acc 95.756%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.087 Acc 97.285%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.093 Acc 97.240%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.093 Acc 97.197%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.094 Acc 97.157%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.096 Acc 97.135%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.173 Acc 95.955%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.169 Acc 96.008%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.091 Acc 97.300%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.094 Acc 97.209%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.094 Acc 97.181%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.096 Acc 97.156%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.095 Acc 97.167%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.188 Acc 95.753%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.183 Acc 95.802%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.092 Acc 97.153%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.096 Acc 97.111%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.096 Acc 97.048%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.095 Acc 97.065%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.188 Acc 95.627%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.089 Acc 97.262%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.091 Acc 97.170%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.092 Acc 97.212%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.095 Acc 97.161%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.095 Acc 97.170%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.171 Acc 95.939%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.168 Acc 95.997%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.088 Acc 97.362%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.090 Acc 97.329%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.091 Acc 97.265%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.094 Acc 97.192%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.174 Acc 95.934%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.092 Acc 97.324%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.094 Acc 97.163%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.095 Acc 97.134%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.094 Acc 97.163%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.177 Acc 96.024%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.171 Acc 96.102%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.094 Acc 97.061%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.095 Acc 97.120%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.094 Acc 97.127%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.093 Acc 97.140%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.182 Acc 95.707%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.178 Acc 95.818%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.096 Acc 97.068%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.092 Acc 97.213%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.091 Acc 97.244%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.090 Acc 97.222%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.092 Acc 97.163%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.177 Acc 95.869%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.173 Acc 95.954%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.093 Acc 97.123%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.092 Acc 97.217%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.094 Acc 97.145%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.094 Acc 97.124%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.095 Acc 97.100%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.185 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.182 Acc 95.864%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.088 Acc 97.269%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.089 Acc 97.317%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.090 Acc 97.243%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.180 Acc 95.746%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.176 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.087 Acc 97.370%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.090 Acc 97.277%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.091 Acc 97.247%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.091 Acc 97.240%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.178 Acc 95.730%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.174 Acc 95.783%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.090 Acc 97.153%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.087 Acc 97.252%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.092 Acc 97.171%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.092 Acc 97.181%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.092 Acc 97.188%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.181 Acc 95.800%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.175 Acc 95.884%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.185 Acc 96.875%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.089 Acc 97.163%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.088 Acc 97.228%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.088 Acc 97.232%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.091 Acc 97.185%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.179 Acc 95.985%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.173 Acc 96.059%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.089 Acc 97.361%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.088 Acc 97.368%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.088 Acc 97.350%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.090 Acc 97.274%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.661%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.090 Acc 97.347%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.088 Acc 97.407%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.088 Acc 97.364%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.089 Acc 97.349%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.173 Acc 95.924%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.169 Acc 96.074%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.082 Acc 97.409%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.087 Acc 97.264%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.089 Acc 97.199%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.089 Acc 97.233%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.089 Acc 97.252%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.172 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.185 Acc 95.955%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.182 Acc 95.958%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.200 Acc 95.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.084 Acc 97.509%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.086 Acc 97.376%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.089 Acc 97.237%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.090 Acc 97.235%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.182 Acc 95.808%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.175 Acc 95.861%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.080 Acc 97.579%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.083 Acc 97.454%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.086 Acc 97.415%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.088 Acc 97.331%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.088 Acc 97.326%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.179 Acc 96.001%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.175 Acc 96.148%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.091 Acc 97.231%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.091 Acc 97.128%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.091 Acc 97.186%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.090 Acc 97.249%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.090 Acc 97.280%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.182 Acc 95.893%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.175 Acc 96.028%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.084 Acc 97.502%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.091 Acc 97.209%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.091 Acc 97.166%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.089 Acc 97.210%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.090 Acc 97.204%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.178 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.183 Acc 95.722%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.177 Acc 95.903%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.093 Acc 97.223%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.086 Acc 97.396%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.088 Acc 97.293%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.088 Acc 97.288%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.089 Acc 97.285%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.184 Acc 95.753%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.179 Acc 95.907%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.084 Acc 97.416%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.085 Acc 97.345%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.087 Acc 97.298%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.088 Acc 97.301%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.184 Acc 95.869%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.178 Acc 95.888%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.087 Acc 97.471%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.089 Acc 97.338%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.088 Acc 97.334%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.089 Acc 97.329%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.091 Acc 97.259%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.885%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.172 Acc 95.942%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.141 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.091 Acc 97.293%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.090 Acc 97.223%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.089 Acc 97.237%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.089 Acc 97.227%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.195 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.188 Acc 95.668%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.185 Acc 95.748%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.083 Acc 97.466%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.084 Acc 97.451%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.085 Acc 97.401%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.182 Acc 95.823%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.177 Acc 95.938%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.087 Acc 97.316%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.088 Acc 97.303%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.088 Acc 97.273%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.189 Acc 95.707%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.186 Acc 95.709%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.086 Acc 97.347%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.086 Acc 97.322%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.085 Acc 97.392%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.086 Acc 97.345%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.086 Acc 97.349%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.179 Acc 95.931%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.176 Acc 95.977%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.087 Acc 97.231%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.086 Acc 97.358%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.086 Acc 97.346%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.087 Acc 97.309%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.185 Acc 95.784%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.180 Acc 95.857%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.082 Acc 97.455%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.085 Acc 97.404%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.086 Acc 97.397%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.087 Acc 97.368%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.205 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.184 Acc 95.800%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.178 Acc 95.915%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.085 Acc 97.447%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.083 Acc 97.516%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.085 Acc 97.446%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.085 Acc 97.422%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.085 Acc 97.424%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.187 Acc 95.645%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.182 Acc 95.845%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.083 Acc 97.454%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.084 Acc 97.449%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.085 Acc 97.442%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.084 Acc 97.478%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.185 Acc 95.753%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.182 Acc 95.857%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.082 Acc 97.579%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.080 Acc 97.590%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.083 Acc 97.485%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.084 Acc 97.401%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.084 Acc 97.379%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.186 Acc 95.800%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.181 Acc 95.927%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.078 Acc 97.579%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.081 Acc 97.547%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.083 Acc 97.463%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.208 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.196 Acc 95.614%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.187 Acc 95.775%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.079 Acc 97.486%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.083 Acc 97.388%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.082 Acc 97.420%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.082 Acc 97.446%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.084 Acc 97.371%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.185 Acc 95.808%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.184 Acc 95.896%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.077 Acc 97.679%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.077 Acc 97.695%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.083 Acc 97.479%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.083 Acc 97.464%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.181 Acc 95.978%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.179 Acc 96.074%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.082 Acc 97.447%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.083 Acc 97.516%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.085 Acc 97.423%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.085 Acc 97.368%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.084 Acc 97.382%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.185 Acc 95.862%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.179 Acc 95.985%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.076 Acc 97.540%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.077 Acc 97.551%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.081 Acc 97.451%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.082 Acc 97.446%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.084 Acc 97.354%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.165 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.191 Acc 95.591%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.185 Acc 95.775%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.177 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.079 Acc 97.679%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.082 Acc 97.485%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.083 Acc 97.436%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.082 Acc 97.481%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.083 Acc 97.463%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.183 Acc 95.900%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.179 Acc 95.934%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.106 Acc 94.531%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.077 Acc 97.509%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.082 Acc 97.514%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.083 Acc 97.474%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.174 Acc 96.101%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.170 Acc 96.109%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.085 Acc 97.324%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.085 Acc 97.322%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.084 Acc 97.290%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.085 Acc 97.304%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.084 Acc 97.337%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.188 Acc 96.016%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.180 Acc 96.067%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.077 Acc 97.795%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.082 Acc 97.532%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.081 Acc 97.501%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.082 Acc 97.461%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.082 Acc 97.482%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.191 Acc 95.808%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.185 Acc 95.931%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.075 Acc 97.718%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [200/573] Loss: 0.076 Acc 97.606%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.079 Acc 97.612%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.082 Acc 97.553%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.083 Acc 97.486%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.182 Acc 95.730%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.132 Acc 94.531%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.076 Acc 97.401%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.081 Acc 97.361%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.081 Acc 97.417%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.082 Acc 97.419%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.083 Acc 97.405%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.185 Acc 95.792%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.182 Acc 95.853%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.079 Acc 97.587%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.082 Acc 97.435%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.082 Acc 97.425%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.081 Acc 97.469%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.083 Acc 97.404%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.190 Acc 95.753%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.185 Acc 95.919%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.083 Acc 97.625%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.080 Acc 97.629%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.082 Acc 97.558%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.082 Acc 97.553%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.081 Acc 97.567%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.174 Acc 96.117%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074af0a5984948e88e674dac2b2c88a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.310 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.240 Acc 18.975%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.898%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.240 Acc 18.816%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.239 Acc 18.840%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.220 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.221 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.277 Acc 17.188%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.231 Acc 18.696%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.226 Acc 19.026%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.194 Acc 20.416%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.137 Acc 22.765%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.069 Acc 25.787%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.452 Acc 54.688%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.411 Acc 54.100%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.412 Acc 54.023%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.561 Acc 45.312%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.437 Acc 52.081%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.369 Acc 54.019%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.306 Acc 56.240%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.257 Acc 58.031%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.218 Acc 59.433%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.977 Acc 67.969%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.926 Acc 69.980%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.922 Acc 69.963%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 1.128 Acc 62.500%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.948 Acc 69.237%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.936 Acc 69.706%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.912 Acc 70.606%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.898 Acc 71.080%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.883 Acc 71.526%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.764 Acc 76.562%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.681 Acc 78.473%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.675 Acc 78.455%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.635 Acc 82.812%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.754 Acc 76.075%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.745 Acc 76.345%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.735 Acc 76.630%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.722 Acc 76.991%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.713 Acc 77.320%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.644 Acc 81.250%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.574 Acc 81.946%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.566 Acc 82.012%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.714 Acc 77.344%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.643 Acc 79.672%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.628 Acc 80.096%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.626 Acc 80.238%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.618 Acc 80.510%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.612 Acc 80.757%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.516 Acc 85.938%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.467 Acc 85.659%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.462 Acc 85.599%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.509 Acc 82.812%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.577 Acc 81.784%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.568 Acc 82.008%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.564 Acc 82.267%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.555 Acc 82.501%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.547 Acc 82.753%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.409 Acc 88.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.418 Acc 87.593%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.414 Acc 87.547%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.497 Acc 83.594%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.512 Acc 84.120%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.507 Acc 84.107%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.506 Acc 84.160%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.502 Acc 84.320%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.498 Acc 84.381%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.364 Acc 89.844%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.381 Acc 88.521%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.377 Acc 88.569%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.388 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.475 Acc 85.087%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.476 Acc 85.211%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.475 Acc 85.263%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.471 Acc 85.359%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.468 Acc 85.481%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.356 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.352 Acc 89.542%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.349 Acc 89.498%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.363 Acc 88.281%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.444 Acc 86.270%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.437 Acc 86.451%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.435 Acc 86.584%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.437 Acc 86.491%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.437 Acc 86.446%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.370 Acc 89.062%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.344 Acc 89.627%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.339 Acc 89.646%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.413 Acc 85.938%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.429 Acc 86.719%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.421 Acc 86.960%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.419 Acc 87.007%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.422 Acc 87.044%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.420 Acc 87.096%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.317 Acc 89.062%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.335 Acc 90.231%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.330 Acc 90.314%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.530 Acc 87.500%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.407 Acc 87.446%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.397 Acc 87.799%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.400 Acc 87.653%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.397 Acc 87.708%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.397 Acc 87.765%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.365 Acc 89.062%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.320 Acc 90.463%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.316 Acc 90.547%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.320 Acc 90.625%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.388 Acc 88.041%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.385 Acc 88.106%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.381 Acc 88.214%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.379 Acc 88.324%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.379 Acc 88.275%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.326 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.311 Acc 90.903%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.306 Acc 90.975%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.249 Acc 92.188%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.387 Acc 88.088%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.379 Acc 88.301%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.376 Acc 88.367%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.373 Acc 88.490%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.370 Acc 88.601%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.268 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.291 Acc 91.538%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.286 Acc 91.752%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.358 Acc 87.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.353 Acc 89.101%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.349 Acc 89.199%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.353 Acc 89.133%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.350 Acc 89.197%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.354 Acc 89.098%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.274 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.281 Acc 91.677%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.276 Acc 91.818%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.400 Acc 87.500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.344 Acc 89.697%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.341 Acc 89.649%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.341 Acc 89.558%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.341 Acc 89.518%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.342 Acc 89.469%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.276 Acc 89.844%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.294 Acc 91.638%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.287 Acc 91.667%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.251 Acc 93.750%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.331 Acc 89.975%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.334 Acc 89.910%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.333 Acc 89.870%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.337 Acc 89.768%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.336 Acc 89.780%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.270 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.261 Acc 92.551%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.258 Acc 92.561%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.316 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.327 Acc 90.207%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.331 Acc 90.019%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.330 Acc 89.857%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.328 Acc 89.992%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.323 Acc 90.078%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.255 Acc 93.038%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.252 Acc 92.973%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.314 Acc 94.531%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.305 Acc 90.401%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.307 Acc 90.431%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.307 Acc 90.602%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.307 Acc 90.629%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.311 Acc 90.564%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.246 Acc 90.625%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.258 Acc 92.744%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.252 Acc 92.817%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.386 Acc 84.375%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.310 Acc 90.563%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.311 Acc 90.574%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.312 Acc 90.532%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.310 Acc 90.551%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.310 Acc 90.597%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.234 Acc 90.625%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.252 Acc 92.783%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.247 Acc 92.910%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.243 Acc 92.969%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.306 Acc 90.896%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.303 Acc 90.998%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.302 Acc 91.020%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.299 Acc 91.104%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.298 Acc 91.085%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.249 Acc 93.015%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.246 Acc 92.942%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.192 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.290 Acc 91.012%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.292 Acc 91.056%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.294 Acc 91.121%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.291 Acc 91.188%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.294 Acc 91.152%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.233 Acc 90.625%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.228 Acc 93.711%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.227 Acc 93.556%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.277 Acc 91.399%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.284 Acc 91.115%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.287 Acc 91.219%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.289 Acc 91.200%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.287 Acc 91.250%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.232 Acc 93.518%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.229 Acc 93.435%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.240 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.282 Acc 91.662%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.281 Acc 91.546%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.285 Acc 91.440%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.283 Acc 91.424%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.283 Acc 91.447%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.236 Acc 93.572%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.233 Acc 93.435%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.260 Acc 90.625%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.270 Acc 91.948%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.273 Acc 91.810%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.275 Acc 91.816%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.277 Acc 91.761%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.277 Acc 91.734%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.199 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.219 Acc 94.121%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.216 Acc 94.045%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.282 Acc 91.855%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.277 Acc 91.888%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.274 Acc 91.951%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.273 Acc 91.956%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.272 Acc 91.957%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.216 Acc 91.406%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.229 Acc 93.874%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.227 Acc 93.664%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.275 Acc 91.878%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.271 Acc 92.153%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.273 Acc 91.988%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.270 Acc 91.993%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.267 Acc 92.086%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.219 Acc 90.625%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.221 Acc 93.974%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.218 Acc 93.874%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.167 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.257 Acc 92.412%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.257 Acc 92.460%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.259 Acc 92.330%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.263 Acc 92.254%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.261 Acc 92.292%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.216 Acc 94.338%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.211 Acc 94.267%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.230 Acc 92.969%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.252 Acc 92.474%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.257 Acc 92.277%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.252 Acc 92.429%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.254 Acc 92.441%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.257 Acc 92.315%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.224 Acc 93.781%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.222 Acc 93.812%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.260 Acc 92.242%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.254 Acc 92.374%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.255 Acc 92.494%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.256 Acc 92.462%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.255 Acc 92.498%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.213 Acc 94.253%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.210 Acc 94.189%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.234 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.260 Acc 92.195%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.256 Acc 92.374%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.252 Acc 92.465%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.253 Acc 92.449%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.253 Acc 92.473%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.211 Acc 94.330%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.209 Acc 94.267%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.248 Acc 92.698%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.248 Acc 92.654%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.246 Acc 92.681%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.251 Acc 92.628%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.250 Acc 92.652%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.173 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.205 Acc 94.562%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.202 Acc 94.504%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.330 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.244 Acc 92.752%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.241 Acc 92.774%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.245 Acc 92.701%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.246 Acc 92.741%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.249 Acc 92.702%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.210 Acc 94.400%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.211 Acc 94.248%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.184 Acc 91.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.231 Acc 92.938%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.239 Acc 92.949%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.240 Acc 92.844%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.240 Acc 92.786%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.241 Acc 92.791%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.547%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.201 Acc 94.578%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.312 Acc 92.188%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.243 Acc 92.984%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.244 Acc 92.771%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.239 Acc 92.943%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.238 Acc 92.994%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.239 Acc 92.970%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.933%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.192 Acc 94.951%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.279 Acc 92.188%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.231 Acc 93.394%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.232 Acc 93.136%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.234 Acc 93.119%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.233 Acc 93.169%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.234 Acc 93.154%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.205 Acc 94.585%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.203 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.221 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.226 Acc 93.626%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.232 Acc 93.412%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.232 Acc 93.335%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.233 Acc 93.238%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.232 Acc 93.254%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.189 Acc 95.011%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.187 Acc 94.935%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.223 Acc 93.572%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.225 Acc 93.330%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.230 Acc 93.241%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.231 Acc 93.216%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.232 Acc 93.200%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.197 Acc 94.864%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.196 Acc 94.726%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.227 Acc 93.294%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.227 Acc 93.315%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.298%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.227 Acc 93.288%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.228 Acc 93.239%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.200 Acc 94.756%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.198 Acc 94.656%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.356 Acc 90.625%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.233 Acc 93.170%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.225 Acc 93.509%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.228 Acc 93.392%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.226 Acc 93.405%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.224 Acc 93.437%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.208 Acc 92.188%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.200 Acc 94.817%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.198 Acc 94.675%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.243 Acc 89.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.226 Acc 93.332%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.219 Acc 93.474%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.222 Acc 93.477%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.221 Acc 93.458%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.220 Acc 93.532%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.206 Acc 94.500%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.206 Acc 94.415%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.266 Acc 91.406%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.223 Acc 93.425%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.223 Acc 93.521%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.225 Acc 93.457%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.224 Acc 93.456%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.224 Acc 93.497%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.202 Acc 94.756%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.201 Acc 94.652%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.292 Acc 92.188%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.215 Acc 93.611%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.222 Acc 93.493%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.218 Acc 93.623%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.218 Acc 93.674%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.219 Acc 93.574%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.201 Acc 94.640%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.199 Acc 94.617%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.228 Acc 91.406%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.209 Acc 93.858%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.206 Acc 93.882%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.210 Acc 93.882%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.211 Acc 93.914%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.213 Acc 93.847%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.195 Acc 94.856%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.192 Acc 94.897%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.210 Acc 93.634%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.215 Acc 93.575%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.211 Acc 93.776%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.211 Acc 93.826%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.213 Acc 93.759%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.202 Acc 94.632%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.201 Acc 94.535%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.083 Acc 99.219%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.210 Acc 93.827%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.212 Acc 93.781%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.214 Acc 93.706%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.214 Acc 93.713%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.213 Acc 93.789%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.182 Acc 95.405%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.279 Acc 93.750%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.200 Acc 94.121%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.202 Acc 94.201%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.207 Acc 94.087%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.211 Acc 93.999%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.211 Acc 93.943%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.189 Acc 94.995%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.187 Acc 95.005%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.305 Acc 90.625%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.200 Acc 93.881%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.202 Acc 94.135%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.208 Acc 94.015%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.210 Acc 93.982%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.210 Acc 93.959%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.186 Acc 95.150%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.185 Acc 94.951%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.191 Acc 94.477%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.205 Acc 94.073%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.206 Acc 94.108%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.209 Acc 94.048%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.207 Acc 94.098%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.188 Acc 95.166%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.186 Acc 95.173%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.320 Acc 89.844%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.197 Acc 94.291%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.207 Acc 93.975%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.205 Acc 94.010%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.205 Acc 94.027%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.208 Acc 93.962%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.183 Acc 95.142%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.182 Acc 95.079%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.269 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.196 Acc 94.276%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.198 Acc 94.352%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.201 Acc 94.282%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.202 Acc 94.249%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.204 Acc 94.140%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.194 Acc 94.926%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.195 Acc 94.850%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.295 Acc 94.531%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.208 Acc 94.129%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.207 Acc 94.042%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.207 Acc 94.002%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.205 Acc 94.046%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.202 Acc 94.127%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.176 Acc 95.429%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.201 Acc 94.199%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.197 Acc 94.263%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.194 Acc 94.329%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.197 Acc 94.214%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.198 Acc 94.151%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.178 Acc 95.297%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.177 Acc 95.208%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.298 Acc 90.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.193 Acc 94.253%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.195 Acc 94.193%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.199 Acc 94.145%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.197 Acc 94.192%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.199 Acc 94.196%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.413%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.177 Acc 95.386%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.197 Acc 94.338%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.194 Acc 94.438%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.193 Acc 94.440%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.196 Acc 94.397%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.198 Acc 94.341%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.142 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.182 Acc 95.181%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.227%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.196 Acc 92.188%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.195 Acc 94.384%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.201 Acc 94.306%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.197 Acc 94.383%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.197 Acc 94.346%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.198 Acc 94.347%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.195 Acc 95.104%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.194 Acc 95.025%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.192 Acc 94.462%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.194 Acc 94.345%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.195 Acc 94.303%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.196 Acc 94.305%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.196 Acc 94.346%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.180 Acc 95.266%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.179 Acc 95.231%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.167 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.190 Acc 94.454%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.191 Acc 94.492%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.191 Acc 94.443%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.189 Acc 94.527%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.192 Acc 94.435%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.173 Acc 95.552%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.171 Acc 95.441%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.231 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.185 Acc 94.694%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.184 Acc 94.764%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.188 Acc 94.581%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.191 Acc 94.528%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.190 Acc 95.003%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.189 Acc 94.963%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.179 Acc 94.779%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.186 Acc 94.500%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.191 Acc 94.559%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.192 Acc 94.536%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.183 Acc 95.351%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.181 Acc 95.258%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.256 Acc 90.625%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.190 Acc 94.438%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.192 Acc 94.415%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.188 Acc 94.492%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.191 Acc 94.438%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.191 Acc 94.453%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.112 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.374%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.171 Acc 95.476%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.126 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.177 Acc 94.670%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.189 Acc 94.609%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.191 Acc 94.555%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.191 Acc 94.553%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.177 Acc 95.459%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.176 Acc 95.336%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.214 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.177 Acc 94.787%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.186 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.185 Acc 94.578%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.187 Acc 94.574%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.188 Acc 94.556%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.182 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.190 Acc 94.451%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.189 Acc 94.547%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.188 Acc 94.578%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.179 Acc 95.552%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.177 Acc 95.515%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.185 Acc 94.856%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.187 Acc 94.726%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.191 Acc 94.583%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.190 Acc 94.629%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.188 Acc 94.726%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.183 Acc 95.390%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.185 Acc 95.316%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.164 Acc 93.750%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.180 Acc 94.825%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.179 Acc 94.908%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.179 Acc 94.908%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.180 Acc 94.882%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.182 Acc 94.824%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.181 Acc 95.552%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.507%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.177 Acc 94.810%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.186 Acc 94.582%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.183 Acc 94.625%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.180 Acc 94.744%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.183 Acc 94.656%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.178 Acc 95.355%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.174 Acc 95.073%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.182 Acc 94.862%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.180 Acc 94.850%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.181 Acc 94.798%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.183 Acc 94.756%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.177 Acc 95.568%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.588%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.184 Acc 94.678%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.180 Acc 94.733%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.183 Acc 94.658%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.184 Acc 94.689%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.183 Acc 94.665%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.180 Acc 95.336%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.179 Acc 95.371%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.277 Acc 91.406%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.183 Acc 94.701%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.186 Acc 94.663%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.186 Acc 94.708%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.183 Acc 94.761%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.181 Acc 94.760%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.107 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.274%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.175 Acc 95.340%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.169 Acc 94.949%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.175 Acc 94.842%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.178 Acc 94.848%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.178 Acc 94.804%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.178 Acc 94.818%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.179 Acc 95.251%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.177 Acc 95.305%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.235 Acc 93.750%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.178 Acc 95.011%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.175 Acc 95.009%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.176 Acc 94.928%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.177 Acc 94.907%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.096 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.176 Acc 95.568%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.173 Acc 95.585%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.168 Acc 95.119%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.171 Acc 94.974%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.173 Acc 94.978%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.174 Acc 94.950%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.176 Acc 94.863%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.175 Acc 95.445%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.188 Acc 92.969%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.174 Acc 94.779%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.173 Acc 94.881%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.175 Acc 94.960%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.175 Acc 94.942%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.175 Acc 94.935%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.105 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.178 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.171 Acc 95.142%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 95.001%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.174 Acc 95.030%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.173 Acc 95.015%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.178 Acc 95.289%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.174 Acc 95.472%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.171 Acc 95.042%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.171 Acc 95.037%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.171 Acc 95.076%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.169 Acc 95.063%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.172 Acc 95.058%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.185 Acc 95.251%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.186 Acc 95.192%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.185 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.162 Acc 95.227%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.167 Acc 95.095%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.167 Acc 95.175%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.169 Acc 95.162%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.171 Acc 95.094%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.506%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.176 Acc 95.460%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.172 Acc 95.042%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.170 Acc 94.967%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.170 Acc 95.040%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.172 Acc 95.042%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.174 Acc 94.966%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.171 Acc 95.701%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.161 Acc 95.142%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.166 Acc 95.200%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.168 Acc 95.170%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.169 Acc 95.122%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.171 Acc 95.088%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.168 Acc 95.661%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.167 Acc 95.612%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.184 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.167 Acc 95.243%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.176%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.171 Acc 95.092%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.172 Acc 95.108%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.169 Acc 95.141%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.179 Acc 95.483%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.179 Acc 95.468%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.167 Acc 95.297%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.168 Acc 95.131%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.170 Acc 95.055%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.170 Acc 95.061%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.114 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.176 Acc 95.630%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.167 Acc 95.320%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.165 Acc 95.394%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.168 Acc 95.315%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.168 Acc 95.235%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.169 Acc 95.163%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.193 Acc 95.235%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.191 Acc 95.200%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.165 Acc 95.034%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.166 Acc 95.095%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.166 Acc 95.136%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.166 Acc 95.153%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.166 Acc 95.227%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.119 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.175 Acc 95.653%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.172 Acc 95.690%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.166 Acc 95.359%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.169 Acc 95.223%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.166 Acc 95.328%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.166 Acc 95.332%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.168 Acc 95.189%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.188 Acc 95.057%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.187 Acc 95.211%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.127 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.157 Acc 95.452%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.161 Acc 95.281%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.166 Acc 95.224%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.167 Acc 95.149%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.166 Acc 95.214%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.180 Acc 95.568%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.179 Acc 95.495%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.242 Acc 91.406%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.164 Acc 95.305%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.166 Acc 95.274%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.166 Acc 95.331%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.165 Acc 95.303%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.166 Acc 95.213%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.185 Acc 95.374%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.183 Acc 95.433%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.166 Acc 95.274%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.163 Acc 95.417%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.165 Acc 95.341%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.164 Acc 95.316%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.165 Acc 95.300%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.172 Acc 95.661%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.170 Acc 95.693%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.281 Acc 93.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.164 Acc 95.537%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.165 Acc 95.390%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.164 Acc 95.362%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.165 Acc 95.305%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.164 Acc 95.337%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.171 Acc 95.637%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.167 Acc 95.736%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.159 Acc 95.545%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.162 Acc 95.519%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.162 Acc 95.536%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.165 Acc 95.406%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.164 Acc 95.375%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.178 Acc 95.599%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.175 Acc 95.701%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.168 Acc 92.969%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.104%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.159 Acc 95.188%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.161 Acc 95.261%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.162 Acc 95.274%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.162 Acc 95.295%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.119 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.178 Acc 95.490%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.177 Acc 95.565%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.127 Acc 95.312%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.156 Acc 95.483%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.159 Acc 95.355%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.161 Acc 95.357%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.162 Acc 95.350%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.162 Acc 95.361%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.174 Acc 95.862%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.155 Acc 95.514%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.156 Acc 95.600%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.158 Acc 95.559%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.160 Acc 95.488%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.160 Acc 95.412%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.179 Acc 95.336%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.169 Acc 95.305%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.162 Acc 95.398%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.160 Acc 95.471%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.160 Acc 95.431%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.160 Acc 95.408%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.168 Acc 95.815%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.168 Acc 95.814%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.150 Acc 95.498%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.154 Acc 95.530%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.155 Acc 95.551%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.154 Acc 95.558%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.159 Acc 95.490%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.170 Acc 95.794%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.232 Acc 92.188%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.153 Acc 95.521%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.155 Acc 95.612%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.158 Acc 95.588%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.158 Acc 95.511%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.159 Acc 95.479%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.087 Acc 96.875%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.181 Acc 95.537%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.177 Acc 95.620%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.082 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.152 Acc 95.722%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.666%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.155 Acc 95.601%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.156 Acc 95.620%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.156 Acc 95.568%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.173 Acc 95.699%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.169 Acc 95.779%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.150 Acc 95.490%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.152 Acc 95.441%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.158 Acc 95.341%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.156 Acc 95.394%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.157 Acc 95.403%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.171 Acc 95.831%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.168 Acc 95.752%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.153 Acc 95.429%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.152 Acc 95.674%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.154 Acc 95.673%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.156 Acc 95.579%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.157 Acc 95.537%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.178 Acc 95.722%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.175 Acc 95.728%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.150 Acc 95.699%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.156 Acc 95.550%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.153 Acc 95.556%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.156 Acc 95.544%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.157 Acc 95.498%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.179 Acc 95.784%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.176 Acc 95.775%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.161 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.161 Acc 95.452%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.157 Acc 95.550%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.157 Acc 95.531%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.153 Acc 95.560%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.153 Acc 95.610%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.181 Acc 95.374%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.179 Acc 95.456%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.132 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.575%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.153 Acc 95.425%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.154 Acc 95.447%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.154 Acc 95.496%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.155 Acc 95.543%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.186 Acc 95.459%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.184 Acc 95.534%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.151 Acc 95.630%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.150 Acc 95.643%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.151 Acc 95.663%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.149 Acc 95.712%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.150 Acc 95.684%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.175 Acc 95.568%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.173 Acc 95.600%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.149 Acc 95.506%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.146 Acc 95.658%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.150 Acc 95.595%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.153 Acc 95.564%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.153 Acc 95.581%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.104 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.575%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.173 Acc 95.662%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.309 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.158 Acc 95.475%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.152 Acc 95.693%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.152 Acc 95.621%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.152 Acc 95.611%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.152 Acc 95.657%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.170 Acc 95.792%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.167 Acc 95.791%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.150 Acc 95.599%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.147 Acc 95.635%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.150 Acc 95.614%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.150 Acc 95.689%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.151 Acc 95.668%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.166 Acc 95.931%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.163 Acc 95.896%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.147 Acc 95.846%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.150 Acc 95.651%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.150 Acc 95.629%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.152 Acc 95.609%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.152 Acc 95.634%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.166 Acc 95.838%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.163 Acc 95.923%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.138 Acc 96.055%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.143 Acc 95.969%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.146 Acc 95.847%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.148 Acc 95.798%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.151 Acc 95.685%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.413%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.180 Acc 95.433%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.146 Acc 95.521%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.145 Acc 95.791%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.146 Acc 95.811%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.146 Acc 95.827%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.147 Acc 95.766%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.171 Acc 95.614%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.169 Acc 95.732%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.147 Acc 95.893%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.149 Acc 95.682%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.150 Acc 95.630%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.149 Acc 95.640%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.118 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.164 Acc 95.761%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.162 Acc 95.853%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.112 Acc 93.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.142 Acc 95.746%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.146 Acc 95.810%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.149 Acc 95.684%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.150 Acc 95.687%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.147 Acc 95.734%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.162 Acc 95.854%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.161 Acc 95.868%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.153 Acc 95.831%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.148 Acc 95.833%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.149 Acc 95.780%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.149 Acc 95.772%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.149 Acc 95.769%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.176 Acc 95.699%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.173 Acc 95.752%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.139 Acc 95.939%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.147 Acc 95.693%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.144 Acc 95.733%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.146 Acc 95.704%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.147 Acc 95.723%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.099 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.165 Acc 95.893%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.163 Acc 95.845%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.151 Acc 95.622%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.154 Acc 95.515%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.149 Acc 95.642%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.147 Acc 95.755%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.147 Acc 95.760%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.086 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 95.970%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.168 Acc 95.981%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.225 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.138 Acc 95.784%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.138 Acc 95.791%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.140 Acc 95.829%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.142 Acc 95.780%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.143 Acc 95.774%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.173 Acc 95.730%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.170 Acc 95.752%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.134 Acc 96.202%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.143 Acc 95.931%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.146 Acc 95.839%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.146 Acc 95.874%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.146 Acc 95.843%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.082 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.176 Acc 95.614%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.172 Acc 95.798%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.138 Acc 96.028%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.144 Acc 95.865%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.145 Acc 95.842%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.144 Acc 95.877%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.179 Acc 95.676%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.176 Acc 95.643%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.143 Acc 95.692%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.144 Acc 95.725%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.146 Acc 95.772%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.145 Acc 95.780%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.144 Acc 95.810%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.171 Acc 95.885%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.168 Acc 95.864%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.138 Acc 96.032%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.136 Acc 96.043%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.139 Acc 95.967%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.143 Acc 95.825%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.145 Acc 95.769%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.173 Acc 95.924%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.141 Acc 95.831%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.144 Acc 96.000%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.143 Acc 95.998%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.142 Acc 95.967%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.076 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.174 Acc 95.784%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.172 Acc 95.705%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.131 Acc 95.978%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.141 Acc 95.943%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.142 Acc 95.885%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.142 Acc 95.900%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.142 Acc 95.978%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.139 Acc 96.021%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.141 Acc 95.989%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.142 Acc 95.966%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.181 Acc 95.560%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.178 Acc 95.620%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.132 Acc 95.962%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.137 Acc 95.954%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.136 Acc 95.967%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.139 Acc 95.895%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.141 Acc 95.885%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.172 Acc 95.715%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.167 Acc 95.725%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.140 Acc 95.862%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.141 Acc 95.933%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.143 Acc 95.866%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.142 Acc 95.874%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.168 Acc 95.818%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.139 Acc 96.241%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.137 Acc 96.028%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.137 Acc 96.008%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.136 Acc 96.066%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.138 Acc 96.017%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.183 Acc 95.498%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.179 Acc 95.631%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.137 Acc 96.032%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.131 Acc 96.218%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.133 Acc 96.169%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.137 Acc 96.057%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.138 Acc 96.038%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.178 Acc 95.591%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.173 Acc 95.697%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.171 Acc 94.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.141 Acc 96.071%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.140 Acc 96.028%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.142 Acc 95.881%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.141 Acc 95.918%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.140 Acc 95.933%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.183 Acc 95.692%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.180 Acc 95.752%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.162 Acc 93.750%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.136 Acc 95.924%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.142 Acc 95.888%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.142 Acc 95.954%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.141 Acc 95.959%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.140 Acc 96.002%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.114 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.885%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.168 Acc 95.888%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.128 Acc 96.194%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.137 Acc 95.977%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.135 Acc 95.930%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.138 Acc 95.891%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.138 Acc 95.910%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.166 Acc 95.854%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.162 Acc 95.911%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.207 Acc 92.188%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.133 Acc 96.129%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.135 Acc 96.070%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.138 Acc 95.952%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.138 Acc 95.953%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.171 Acc 95.800%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.135 Acc 96.202%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.134 Acc 96.143%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.133 Acc 96.150%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.135 Acc 96.103%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.080 Acc 96.875%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.181 Acc 95.661%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.713%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.332 Acc 95.312%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.140 Acc 96.028%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.139 Acc 96.081%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.137 Acc 96.098%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.136 Acc 96.092%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.172 Acc 95.872%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.137 Acc 96.179%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.138 Acc 96.144%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.137 Acc 96.104%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.135 Acc 96.139%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.134 Acc 96.181%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.167 Acc 96.109%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.166 Acc 95.981%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.120 Acc 96.581%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.129 Acc 96.385%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.130 Acc 96.278%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.134 Acc 96.166%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.136 Acc 96.106%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.184 Acc 95.606%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.181 Acc 95.588%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.221 Acc 91.406%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.135 Acc 96.183%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.133 Acc 96.270%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.132 Acc 96.254%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.134 Acc 96.192%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.173 Acc 95.769%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.946%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.134 Acc 96.047%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.133 Acc 96.168%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.131 Acc 96.166%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.133 Acc 96.150%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.135 Acc 96.056%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.089 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.169 Acc 95.630%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.167 Acc 95.783%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.132 Acc 96.310%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.128 Acc 96.327%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.133 Acc 96.161%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.134 Acc 96.207%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.132 Acc 96.243%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.177 Acc 95.753%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.174 Acc 95.736%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.126 Acc 96.310%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.130 Acc 96.280%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.129 Acc 96.273%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.133 Acc 96.162%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.133 Acc 96.126%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.099 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.186 Acc 95.568%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.185 Acc 95.635%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.127 Acc 96.241%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.130 Acc 96.117%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.133 Acc 96.078%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.134 Acc 96.063%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.133 Acc 96.053%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.184 Acc 95.885%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.183 Acc 95.853%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.127 Acc 96.349%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.125 Acc 96.428%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.127 Acc 96.403%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.129 Acc 96.337%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.131 Acc 96.303%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.177 Acc 95.715%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.173 Acc 95.849%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.135 Acc 96.140%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.132 Acc 96.164%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.132 Acc 96.168%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.131 Acc 96.189%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.169 Acc 95.970%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 95.989%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.123 Acc 96.218%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.127 Acc 96.156%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.129 Acc 96.107%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.130 Acc 96.053%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.131 Acc 96.047%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.178 Acc 95.668%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.175 Acc 95.759%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.123 Acc 96.233%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.126 Acc 96.051%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.131 Acc 96.031%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.131 Acc 96.053%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.132 Acc 96.047%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.083 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.171 Acc 95.829%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.118 Acc 96.519%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.121 Acc 96.409%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.125 Acc 96.317%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.129 Acc 96.207%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.128 Acc 96.237%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.168 Acc 95.784%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.165 Acc 95.880%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.126 Acc 96.300%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.126 Acc 96.213%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.128 Acc 96.199%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.129 Acc 96.225%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.110 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.174 Acc 95.529%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.171 Acc 95.690%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.125 Acc 96.253%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.128 Acc 96.275%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.129 Acc 96.211%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.130 Acc 96.189%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.186 Acc 95.459%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.183 Acc 95.655%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.274 Acc 94.531%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.131 Acc 96.101%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.132 Acc 96.063%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.130 Acc 96.117%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.129 Acc 96.189%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.129 Acc 96.153%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.107 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.175 Acc 95.792%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.171 Acc 95.919%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.128 Acc 96.303%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.127 Acc 96.276%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.129 Acc 96.198%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.130 Acc 96.226%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.180 Acc 95.622%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.176 Acc 95.678%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.033 Acc 100.000%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.126 Acc 96.327%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.126 Acc 96.299%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.128 Acc 96.255%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.130 Acc 96.220%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.177 Acc 95.676%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.172 Acc 95.849%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.117 Acc 96.403%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.123 Acc 96.315%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.127 Acc 96.226%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.128 Acc 96.218%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.129 Acc 96.219%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.107 Acc 96.875%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.182 Acc 95.993%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.179 Acc 96.012%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.119 Acc 96.419%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.125 Acc 96.265%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.125 Acc 96.260%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.127 Acc 96.261%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.127 Acc 96.276%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.715%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 95.826%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.127 Acc 96.481%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.126 Acc 96.405%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.125 Acc 96.413%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.128 Acc 96.341%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.129 Acc 96.289%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.176 Acc 95.862%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.171 Acc 95.993%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.123 Acc 96.349%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.123 Acc 96.304%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.129 Acc 96.224%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.125 Acc 96.359%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.085 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.184 Acc 95.560%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.177 Acc 95.717%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.182 Acc 96.094%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.124 Acc 96.457%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.123 Acc 96.436%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.123 Acc 96.369%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.124 Acc 96.376%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.126 Acc 96.315%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.175 Acc 95.931%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.172 Acc 95.896%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.125 Acc 96.334%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.122 Acc 96.409%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.123 Acc 96.387%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.126 Acc 96.271%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.127 Acc 96.278%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.099 Acc 94.531%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.176 Acc 95.784%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.172 Acc 95.853%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.180 Acc 92.188%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.124 Acc 96.256%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.122 Acc 96.284%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.126 Acc 96.262%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.124 Acc 96.298%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.126 Acc 96.286%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.068 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.170 Acc 95.661%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.165 Acc 95.853%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.116 Acc 96.566%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.117 Acc 96.475%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.122 Acc 96.426%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.124 Acc 96.368%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.181 Acc 95.777%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.179 Acc 95.818%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.118 Acc 96.465%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.121 Acc 96.401%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.124 Acc 96.327%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.124 Acc 96.294%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.124 Acc 96.287%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.176 Acc 95.730%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.173 Acc 95.833%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.111 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.116 Acc 96.519%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.119 Acc 96.490%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.125 Acc 96.322%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.130 Acc 96.267%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.129 Acc 96.237%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.178 Acc 95.761%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.176 Acc 95.829%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.123 Acc 96.442%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.124 Acc 96.385%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.122 Acc 96.501%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.122 Acc 96.442%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.122 Acc 96.423%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.093 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.171 Acc 95.924%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.167 Acc 96.000%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.110 Acc 96.836%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.112 Acc 96.685%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.117 Acc 96.574%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.119 Acc 96.526%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.121 Acc 96.449%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.074 Acc 98.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.178 Acc 95.916%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.174 Acc 95.919%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.117 Acc 96.504%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.117 Acc 96.393%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.120 Acc 96.460%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.122 Acc 96.413%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.122 Acc 96.401%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.176 Acc 95.962%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.186 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.119 Acc 96.589%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.120 Acc 96.482%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.123 Acc 96.374%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.121 Acc 96.441%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.121 Acc 96.417%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.177 Acc 95.908%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.173 Acc 95.868%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.119 Acc 96.459%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.120 Acc 96.382%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.120 Acc 96.404%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.120 Acc 96.412%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.185 Acc 95.777%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.182 Acc 95.818%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.145 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.115 Acc 96.488%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.122 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.123 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.122 Acc 96.372%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.122 Acc 96.401%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.176 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.171 Acc 95.892%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.206 Acc 94.531%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.122 Acc 96.473%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.120 Acc 96.545%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.121 Acc 96.460%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.121 Acc 96.466%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.120 Acc 96.504%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.170 Acc 95.831%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.166 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.111 Acc 96.666%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.120 Acc 96.482%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.119 Acc 96.491%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.117 Acc 96.563%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.120 Acc 96.459%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.081 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.171 Acc 95.900%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.040 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.115 Acc 96.666%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.116 Acc 96.537%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.118 Acc 96.488%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.119 Acc 96.482%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.176 Acc 96.109%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.171 Acc 96.113%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.113 Acc 96.615%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.117 Acc 96.564%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.119 Acc 96.509%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.119 Acc 96.515%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.172 Acc 95.800%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.168 Acc 95.837%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.111 Acc 96.720%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.116 Acc 96.587%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.118 Acc 96.555%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.119 Acc 96.527%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.094 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.170 Acc 95.838%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.165 Acc 95.911%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.123 Acc 96.426%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.117 Acc 96.549%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.120 Acc 96.491%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.121 Acc 96.493%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.120 Acc 96.499%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.075 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.172 Acc 95.808%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.170 Acc 95.849%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.117 Acc 96.465%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.117 Acc 96.553%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.119 Acc 96.501%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.117 Acc 96.523%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.082 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.173 Acc 95.854%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.169 Acc 95.942%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.113 Acc 96.689%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.115 Acc 96.739%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.118 Acc 96.644%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.117 Acc 96.655%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.116 Acc 96.610%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.182 Acc 95.831%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.179 Acc 95.977%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.132 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.108 Acc 96.689%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.108 Acc 96.793%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.114 Acc 96.631%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.114 Acc 96.629%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.085 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.171 Acc 95.761%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.220 Acc 94.531%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.122 Acc 96.457%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.118 Acc 96.572%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.121 Acc 96.486%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.118 Acc 96.540%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.117 Acc 96.546%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.182 Acc 95.722%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.176 Acc 95.791%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.104 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.117 Acc 96.473%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.115 Acc 96.549%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.117 Acc 96.429%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.115 Acc 96.462%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.116 Acc 96.473%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.103 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.185 Acc 95.815%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.178 Acc 95.907%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.111 Acc 96.473%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.118 Acc 96.381%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.118 Acc 96.465%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.117 Acc 96.530%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.118 Acc 96.523%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.181 Acc 95.808%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.178 Acc 95.876%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.109 Acc 96.573%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.106 Acc 96.704%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.111 Acc 96.618%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.114 Acc 96.529%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.085 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.187 Acc 95.692%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.185 Acc 95.728%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.153 Acc 93.750%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.109 Acc 96.504%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.113 Acc 96.498%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.117 Acc 96.520%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.117 Acc 96.484%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.177 Acc 95.715%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.173 Acc 95.872%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.119 Acc 96.697%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.117 Acc 96.642%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.117 Acc 96.579%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.115 Acc 96.598%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.114 Acc 96.624%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.187 Acc 95.761%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.183 Acc 95.857%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.107 Acc 96.774%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.114 Acc 96.537%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.114 Acc 96.517%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.114 Acc 96.567%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.114 Acc 96.601%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.091 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.173 Acc 95.862%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.169 Acc 96.024%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.113 Acc 96.798%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.113 Acc 96.696%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.111 Acc 96.694%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.113 Acc 96.680%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.171 Acc 95.893%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.117 Acc 96.529%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.115 Acc 96.592%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.115 Acc 96.622%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.182 Acc 95.792%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.178 Acc 95.884%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.169 Acc 93.750%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.112 Acc 96.635%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.114 Acc 96.615%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.112 Acc 96.654%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.114 Acc 96.625%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.179 Acc 95.854%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.175 Acc 95.997%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.116 Acc 96.658%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.113 Acc 96.580%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.115 Acc 96.566%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.115 Acc 96.608%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.115 Acc 96.572%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.177 Acc 95.978%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.175 Acc 95.981%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.105 Acc 96.744%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.109 Acc 96.720%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.110 Acc 96.673%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.112 Acc 96.644%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.178 Acc 95.637%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.172 Acc 95.721%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.134 Acc 95.312%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.113 Acc 96.767%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.111 Acc 96.735%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.112 Acc 96.702%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.114 Acc 96.650%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.170 Acc 95.885%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.165 Acc 96.008%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.108 Acc 96.651%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.109 Acc 96.774%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.110 Acc 96.737%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.110 Acc 96.709%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.113 Acc 96.640%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.180 Acc 95.676%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.176 Acc 95.798%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.113 Acc 96.643%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.109 Acc 96.700%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.111 Acc 96.701%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.111 Acc 96.707%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.112 Acc 96.682%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.185 Acc 95.560%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.179 Acc 95.635%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.110 Acc 96.798%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.111 Acc 96.817%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.110 Acc 96.784%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.112 Acc 96.744%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.112 Acc 96.763%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.184 Acc 95.815%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.179 Acc 95.958%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.094 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.109 Acc 96.774%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.112 Acc 96.622%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.116 Acc 96.527%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.115 Acc 96.580%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.095 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.188 Acc 95.661%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.184 Acc 95.872%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.110 Acc 96.960%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.111 Acc 96.797%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.109 Acc 96.787%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.110 Acc 96.744%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.193 Acc 95.637%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.189 Acc 95.783%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.107 Acc 96.682%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.111 Acc 96.688%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.110 Acc 96.660%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.112 Acc 96.593%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.112 Acc 96.636%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.084 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.177 Acc 95.916%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.173 Acc 95.872%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.111 Acc 96.960%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.108 Acc 96.902%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.111 Acc 96.771%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.111 Acc 96.682%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.074 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.187 Acc 95.475%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.182 Acc 95.546%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.109 Acc 96.635%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.115 Acc 96.482%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.112 Acc 96.605%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.113 Acc 96.618%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.111 Acc 96.672%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.067 Acc 98.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.192 Acc 95.715%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.185 Acc 95.833%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.104 Acc 96.728%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.108 Acc 96.576%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.110 Acc 96.644%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.108 Acc 96.721%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.108 Acc 96.716%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.183 Acc 95.459%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.177 Acc 95.623%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.111 Acc 96.604%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.111 Acc 96.642%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.113 Acc 96.605%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.108 Acc 96.750%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.108 Acc 96.763%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.179 Acc 95.748%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.108 Acc 96.840%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.108 Acc 96.805%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.109 Acc 96.803%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.110 Acc 96.733%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.195 Acc 95.591%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.190 Acc 95.713%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.114 Acc 96.620%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.115 Acc 96.646%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.112 Acc 96.719%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.110 Acc 96.721%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.108 Acc 96.780%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.179 Acc 95.900%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.174 Acc 95.942%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.108 Acc 96.774%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.109 Acc 96.618%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.107 Acc 96.709%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.108 Acc 96.715%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.109 Acc 96.707%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.177 Acc 95.845%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.105 Acc 96.898%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.107 Acc 96.769%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.107 Acc 96.764%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.107 Acc 96.785%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.184 Acc 95.684%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.177 Acc 95.841%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbce4f4a26e45ad9884465c97009d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.331 Acc 5.469%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.271 Acc 14.875%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.254 Acc 16.857%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.249 Acc 17.385%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.242 Acc 17.745%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.225 Acc 18.755%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.992 Acc 32.031%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.036 Acc 30.794%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.039 Acc 30.803%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.003 Acc 32.031%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.887 Acc 34.677%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.819 Acc 37.310%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.748 Acc 40.111%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.673 Acc 42.994%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.600 Acc 45.613%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.994 Acc 67.969%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.020 Acc 67.188%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.016 Acc 67.137%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.092 Acc 65.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.128 Acc 63.281%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.097 Acc 64.179%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.060 Acc 65.441%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.030 Acc 66.398%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.004 Acc 67.237%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.713 Acc 79.688%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.734 Acc 76.679%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.725 Acc 76.889%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.996 Acc 69.531%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.847 Acc 72.409%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.830 Acc 72.998%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.815 Acc 73.656%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.796 Acc 74.295%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.783 Acc 74.772%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.624 Acc 82.812%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.631 Acc 79.943%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.624 Acc 80.049%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.822 Acc 74.219%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.722 Acc 77.313%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.702 Acc 77.880%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.691 Acc 78.159%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.680 Acc 78.497%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.668 Acc 78.842%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.512 Acc 82.031%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.525 Acc 83.725%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.517 Acc 84.033%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.566 Acc 79.688%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.606 Acc 80.933%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.601 Acc 80.927%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.593 Acc 81.206%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.592 Acc 81.289%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.586 Acc 81.528%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.441 Acc 85.156%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.462 Acc 85.837%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.454 Acc 86.124%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.540 Acc 85.156%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.532 Acc 83.470%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.530 Acc 83.586%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.533 Acc 83.308%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.531 Acc 83.457%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.530 Acc 83.416%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.401 Acc 87.500%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.410 Acc 87.454%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.403 Acc 87.815%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.548 Acc 82.812%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.509 Acc 83.880%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.506 Acc 83.947%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.498 Acc 84.141%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.497 Acc 84.299%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.495 Acc 84.430%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.370 Acc 85.938%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.370 Acc 89.124%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.363 Acc 89.358%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.466 Acc 84.375%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.478 Acc 85.272%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.469 Acc 85.397%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.463 Acc 85.644%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.458 Acc 85.776%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.460 Acc 85.688%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.353 Acc 87.500%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.349 Acc 89.519%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.341 Acc 89.801%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.410 Acc 88.281%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.445 Acc 86.139%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.443 Acc 86.291%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.437 Acc 86.451%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.438 Acc 86.458%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.439 Acc 86.441%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.300 Acc 90.625%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.341 Acc 89.867%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.337 Acc 90.007%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.640 Acc 82.031%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.414 Acc 87.423%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.423 Acc 87.096%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.419 Acc 87.168%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.418 Acc 87.134%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.418 Acc 87.121%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.315 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.326 Acc 90.408%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.320 Acc 90.536%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.281 Acc 91.406%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.397 Acc 87.701%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.396 Acc 87.861%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.395 Acc 87.879%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.398 Acc 87.771%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.398 Acc 87.703%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.274 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.300 Acc 91.182%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.296 Acc 91.348%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.490 Acc 83.594%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.374 Acc 88.738%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.385 Acc 88.386%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.386 Acc 88.286%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.382 Acc 88.328%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.384 Acc 88.225%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.255 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.295 Acc 91.491%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.292 Acc 91.566%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.334 Acc 87.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.368 Acc 88.513%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.371 Acc 88.495%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.367 Acc 88.676%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.366 Acc 88.702%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.367 Acc 88.682%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.277 Acc 89.062%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.288 Acc 91.793%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.283 Acc 91.861%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.295 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.354 Acc 89.240%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.356 Acc 89.031%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.352 Acc 89.203%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.355 Acc 89.183%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.355 Acc 89.245%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.240 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.277 Acc 92.048%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.274 Acc 92.145%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.329 Acc 89.844%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.350 Acc 89.140%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.339 Acc 89.587%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.345 Acc 89.522%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.341 Acc 89.511%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.342 Acc 89.490%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.218 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.268 Acc 92.466%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.265 Acc 92.514%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.468 Acc 89.062%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.333 Acc 89.921%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.339 Acc 89.509%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.344 Acc 89.330%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.344 Acc 89.349%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.339 Acc 89.543%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.254 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.261 Acc 92.636%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.258 Acc 92.821%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.466 Acc 85.938%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.333 Acc 89.790%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.328 Acc 90.023%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.329 Acc 89.974%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.326 Acc 90.027%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.327 Acc 90.012%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.212 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.254 Acc 92.884%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.252 Acc 92.922%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.330 Acc 89.844%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.319 Acc 90.292%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.327 Acc 90.089%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.328 Acc 89.984%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.321 Acc 90.155%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.321 Acc 90.193%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.193 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.246 Acc 93.147%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.242 Acc 93.237%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.382 Acc 89.844%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.309 Acc 90.617%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.311 Acc 90.648%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.315 Acc 90.454%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.314 Acc 90.391%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.313 Acc 90.452%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.254 Acc 92.737%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.248 Acc 92.875%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.366 Acc 89.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.307 Acc 90.548%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.314 Acc 90.435%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.311 Acc 90.511%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.310 Acc 90.518%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.308 Acc 90.553%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.218 Acc 91.406%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.241 Acc 93.216%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.238 Acc 93.179%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.220 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.291 Acc 91.120%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.297 Acc 91.045%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.304 Acc 90.843%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.302 Acc 90.882%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.302 Acc 90.807%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.235 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.236 Acc 93.448%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.231 Acc 93.458%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.437 Acc 88.281%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.301 Acc 90.787%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.300 Acc 90.994%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.301 Acc 91.009%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.298 Acc 91.108%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.296 Acc 91.144%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.223 Acc 90.625%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.228 Acc 93.479%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.224 Acc 93.630%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.437 Acc 89.844%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.296 Acc 91.182%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.296 Acc 91.274%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.293 Acc 91.201%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.292 Acc 91.206%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.293 Acc 91.202%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.232 Acc 93.472%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.228 Acc 93.517%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.268 Acc 91.406%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.285 Acc 91.437%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.282 Acc 91.395%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.280 Acc 91.523%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.281 Acc 91.494%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.283 Acc 91.403%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.232 Acc 93.557%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.226 Acc 93.672%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.268 Acc 92.157%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.274 Acc 91.748%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.280 Acc 91.627%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.281 Acc 91.566%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.281 Acc 91.584%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.218 Acc 92.188%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.232 Acc 93.603%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.227 Acc 93.618%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.252 Acc 91.406%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.273 Acc 91.801%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.277 Acc 91.674%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.278 Acc 91.720%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.281 Acc 91.603%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.279 Acc 91.684%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.221 Acc 93.820%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.218 Acc 93.921%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.188 Acc 95.312%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.261 Acc 92.110%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.266 Acc 92.051%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.269 Acc 91.894%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.269 Acc 91.913%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.270 Acc 91.829%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.217 Acc 94.114%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.214 Acc 94.092%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.262 Acc 92.203%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.277 Acc 91.659%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.270 Acc 91.796%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.270 Acc 91.870%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.268 Acc 91.952%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.188 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.219 Acc 93.990%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.214 Acc 93.979%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.250 Acc 92.234%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.258 Acc 92.028%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.262 Acc 91.988%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.262 Acc 92.043%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.262 Acc 92.066%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.188 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.216 Acc 94.377%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.212 Acc 94.290%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.299 Acc 92.188%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.254 Acc 92.249%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.260 Acc 92.121%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.259 Acc 92.219%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.260 Acc 92.186%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.263 Acc 92.136%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.212 Acc 94.245%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.208 Acc 94.213%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.303 Acc 89.062%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.266 Acc 91.878%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.270 Acc 91.877%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.264 Acc 92.019%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.261 Acc 92.045%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.261 Acc 92.064%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.213 Acc 94.199%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.209 Acc 94.282%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.406 Acc 89.062%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.256 Acc 92.791%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.257 Acc 92.518%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.257 Acc 92.481%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.257 Acc 92.505%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.255 Acc 92.487%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.213 Acc 94.230%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.207 Acc 94.325%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.322 Acc 92.188%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.254 Acc 92.489%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.255 Acc 92.405%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.252 Acc 92.431%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.249 Acc 92.540%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.250 Acc 92.566%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.207 Acc 94.353%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.204 Acc 94.341%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.194 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.255 Acc 92.342%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.247 Acc 92.553%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.250 Acc 92.556%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.249 Acc 92.562%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.249 Acc 92.565%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.209 Acc 94.230%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.205 Acc 94.263%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.243 Acc 94.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.245 Acc 92.752%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.245 Acc 92.751%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.247 Acc 92.634%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.247 Acc 92.571%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.247 Acc 92.616%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.191 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.198 Acc 94.725%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.195 Acc 94.656%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.322 Acc 90.625%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.232 Acc 93.178%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.241 Acc 92.930%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.246 Acc 92.818%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.246 Acc 92.786%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.244 Acc 92.755%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.208 Acc 94.384%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.205 Acc 94.349%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.234 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.233 Acc 92.953%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.239 Acc 92.895%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.244 Acc 92.784%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.242 Acc 92.879%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.242 Acc 92.846%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.200 Acc 94.779%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.196 Acc 94.729%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.201 Acc 91.406%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.240 Acc 92.884%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.239 Acc 92.883%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.239 Acc 92.906%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.239 Acc 92.938%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.239 Acc 92.928%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.200 Acc 94.570%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.197 Acc 94.543%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.307 Acc 93.750%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.229 Acc 93.394%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.237 Acc 93.249%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.235 Acc 93.218%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.235 Acc 93.162%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.235 Acc 93.164%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.198 Acc 94.794%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.193 Acc 94.772%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.241 Acc 93.093%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.233 Acc 93.186%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.235 Acc 93.117%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.234 Acc 93.074%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.236 Acc 93.001%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.196 Acc 94.918%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.192 Acc 94.881%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.268 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.222 Acc 93.441%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.228 Acc 93.431%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.230 Acc 93.265%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.230 Acc 93.298%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.233 Acc 93.195%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.190 Acc 95.111%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.187 Acc 95.017%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.222 Acc 93.611%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.222 Acc 93.424%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.226 Acc 93.239%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.228 Acc 93.195%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.230 Acc 93.200%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.191 Acc 92.969%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.201 Acc 94.609%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.194 Acc 94.714%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.223 Acc 93.286%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.220 Acc 93.517%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.223 Acc 93.605%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.225 Acc 93.407%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.225 Acc 93.462%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.167 Acc 93.750%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.194 Acc 94.810%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.189 Acc 94.823%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.218 Acc 93.502%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.220 Acc 93.490%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.223 Acc 93.472%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.225 Acc 93.382%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.224 Acc 93.399%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.192 Acc 94.771%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.230 Acc 93.185%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.225 Acc 93.365%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.225 Acc 93.433%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.224 Acc 93.440%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.224 Acc 93.457%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.208 Acc 92.188%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.194 Acc 94.841%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.189 Acc 94.757%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.246 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.222 Acc 93.425%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.221 Acc 93.501%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.220 Acc 93.553%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.223 Acc 93.516%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.221 Acc 93.544%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.185 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.191 Acc 94.794%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.187 Acc 94.838%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.177 Acc 92.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.212 Acc 93.928%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.217 Acc 93.734%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.220 Acc 93.677%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.222 Acc 93.567%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.222 Acc 93.515%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.190 Acc 95.003%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.183 Acc 95.091%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.229 Acc 92.969%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.213 Acc 93.549%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.211 Acc 93.641%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.215 Acc 93.625%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.218 Acc 93.542%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.219 Acc 93.527%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.197 Acc 94.732%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.191 Acc 94.815%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.214 Acc 93.742%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.208 Acc 93.878%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.212 Acc 93.773%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.214 Acc 93.660%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.216 Acc 93.649%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.183 Acc 95.021%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.259 Acc 89.844%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.204 Acc 93.982%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.219 Acc 93.688%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.215 Acc 93.753%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.217 Acc 93.694%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.214 Acc 93.734%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.189 Acc 95.034%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.184 Acc 95.060%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.200 Acc 93.812%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.207 Acc 93.750%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.208 Acc 93.771%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.209 Acc 93.881%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.210 Acc 93.834%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.181 Acc 95.119%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.178 Acc 95.169%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.206 Acc 94.106%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.209 Acc 93.987%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.209 Acc 93.945%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.210 Acc 93.953%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.210 Acc 93.943%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.188 Acc 95.042%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.183 Acc 95.033%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.264 Acc 92.188%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.205 Acc 93.974%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.205 Acc 93.983%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.205 Acc 93.971%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.207 Acc 93.939%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.207 Acc 93.926%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.172 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.186 Acc 95.050%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.182 Acc 95.068%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.183 Acc 95.312%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.219 Acc 93.804%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.212 Acc 93.991%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.210 Acc 94.061%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.209 Acc 94.083%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.207 Acc 94.092%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.189 Acc 95.088%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.184 Acc 95.072%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.204 Acc 93.982%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.209 Acc 93.925%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.208 Acc 93.973%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.206 Acc 93.951%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.208 Acc 93.901%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.186 Acc 95.042%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.182 Acc 95.138%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.289 Acc 92.188%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.208 Acc 94.168%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.202 Acc 94.166%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.207 Acc 94.025%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.208 Acc 93.990%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.206 Acc 94.000%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.181 Acc 95.215%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.123 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.206 Acc 94.059%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.202 Acc 94.193%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.203 Acc 94.108%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.202 Acc 94.103%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.203 Acc 94.127%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.174 Acc 92.188%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.181 Acc 95.111%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.176 Acc 95.305%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.198 Acc 94.152%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.200 Acc 94.205%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.200 Acc 94.142%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.201 Acc 94.142%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.200 Acc 94.145%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.190 Acc 95.135%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.186 Acc 95.052%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.230 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.196 Acc 94.330%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.200 Acc 94.294%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.203 Acc 94.157%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.202 Acc 94.157%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.199 Acc 94.243%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.178 Acc 95.351%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.153 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.200 Acc 94.361%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.194 Acc 94.446%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.199 Acc 94.272%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.198 Acc 94.336%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.200 Acc 94.260%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.185 Acc 95.196%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.180 Acc 95.223%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.189 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.195 Acc 94.321%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.195 Acc 94.292%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.196 Acc 94.280%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.198 Acc 94.174%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.184 Acc 95.274%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.178 Acc 95.336%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.197 Acc 94.261%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.196 Acc 94.360%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.196 Acc 94.430%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.196 Acc 94.407%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.196 Acc 94.413%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.187 Acc 95.150%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.182 Acc 95.200%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.233 Acc 89.844%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.184 Acc 94.423%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.189 Acc 94.492%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.189 Acc 94.409%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.192 Acc 94.387%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.192 Acc 94.391%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.187 Acc 95.142%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.181 Acc 95.200%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.196 Acc 92.188%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.195 Acc 94.199%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.193 Acc 94.314%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.193 Acc 94.321%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.194 Acc 94.294%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.196 Acc 94.272%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.179 Acc 92.188%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.212%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.178 Acc 95.371%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.182 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.196 Acc 94.315%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.194 Acc 94.275%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.193 Acc 94.360%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.193 Acc 94.366%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.193 Acc 94.422%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.183 Acc 95.297%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.320%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.199 Acc 94.307%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.194 Acc 94.372%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.193 Acc 94.383%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.191 Acc 94.399%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.193 Acc 94.336%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.177 Acc 95.320%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.171 Acc 95.437%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.272 Acc 92.188%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.182 Acc 94.601%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.574%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.184 Acc 94.588%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.186 Acc 94.502%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.189 Acc 94.469%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.188 Acc 95.026%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.183 Acc 95.075%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.246 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.201 Acc 94.168%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.191 Acc 94.457%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.188 Acc 94.505%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.190 Acc 94.518%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.191 Acc 94.447%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.186 Acc 95.134%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.177 Acc 94.717%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.182 Acc 94.675%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.185 Acc 94.555%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.187 Acc 94.477%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.188 Acc 94.464%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.176 Acc 95.514%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.169 Acc 95.581%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.202 Acc 95.312%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.190 Acc 94.570%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.185 Acc 94.761%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.184 Acc 94.697%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.186 Acc 94.613%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.187 Acc 94.575%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.174 Acc 95.467%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.169 Acc 95.499%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.185 Acc 93.750%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.190 Acc 94.346%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.186 Acc 94.516%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.188 Acc 94.430%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.188 Acc 94.471%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.188 Acc 94.511%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.183 Acc 95.343%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.177 Acc 95.367%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.182 Acc 94.717%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.187 Acc 94.570%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.181 Acc 94.726%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.184 Acc 94.670%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.186 Acc 94.567%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.177 Acc 95.514%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.171 Acc 95.553%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.159 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.186 Acc 94.794%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.186 Acc 94.733%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.181 Acc 94.804%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.183 Acc 94.695%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.184 Acc 94.650%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.181 Acc 95.266%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.175 Acc 95.429%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.151 Acc 93.750%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.182 Acc 94.609%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.180 Acc 94.815%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.179 Acc 94.791%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.181 Acc 94.722%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.183 Acc 94.706%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.661%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.165 Acc 95.728%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.208 Acc 92.969%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.189 Acc 94.369%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.188 Acc 94.516%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.183 Acc 94.619%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.183 Acc 94.646%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.182 Acc 94.648%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.174 Acc 95.320%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.168 Acc 95.553%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.184 Acc 94.640%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.176 Acc 94.807%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.174 Acc 94.830%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.181 Acc 94.703%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.182 Acc 94.740%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.182 Acc 95.382%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.176 Acc 95.449%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.181 Acc 94.972%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.179 Acc 94.970%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.180 Acc 94.936%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.180 Acc 94.898%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.182 Acc 94.823%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.116 Acc 94.531%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.176 Acc 95.459%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.171 Acc 95.565%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.152 Acc 97.656%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.184 Acc 94.802%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.185 Acc 94.823%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.182 Acc 94.835%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.181 Acc 94.859%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.181 Acc 94.881%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.183 Acc 95.289%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.176 Acc 95.371%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.180 Acc 94.686%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.177 Acc 94.842%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.180 Acc 94.762%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.180 Acc 94.831%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.180 Acc 94.778%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.189 Acc 93.750%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.178 Acc 95.374%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.172 Acc 95.546%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.173 Acc 94.895%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.177 Acc 94.838%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.177 Acc 94.866%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.177 Acc 94.864%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.175 Acc 94.926%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.183 Acc 95.212%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.178 Acc 95.281%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.211 Acc 95.312%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.172 Acc 95.091%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.175 Acc 95.001%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.176 Acc 94.974%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.176 Acc 94.940%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.182 Acc 95.359%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.176 Acc 95.433%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.169 Acc 95.274%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.173 Acc 95.048%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.176 Acc 94.991%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.179 Acc 94.933%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.180 Acc 94.924%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.178 Acc 95.421%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.173 Acc 95.472%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.173 Acc 94.848%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.173 Acc 94.900%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.172 Acc 94.967%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.172 Acc 94.979%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.173 Acc 94.977%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.179 Acc 95.382%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.172 Acc 95.538%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.157 Acc 95.204%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.169 Acc 94.963%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.175 Acc 94.861%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.175 Acc 94.890%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.175 Acc 94.898%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.176 Acc 95.374%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.169 Acc 95.569%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.154 Acc 92.969%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.177 Acc 94.887%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.176 Acc 94.831%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.173 Acc 94.822%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.172 Acc 94.866%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.174 Acc 94.854%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.179 Acc 95.405%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.172 Acc 95.581%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.179 Acc 94.756%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.177 Acc 94.831%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.175 Acc 94.952%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.177 Acc 94.964%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.175 Acc 94.985%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.171 Acc 95.721%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.163 Acc 95.149%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.166 Acc 95.146%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.170 Acc 95.102%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.173 Acc 95.022%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.174 Acc 95.449%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.145 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.172 Acc 94.879%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.165 Acc 95.130%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.165 Acc 95.152%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.167 Acc 95.110%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.167 Acc 95.111%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.176 Acc 95.367%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.170 Acc 95.553%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.283 Acc 91.406%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.160 Acc 95.243%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.162 Acc 95.173%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.167 Acc 95.126%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.171 Acc 95.016%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.170 Acc 95.044%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.128 Acc 92.969%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.183 Acc 95.328%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.175 Acc 95.472%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.167 Acc 95.096%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.168 Acc 95.052%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.172 Acc 94.980%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.170 Acc 95.090%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.169 Acc 95.102%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.176 Acc 95.475%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.169 Acc 95.534%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.160 Acc 95.166%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.167 Acc 95.114%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.169 Acc 95.097%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.167 Acc 95.147%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.168 Acc 95.132%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.177 Acc 95.444%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.170 Acc 95.585%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.102 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.172 Acc 95.135%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.169 Acc 95.122%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.170 Acc 95.162%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.168 Acc 95.198%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.168 Acc 95.189%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.266%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.180 Acc 95.375%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.170 Acc 95.135%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.169 Acc 95.044%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.168 Acc 95.131%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.169 Acc 95.090%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.169 Acc 95.091%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.184 Acc 95.166%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.176 Acc 95.363%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.160 Acc 95.467%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.162 Acc 95.460%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.159 Acc 95.460%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.161 Acc 95.396%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.163 Acc 95.334%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.122 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.171 Acc 95.637%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.163 Acc 95.771%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.161 Acc 95.212%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.170 Acc 95.106%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.166 Acc 95.268%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.165 Acc 95.237%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.165 Acc 95.277%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.180 Acc 95.343%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.173 Acc 95.538%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.158 Acc 95.483%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.161 Acc 95.297%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.160 Acc 95.393%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.160 Acc 95.351%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.162 Acc 95.297%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.166 Acc 95.692%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.160 Acc 95.857%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.159 Acc 95.336%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.165 Acc 95.204%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.163 Acc 95.268%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.166 Acc 95.198%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.179 Acc 95.274%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.171 Acc 95.522%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.159 Acc 95.459%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.163 Acc 95.456%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.163 Acc 95.362%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.165 Acc 95.330%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.164 Acc 95.355%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.181 Acc 95.328%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.173 Acc 95.565%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.405 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.164 Acc 95.088%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.163 Acc 95.176%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.165 Acc 95.136%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.163 Acc 95.246%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.163 Acc 95.238%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.170 Acc 95.606%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.165 Acc 95.705%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.166 Acc 95.258%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.167 Acc 95.223%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.163 Acc 95.263%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.161 Acc 95.334%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.162 Acc 95.292%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.175 Acc 95.498%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.168 Acc 95.732%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.150 Acc 95.545%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.155 Acc 95.371%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.158 Acc 95.422%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.162 Acc 95.289%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.162 Acc 95.334%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.173 Acc 95.526%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.076 Acc 99.219%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.161 Acc 95.220%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.153 Acc 95.328%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.158 Acc 95.294%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.158 Acc 95.314%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.160 Acc 95.270%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 95.651%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.155 Acc 95.467%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.398%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.158 Acc 95.408%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.159 Acc 95.408%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.137 Acc 93.750%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.176 Acc 95.490%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.168 Acc 95.655%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.155 Acc 95.645%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.152 Acc 95.639%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.155 Acc 95.595%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.157 Acc 95.550%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.160 Acc 95.420%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.175 Acc 95.506%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.166 Acc 95.643%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.274 Acc 92.188%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.161 Acc 95.545%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.158 Acc 95.522%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.159 Acc 95.419%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.161 Acc 95.427%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.158 Acc 95.464%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.177 Acc 95.336%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.170 Acc 95.596%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.262 Acc 92.188%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.144 Acc 95.784%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.151 Acc 95.678%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.154 Acc 95.614%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.153 Acc 95.613%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.156 Acc 95.515%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.113 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.165 Acc 95.794%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.160 Acc 95.421%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.160 Acc 95.441%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.155 Acc 95.541%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.156 Acc 95.496%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.158 Acc 95.442%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.178 Acc 95.359%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.170 Acc 95.596%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.151 Acc 95.715%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.156 Acc 95.550%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.158 Acc 95.510%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.157 Acc 95.513%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.157 Acc 95.495%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.176 Acc 95.421%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.168 Acc 95.701%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.160 Acc 93.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.151 Acc 95.483%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.146 Acc 95.705%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.149 Acc 95.619%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.151 Acc 95.552%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.152 Acc 95.520%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.179 Acc 95.351%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.171 Acc 95.623%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.211 Acc 93.750%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.150 Acc 95.653%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.150 Acc 95.690%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.154 Acc 95.632%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.155 Acc 95.628%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.157 Acc 95.562%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.185 Acc 95.150%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.177 Acc 95.359%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.155 Acc 95.351%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.154 Acc 95.503%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.153 Acc 95.536%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.158 Acc 95.414%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.157 Acc 95.420%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.169 Acc 95.692%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.163 Acc 95.903%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.153 Acc 95.519%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.152 Acc 95.549%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.153 Acc 95.593%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.153 Acc 95.581%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.176 Acc 95.351%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.170 Acc 95.468%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.147 Acc 95.645%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.146 Acc 95.690%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.150 Acc 95.642%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.150 Acc 95.677%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.152 Acc 95.662%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.166 Acc 95.763%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.153 Acc 95.568%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.153 Acc 95.546%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.152 Acc 95.525%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.153 Acc 95.519%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.154 Acc 95.512%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.174 Acc 95.413%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.165 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.146 Acc 95.630%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.150 Acc 95.697%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.149 Acc 95.712%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.149 Acc 95.681%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.150 Acc 95.656%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.170 Acc 95.560%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.162 Acc 95.872%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.137 Acc 95.862%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.144 Acc 95.794%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.148 Acc 95.722%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.149 Acc 95.640%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.174 Acc 95.475%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.166 Acc 95.620%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.139 Acc 95.962%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.143 Acc 95.841%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.146 Acc 95.816%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.148 Acc 95.766%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.150 Acc 95.674%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.181 Acc 95.506%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.174 Acc 95.662%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.321 Acc 89.844%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.154 Acc 95.452%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.156 Acc 95.499%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.151 Acc 95.629%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.151 Acc 95.673%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.150 Acc 95.654%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.124 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.172 Acc 95.622%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.164 Acc 95.787%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.143 Acc 95.815%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.145 Acc 95.631%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.148 Acc 95.590%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.147 Acc 95.624%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.150 Acc 95.562%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.176 Acc 95.583%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.167 Acc 95.794%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.143 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.141 Acc 95.978%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.145 Acc 95.868%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.148 Acc 95.766%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.149 Acc 95.705%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.179 Acc 95.560%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.170 Acc 95.678%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.148 Acc 95.614%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.152 Acc 95.596%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.150 Acc 95.691%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.151 Acc 95.630%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.149 Acc 95.654%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.176 Acc 95.583%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.168 Acc 95.767%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.149 Acc 95.614%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.147 Acc 95.767%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.148 Acc 95.808%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.150 Acc 95.739%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.149 Acc 95.776%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.178 Acc 95.614%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.172 Acc 95.771%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.166 Acc 92.188%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.146 Acc 95.645%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.148 Acc 95.693%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.146 Acc 95.749%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.145 Acc 95.803%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.147 Acc 95.754%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.174 Acc 95.612%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.195 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.147 Acc 95.637%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.143 Acc 95.899%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.143 Acc 95.839%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.144 Acc 95.823%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.145 Acc 95.794%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.177 Acc 95.490%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.167 Acc 95.732%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.141 Acc 96.040%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.145 Acc 95.771%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.141 Acc 95.928%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.144 Acc 95.911%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.147 Acc 95.810%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.176 Acc 95.545%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.169 Acc 95.725%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.149 Acc 95.753%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.145 Acc 95.911%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.146 Acc 95.873%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.146 Acc 95.800%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.148 Acc 95.735%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.175 Acc 95.581%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.136 Acc 96.163%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.140 Acc 96.063%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.139 Acc 96.006%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.141 Acc 95.994%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.144 Acc 95.960%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.176 Acc 95.668%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.168 Acc 95.841%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.148 Acc 95.885%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.148 Acc 95.763%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.144 Acc 95.870%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.146 Acc 95.791%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.176 Acc 95.444%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.168 Acc 95.791%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.135 Acc 95.962%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.141 Acc 95.849%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.143 Acc 95.800%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.143 Acc 95.793%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.181 Acc 95.274%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.172 Acc 95.522%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.197 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.144 Acc 95.826%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.144 Acc 95.798%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.144 Acc 95.889%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.144 Acc 95.838%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.179 Acc 95.537%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.170 Acc 95.748%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.139 Acc 96.009%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.143 Acc 95.985%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.142 Acc 95.959%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.145 Acc 95.889%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.144 Acc 95.894%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.118 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.175 Acc 95.637%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.168 Acc 95.829%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.140 Acc 95.900%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.141 Acc 95.837%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.141 Acc 95.855%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.145 Acc 95.809%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.144 Acc 95.838%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.182 Acc 95.398%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.173 Acc 95.639%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.141 Acc 95.784%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.140 Acc 95.771%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.142 Acc 95.815%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.142 Acc 95.833%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.178 Acc 95.429%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.135 Acc 95.924%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.136 Acc 95.872%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.138 Acc 95.915%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.141 Acc 95.876%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.142 Acc 95.882%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.179 Acc 95.328%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.171 Acc 95.592%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.066 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.147 Acc 95.746%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.147 Acc 95.802%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.145 Acc 95.764%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.145 Acc 95.790%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.143 Acc 95.865%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.661%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.167 Acc 95.806%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.245 Acc 94.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.134 Acc 96.163%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.135 Acc 96.102%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.138 Acc 96.024%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.141 Acc 95.961%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.140 Acc 96.011%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.181 Acc 95.405%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.173 Acc 95.608%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.225 Acc 93.750%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.140 Acc 95.869%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.136 Acc 96.004%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.138 Acc 96.018%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.139 Acc 95.942%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.140 Acc 95.927%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.183 Acc 95.204%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.176 Acc 95.398%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.265 Acc 91.406%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.145 Acc 95.893%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.140 Acc 95.997%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.137 Acc 96.065%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.138 Acc 95.963%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.140 Acc 95.942%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.179 Acc 95.490%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.170 Acc 95.783%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.143 Acc 96.109%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.142 Acc 95.946%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.141 Acc 95.972%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.139 Acc 95.948%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.140 Acc 95.944%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.444%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.167 Acc 95.666%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.063 Acc 96.875%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.133 Acc 96.117%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.135 Acc 96.102%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.134 Acc 96.089%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.135 Acc 96.074%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.137 Acc 96.022%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.172 Acc 95.622%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.165 Acc 95.861%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.269 Acc 94.531%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.136 Acc 95.970%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.132 Acc 96.168%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.137 Acc 96.035%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.137 Acc 96.008%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.172 Acc 95.630%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.164 Acc 95.888%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.132 Acc 96.364%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.132 Acc 96.238%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.133 Acc 96.135%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.137 Acc 96.035%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.137 Acc 96.036%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.181 Acc 95.568%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.172 Acc 95.767%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.117 Acc 96.434%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.129 Acc 96.195%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.131 Acc 96.107%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.133 Acc 96.053%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.135 Acc 95.991%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.174 Acc 95.514%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.167 Acc 95.736%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.128 Acc 96.395%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.124 Acc 96.412%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.130 Acc 96.104%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.133 Acc 96.082%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.135 Acc 96.058%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.171 Acc 95.707%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.164 Acc 95.931%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.127 Acc 96.109%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.135 Acc 96.137%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.133 Acc 96.135%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.133 Acc 96.121%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.135 Acc 96.091%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.178 Acc 95.498%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.168 Acc 95.872%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.131 Acc 96.132%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.133 Acc 96.152%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.133 Acc 96.086%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.135 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.136 Acc 96.033%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.174 Acc 95.552%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.166 Acc 95.861%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.135 Acc 96.024%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.134 Acc 96.047%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.133 Acc 96.097%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.180 Acc 95.490%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.181 Acc 93.750%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.130 Acc 96.261%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.135 Acc 96.091%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.134 Acc 96.080%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.135 Acc 96.056%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.173 Acc 95.560%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.164 Acc 95.857%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.128 Acc 96.272%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.129 Acc 96.206%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.129 Acc 96.161%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.132 Acc 96.074%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.134 Acc 96.014%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.177 Acc 95.668%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.169 Acc 95.919%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.126 Acc 96.140%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.130 Acc 96.152%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.133 Acc 96.096%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.131 Acc 96.154%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.133 Acc 96.109%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.180 Acc 95.552%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.173 Acc 95.814%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.129 Acc 96.055%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.127 Acc 96.156%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.131 Acc 96.070%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.132 Acc 96.068%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.132 Acc 96.088%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.172 Acc 95.854%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.163 Acc 96.086%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.131 Acc 96.295%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.130 Acc 96.218%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.131 Acc 96.169%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.132 Acc 96.170%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.132 Acc 96.203%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.176 Acc 95.676%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.167 Acc 95.915%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.148 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.143 Acc 95.862%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.138 Acc 95.985%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.135 Acc 96.013%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.135 Acc 96.041%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.133 Acc 96.077%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.180 Acc 95.722%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.171 Acc 95.896%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.116 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.130 Acc 96.109%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.128 Acc 96.226%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.129 Acc 96.244%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.131 Acc 96.195%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.176 Acc 95.690%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.131 Acc 96.272%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.133 Acc 96.199%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.131 Acc 96.191%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.133 Acc 96.173%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.178 Acc 95.684%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.168 Acc 95.849%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.128 Acc 96.364%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.130 Acc 96.257%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.131 Acc 96.198%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.132 Acc 96.158%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.133 Acc 96.103%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.140 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.176 Acc 95.761%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.168 Acc 95.931%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.257 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.132 Acc 96.194%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.131 Acc 96.121%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.131 Acc 96.164%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.131 Acc 96.164%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.129 Acc 96.395%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.126 Acc 96.385%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.129 Acc 96.301%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.130 Acc 96.283%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.131 Acc 96.254%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.174 Acc 95.622%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.167 Acc 95.896%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.131 Acc 96.395%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.132 Acc 96.284%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.129 Acc 96.294%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.130 Acc 96.240%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.130 Acc 96.231%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.165 Acc 95.927%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.119 Acc 96.318%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.123 Acc 96.362%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.128 Acc 96.283%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.130 Acc 96.209%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.129 Acc 96.248%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.187 Acc 95.374%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.179 Acc 95.600%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.154 Acc 93.750%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.129 Acc 96.009%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.128 Acc 96.133%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.130 Acc 96.127%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.130 Acc 96.148%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.130 Acc 96.155%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.176 Acc 95.637%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.132 Acc 96.248%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.125 Acc 96.350%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.125 Acc 96.327%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.128 Acc 96.255%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.128 Acc 96.245%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.180 Acc 95.661%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.174 Acc 95.864%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.126 Acc 96.248%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.123 Acc 96.343%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.125 Acc 96.327%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.125 Acc 96.326%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.127 Acc 96.245%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.168 Acc 95.884%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.128 Acc 96.218%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.127 Acc 96.308%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.127 Acc 96.252%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.128 Acc 96.250%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.127 Acc 96.250%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.181 Acc 95.692%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.174 Acc 95.868%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.126 Acc 96.372%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.125 Acc 96.408%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.125 Acc 96.405%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.125 Acc 96.398%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.177 Acc 95.583%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.167 Acc 95.845%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.121 Acc 96.481%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.121 Acc 96.463%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.124 Acc 96.366%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.124 Acc 96.390%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.124 Acc 96.374%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.181 Acc 95.421%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.171 Acc 95.756%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.214 Acc 95.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.123 Acc 96.279%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.123 Acc 96.315%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.125 Acc 96.275%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.123 Acc 96.304%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.122 Acc 96.328%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.178 Acc 95.692%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.168 Acc 95.927%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.121 Acc 96.303%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.125 Acc 96.199%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.127 Acc 96.244%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.127 Acc 96.240%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.125 Acc 96.292%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.185 Acc 95.429%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.176 Acc 95.635%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.125 Acc 96.078%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.124 Acc 96.249%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.123 Acc 96.333%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.122 Acc 96.400%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.124 Acc 96.357%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.181 Acc 95.328%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.172 Acc 95.573%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.125 Acc 96.419%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.127 Acc 96.416%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.125 Acc 96.462%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.124 Acc 96.437%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.124 Acc 96.404%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.183 Acc 95.684%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.175 Acc 95.946%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.116 Acc 96.620%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.117 Acc 96.552%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.118 Acc 96.496%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.119 Acc 96.478%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.123 Acc 96.370%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.155 Acc 96.875%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.181 Acc 95.637%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.172 Acc 95.826%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.109 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.119 Acc 96.481%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.120 Acc 96.537%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.120 Acc 96.501%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.121 Acc 96.478%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.121 Acc 96.456%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.182 Acc 95.119%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.171 Acc 95.519%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.372 Acc 92.188%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.124 Acc 96.318%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.123 Acc 96.459%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.122 Acc 96.449%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.123 Acc 96.402%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.124 Acc 96.406%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.183 Acc 95.599%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.172 Acc 95.981%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.125 Acc 96.241%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.120 Acc 96.393%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.122 Acc 96.408%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.124 Acc 96.355%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.123 Acc 96.384%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.092 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.176 Acc 95.622%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.167 Acc 95.950%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.122 Acc 96.380%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.119 Acc 96.467%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.123 Acc 96.361%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.123 Acc 96.374%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.125 Acc 96.325%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.170 Acc 95.876%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.125 Acc 96.372%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.127 Acc 96.273%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.124 Acc 96.365%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.173 Acc 95.794%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.112 Acc 96.651%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.115 Acc 96.688%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.119 Acc 96.540%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.120 Acc 96.544%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.121 Acc 96.435%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.653%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.166 Acc 95.927%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.125 Acc 96.310%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.122 Acc 96.447%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.123 Acc 96.400%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.122 Acc 96.392%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.122 Acc 96.395%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.180 Acc 95.498%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.169 Acc 95.915%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.125 Acc 94.531%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.114 Acc 96.542%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.119 Acc 96.374%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.119 Acc 96.455%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.117 Acc 96.567%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.120 Acc 96.488%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.179 Acc 95.583%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.171 Acc 95.853%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.119 Acc 96.651%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.115 Acc 96.650%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.118 Acc 96.569%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.120 Acc 96.499%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.120 Acc 96.509%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.180 Acc 95.668%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.173 Acc 95.907%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.118 Acc 96.372%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.122 Acc 96.374%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.118 Acc 96.478%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.118 Acc 96.505%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.120 Acc 96.479%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.175 Acc 95.753%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.169 Acc 96.004%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.109 Acc 96.852%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.114 Acc 96.681%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.118 Acc 96.621%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.118 Acc 96.583%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.121 Acc 96.509%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.172 Acc 95.884%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.114 Acc 96.511%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.116 Acc 96.467%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.120 Acc 96.382%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.121 Acc 96.386%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.119 Acc 96.415%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.171 Acc 96.875%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.181 Acc 95.429%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.173 Acc 95.655%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.113 Acc 96.612%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.118 Acc 96.482%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.115 Acc 96.545%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.116 Acc 96.511%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.118 Acc 96.498%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.181 Acc 95.529%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.173 Acc 95.791%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.117 Acc 96.658%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.114 Acc 96.774%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.117 Acc 96.567%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.118 Acc 96.551%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.183 Acc 95.467%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.174 Acc 95.717%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.165 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.115 Acc 96.630%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.117 Acc 96.569%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.118 Acc 96.548%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.119 Acc 96.505%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.175 Acc 95.521%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.167 Acc 95.802%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.107 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.113 Acc 96.627%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.115 Acc 96.583%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.114 Acc 96.587%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.117 Acc 96.507%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.117 Acc 96.510%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.177 Acc 95.599%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.170 Acc 95.756%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.120 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.117 Acc 96.349%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.117 Acc 96.470%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.117 Acc 96.460%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.118 Acc 96.440%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.161 Acc 97.656%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.186 Acc 95.436%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.176 Acc 95.736%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.112 Acc 96.535%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.117 Acc 96.444%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.115 Acc 96.522%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.116 Acc 96.528%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.116 Acc 96.558%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.179 Acc 95.552%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.056 Acc 100.000%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.108 Acc 96.929%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.111 Acc 96.727%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.113 Acc 96.680%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.114 Acc 96.600%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.115 Acc 96.560%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.179 Acc 95.630%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.171 Acc 95.794%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.116 Acc 96.380%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.119 Acc 96.377%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.118 Acc 96.418%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.118 Acc 96.388%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.116 Acc 96.493%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.189 Acc 95.692%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.180 Acc 95.814%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.117 Acc 96.612%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.117 Acc 96.642%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.118 Acc 96.473%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.116 Acc 96.466%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.117 Acc 96.463%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.173 Acc 95.864%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.109 Acc 96.914%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.112 Acc 96.720%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.115 Acc 96.592%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.117 Acc 96.610%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.174 Acc 95.732%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.134 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.117 Acc 96.295%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.118 Acc 96.315%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.115 Acc 96.499%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.115 Acc 96.517%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.115 Acc 96.541%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.183 Acc 95.715%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.173 Acc 95.931%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.111 Acc 96.743%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.112 Acc 96.683%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.115 Acc 96.582%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.125 Acc 96.875%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.187 Acc 95.490%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.176 Acc 95.763%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.110 Acc 96.550%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.112 Acc 96.700%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.115 Acc 96.631%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.114 Acc 96.657%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.113 Acc 96.635%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.184 Acc 95.676%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.174 Acc 95.802%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.115 Acc 96.380%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.116 Acc 96.436%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.114 Acc 96.579%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.113 Acc 96.637%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.113 Acc 96.657%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.188 Acc 95.599%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.178 Acc 95.767%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.113 Acc 96.798%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.112 Acc 96.797%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.112 Acc 96.709%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.114 Acc 96.600%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.114 Acc 96.602%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.180 Acc 95.630%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.171 Acc 95.907%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.109 Acc 96.705%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.109 Acc 96.735%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.111 Acc 96.673%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.113 Acc 96.633%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.113 Acc 96.649%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.179 Acc 95.831%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.171 Acc 96.032%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775f86c4cd6346e49ea23d0a9ba6cec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.321 Acc 17.969%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.250 Acc 19.872%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.242 Acc 19.306%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.232 Acc 19.440%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.194 Acc 21.010%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.124 Acc 23.944%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.583 Acc 47.656%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.619 Acc 46.612%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.615 Acc 46.723%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.731 Acc 38.281%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.520 Acc 48.461%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.444 Acc 51.586%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.374 Acc 54.015%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.322 Acc 55.858%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.273 Acc 57.663%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.831 Acc 72.656%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.833 Acc 73.762%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.830 Acc 73.729%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.889 Acc 68.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.980 Acc 68.116%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.952 Acc 69.213%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.921 Acc 70.159%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.892 Acc 71.061%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.876 Acc 71.655%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.574 Acc 81.250%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.606 Acc 81.219%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.600 Acc 81.367%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.710 Acc 74.219%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.719 Acc 77.011%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.711 Acc 77.367%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.698 Acc 77.775%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.687 Acc 78.113%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.677 Acc 78.463%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.417 Acc 86.719%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.474 Acc 85.620%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.466 Acc 85.844%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.724 Acc 80.469%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.598 Acc 80.879%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.592 Acc 81.161%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.587 Acc 81.312%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.583 Acc 81.521%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.578 Acc 81.766%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.382 Acc 87.500%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.429 Acc 87.399%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.422 Acc 87.438%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.590 Acc 80.469%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.542 Acc 83.269%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.535 Acc 83.364%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.528 Acc 83.498%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.523 Acc 83.701%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.519 Acc 83.772%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.361 Acc 87.500%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.389 Acc 88.351%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.383 Acc 88.378%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.470 Acc 87.500%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.493 Acc 84.599%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.482 Acc 84.962%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.483 Acc 84.860%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.479 Acc 84.987%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.475 Acc 85.187%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.349 Acc 88.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.360 Acc 89.503%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.353 Acc 89.576%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.414 Acc 85.156%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.452 Acc 85.512%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.454 Acc 85.833%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.452 Acc 85.979%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.450 Acc 86.107%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.446 Acc 86.173%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.290 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.332 Acc 90.130%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.326 Acc 90.267%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.375 Acc 90.625%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.414 Acc 87.299%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.423 Acc 87.193%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.425 Acc 86.942%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.422 Acc 86.923%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.422 Acc 87.013%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.347 Acc 88.281%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.332 Acc 90.370%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.327 Acc 90.454%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.414 Acc 85.938%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.418 Acc 87.067%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.410 Acc 87.360%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.401 Acc 87.635%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.404 Acc 87.570%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.399 Acc 87.703%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.282 Acc 89.062%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.300 Acc 91.244%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.294 Acc 91.465%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.438 Acc 86.719%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.393 Acc 87.786%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.393 Acc 87.869%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.390 Acc 88.019%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.385 Acc 88.186%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.385 Acc 88.167%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.287 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.302 Acc 91.236%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.297 Acc 91.301%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.386 Acc 90.625%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.379 Acc 88.459%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.381 Acc 88.382%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.377 Acc 88.476%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.371 Acc 88.648%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.367 Acc 88.755%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.272 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.285 Acc 91.832%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.280 Acc 91.892%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.386 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.337 Acc 89.449%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.345 Acc 89.253%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.350 Acc 89.182%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.350 Acc 89.082%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.351 Acc 89.128%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.283 Acc 92.041%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.278 Acc 92.203%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.282 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.339 Acc 89.581%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.347 Acc 89.471%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.343 Acc 89.597%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.345 Acc 89.516%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.343 Acc 89.540%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.261 Acc 90.625%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.266 Acc 92.296%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.264 Acc 92.331%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.393 Acc 87.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.338 Acc 89.720%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.338 Acc 89.692%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.333 Acc 89.763%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.332 Acc 89.832%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.332 Acc 89.828%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.270 Acc 92.435%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.266 Acc 92.409%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.327 Acc 87.500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.322 Acc 90.339%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.323 Acc 90.089%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.321 Acc 90.134%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.322 Acc 90.120%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.322 Acc 90.198%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.260 Acc 93.015%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.255 Acc 92.872%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.384 Acc 86.719%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.309 Acc 90.486%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.310 Acc 90.726%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.311 Acc 90.690%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.315 Acc 90.594%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.314 Acc 90.675%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.239 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.246 Acc 93.239%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.242 Acc 93.179%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.310 Acc 90.478%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.307 Acc 90.730%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.306 Acc 90.794%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.304 Acc 90.849%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.304 Acc 90.889%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.235 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.237 Acc 93.626%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.233 Acc 93.528%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.414 Acc 83.594%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.294 Acc 91.298%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.294 Acc 91.231%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.294 Acc 91.087%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.298 Acc 90.982%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.299 Acc 90.923%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.229 Acc 92.188%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.236 Acc 93.487%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.231 Acc 93.455%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.284 Acc 91.252%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.287 Acc 91.212%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.289 Acc 91.276%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.292 Acc 91.132%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.292 Acc 91.219%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.234 Acc 93.704%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.231 Acc 93.610%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.227 Acc 93.750%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.290 Acc 91.244%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.288 Acc 90.990%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.291 Acc 90.949%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.289 Acc 91.048%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.289 Acc 91.074%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.231 Acc 93.773%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.229 Acc 93.661%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.195 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.276 Acc 91.739%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.282 Acc 91.643%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.277 Acc 91.775%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.279 Acc 91.654%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.279 Acc 91.671%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.223 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.224 Acc 94.005%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.222 Acc 93.878%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.327 Acc 92.969%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.279 Acc 91.762%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.278 Acc 91.772%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.276 Acc 91.798%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.275 Acc 91.815%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.277 Acc 91.742%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.223 Acc 93.773%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.219 Acc 93.832%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.227 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.267 Acc 91.955%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.265 Acc 92.125%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.265 Acc 92.120%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.267 Acc 92.059%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.271 Acc 91.960%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.258 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.229 Acc 93.735%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.225 Acc 93.664%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.292 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.258 Acc 92.373%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.262 Acc 92.300%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.265 Acc 92.089%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.267 Acc 92.032%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.268 Acc 92.028%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.212 Acc 94.431%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.207 Acc 94.380%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.260 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.268 Acc 92.025%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.270 Acc 92.009%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.263 Acc 92.203%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.260 Acc 92.289%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.261 Acc 92.295%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.217 Acc 94.168%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.215 Acc 93.964%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.217 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.245 Acc 92.659%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.258 Acc 92.273%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.259 Acc 92.317%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.259 Acc 92.367%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.258 Acc 92.331%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.230 Acc 92.969%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.208 Acc 94.454%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.203 Acc 94.360%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.320 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.256 Acc 92.257%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.257 Acc 92.242%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.260 Acc 92.224%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.256 Acc 92.423%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.254 Acc 92.420%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.180 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.212 Acc 94.261%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.208 Acc 94.135%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.137 Acc 94.531%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.249 Acc 92.528%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.255 Acc 92.374%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.253 Acc 92.411%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.250 Acc 92.515%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.252 Acc 92.499%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.213 Acc 94.361%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.208 Acc 94.236%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.178 Acc 94.531%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.238 Acc 92.868%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.244 Acc 92.736%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.244 Acc 92.652%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.245 Acc 92.614%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.247 Acc 92.541%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.197 Acc 94.787%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.193 Acc 94.776%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.267 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.236 Acc 92.961%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.244 Acc 92.868%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.241 Acc 92.912%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.244 Acc 92.795%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.243 Acc 92.861%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.205 Acc 94.701%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.200 Acc 94.640%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.276 Acc 90.625%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.231 Acc 93.069%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.238 Acc 93.004%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.240 Acc 92.899%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.240 Acc 92.926%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.243 Acc 92.855%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.200 Acc 94.732%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.195 Acc 94.710%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.250 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.233 Acc 93.139%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.237 Acc 93.109%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.239 Acc 92.964%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.238 Acc 92.938%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.238 Acc 92.909%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.201 Acc 92.188%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.202 Acc 94.686%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.196 Acc 94.640%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.131 Acc 95.312%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.244 Acc 92.822%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.236 Acc 92.965%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.235 Acc 93.039%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.236 Acc 93.025%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.238 Acc 92.967%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.197 Acc 95.011%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.192 Acc 94.869%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.147 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.221 Acc 93.441%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.226 Acc 93.078%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.227 Acc 93.171%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.231 Acc 93.070%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.231 Acc 93.143%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.957%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.193 Acc 94.862%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.232 Acc 93.170%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.225 Acc 93.287%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.230 Acc 93.161%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.232 Acc 93.109%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.231 Acc 93.140%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.199 Acc 94.802%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.195 Acc 94.757%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.227 Acc 93.255%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.224 Acc 93.462%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.229 Acc 93.285%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.227 Acc 93.374%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.228 Acc 93.302%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.196 Acc 94.810%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.190 Acc 94.873%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.233 Acc 93.054%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.229 Acc 93.194%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.228 Acc 93.200%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.226 Acc 93.331%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.227 Acc 93.321%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.185 Acc 94.998%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.329 Acc 89.062%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.226 Acc 93.301%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.234 Acc 93.291%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.226 Acc 93.413%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.223 Acc 93.473%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.224 Acc 93.446%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.199 Acc 94.740%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.194 Acc 94.675%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.221 Acc 93.704%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.221 Acc 93.602%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.221 Acc 93.498%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.220 Acc 93.528%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.220 Acc 93.558%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.190 Acc 95.111%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.187 Acc 95.052%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.283 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.229 Acc 93.433%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.227 Acc 93.540%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.231 Acc 93.374%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.228 Acc 93.390%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.224 Acc 93.504%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.193 Acc 94.879%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.225 Acc 93.402%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.220 Acc 93.462%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.216 Acc 93.529%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.220 Acc 93.458%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.221 Acc 93.455%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.183 Acc 95.141%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.212 Acc 92.969%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.216 Acc 93.680%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.211 Acc 93.711%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.213 Acc 93.680%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.215 Acc 93.631%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.216 Acc 93.624%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.194 Acc 94.748%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.189 Acc 94.799%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.185 Acc 93.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.216 Acc 93.595%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.205 Acc 93.878%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.209 Acc 93.856%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.210 Acc 93.826%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.212 Acc 93.823%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.192 Acc 95.003%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.186 Acc 95.072%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.383 Acc 90.625%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.213 Acc 93.472%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.215 Acc 93.602%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.212 Acc 93.724%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.213 Acc 93.762%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.213 Acc 93.717%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.173 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.184 Acc 95.173%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.179 Acc 95.246%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.208 Acc 93.982%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.205 Acc 94.030%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.207 Acc 93.973%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.211 Acc 93.816%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.212 Acc 93.867%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.183 Acc 95.320%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.180 Acc 95.215%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.244 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.207 Acc 93.889%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.206 Acc 93.925%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.207 Acc 93.994%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.208 Acc 93.943%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.210 Acc 93.822%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.180 Acc 95.328%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.176 Acc 95.355%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.212 Acc 93.758%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.214 Acc 93.777%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.210 Acc 93.838%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.209 Acc 93.869%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.207 Acc 93.937%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.183 Acc 95.328%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.179 Acc 95.289%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.155 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.212 Acc 94.044%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.210 Acc 93.933%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.209 Acc 93.903%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.207 Acc 93.957%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.207 Acc 93.936%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.180 Acc 95.320%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.177 Acc 95.285%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.251 Acc 90.625%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.200 Acc 94.191%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.201 Acc 94.216%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.203 Acc 94.134%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.205 Acc 94.097%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.206 Acc 94.057%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.174 Acc 95.386%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.207 Acc 94.083%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.204 Acc 94.123%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.204 Acc 93.989%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.206 Acc 93.939%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.204 Acc 94.028%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.266%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.174 Acc 95.433%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.194 Acc 92.969%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.191 Acc 94.384%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.196 Acc 94.279%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.198 Acc 94.264%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.199 Acc 94.171%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.200 Acc 94.112%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.188 Acc 94.972%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 94.935%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.196 Acc 94.245%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.200 Acc 93.983%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.200 Acc 94.015%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.202 Acc 94.013%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.200 Acc 94.056%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.174 Acc 95.421%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.170 Acc 95.484%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.189 Acc 94.183%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.189 Acc 94.267%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.195 Acc 94.298%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.198 Acc 94.216%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.198 Acc 94.176%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.178 Acc 95.270%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.129 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.194 Acc 94.291%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.191 Acc 94.345%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.192 Acc 94.334%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.195 Acc 94.276%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.197 Acc 94.243%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.172 Acc 95.526%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.204 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.189 Acc 94.701%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.194 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.196 Acc 94.376%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.195 Acc 94.368%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.196 Acc 94.363%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.182 Acc 95.367%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.176 Acc 95.390%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.094 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.189 Acc 94.670%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.197 Acc 94.356%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.191 Acc 94.443%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.192 Acc 94.430%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.194 Acc 94.442%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.186 Acc 95.212%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.182 Acc 95.211%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.169 Acc 93.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.190 Acc 94.508%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.184 Acc 94.632%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.190 Acc 94.425%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.193 Acc 94.424%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.193 Acc 94.402%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.192 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.170 Acc 95.568%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.546%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.196 Acc 94.493%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.190 Acc 94.551%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.188 Acc 94.614%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.189 Acc 94.533%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.190 Acc 94.519%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.176 Acc 95.405%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.173 Acc 95.425%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.175 Acc 94.964%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.183 Acc 94.698%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.185 Acc 94.630%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.189 Acc 94.559%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.189 Acc 94.520%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.177 Acc 95.374%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.172 Acc 95.464%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.186 Acc 94.810%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.186 Acc 94.698%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.189 Acc 94.557%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.191 Acc 94.549%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.190 Acc 94.523%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.661%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.169 Acc 95.623%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.182 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.186 Acc 94.554%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.188 Acc 94.543%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.185 Acc 94.570%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.186 Acc 94.522%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.188 Acc 94.467%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.171 Acc 95.476%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.216 Acc 92.188%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.191 Acc 94.168%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.188 Acc 94.325%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.187 Acc 94.396%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.190 Acc 94.352%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.188 Acc 94.427%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.177 Acc 95.405%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.172 Acc 95.553%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.188 Acc 94.717%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.191 Acc 94.597%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.186 Acc 94.671%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.186 Acc 94.642%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.187 Acc 94.648%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.177 Acc 95.343%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.173 Acc 95.398%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.135 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.176 Acc 94.802%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.181 Acc 94.679%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.185 Acc 94.583%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.518%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.186 Acc 94.537%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.174 Acc 95.459%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.169 Acc 95.561%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.182 Acc 94.949%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.179 Acc 94.850%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.180 Acc 94.801%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.183 Acc 94.726%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.184 Acc 94.731%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.178 Acc 95.297%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.171 Acc 95.390%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.205 Acc 94.531%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.184 Acc 94.686%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.179 Acc 94.823%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.180 Acc 94.835%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.182 Acc 94.814%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.184 Acc 94.700%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.167 Acc 92.188%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.175 Acc 95.490%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.170 Acc 95.546%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.144 Acc 92.969%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.183 Acc 94.632%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.345%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.185 Acc 94.464%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.186 Acc 94.496%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.186 Acc 94.522%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.171 Acc 95.661%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.368 Acc 92.969%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.185 Acc 94.686%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.182 Acc 94.737%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.180 Acc 94.679%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.180 Acc 94.718%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.181 Acc 94.693%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.182 Acc 92.188%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.173 Acc 95.475%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.168 Acc 95.534%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.176 Acc 94.771%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.177 Acc 94.726%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.179 Acc 94.786%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.178 Acc 94.804%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.181 Acc 94.801%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.178 Acc 95.444%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.172 Acc 95.538%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.166 Acc 95.050%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.168 Acc 94.990%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.172 Acc 94.931%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.174 Acc 94.921%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.176 Acc 94.888%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.169 Acc 95.405%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.163 Acc 95.553%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.184 Acc 92.969%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.167 Acc 95.026%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.172 Acc 95.017%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.176 Acc 94.887%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.177 Acc 94.864%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.176 Acc 94.896%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.214 Acc 90.625%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.174 Acc 95.460%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.163 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.183 Acc 94.895%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.177 Acc 95.044%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.175 Acc 95.050%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.177 Acc 95.026%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.178 Acc 94.988%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.173 Acc 95.421%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.515%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.163 Acc 95.119%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.166 Acc 95.157%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.170 Acc 95.066%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.173 Acc 95.009%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.173 Acc 94.993%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.170 Acc 95.722%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 95.709%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.172 Acc 94.918%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.174 Acc 94.982%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.173 Acc 94.991%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.176 Acc 94.907%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.176 Acc 94.882%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.630%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.166 Acc 95.709%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.169 Acc 94.933%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.171 Acc 94.943%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.173 Acc 94.934%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.174 Acc 94.905%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.175 Acc 94.941%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.174 Acc 95.467%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.170 Acc 95.565%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.105 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.178 Acc 94.624%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.173 Acc 94.799%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.173 Acc 94.939%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.172 Acc 94.958%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.173 Acc 94.963%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.189 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.173 Acc 95.459%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.167 Acc 95.569%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.176 Acc 92.969%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.175 Acc 94.879%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.172 Acc 95.029%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.174 Acc 94.991%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.175 Acc 94.974%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.175 Acc 94.962%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.166 Acc 95.707%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.163 Acc 95.794%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.161 Acc 95.320%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.175 Acc 95.068%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.175 Acc 94.949%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.174 Acc 94.952%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.172 Acc 94.954%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.172 Acc 95.591%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.166 Acc 95.736%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.161 Acc 95.258%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.169 Acc 95.048%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.170 Acc 95.006%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.171 Acc 95.065%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.172 Acc 95.099%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.138 Acc 93.750%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.170 Acc 95.483%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.608%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.105 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.170 Acc 94.895%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.166 Acc 95.141%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.164 Acc 95.271%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.166 Acc 95.221%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.166 Acc 95.211%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.343%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.173 Acc 95.507%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.240 Acc 92.188%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.170 Acc 95.088%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.173 Acc 94.970%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.171 Acc 95.048%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.171 Acc 95.067%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.170 Acc 95.069%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.169 Acc 95.560%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.165 Acc 95.604%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.162 Acc 95.374%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.174 Acc 95.068%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.173 Acc 95.105%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.170 Acc 95.184%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.170 Acc 95.150%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.169 Acc 95.630%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.164 Acc 95.686%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.137 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.155 Acc 95.336%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.161 Acc 95.293%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.165 Acc 95.227%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.166 Acc 95.131%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.166 Acc 95.169%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.173 Acc 95.405%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.169 Acc 95.476%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.188 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.159 Acc 95.166%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.163 Acc 95.130%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.167 Acc 95.081%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.166 Acc 95.087%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.166 Acc 95.085%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.173 Acc 95.506%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.167 Acc 95.655%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.167 Acc 95.235%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.165 Acc 95.196%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.164 Acc 95.227%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.167 Acc 95.213%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.166 Acc 95.182%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.176 Acc 95.421%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.171 Acc 95.573%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.155 Acc 95.568%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.161 Acc 95.476%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.162 Acc 95.471%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.161 Acc 95.404%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.162 Acc 95.364%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.215 Acc 92.188%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.529%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.174 Acc 95.569%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.164 Acc 95.297%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.166 Acc 95.281%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.165 Acc 95.214%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.163 Acc 95.291%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.186 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.175 Acc 95.490%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.171 Acc 95.519%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.159 Acc 95.490%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.160 Acc 95.437%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.159 Acc 95.528%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.162 Acc 95.431%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.162 Acc 95.434%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.198 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.169 Acc 95.707%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.164 Acc 95.814%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.161 Acc 95.514%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.163 Acc 95.336%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.163 Acc 95.315%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.161 Acc 95.326%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.162 Acc 95.353%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.560%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.169 Acc 95.639%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.155 Acc 95.413%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.157 Acc 95.484%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.159 Acc 95.449%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.161 Acc 95.369%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.175 Acc 95.575%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.170 Acc 95.717%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.162 Acc 95.212%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.164 Acc 95.324%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.163 Acc 95.268%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.162 Acc 95.291%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.162 Acc 95.291%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.145 Acc 92.969%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.168 Acc 95.722%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.164 Acc 95.779%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.187 Acc 92.969%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.153 Acc 95.475%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.157 Acc 95.433%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.159 Acc 95.359%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.159 Acc 95.308%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.171 Acc 95.568%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.167 Acc 95.674%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.110 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.155 Acc 95.444%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.155 Acc 95.452%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.155 Acc 95.447%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.156 Acc 95.406%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.157 Acc 95.433%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.168 Acc 95.684%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.162 Acc 95.771%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.147 Acc 95.869%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.153 Acc 95.604%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.154 Acc 95.564%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.155 Acc 95.542%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.157 Acc 95.520%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.166 Acc 95.756%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.157 Acc 95.220%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.152 Acc 95.480%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.154 Acc 95.525%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.157 Acc 95.494%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.157 Acc 95.482%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.170 Acc 95.490%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.164 Acc 95.631%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.148 Acc 96.875%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.153 Acc 95.715%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.157 Acc 95.647%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.156 Acc 95.562%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.158 Acc 95.463%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.158 Acc 95.428%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.168 Acc 95.645%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.163 Acc 95.810%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.155 Acc 95.591%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.153 Acc 95.530%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.156 Acc 95.450%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.156 Acc 95.503%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.155 Acc 95.497%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.168 Acc 95.769%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.163 Acc 95.779%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.160 Acc 95.189%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.154 Acc 95.421%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.154 Acc 95.536%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.156 Acc 95.457%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.155 Acc 95.478%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.171 Acc 95.668%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.165 Acc 95.756%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.147 Acc 95.668%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.151 Acc 95.616%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.153 Acc 95.611%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.156 Acc 95.500%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.156 Acc 95.565%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.174 Acc 95.490%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.169 Acc 95.635%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.151 Acc 95.777%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.150 Acc 95.794%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.153 Acc 95.575%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.156 Acc 95.513%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.157 Acc 95.487%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.168 Acc 95.666%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.152 Acc 95.545%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.153 Acc 95.686%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.153 Acc 95.582%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.152 Acc 95.599%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.153 Acc 95.523%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.171 Acc 95.653%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.165 Acc 95.787%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.154 Acc 95.699%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.159 Acc 95.495%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.156 Acc 95.559%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.155 Acc 95.568%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.153 Acc 95.587%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.174 Acc 95.514%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.169 Acc 95.577%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.156 Acc 95.297%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.316%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.156 Acc 95.388%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.154 Acc 95.461%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.167 Acc 95.777%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.162 Acc 95.880%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.152 Acc 95.483%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.156 Acc 95.301%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.151 Acc 95.505%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.150 Acc 95.583%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.150 Acc 95.570%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.169 Acc 95.637%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.166 Acc 95.798%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.189 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.147 Acc 95.777%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.151 Acc 95.676%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.151 Acc 95.696%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.150 Acc 95.709%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.163 Acc 95.792%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.160 Acc 95.798%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.206 Acc 92.969%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.152 Acc 95.653%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.147 Acc 95.655%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.149 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.150 Acc 95.554%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.150 Acc 95.581%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.167 Acc 95.622%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.163 Acc 95.697%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.251 Acc 92.969%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.145 Acc 95.846%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.146 Acc 95.783%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.150 Acc 95.681%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.152 Acc 95.650%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.151 Acc 95.719%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.167 Acc 95.792%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.163 Acc 95.861%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.131 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.147 Acc 95.639%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.146 Acc 95.704%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.148 Acc 95.663%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.150 Acc 95.682%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.173 Acc 95.614%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.170 Acc 95.588%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.152 Acc 95.668%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.151 Acc 95.637%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.149 Acc 95.651%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.150 Acc 95.651%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.475%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.168 Acc 95.620%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.169 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.152 Acc 95.575%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.150 Acc 95.608%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.153 Acc 95.505%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.152 Acc 95.544%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.150 Acc 95.615%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.165 Acc 95.800%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.162 Acc 95.872%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.151 Acc 95.560%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.144 Acc 95.736%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.144 Acc 95.717%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.145 Acc 95.720%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.146 Acc 95.654%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.164 Acc 95.808%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.159 Acc 95.954%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.183 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.144 Acc 95.684%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.142 Acc 95.787%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.145 Acc 95.793%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.146 Acc 95.807%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.147 Acc 95.741%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.167 Acc 95.823%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.163 Acc 95.833%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.148 Acc 95.800%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.149 Acc 95.818%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.146 Acc 95.847%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.144 Acc 95.885%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.145 Acc 95.840%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.176 Acc 95.452%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.168 Acc 95.612%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.148 Acc 95.893%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.146 Acc 95.876%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.146 Acc 95.718%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.146 Acc 95.705%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.170 Acc 95.831%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.164 Acc 95.923%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.169 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.142 Acc 95.792%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.145 Acc 95.639%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.145 Acc 95.660%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.148 Acc 95.632%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.147 Acc 95.681%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.172 Acc 95.639%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.142 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.136 Acc 95.985%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.140 Acc 95.962%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.145 Acc 95.850%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.144 Acc 95.836%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.167 Acc 95.792%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.162 Acc 95.927%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.149 Acc 95.661%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.145 Acc 95.806%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.144 Acc 95.856%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.145 Acc 95.818%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.166 Acc 95.748%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.145 Acc 95.560%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.146 Acc 95.620%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.142 Acc 95.699%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.142 Acc 95.778%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.144 Acc 95.713%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.166 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.175 Acc 95.498%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.169 Acc 95.682%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.145 Acc 95.792%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.143 Acc 95.806%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.143 Acc 95.829%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.144 Acc 95.741%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.145 Acc 95.744%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.170 Acc 95.738%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.167 Acc 95.798%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.138 Acc 96.132%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.144 Acc 95.883%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.143 Acc 95.907%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.170 Acc 95.715%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.137 Acc 95.831%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.141 Acc 95.896%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.140 Acc 95.941%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.142 Acc 95.811%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.142 Acc 95.813%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.168 Acc 95.815%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.166 Acc 95.822%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.140 Acc 96.034%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.142 Acc 95.950%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.141 Acc 95.925%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.168 Acc 95.908%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.163 Acc 95.938%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.142 Acc 95.970%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.141 Acc 95.969%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.140 Acc 95.977%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.140 Acc 95.930%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.141 Acc 95.921%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.164 Acc 95.962%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.160 Acc 95.946%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.140 Acc 95.823%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.138 Acc 95.903%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.140 Acc 95.805%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.141 Acc 95.802%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.168 Acc 95.777%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 95.759%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.142 Acc 95.777%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.138 Acc 95.907%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.137 Acc 95.896%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.139 Acc 95.864%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.140 Acc 95.849%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.166 Acc 95.837%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.197 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.135 Acc 96.000%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.136 Acc 95.974%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.136 Acc 95.942%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.139 Acc 95.911%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.172 Acc 95.614%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.167 Acc 95.631%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.137 Acc 96.125%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.141 Acc 95.993%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.141 Acc 95.995%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.140 Acc 95.961%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.140 Acc 95.972%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.174 Acc 95.622%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.169 Acc 95.783%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.128 Acc 96.442%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.134 Acc 96.175%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.136 Acc 96.156%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.138 Acc 96.055%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.137 Acc 96.056%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.174 Acc 95.529%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.169 Acc 95.693%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.141 Acc 95.861%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.140 Acc 95.873%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.139 Acc 95.895%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.140 Acc 95.871%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.165 Acc 95.862%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.160 Acc 95.965%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.136 Acc 96.003%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.134 Acc 96.080%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.137 Acc 96.017%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.174 Acc 95.684%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.170 Acc 95.732%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.137 Acc 96.001%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.135 Acc 96.034%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.135 Acc 96.103%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.135 Acc 96.055%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.174 Acc 95.537%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.167 Acc 95.608%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.106 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.126 Acc 96.349%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.129 Acc 96.304%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.131 Acc 96.208%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.134 Acc 96.121%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.135 Acc 96.123%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.173 Acc 95.606%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.167 Acc 95.857%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.245 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.133 Acc 96.295%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.136 Acc 96.102%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.136 Acc 96.047%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.134 Acc 96.051%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.136 Acc 96.010%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.174 Acc 95.568%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.170 Acc 95.655%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.201 Acc 92.188%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.138 Acc 95.893%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.132 Acc 96.024%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.132 Acc 96.006%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.133 Acc 95.952%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.134 Acc 95.952%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.169 Acc 95.815%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.164 Acc 95.927%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.132 Acc 95.893%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.131 Acc 95.946%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.131 Acc 96.073%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.133 Acc 96.055%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.136 Acc 96.019%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.134 Acc 95.985%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.134 Acc 96.042%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.133 Acc 96.092%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.135 Acc 96.030%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.170 Acc 95.645%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.166 Acc 95.853%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.133 Acc 96.210%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.135 Acc 96.129%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.134 Acc 96.164%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.133 Acc 96.220%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.134 Acc 96.198%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.167 Acc 95.854%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.163 Acc 95.942%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.141 Acc 95.985%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.140 Acc 96.012%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.136 Acc 96.078%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.135 Acc 96.055%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.134 Acc 96.038%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.166 Acc 95.900%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.162 Acc 95.997%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.135 Acc 96.109%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.131 Acc 96.214%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.134 Acc 96.099%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.134 Acc 96.115%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.133 Acc 96.133%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.174 Acc 95.599%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.168 Acc 95.752%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.122 Acc 96.287%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.128 Acc 96.102%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.131 Acc 96.161%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.132 Acc 96.121%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.132 Acc 96.098%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.171 Acc 95.583%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.167 Acc 95.744%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.125 Acc 96.380%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.135 Acc 96.222%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.132 Acc 96.242%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.132 Acc 96.174%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.132 Acc 96.176%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.169 Acc 95.670%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.125 Acc 96.346%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.126 Acc 96.294%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.129 Acc 96.218%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.130 Acc 96.186%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.165 Acc 95.746%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.161 Acc 95.857%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.141 Acc 95.312%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.129 Acc 96.310%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.127 Acc 96.428%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.131 Acc 96.135%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.131 Acc 96.150%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.170 Acc 95.784%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.165 Acc 95.864%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.129 Acc 96.210%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.128 Acc 96.323%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.130 Acc 96.320%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.130 Acc 96.244%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.131 Acc 96.201%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.170 Acc 95.614%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.166 Acc 95.794%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.123 Acc 96.357%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.126 Acc 96.206%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.127 Acc 96.296%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.130 Acc 96.215%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.132 Acc 96.170%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.169 Acc 95.568%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.164 Acc 95.849%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.201 Acc 93.750%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.122 Acc 96.488%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.123 Acc 96.381%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.127 Acc 96.307%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.128 Acc 96.228%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.129 Acc 96.209%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.165 Acc 95.769%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.162 Acc 95.958%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.121 Acc 96.498%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.125 Acc 96.351%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.132 Acc 96.151%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.149 Acc 93.750%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.164 Acc 95.899%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.127 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.129 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.131 Acc 96.187%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.130 Acc 96.201%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.128 Acc 96.248%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.169 Acc 95.792%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.162 Acc 95.934%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.163 Acc 95.312%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.121 Acc 96.349%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.125 Acc 96.276%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.127 Acc 96.205%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.127 Acc 96.228%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.129 Acc 96.203%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.171 Acc 95.931%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.166 Acc 95.942%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.126 Acc 96.279%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.127 Acc 96.137%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.130 Acc 96.144%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.129 Acc 96.175%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.166 Acc 95.806%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.120 Acc 96.666%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.124 Acc 96.529%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.125 Acc 96.403%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.127 Acc 96.335%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.128 Acc 96.262%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.177 Acc 95.413%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.172 Acc 95.542%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.125 Acc 96.287%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.123 Acc 96.346%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.124 Acc 96.371%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.126 Acc 96.318%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.127 Acc 96.314%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.171 Acc 95.730%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.165 Acc 95.837%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.134 Acc 96.109%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.131 Acc 96.199%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.130 Acc 96.203%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.126 Acc 96.324%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.126 Acc 96.268%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.176 Acc 95.459%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.171 Acc 95.588%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.164 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.123 Acc 96.300%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.125 Acc 96.257%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.127 Acc 96.269%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.129 Acc 96.184%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.167 Acc 95.705%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.147 Acc 93.750%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.127 Acc 96.354%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.128 Acc 96.335%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.129 Acc 96.292%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.129 Acc 96.239%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.171 Acc 95.784%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.168 Acc 95.818%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.123 Acc 96.457%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.124 Acc 96.358%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.126 Acc 96.269%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.125 Acc 96.323%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.189 Acc 92.188%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.175 Acc 95.777%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.171 Acc 95.876%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.139 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.127 Acc 96.295%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.121 Acc 96.440%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.122 Acc 96.366%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.125 Acc 96.339%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.126 Acc 96.348%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.197 Acc 92.188%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.182 Acc 95.506%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.175 Acc 95.662%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.121 Acc 96.506%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.123 Acc 96.416%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.123 Acc 96.384%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.125 Acc 96.282%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.176 Acc 95.591%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.171 Acc 95.690%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.198 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.124 Acc 96.403%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.125 Acc 96.335%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.124 Acc 96.322%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.125 Acc 96.284%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.177 Acc 95.637%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.172 Acc 95.763%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.125 Acc 96.426%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.120 Acc 96.502%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.122 Acc 96.410%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.124 Acc 96.354%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.176 Acc 95.552%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.171 Acc 95.670%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.122 Acc 96.434%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.124 Acc 96.257%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.125 Acc 96.211%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.123 Acc 96.310%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.123 Acc 96.321%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.171 Acc 95.777%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.164 Acc 95.903%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.119 Acc 96.728%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.121 Acc 96.545%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.120 Acc 96.488%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.123 Acc 96.386%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.124 Acc 96.348%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.170 Acc 95.730%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.166 Acc 95.845%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.189 Acc 92.969%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.115 Acc 96.457%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.120 Acc 96.377%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.122 Acc 96.353%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.121 Acc 96.353%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.164 Acc 95.818%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.121 Acc 96.542%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.120 Acc 96.514%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.122 Acc 96.426%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.122 Acc 96.423%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.164 Acc 95.826%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.122 Acc 95.312%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.119 Acc 96.589%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.122 Acc 96.432%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.122 Acc 96.423%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.123 Acc 96.329%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.122 Acc 96.443%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.175 Acc 95.707%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.168 Acc 95.810%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.114 Acc 96.798%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.118 Acc 96.479%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.120 Acc 96.473%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.120 Acc 96.485%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.123 Acc 96.403%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.176 Acc 95.661%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.169 Acc 95.806%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.115 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.118 Acc 96.419%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.120 Acc 96.401%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.123 Acc 96.330%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.122 Acc 96.368%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.123 Acc 96.329%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.174 Acc 95.899%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.243 Acc 91.406%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.117 Acc 96.558%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.121 Acc 96.393%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.122 Acc 96.390%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.124 Acc 96.316%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.123 Acc 96.356%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.132 Acc 92.969%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.167 Acc 95.900%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.163 Acc 95.954%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.127 Acc 96.125%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.121 Acc 96.308%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.122 Acc 96.288%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.123 Acc 96.283%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.122 Acc 96.329%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.173 Acc 95.800%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.168 Acc 95.896%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.134 Acc 92.969%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.115 Acc 96.473%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.117 Acc 96.521%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.120 Acc 96.496%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.120 Acc 96.464%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.121 Acc 96.403%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.181 Acc 95.521%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.174 Acc 95.674%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.181 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.119 Acc 96.527%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.122 Acc 96.385%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.119 Acc 96.426%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.119 Acc 96.433%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.119 Acc 96.446%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.180 Acc 95.614%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.173 Acc 95.767%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.113 Acc 96.736%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.120 Acc 96.498%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.121 Acc 96.421%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.120 Acc 96.444%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.120 Acc 96.465%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.176 Acc 95.529%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.171 Acc 95.725%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.114 Acc 96.658%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.119 Acc 96.545%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.121 Acc 96.457%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.123 Acc 96.433%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.122 Acc 96.456%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.186 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.174 Acc 95.869%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.169 Acc 95.923%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.115 Acc 96.643%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.119 Acc 96.479%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.119 Acc 96.474%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.121 Acc 96.421%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.167 Acc 95.857%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.116 Acc 96.612%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.115 Acc 96.630%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.116 Acc 96.634%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.118 Acc 96.542%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.118 Acc 96.533%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.176 Acc 95.753%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.172 Acc 95.849%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.150 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.109 Acc 96.767%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.112 Acc 96.766%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.113 Acc 96.683%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.114 Acc 96.614%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.116 Acc 96.593%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.166 Acc 95.761%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.161 Acc 95.868%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.114 Acc 96.504%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.115 Acc 96.607%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.116 Acc 96.532%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.115 Acc 96.489%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.118 Acc 96.406%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.172 Acc 95.514%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.165 Acc 95.779%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.190 Acc 96.094%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.121 Acc 96.457%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.117 Acc 96.490%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.117 Acc 96.517%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.118 Acc 96.458%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.119 Acc 96.445%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.170 Acc 95.753%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.166 Acc 95.896%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.117 Acc 96.651%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.118 Acc 96.568%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.119 Acc 96.519%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.118 Acc 96.462%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.182 Acc 95.413%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.174 Acc 95.600%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.112 Acc 96.682%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.112 Acc 96.630%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.111 Acc 96.641%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.114 Acc 96.569%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.116 Acc 96.499%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.171 Acc 95.514%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.164 Acc 95.759%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.041 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.111 Acc 96.573%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.116 Acc 96.479%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.116 Acc 96.538%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.117 Acc 96.537%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.170 Acc 95.868%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.116 Acc 96.612%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.119 Acc 96.583%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.119 Acc 96.522%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.119 Acc 96.523%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.175 Acc 95.684%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.169 Acc 95.822%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.102 Acc 96.960%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.109 Acc 96.677%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.112 Acc 96.628%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.113 Acc 96.555%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.114 Acc 96.532%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.174 Acc 95.908%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.169 Acc 95.927%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.091 Acc 96.094%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.112 Acc 96.488%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.114 Acc 96.510%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.119 Acc 96.405%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.118 Acc 96.501%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.119 Acc 96.495%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.169 Acc 95.924%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.166 Acc 95.965%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.113 Acc 96.674%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.116 Acc 96.595%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.115 Acc 96.673%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.116 Acc 96.645%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.117 Acc 96.576%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.167 Acc 95.868%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.112 Acc 96.762%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.114 Acc 96.649%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.114 Acc 96.659%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.115 Acc 96.601%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.169 Acc 95.965%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.138 Acc 97.656%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.112 Acc 96.678%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.115 Acc 96.583%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.171 Acc 96.001%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.167 Acc 96.000%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.179 Acc 96.094%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.112 Acc 96.689%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.118 Acc 96.506%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.119 Acc 96.452%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.117 Acc 96.530%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.115 Acc 96.568%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.176 Acc 95.692%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.171 Acc 95.806%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.116 Acc 96.627%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.114 Acc 96.615%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.114 Acc 96.597%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.115 Acc 96.571%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.114 Acc 96.577%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.169 Acc 95.908%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.163 Acc 96.039%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.126 Acc 92.969%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.111 Acc 96.736%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.109 Acc 96.817%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.112 Acc 96.699%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.113 Acc 96.616%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.112 Acc 96.627%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.175 Acc 95.769%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.169 Acc 95.857%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.196 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.109 Acc 96.713%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.111 Acc 96.587%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.111 Acc 96.610%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.112 Acc 96.579%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.165 Acc 95.769%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.159 Acc 95.993%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.108 Acc 96.836%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.111 Acc 96.700%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.113 Acc 96.610%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.115 Acc 96.604%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.115 Acc 96.551%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.182 Acc 95.653%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.177 Acc 95.721%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.114 Acc 96.728%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.110 Acc 96.743%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.111 Acc 96.636%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.115 Acc 96.555%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.114 Acc 96.529%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.183 Acc 95.738%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.176 Acc 95.802%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.107 Acc 96.728%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.112 Acc 96.595%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.114 Acc 96.594%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.177 Acc 95.596%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.117 Acc 96.620%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.115 Acc 96.638%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.112 Acc 96.692%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.112 Acc 96.650%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.173 Acc 95.808%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.167 Acc 95.896%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.106 Acc 96.713%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.109 Acc 96.688%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.111 Acc 96.722%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.111 Acc 96.727%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.111 Acc 96.722%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.179 Acc 95.715%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.106 Acc 96.713%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.106 Acc 96.793%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.110 Acc 96.683%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.109 Acc 96.659%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.111 Acc 96.616%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.180 Acc 95.630%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.174 Acc 95.791%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.114 Acc 96.589%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.112 Acc 96.634%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.112 Acc 96.644%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.111 Acc 96.657%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.114 Acc 96.615%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.174 Acc 95.722%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.168 Acc 95.814%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.108 Acc 96.705%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.109 Acc 96.747%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.112 Acc 96.602%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.113 Acc 96.546%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.113 Acc 96.548%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.176 Acc 95.661%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.170 Acc 95.775%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a3282cc94a49e0bb961a8f7ca197fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.338 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.285 Acc 15.231%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.265 Acc 16.818%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.250 Acc 17.720%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.200 Acc 20.244%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.115 Acc 23.832%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.376 Acc 50.781%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.383 Acc 52.591%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.379 Acc 52.394%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.413 Acc 53.906%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.261 Acc 57.805%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.181 Acc 60.969%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.116 Acc 63.164%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.059 Acc 65.272%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.008 Acc 67.066%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.654 Acc 75.781%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.618 Acc 80.879%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.608 Acc 81.429%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.808 Acc 78.906%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.715 Acc 77.669%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.695 Acc 78.152%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.676 Acc 78.914%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.655 Acc 79.454%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.643 Acc 79.818%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.511 Acc 83.594%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.468 Acc 85.466%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.464 Acc 85.665%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.684 Acc 82.812%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.539 Acc 83.199%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.535 Acc 83.306%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.523 Acc 83.638%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.519 Acc 83.775%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.516 Acc 83.935%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.383 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.382 Acc 88.877%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.380 Acc 88.685%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.747 Acc 86.719%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.450 Acc 86.077%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.447 Acc 86.151%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.450 Acc 86.161%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.449 Acc 86.187%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.445 Acc 86.263%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.354 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.358 Acc 89.411%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.355 Acc 89.335%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.320 Acc 89.844%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.416 Acc 87.013%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.420 Acc 86.952%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.414 Acc 87.163%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.408 Acc 87.369%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.404 Acc 87.506%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.320 Acc 90.888%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.314 Acc 90.913%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.434 Acc 85.938%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.381 Acc 88.498%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.382 Acc 88.413%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.378 Acc 88.491%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.376 Acc 88.556%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.374 Acc 88.618%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.261 Acc 92.188%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.301 Acc 91.360%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.297 Acc 91.418%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.364 Acc 89.062%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.352 Acc 89.434%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.353 Acc 89.237%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.347 Acc 89.418%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.350 Acc 89.349%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.351 Acc 89.382%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.230 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.277 Acc 92.071%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.273 Acc 92.125%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.302 Acc 91.406%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.335 Acc 89.759%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.337 Acc 89.727%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.335 Acc 89.805%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.333 Acc 89.883%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.329 Acc 89.933%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.269 Acc 92.296%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.266 Acc 92.347%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.353 Acc 89.062%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.307 Acc 90.501%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.314 Acc 90.400%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.318 Acc 90.301%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.315 Acc 90.454%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.315 Acc 90.449%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.293 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.268 Acc 92.396%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.266 Acc 92.409%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.252 Acc 92.969%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.309 Acc 90.880%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.306 Acc 90.885%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.307 Acc 90.830%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.305 Acc 90.880%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.304 Acc 90.854%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.252 Acc 92.938%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.251 Acc 92.833%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.423 Acc 86.719%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.295 Acc 91.143%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.293 Acc 91.091%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.291 Acc 91.271%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.288 Acc 91.385%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.288 Acc 91.431%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.262 Acc 92.481%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.257 Acc 92.491%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.276 Acc 91.515%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.277 Acc 91.737%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.274 Acc 91.788%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.279 Acc 91.687%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.280 Acc 91.684%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.248 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.238 Acc 93.356%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.235 Acc 93.350%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.323 Acc 92.969%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.270 Acc 91.979%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.265 Acc 92.055%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.272 Acc 91.770%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.270 Acc 91.917%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.270 Acc 91.908%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.230 Acc 93.758%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.228 Acc 93.692%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.264 Acc 92.079%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.262 Acc 92.176%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.257 Acc 92.322%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.260 Acc 92.314%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.261 Acc 92.304%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.231 Acc 93.580%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.226 Acc 93.521%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.334 Acc 90.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.250 Acc 92.597%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.248 Acc 92.697%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.253 Acc 92.476%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.255 Acc 92.460%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.255 Acc 92.425%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.243 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.232 Acc 93.595%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.228 Acc 93.657%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.127 Acc 96.094%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.245 Acc 92.729%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.247 Acc 92.658%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.250 Acc 92.668%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.249 Acc 92.624%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.251 Acc 92.548%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.225 Acc 93.704%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.224 Acc 93.672%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.245 Acc 92.675%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.246 Acc 92.837%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.242 Acc 92.919%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.245 Acc 92.840%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.246 Acc 92.797%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.212 Acc 94.160%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.209 Acc 94.174%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.213 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.230 Acc 93.031%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.233 Acc 93.062%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.238 Acc 92.964%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.238 Acc 93.016%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.237 Acc 93.003%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.218 Acc 94.075%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.214 Acc 94.065%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.236 Acc 92.775%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.234 Acc 93.074%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.235 Acc 93.041%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.235 Acc 93.031%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.236 Acc 93.028%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.214 Acc 94.144%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.210 Acc 94.154%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.247 Acc 92.188%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.240 Acc 92.930%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.230 Acc 93.260%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.229 Acc 93.376%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.229 Acc 93.308%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.228 Acc 93.327%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.205 Acc 94.462%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.204 Acc 94.349%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.241 Acc 92.188%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.219 Acc 93.487%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.226 Acc 93.408%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.226 Acc 93.420%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.226 Acc 93.353%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.227 Acc 93.370%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.214 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.212 Acc 94.268%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.210 Acc 94.154%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.295 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.219 Acc 93.580%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.223 Acc 93.482%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.222 Acc 93.449%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.222 Acc 93.514%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.219 Acc 93.621%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.215 Acc 95.312%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.209 Acc 94.400%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.208 Acc 94.267%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.191 Acc 92.969%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.225 Acc 93.765%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.219 Acc 93.789%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.216 Acc 93.794%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.218 Acc 93.680%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.217 Acc 93.666%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.197 Acc 94.810%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.195 Acc 94.687%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.239 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.204 Acc 94.036%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.211 Acc 93.828%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.210 Acc 93.906%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.210 Acc 93.884%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.210 Acc 93.909%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.198 Acc 94.856%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.198 Acc 94.737%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.205 Acc 94.083%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.210 Acc 93.972%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.212 Acc 93.776%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.210 Acc 93.793%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.208 Acc 93.850%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.210 Acc 94.129%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.206 Acc 94.076%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.141 Acc 98.438%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.198 Acc 94.230%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.200 Acc 94.150%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.203 Acc 94.025%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.203 Acc 94.048%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.204 Acc 94.034%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.186 Acc 95.013%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.256 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.193 Acc 94.407%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.199 Acc 94.131%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.203 Acc 94.010%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.203 Acc 94.015%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.201 Acc 94.087%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.202 Acc 94.740%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.197 Acc 94.652%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.196 Acc 94.516%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.194 Acc 94.352%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.195 Acc 94.277%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.197 Acc 94.220%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.199 Acc 94.159%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.194 Acc 94.825%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.192 Acc 94.819%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.253 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.178 Acc 95.073%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.181 Acc 94.862%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.186 Acc 94.718%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.190 Acc 94.584%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.194 Acc 94.525%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.190 Acc 94.725%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.187 Acc 94.733%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.184 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.187 Acc 94.656%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.190 Acc 94.604%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.192 Acc 94.580%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.192 Acc 94.833%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.188 Acc 94.881%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.135 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.196 Acc 94.369%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.195 Acc 94.391%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.189 Acc 94.472%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.191 Acc 94.488%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.196 Acc 94.802%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.192 Acc 94.803%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.235 Acc 89.844%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.179 Acc 94.601%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.181 Acc 94.582%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.183 Acc 94.622%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.186 Acc 94.543%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.187 Acc 94.548%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.193 Acc 94.995%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.189 Acc 94.904%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.192 Acc 94.771%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.185 Acc 94.710%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.184 Acc 94.679%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.184 Acc 94.681%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.186 Acc 94.654%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.200 Acc 94.740%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.195 Acc 94.772%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.181 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.185 Acc 94.794%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.184 Acc 94.811%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.187 Acc 94.638%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.185 Acc 94.590%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.184 Acc 94.639%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.185 Acc 95.189%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.181 Acc 95.134%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.182 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.171 Acc 95.009%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.176 Acc 94.957%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.177 Acc 94.960%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.178 Acc 94.851%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.182 Acc 95.270%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.255 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.167 Acc 95.274%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.175 Acc 94.959%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.177 Acc 94.918%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.177 Acc 94.876%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.177 Acc 94.885%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.128 Acc 96.875%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.191 Acc 94.903%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.189 Acc 94.908%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.173 Acc 95.119%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.171 Acc 95.095%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.171 Acc 95.074%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.176 Acc 94.956%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.176 Acc 94.955%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.184 Acc 95.204%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.181 Acc 95.149%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.164 Acc 95.266%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.169 Acc 95.110%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.167 Acc 95.198%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.171 Acc 95.094%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.173 Acc 95.030%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.191 Acc 94.787%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.186 Acc 94.850%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.165 Acc 95.343%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.168 Acc 95.134%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.172 Acc 95.030%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.171 Acc 95.032%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.172 Acc 94.994%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.186 Acc 95.104%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.182 Acc 95.173%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.243 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.163 Acc 95.467%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.162 Acc 95.293%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.166 Acc 95.229%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.213%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.169 Acc 95.147%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.175 Acc 95.464%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.158 Acc 95.343%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.161 Acc 95.285%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.163 Acc 95.341%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.166 Acc 95.256%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.168 Acc 95.182%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.184 Acc 95.328%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.180 Acc 95.285%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.160 Acc 95.490%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.162 Acc 95.386%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.164 Acc 95.364%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.164 Acc 95.294%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.184 Acc 95.088%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.179 Acc 95.169%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.169 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.167 Acc 95.328%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.164 Acc 95.325%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.163 Acc 95.377%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.163 Acc 95.358%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.187 Acc 95.080%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.181 Acc 95.161%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.168 Acc 95.204%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.163 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.163 Acc 95.333%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.163 Acc 95.305%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.162 Acc 95.342%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.193 Acc 95.135%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.189 Acc 95.176%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.161 Acc 95.212%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.162 Acc 95.417%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.161 Acc 95.372%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.159 Acc 95.435%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.159 Acc 95.428%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.117 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.183 Acc 95.274%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.181 Acc 95.149%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.149 Acc 95.630%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.152 Acc 95.522%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.153 Acc 95.479%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.156 Acc 95.418%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.158 Acc 95.389%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.176 Acc 95.382%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.175 Acc 95.355%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.149 Acc 95.792%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.151 Acc 95.569%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.489%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.154 Acc 95.511%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.156 Acc 95.492%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.180 Acc 95.359%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.178 Acc 95.336%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.145 Acc 95.676%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.152 Acc 95.588%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.153 Acc 95.544%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.155 Acc 95.478%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.155 Acc 95.484%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.183 Acc 95.181%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.179 Acc 95.281%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.147 Acc 96.024%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.143 Acc 95.923%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.146 Acc 95.829%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.149 Acc 95.763%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.151 Acc 95.688%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.183 Acc 95.110%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.193 Acc 92.188%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.148 Acc 95.784%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.151 Acc 95.713%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.156 Acc 95.616%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.156 Acc 95.622%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.152 Acc 95.665%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.177 Acc 95.429%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.148 Acc 95.728%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.148 Acc 95.704%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.148 Acc 95.718%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.149 Acc 95.642%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 95.336%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.183 Acc 95.297%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.151 Acc 95.846%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.149 Acc 95.678%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.151 Acc 95.660%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.149 Acc 95.706%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.149 Acc 95.702%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.177 Acc 95.568%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.175 Acc 95.542%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.133 Acc 96.047%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.139 Acc 96.043%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.144 Acc 95.878%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.145 Acc 95.819%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.146 Acc 95.819%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.137 Acc 96.875%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.183 Acc 95.367%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.179 Acc 95.367%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.142 Acc 95.958%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.140 Acc 96.016%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.141 Acc 95.959%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.143 Acc 95.904%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.178 Acc 95.490%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.235 Acc 90.625%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.142 Acc 95.722%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.142 Acc 95.829%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.143 Acc 95.824%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.143 Acc 95.848%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.144 Acc 95.812%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.183 Acc 95.135%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.181 Acc 95.118%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.128 Acc 96.481%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.136 Acc 96.102%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.139 Acc 96.013%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.141 Acc 95.965%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.141 Acc 95.944%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.181 Acc 95.204%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.176 Acc 95.297%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.228 Acc 95.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.132 Acc 96.163%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.135 Acc 96.090%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.135 Acc 96.073%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.137 Acc 96.010%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.138 Acc 96.005%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.179 Acc 95.266%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.119 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.131 Acc 96.357%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.137 Acc 96.144%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.139 Acc 96.109%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.138 Acc 96.090%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.140 Acc 96.027%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.095 Acc 96.875%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.197 Acc 95.104%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.196 Acc 95.114%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.134 Acc 96.295%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.140 Acc 96.133%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.138 Acc 96.081%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.137 Acc 96.041%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.139 Acc 96.028%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.166 Acc 96.875%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.183 Acc 95.529%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.182 Acc 95.542%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.141 Acc 95.931%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.137 Acc 95.993%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.137 Acc 95.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.135 Acc 96.084%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.137 Acc 96.034%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.187 Acc 95.297%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.185 Acc 95.332%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.978%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.140 Acc 95.931%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.140 Acc 95.941%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.136 Acc 96.103%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.136 Acc 96.064%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.173 Acc 95.599%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.170 Acc 95.678%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.128 Acc 96.318%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.128 Acc 96.331%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.129 Acc 96.273%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.128 Acc 96.326%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.270%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.081 Acc 97.656%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.188 Acc 95.359%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.184 Acc 95.309%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.131 Acc 96.349%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.135 Acc 96.273%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.134 Acc 96.255%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.132 Acc 96.259%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.132 Acc 96.159%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.258%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.183 Acc 95.243%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.124 Acc 96.233%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.128 Acc 96.230%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.131 Acc 96.211%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.132 Acc 96.160%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.133 Acc 96.170%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.100 Acc 96.875%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.181 Acc 95.441%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.162 Acc 95.312%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.121 Acc 96.542%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.126 Acc 96.482%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.128 Acc 96.348%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.127 Acc 96.337%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.129 Acc 96.290%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.186 Acc 95.231%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.123 Acc 96.496%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.122 Acc 96.401%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.122 Acc 96.439%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.125 Acc 96.353%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.126 Acc 96.335%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.194 Acc 95.351%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.191 Acc 95.316%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.218 Acc 95.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.126 Acc 96.465%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.127 Acc 96.315%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.126 Acc 96.291%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.125 Acc 96.269%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.127 Acc 96.229%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.080 Acc 97.656%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.178 Acc 95.545%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.530%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.117 Acc 96.581%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.125 Acc 96.440%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.122 Acc 96.473%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.123 Acc 96.444%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.125 Acc 96.346%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.178 Acc 95.452%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.175 Acc 95.441%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.126 Acc 96.450%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.120 Acc 96.568%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.121 Acc 96.447%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.125 Acc 96.335%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.174 Acc 95.761%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.172 Acc 95.658%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.124 Acc 96.287%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.122 Acc 96.331%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.122 Acc 96.309%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.124 Acc 96.250%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.124 Acc 96.250%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.183 Acc 95.452%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.180 Acc 95.449%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.121 Acc 96.558%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.122 Acc 96.444%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.123 Acc 96.361%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.122 Acc 96.384%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.124 Acc 96.329%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.183 Acc 95.436%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.182 Acc 95.417%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.116 Acc 96.774%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.118 Acc 96.618%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.119 Acc 96.564%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.119 Acc 96.563%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.121 Acc 96.519%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.192 Acc 95.065%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.188 Acc 95.095%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.116 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.112 Acc 96.805%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.545%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.120 Acc 96.519%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.120 Acc 96.522%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.120 Acc 96.533%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.180 Acc 95.599%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.178 Acc 95.534%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.121 Acc 96.432%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.117 Acc 96.558%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.119 Acc 96.505%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.119 Acc 96.529%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.179 Acc 95.382%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.176 Acc 95.414%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.116 Acc 96.457%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.114 Acc 96.599%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.115 Acc 96.561%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.116 Acc 96.548%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.117 Acc 96.527%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.193 Acc 95.135%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.189 Acc 95.208%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.114 Acc 96.720%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.116 Acc 96.580%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.114 Acc 96.680%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.117 Acc 96.616%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.117 Acc 96.610%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.181 Acc 95.490%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.180 Acc 95.495%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.106 Acc 96.867%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.108 Acc 96.774%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.114 Acc 96.573%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.115 Acc 96.562%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.182 Acc 95.506%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.181 Acc 95.557%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.116 Acc 96.545%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.117 Acc 96.448%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.117 Acc 96.484%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.184 Acc 95.661%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.184 Acc 95.616%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.115 Acc 96.674%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.117 Acc 96.665%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.117 Acc 96.587%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.115 Acc 96.616%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.114 Acc 96.646%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.184 Acc 95.521%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.181 Acc 95.487%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.113 Acc 96.751%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.109 Acc 96.778%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.113 Acc 96.696%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.113 Acc 96.697%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.179 Acc 95.599%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.178 Acc 95.480%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.107 Acc 96.813%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.682%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.113 Acc 96.636%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.188 Acc 95.390%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.186 Acc 95.367%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.108 Acc 96.906%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.111 Acc 96.805%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.112 Acc 96.774%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.110 Acc 96.789%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.111 Acc 96.760%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.092 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.180 Acc 95.506%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.180 Acc 95.480%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.108 Acc 96.739%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.106 Acc 96.735%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.110 Acc 96.668%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.111 Acc 96.661%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.197 Acc 95.297%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.195 Acc 95.297%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.108 Acc 96.867%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.105 Acc 96.836%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.107 Acc 96.823%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.104 Acc 96.873%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.107 Acc 96.836%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.084 Acc 97.656%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.188 Acc 95.467%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.185 Acc 95.464%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.105 Acc 96.727%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.106 Acc 96.766%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.106 Acc 96.780%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.107 Acc 96.786%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.186 Acc 95.158%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.186 Acc 95.165%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.094 Acc 97.231%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.097 Acc 97.093%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.104 Acc 96.888%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.106 Acc 96.832%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.107 Acc 96.810%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.187 Acc 95.405%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.186 Acc 95.402%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.118 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.105 Acc 96.910%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.105 Acc 96.924%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.106 Acc 96.870%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.186 Acc 95.444%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.186 Acc 95.433%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.103 Acc 97.073%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.105 Acc 96.984%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.105 Acc 96.951%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.104 Acc 96.965%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.200 Acc 95.328%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.197 Acc 95.285%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 97.169%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.102 Acc 96.949%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.102 Acc 96.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.104 Acc 96.943%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.105 Acc 96.897%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.195 Acc 95.243%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.194 Acc 95.270%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.102 Acc 96.828%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.101 Acc 96.914%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.103 Acc 96.844%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.103 Acc 96.847%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.201 Acc 95.189%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.199 Acc 95.106%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.097 Acc 97.200%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.102 Acc 96.953%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.101 Acc 97.020%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.101 Acc 97.019%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.101 Acc 96.986%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.103 Acc 97.656%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.188 Acc 95.343%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.188 Acc 95.324%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.099 Acc 96.890%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.103 Acc 96.786%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.100 Acc 96.870%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.101 Acc 96.863%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.102 Acc 96.820%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.183 Acc 95.777%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.183 Acc 95.643%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.093 Acc 97.003%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.100 Acc 96.893%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.101 Acc 96.858%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.189 Acc 95.498%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.189 Acc 95.379%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.096 Acc 96.952%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.097 Acc 96.995%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.100 Acc 97.015%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.102 Acc 96.922%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.102 Acc 96.926%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.197 Acc 95.305%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.194 Acc 95.363%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.098 Acc 97.092%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.099 Acc 97.178%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.100 Acc 97.072%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.099 Acc 97.009%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.100 Acc 96.997%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.199 Acc 95.235%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.201 Acc 95.130%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.056 Acc 96.875%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.099 Acc 97.084%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.101 Acc 96.933%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.099 Acc 97.007%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.098 Acc 97.060%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.097 Acc 97.098%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.198 Acc 95.367%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.195 Acc 95.239%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.089 Acc 97.239%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.094 Acc 97.093%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.096 Acc 97.007%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.096 Acc 97.056%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.098 Acc 97.018%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.189 Acc 95.452%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.186 Acc 95.542%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.092 Acc 97.037%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.094 Acc 97.116%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.096 Acc 97.097%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.097 Acc 97.076%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.189 Acc 95.577%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.224 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.091 Acc 97.300%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.094 Acc 97.139%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.096 Acc 97.077%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.097 Acc 97.037%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.099 Acc 97.009%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.198 Acc 95.351%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.195 Acc 95.375%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.088 Acc 97.393%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.090 Acc 97.306%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.090 Acc 97.308%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.092 Acc 97.255%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.094 Acc 97.182%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.200 Acc 95.421%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.198 Acc 95.351%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.153 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.087 Acc 97.339%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.095 Acc 97.159%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.095 Acc 97.088%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.094 Acc 97.154%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.094 Acc 97.153%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.192 Acc 95.320%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.090 Acc 97.370%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.091 Acc 97.314%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.092 Acc 97.207%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.096 Acc 97.095%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.095 Acc 97.131%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.134 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.206 Acc 95.266%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.204 Acc 95.176%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.077 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.085 Acc 97.378%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.085 Acc 97.326%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.093 Acc 97.176%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.092 Acc 97.142%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.199 Acc 95.065%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.195 Acc 95.083%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.093 Acc 97.208%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.093 Acc 97.236%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.092 Acc 97.239%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.092 Acc 97.209%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.151 Acc 97.656%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.205 Acc 95.467%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.202 Acc 95.390%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.279 Acc 93.750%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.090 Acc 97.146%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.089 Acc 97.236%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.090 Acc 97.282%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.091 Acc 97.232%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.194 Acc 95.289%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.190 Acc 95.425%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.085 Acc 97.432%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.087 Acc 97.225%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.090 Acc 97.224%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.091 Acc 97.170%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.118 Acc 97.656%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.199 Acc 95.251%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.196 Acc 95.289%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.092 Acc 97.269%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.092 Acc 97.318%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.091 Acc 97.264%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.092 Acc 97.169%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.092 Acc 97.163%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.199 Acc 95.382%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.198 Acc 95.316%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.088 Acc 97.208%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.086 Acc 97.334%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.089 Acc 97.244%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.088 Acc 97.259%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.090 Acc 97.274%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.194 Acc 95.459%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.191 Acc 95.480%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.092 Acc 97.200%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.091 Acc 97.198%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.090 Acc 97.238%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.091 Acc 97.204%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.090 Acc 97.204%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.166 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.207 Acc 95.119%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.204 Acc 95.141%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.081 Acc 97.525%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.084 Acc 97.380%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.086 Acc 97.368%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.087 Acc 97.352%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.093 Acc 97.656%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.196 Acc 95.459%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.193 Acc 95.503%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.079 Acc 97.594%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.086 Acc 97.384%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.087 Acc 97.368%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.086 Acc 97.389%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.088 Acc 97.346%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.198 Acc 95.057%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.195 Acc 95.103%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.085 Acc 97.347%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.084 Acc 97.291%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.084 Acc 97.363%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.085 Acc 97.346%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.087 Acc 97.310%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.205 Acc 95.111%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.205 Acc 95.021%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.084 Acc 97.362%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.085 Acc 97.373%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.084 Acc 97.386%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.085 Acc 97.276%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.085 Acc 97.241%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.197 Acc 95.289%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.198 Acc 95.266%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.079 Acc 97.532%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.082 Acc 97.474%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.083 Acc 97.423%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.085 Acc 97.387%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.087 Acc 97.277%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.206 Acc 95.073%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.202 Acc 95.126%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.082 Acc 97.493%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.084 Acc 97.428%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.084 Acc 97.458%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.084 Acc 97.464%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.204 Acc 95.274%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.203 Acc 95.246%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.080 Acc 97.440%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.082 Acc 97.477%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.084 Acc 97.451%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.083 Acc 97.475%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.084 Acc 97.376%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.203 Acc 95.158%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.198 Acc 95.250%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.083 Acc 97.339%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.084 Acc 97.357%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.083 Acc 97.412%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.084 Acc 97.385%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.085 Acc 97.337%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.200 Acc 95.119%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.198 Acc 95.208%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.194 Acc 94.531%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.086 Acc 97.330%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.084 Acc 97.358%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.084 Acc 97.378%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.083 Acc 97.396%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.200 Acc 95.320%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.197 Acc 95.344%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.081 Acc 97.556%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.077 Acc 97.567%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.080 Acc 97.488%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.079 Acc 97.491%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.082 Acc 97.386%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.201 Acc 95.196%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.202 Acc 95.118%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.083 Acc 97.471%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.084 Acc 97.431%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.084 Acc 97.425%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.085 Acc 97.385%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.084 Acc 97.418%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.195 Acc 95.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.196 Acc 95.592%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.084 Acc 97.331%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.081 Acc 97.410%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.081 Acc 97.413%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.083 Acc 97.386%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.208 Acc 95.398%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.205 Acc 95.355%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.152 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.073 Acc 97.811%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.074 Acc 97.695%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.079 Acc 97.571%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.080 Acc 97.555%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.081 Acc 97.533%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.209 Acc 95.328%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.206 Acc 95.305%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.072 Acc 97.765%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.076 Acc 97.676%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.076 Acc 97.659%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.079 Acc 97.582%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.080 Acc 97.522%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.200 Acc 95.289%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.197 Acc 95.398%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.067 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.076 Acc 97.579%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.076 Acc 97.560%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.078 Acc 97.456%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.080 Acc 97.419%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.205 Acc 95.196%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.202 Acc 95.270%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.075 Acc 97.579%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.081 Acc 97.467%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.080 Acc 97.510%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.081 Acc 97.507%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.219 Acc 95.065%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.213 Acc 95.165%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.070 Acc 97.749%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.075 Acc 97.660%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.074 Acc 97.646%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.075 Acc 97.615%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.077 Acc 97.589%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.197 Acc 95.382%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.196 Acc 95.371%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.074 Acc 97.734%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.071 Acc 97.746%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.073 Acc 97.633%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.076 Acc 97.569%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.077 Acc 97.556%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.202 Acc 95.467%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.200 Acc 95.433%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.114 Acc 94.531%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.077 Acc 97.532%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.077 Acc 97.439%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.075 Acc 97.508%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.076 Acc 97.491%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.076 Acc 97.494%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.208 Acc 95.065%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.201 Acc 95.165%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.071 Acc 97.826%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.072 Acc 97.761%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.074 Acc 97.674%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.076 Acc 97.597%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.212 Acc 95.490%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.212 Acc 95.476%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.133 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.073 Acc 97.649%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.076 Acc 97.652%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.075 Acc 97.680%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.075 Acc 97.639%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.076 Acc 97.585%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.197 Acc 95.359%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.193 Acc 95.476%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.070 Acc 97.649%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.071 Acc 97.660%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.072 Acc 97.700%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.074 Acc 97.662%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.214 Acc 95.196%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.211 Acc 95.235%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.079 Acc 97.455%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.075 Acc 97.629%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.078 Acc 97.537%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.078 Acc 97.516%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.090 Acc 97.656%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.213 Acc 95.150%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.208 Acc 95.297%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.067 Acc 97.912%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.071 Acc 97.788%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.072 Acc 97.713%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.072 Acc 97.715%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.074 Acc 97.670%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.208 Acc 95.483%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.205 Acc 95.449%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.070 Acc 97.811%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.074 Acc 97.695%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.073 Acc 97.700%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.074 Acc 97.659%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.208 Acc 95.235%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.203 Acc 95.309%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.070 Acc 97.788%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.073 Acc 97.761%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.073 Acc 97.706%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.073 Acc 97.682%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.073 Acc 97.680%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.151 Acc 96.875%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.212 Acc 95.266%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.209 Acc 95.266%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.070 Acc 97.659%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.072 Acc 97.629%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.072 Acc 97.613%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.208 Acc 95.374%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.074 Acc 97.633%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.072 Acc 97.641%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.070 Acc 97.698%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.071 Acc 97.709%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.208 Acc 95.336%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.205 Acc 95.336%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.070 Acc 97.769%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.071 Acc 97.716%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.209 Acc 95.328%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.067 Acc 97.851%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.069 Acc 97.752%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.071 Acc 97.709%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.207 Acc 95.235%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.202 Acc 95.281%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.104 Acc 94.531%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.067 Acc 97.772%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.071 Acc 97.628%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.072 Acc 97.645%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.216 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.212 Acc 95.270%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.069 Acc 97.857%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.070 Acc 97.718%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.069 Acc 97.711%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.072 Acc 97.681%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.176 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.215 Acc 95.204%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.212 Acc 95.200%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.068 Acc 97.826%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.069 Acc 97.800%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.070 Acc 97.755%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.070 Acc 97.728%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.070 Acc 97.733%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.212 Acc 95.227%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.207 Acc 95.266%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.069 Acc 97.695%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.066 Acc 97.816%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.066 Acc 97.866%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.069 Acc 97.751%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.200 Acc 95.258%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.198 Acc 95.351%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.065 Acc 97.858%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.069 Acc 97.796%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.069 Acc 97.789%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.070 Acc 97.770%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.213 Acc 95.235%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.210 Acc 95.145%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.070 Acc 97.772%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.067 Acc 97.831%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.068 Acc 97.861%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.069 Acc 97.798%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.069 Acc 97.795%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.214 Acc 95.173%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.211 Acc 95.211%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.068 Acc 97.796%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.070 Acc 97.693%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.070 Acc 97.730%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.210 Acc 95.367%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.210 Acc 95.355%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.066 Acc 97.887%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.066 Acc 97.859%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.068 Acc 97.817%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.221 Acc 94.848%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.219 Acc 94.935%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.044 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.061 Acc 98.089%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.067 Acc 97.901%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.066 Acc 97.916%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.066 Acc 97.880%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.066 Acc 97.843%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.223 Acc 94.910%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.219 Acc 95.091%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.062 Acc 98.028%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.062 Acc 97.944%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.064 Acc 97.915%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.066 Acc 97.832%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.151 Acc 96.875%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.042%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.211 Acc 95.204%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.068 Acc 97.802%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.068 Acc 97.803%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.225 Acc 95.196%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.218 Acc 95.246%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.063 Acc 97.901%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.065 Acc 97.817%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.066 Acc 97.810%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.066 Acc 97.829%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.210 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.224 Acc 95.104%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.222 Acc 95.130%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.068 Acc 97.803%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.064 Acc 97.944%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.065 Acc 97.859%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.067 Acc 97.836%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.229 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.227 Acc 95.011%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.222 Acc 95.079%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.057 Acc 98.089%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.063 Acc 97.991%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.063 Acc 97.955%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.064 Acc 97.917%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.066 Acc 97.823%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.233 Acc 94.740%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.230 Acc 94.819%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.064 Acc 98.066%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.065 Acc 97.956%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.064 Acc 97.986%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.065 Acc 97.915%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.067 Acc 97.831%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.219 Acc 95.390%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.216 Acc 95.394%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.062 Acc 97.847%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.065 Acc 97.737%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.065 Acc 97.779%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.065 Acc 97.798%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.216 Acc 95.289%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.213 Acc 95.402%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.063 Acc 97.893%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.064 Acc 97.906%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.064 Acc 97.906%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.224 Acc 94.980%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.221 Acc 95.068%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.065 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.056 Acc 98.229%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.059 Acc 98.084%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.062 Acc 97.981%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.062 Acc 97.954%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.062 Acc 97.931%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.215 Acc 95.274%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.215 Acc 95.270%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.067 Acc 97.757%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.065 Acc 97.778%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.064 Acc 97.830%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.064 Acc 97.854%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.220 Acc 95.065%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.216 Acc 95.180%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.054 Acc 98.167%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.054 Acc 98.193%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.058 Acc 98.066%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.059 Acc 98.048%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.060 Acc 98.013%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.121 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.216 Acc 95.150%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.210 Acc 95.394%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.063 Acc 97.803%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.065 Acc 97.835%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.065 Acc 97.856%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.064 Acc 97.871%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.065 Acc 97.828%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.223 Acc 94.964%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.222 Acc 95.072%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.057 Acc 98.028%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.059 Acc 97.936%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.062 Acc 97.905%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.061 Acc 97.933%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.062 Acc 97.912%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.226 Acc 95.011%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.220 Acc 95.040%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.063 Acc 97.888%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.061 Acc 97.998%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.061 Acc 98.014%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.062 Acc 97.938%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.230 Acc 95.328%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.226 Acc 95.340%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.068 Acc 99.219%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.054 Acc 98.244%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.058 Acc 98.084%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.060 Acc 98.056%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.061 Acc 98.048%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.060 Acc 98.029%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.209 Acc 95.374%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.472%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.059 Acc 98.035%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.058 Acc 98.045%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.059 Acc 98.020%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.059 Acc 98.023%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.061 Acc 97.988%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.189 Acc 91.406%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.232 Acc 94.941%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.229 Acc 95.075%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.065 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.058 Acc 98.113%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.061 Acc 97.987%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.062 Acc 97.908%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.062 Acc 97.939%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.063 Acc 97.935%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.131 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.227 Acc 95.243%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.226 Acc 95.188%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.059 Acc 98.159%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.059 Acc 98.150%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.060 Acc 98.074%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.061 Acc 98.024%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.062 Acc 98.001%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.211 Acc 95.312%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.216 Acc 95.305%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.212 Acc 95.367%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.052 Acc 98.205%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.053 Acc 98.216%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.055 Acc 98.108%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.057 Acc 98.099%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.058 Acc 98.079%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.229 Acc 95.336%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.224 Acc 95.460%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.059 Acc 98.012%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.058 Acc 97.998%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.059 Acc 97.955%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.060 Acc 97.950%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.060 Acc 97.967%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.229 Acc 95.080%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.228 Acc 95.079%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.055 Acc 98.082%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.057 Acc 98.014%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.060 Acc 97.973%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.060 Acc 97.982%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.059 Acc 97.992%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.220 Acc 95.452%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.220 Acc 95.375%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.055 Acc 98.236%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.056 Acc 98.212%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.058 Acc 98.136%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.061 Acc 98.015%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.061 Acc 97.988%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.221 Acc 95.367%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.219 Acc 95.340%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.056 Acc 98.120%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.058 Acc 98.099%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.058 Acc 98.131%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.059 Acc 98.054%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.060 Acc 98.034%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.223 Acc 95.405%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.222 Acc 95.281%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.054 Acc 98.154%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.056 Acc 98.092%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.058 Acc 98.046%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.058 Acc 98.034%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.215 Acc 95.475%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.217 Acc 95.487%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.051 Acc 98.376%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.054 Acc 98.193%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.056 Acc 98.108%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.056 Acc 98.122%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.058 Acc 98.066%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.097 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.220 Acc 95.266%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.216 Acc 95.336%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.054 Acc 98.208%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.057 Acc 98.087%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.057 Acc 98.102%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.057 Acc 98.108%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.127 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.234 Acc 95.080%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.232 Acc 95.002%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.052 Acc 98.267%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.055 Acc 98.216%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.056 Acc 98.136%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.058 Acc 98.079%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.059 Acc 98.029%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.150 Acc 96.875%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.227 Acc 95.336%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.219 Acc 95.340%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.054 Acc 98.144%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.057 Acc 98.084%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.056 Acc 98.095%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.056 Acc 98.114%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.057 Acc 98.088%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.230 Acc 95.034%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.227 Acc 94.932%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.060 Acc 98.058%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.057 Acc 98.181%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.059 Acc 98.085%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.059 Acc 98.051%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.231 Acc 95.227%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.228 Acc 95.250%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.050 Acc 98.345%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.053 Acc 98.220%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.055 Acc 98.147%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.058 Acc 98.084%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.231 Acc 95.189%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.227 Acc 95.266%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.055 Acc 98.291%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.059 Acc 98.177%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.058 Acc 98.123%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.057 Acc 98.137%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.056 Acc 98.124%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.230 Acc 95.282%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.225 Acc 95.320%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.053 Acc 98.260%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.056 Acc 98.115%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.056 Acc 98.064%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.057 Acc 98.069%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.059 Acc 98.041%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.238 Acc 94.988%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.234 Acc 95.064%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.054 Acc 98.105%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [200/573] Loss: 0.053 Acc 98.165%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.053 Acc 98.186%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.055 Acc 98.126%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.222 Acc 95.312%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.220 Acc 95.297%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.057 Acc 98.035%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.057 Acc 98.123%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.055 Acc 98.181%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.055 Acc 98.192%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.055 Acc 98.172%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.251 Acc 95.065%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.249 Acc 95.103%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.049 Acc 98.395%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.051 Acc 98.334%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.050 Acc 98.323%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.052 Acc 98.239%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.227 Acc 95.212%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.223 Acc 95.180%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.056 Acc 96.875%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.052 Acc 98.244%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.054 Acc 98.231%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.054 Acc 98.196%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.236 Acc 95.266%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.233 Acc 95.332%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.054 Acc 98.260%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.055 Acc 98.185%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.054 Acc 98.178%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.054 Acc 98.161%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.054 Acc 98.154%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.145 Acc 97.656%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.231 Acc 95.135%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.227 Acc 95.184%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.050 Acc 98.336%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.051 Acc 98.297%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.052 Acc 98.216%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.232 Acc 95.274%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.229 Acc 95.305%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.059 Acc 96.875%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.056 Acc 98.082%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.055 Acc 98.134%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.055 Acc 98.113%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.055 Acc 98.079%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.055 Acc 98.060%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.219 Acc 95.475%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.216 Acc 95.437%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.053 Acc 98.198%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.054 Acc 98.196%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.053 Acc 98.207%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.238 Acc 95.204%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.236 Acc 95.192%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.096 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.052 Acc 98.244%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.056 Acc 98.100%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.055 Acc 98.132%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.054 Acc 98.172%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.242 Acc 94.964%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.237 Acc 95.072%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.045 Acc 98.608%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.050 Acc 98.418%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.048 Acc 98.440%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.048 Acc 98.418%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.050 Acc 98.364%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.158 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.226 Acc 95.305%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.226 Acc 95.200%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.051 Acc 98.453%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.050 Acc 98.395%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.051 Acc 98.328%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.052 Acc 98.293%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.053 Acc 98.238%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.242 Acc 95.220%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.241 Acc 95.223%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.059 Acc 97.989%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.054 Acc 98.146%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.050 Acc 98.274%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.053 Acc 98.207%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.231 Acc 95.166%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.227 Acc 95.141%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.051 Acc 98.267%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.052 Acc 98.278%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.053 Acc 98.212%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.053 Acc 98.225%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.053 Acc 98.247%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.169 Acc 97.656%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.233 Acc 95.537%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.231 Acc 95.484%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.051 Acc 98.267%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.052 Acc 98.329%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.051 Acc 98.323%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.053 Acc 98.249%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.054 Acc 98.224%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.233 Acc 95.204%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.228 Acc 95.293%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.047 Acc 98.453%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.048 Acc 98.461%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.049 Acc 98.419%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.050 Acc 98.356%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.051 Acc 98.299%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.130 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.242 Acc 95.251%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.237 Acc 95.274%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.049 Acc 98.321%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.049 Acc 98.309%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [300/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.051 Acc 98.245%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.052 Acc 98.225%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.229 Acc 95.096%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.225 Acc 95.153%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.051 Acc 98.229%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.051 Acc 98.208%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.049 Acc 98.287%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.050 Acc 98.262%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.051 Acc 98.263%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.109 Acc 97.656%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.241 Acc 94.926%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.237 Acc 95.079%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.050 Acc 98.283%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.048 Acc 98.386%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.049 Acc 98.340%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.050 Acc 98.311%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.236 Acc 95.158%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.232 Acc 95.141%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.041 Acc 98.592%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.048 Acc 98.348%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.050 Acc 98.284%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.050 Acc 98.274%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.051 Acc 98.249%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.244 Acc 94.957%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.240 Acc 94.955%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc176bbbc354a0d94deb269ca94e442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.306 Acc 10.938%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.264 Acc 17.628%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.249 Acc 18.412%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.724%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.212 Acc 20.011%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.165 Acc 22.062%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.777 Acc 39.844%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.796 Acc 38.289%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.798 Acc 38.130%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.881 Acc 28.906%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.831 Acc 37.554%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.780 Acc 39.521%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.719 Acc 41.998%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.659 Acc 44.377%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.597 Acc 46.613%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 1.011 Acc 66.406%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 1.105 Acc 64.349%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 1.106 Acc 64.183%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 1.196 Acc 58.594%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 1.183 Acc 61.750%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 1.140 Acc 63.083%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 1.091 Acc 64.779%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 1.058 Acc 65.835%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 1.027 Acc 66.918%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.701 Acc 73.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.715 Acc 77.769%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.713 Acc 77.694%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.787 Acc 78.125%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.798 Acc 74.667%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.782 Acc 75.078%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.765 Acc 75.571%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.748 Acc 76.066%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.735 Acc 76.509%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.574 Acc 80.469%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.555 Acc 82.882%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.550 Acc 82.995%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.838 Acc 76.562%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.627 Acc 80.252%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.618 Acc 80.527%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.611 Acc 80.855%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.598 Acc 81.223%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.588 Acc 81.563%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.474 Acc 84.375%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.463 Acc 86.200%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.455 Acc 86.373%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.589 Acc 83.594%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.536 Acc 83.192%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.524 Acc 83.497%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.517 Acc 83.726%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.510 Acc 84.034%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.504 Acc 84.199%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.511 Acc 85.156%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.420 Acc 87.129%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.415 Acc 87.348%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.532 Acc 86.719%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.467 Acc 85.419%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.460 Acc 85.627%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.457 Acc 85.766%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.453 Acc 85.920%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.445 Acc 86.075%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.394 Acc 86.719%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.376 Acc 88.916%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.372 Acc 89.024%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.375 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.412 Acc 87.392%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.412 Acc 87.290%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.410 Acc 87.383%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.412 Acc 87.278%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.406 Acc 87.436%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.329 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.345 Acc 89.952%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.339 Acc 90.081%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.423 Acc 88.281%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.385 Acc 88.080%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.380 Acc 88.293%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.377 Acc 88.349%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.375 Acc 88.525%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.375 Acc 88.531%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.317 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.326 Acc 90.486%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.320 Acc 90.637%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.288 Acc 90.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.353 Acc 89.109%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.346 Acc 89.323%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.349 Acc 89.281%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.352 Acc 89.158%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.351 Acc 89.234%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.302 Acc 90.625%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.300 Acc 91.259%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.297 Acc 91.309%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.255 Acc 91.406%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.333 Acc 89.913%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.334 Acc 89.844%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.333 Acc 89.818%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.332 Acc 89.861%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.330 Acc 89.954%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.279 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.295 Acc 91.476%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.289 Acc 91.690%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.243 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.301 Acc 90.571%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.310 Acc 90.411%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.310 Acc 90.358%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.311 Acc 90.374%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.311 Acc 90.435%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.296 Acc 89.844%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.283 Acc 91.808%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.277 Acc 92.005%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.350 Acc 89.844%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.302 Acc 90.888%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.299 Acc 90.905%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.301 Acc 90.864%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.303 Acc 90.859%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.300 Acc 90.954%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.264 Acc 90.625%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.261 Acc 92.597%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.256 Acc 92.739%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.269 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.275 Acc 91.731%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.278 Acc 91.519%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.278 Acc 91.570%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.282 Acc 91.459%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.283 Acc 91.486%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.264 Acc 92.621%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.260 Acc 92.650%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.319 Acc 89.062%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.279 Acc 91.847%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.276 Acc 91.554%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.274 Acc 91.702%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.274 Acc 91.741%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.276 Acc 91.727%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.249 Acc 93.139%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.244 Acc 93.214%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.153 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.266 Acc 92.319%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.262 Acc 92.289%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.267 Acc 92.138%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.268 Acc 92.069%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.266 Acc 92.064%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.246 Acc 93.178%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.242 Acc 93.218%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.301 Acc 91.406%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.251 Acc 92.512%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.255 Acc 92.238%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.258 Acc 92.286%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.260 Acc 92.258%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.238 Acc 93.394%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.235 Acc 93.466%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.272 Acc 92.969%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.251 Acc 92.644%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.255 Acc 92.600%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.256 Acc 92.579%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.254 Acc 92.638%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.253 Acc 92.574%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.238 Acc 93.417%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.234 Acc 93.575%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.301 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.253 Acc 92.884%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.248 Acc 92.860%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.247 Acc 92.784%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.247 Acc 92.758%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.246 Acc 92.774%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.225 Acc 93.688%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.221 Acc 93.816%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.247 Acc 92.814%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.241 Acc 92.883%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.239 Acc 92.862%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.239 Acc 92.936%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.238 Acc 92.942%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.225 Acc 93.874%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.221 Acc 93.851%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.189 Acc 95.312%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.227 Acc 93.247%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.227 Acc 93.210%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.227 Acc 93.176%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.229 Acc 93.243%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.232 Acc 93.182%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.216 Acc 93.735%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.212 Acc 93.937%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.166 Acc 92.969%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.234 Acc 93.193%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.222 Acc 93.490%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.224 Acc 93.480%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.227 Acc 93.339%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.229 Acc 93.310%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.216 Acc 93.920%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.212 Acc 94.127%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.189 Acc 93.750%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.221 Acc 93.619%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.219 Acc 93.676%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.221 Acc 93.555%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.223 Acc 93.514%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.223 Acc 93.496%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.214 Acc 94.036%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.209 Acc 94.115%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.193 Acc 93.750%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.221 Acc 93.626%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.219 Acc 93.696%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.218 Acc 93.631%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.220 Acc 93.608%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.220 Acc 93.605%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.209 Acc 94.338%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.206 Acc 94.286%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.201 Acc 93.874%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.217 Acc 93.618%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.216 Acc 93.639%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.216 Acc 93.669%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.214 Acc 93.874%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.212 Acc 94.045%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.228 Acc 92.188%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.218 Acc 93.773%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.213 Acc 93.828%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.213 Acc 93.817%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.212 Acc 93.805%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.212 Acc 93.766%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.213 Acc 94.067%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.208 Acc 94.228%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.207 Acc 92.188%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.206 Acc 94.237%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.205 Acc 94.115%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.205 Acc 94.116%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.204 Acc 94.144%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.208 Acc 94.018%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.202 Acc 94.570%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.200 Acc 94.609%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.272 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.198 Acc 94.400%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.201 Acc 94.220%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.204 Acc 94.147%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.202 Acc 94.167%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.204 Acc 94.026%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.203 Acc 94.291%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.201 Acc 94.465%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.214 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.198 Acc 94.090%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.197 Acc 94.286%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.200 Acc 94.212%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.199 Acc 94.221%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.202 Acc 94.196%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.196 Acc 94.585%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.193 Acc 94.753%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.192 Acc 94.361%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.194 Acc 94.251%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.198 Acc 94.189%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.197 Acc 94.288%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.196 Acc 94.257%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.205 Acc 94.315%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.204 Acc 94.395%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.253 Acc 91.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.195 Acc 94.098%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.189 Acc 94.271%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.189 Acc 94.321%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.191 Acc 94.368%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.193 Acc 94.353%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.200 Acc 94.554%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.196 Acc 94.628%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.184 Acc 92.188%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.169 Acc 95.019%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.838%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.182 Acc 94.674%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.188 Acc 94.523%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.189 Acc 94.484%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.194 Acc 94.794%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.190 Acc 94.959%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.196 Acc 94.268%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.191 Acc 94.566%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.184 Acc 94.638%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.184 Acc 94.652%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.188 Acc 94.586%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.194 Acc 94.709%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.192 Acc 94.780%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.180 Acc 95.312%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.182 Acc 94.802%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.188 Acc 94.652%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.187 Acc 94.695%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.188 Acc 94.646%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.187 Acc 94.636%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.195 Acc 94.748%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.192 Acc 94.788%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.179 Acc 94.926%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.185 Acc 94.722%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.825%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.184 Acc 94.769%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.184 Acc 94.754%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.197 Acc 94.709%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.196 Acc 94.776%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.173 Acc 95.073%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.179 Acc 94.788%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.182 Acc 94.747%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.180 Acc 94.783%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.181 Acc 94.753%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.187 Acc 94.841%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.185 Acc 94.939%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.164 Acc 95.289%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.168 Acc 95.184%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.174 Acc 94.985%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.177 Acc 94.933%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.178 Acc 94.882%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.193 Acc 94.748%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.191 Acc 94.885%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.166 Acc 95.080%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.174 Acc 94.932%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.179 Acc 94.866%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.177 Acc 94.862%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.176 Acc 94.856%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.194 Acc 94.841%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.193 Acc 94.811%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.170 Acc 95.251%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.173 Acc 95.165%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.172 Acc 95.123%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.171 Acc 95.124%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.174 Acc 95.071%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.189 Acc 94.964%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.189 Acc 94.955%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.162 Acc 95.189%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.165 Acc 95.211%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.102%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.171 Acc 95.044%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.170 Acc 95.075%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.193 Acc 94.740%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.192 Acc 94.807%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.203 Acc 91.406%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.173 Acc 95.189%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.171 Acc 95.126%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.167 Acc 95.258%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.219%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.166 Acc 95.253%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.161 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.193 Acc 94.694%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.192 Acc 94.745%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 92.188%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.162 Acc 95.258%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.164 Acc 95.223%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.168 Acc 95.089%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.166 Acc 95.137%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.168 Acc 95.086%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.186 Acc 94.926%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.185 Acc 95.052%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.162 Acc 95.282%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.166 Acc 95.200%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.166 Acc 95.211%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.165 Acc 95.237%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.164 Acc 95.286%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.180 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.188 Acc 94.918%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.190 Acc 94.920%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.144 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.163 Acc 95.305%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.161 Acc 95.417%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.163 Acc 95.349%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.164 Acc 95.346%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.162 Acc 95.350%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.192 Acc 94.663%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.191 Acc 94.788%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.161 Acc 95.441%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.161 Acc 95.450%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.161 Acc 95.406%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.160 Acc 95.395%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.188 Acc 94.841%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.187 Acc 94.877%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.151 Acc 95.753%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.155 Acc 95.569%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.157 Acc 95.536%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.159 Acc 95.507%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.159 Acc 95.443%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.187 Acc 94.794%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.182 Acc 95.005%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.157 Acc 95.498%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.156 Acc 95.511%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.162 Acc 95.372%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.162 Acc 95.353%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.158 Acc 95.411%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.192 Acc 94.879%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.192 Acc 94.904%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.154 Acc 95.653%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.156 Acc 95.472%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.388%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.155 Acc 95.500%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.154 Acc 95.514%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.193 Acc 94.632%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.191 Acc 94.761%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.149 Acc 95.606%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.149 Acc 95.635%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.150 Acc 95.642%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.152 Acc 95.591%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.153 Acc 95.565%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.188 Acc 94.872%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.186 Acc 95.017%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.149 Acc 95.900%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.149 Acc 95.833%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.151 Acc 95.749%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.153 Acc 95.687%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.154 Acc 95.690%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.183 Acc 95.189%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.182 Acc 95.235%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.138 Acc 95.815%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.147 Acc 95.627%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.150 Acc 95.582%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.150 Acc 95.589%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.152 Acc 95.581%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.190 Acc 94.833%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.189 Acc 94.928%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.277 Acc 95.312%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.141 Acc 95.838%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.143 Acc 95.759%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.145 Acc 95.741%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.148 Acc 95.689%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.149 Acc 95.663%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.157 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 94.825%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 94.998%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.241 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.146 Acc 95.885%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.142 Acc 95.899%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.145 Acc 95.829%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.146 Acc 95.819%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.148 Acc 95.802%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.195 Acc 94.833%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.194 Acc 94.998%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.142 Acc 95.985%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.140 Acc 95.969%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.143 Acc 95.930%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.144 Acc 95.881%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.145 Acc 95.852%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.188 Acc 94.787%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.025%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.142 Acc 96.071%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.144 Acc 95.919%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.145 Acc 95.839%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.145 Acc 95.825%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.145 Acc 95.850%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.180 Acc 95.251%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.355%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.136 Acc 95.808%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.145 Acc 95.713%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.144 Acc 95.808%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.142 Acc 95.879%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.144 Acc 95.832%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.187 Acc 94.988%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.184 Acc 95.184%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.307 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.135 Acc 95.908%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.140 Acc 95.861%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.139 Acc 95.917%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.141 Acc 95.946%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.140 Acc 95.938%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.190 Acc 94.787%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.189 Acc 94.893%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.138 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.136 Acc 95.970%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.134 Acc 96.067%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.134 Acc 96.081%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.136 Acc 96.068%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.138 Acc 96.014%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.189 Acc 95.096%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.188 Acc 95.141%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.130 Acc 97.656%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.129 Acc 96.318%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.132 Acc 96.296%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.135 Acc 96.226%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.136 Acc 96.119%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.137 Acc 96.105%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.133 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.192 Acc 95.173%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.189 Acc 95.293%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.291 Acc 92.188%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.126 Acc 96.372%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.131 Acc 96.210%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.132 Acc 96.151%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.134 Acc 96.111%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.136 Acc 96.069%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.190 Acc 94.941%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.189 Acc 94.998%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.136 Acc 96.187%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.128 Acc 96.280%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.132 Acc 96.138%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.135 Acc 96.043%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.136 Acc 96.022%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.191 Acc 95.080%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.190 Acc 95.157%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.133 Acc 95.978%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.132 Acc 96.057%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.134 Acc 96.045%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.135 Acc 96.011%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.199 Acc 94.941%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.198 Acc 95.017%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.156 Acc 94.531%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.128 Acc 96.388%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.135 Acc 96.222%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.131 Acc 96.255%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.132 Acc 96.154%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.164%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.193 Acc 94.802%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.192 Acc 94.947%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.134 Acc 96.040%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.129 Acc 96.200%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.133 Acc 96.139%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.132 Acc 96.190%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.196 Acc 94.756%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.194 Acc 94.850%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.132 Acc 95.947%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.128 Acc 96.152%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.129 Acc 96.177%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.129 Acc 96.187%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.127 Acc 96.231%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.180 Acc 95.250%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.115 Acc 96.682%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.119 Acc 96.510%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.126 Acc 96.317%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.127 Acc 96.259%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.311%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.188 Acc 95.158%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.188 Acc 95.231%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.123 Acc 96.620%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.127 Acc 96.416%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.125 Acc 96.426%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.127 Acc 96.368%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.127 Acc 96.339%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.192 Acc 94.972%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.190 Acc 95.091%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.122 Acc 96.465%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.123 Acc 96.498%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.123 Acc 96.444%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.126 Acc 96.326%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.218 Acc 92.188%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.186 Acc 95.127%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.186 Acc 95.165%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.114 Acc 96.535%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.116 Acc 96.482%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.118 Acc 96.468%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.120 Acc 96.415%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.121 Acc 96.427%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.183 Acc 95.251%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.181 Acc 95.332%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.111 Acc 96.883%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.117 Acc 96.653%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.118 Acc 96.571%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.118 Acc 96.563%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.121 Acc 96.509%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.190 Acc 95.065%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.190 Acc 95.048%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.122 Acc 96.496%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.117 Acc 96.583%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.117 Acc 96.597%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.119 Acc 96.489%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.120 Acc 96.438%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.190 Acc 92.188%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.189 Acc 95.227%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.189 Acc 95.239%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.149 Acc 97.656%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.113 Acc 96.767%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.110 Acc 96.762%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.113 Acc 96.641%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.117 Acc 96.487%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.118 Acc 96.445%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.196 Acc 94.903%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.195 Acc 94.866%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.111 Acc 96.689%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.114 Acc 96.720%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.116 Acc 96.623%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.117 Acc 96.507%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.119 Acc 96.468%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.191 Acc 94.895%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.189 Acc 95.060%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.117 Acc 96.442%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.498%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.116 Acc 96.558%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.117 Acc 96.555%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.119 Acc 96.515%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.203 Acc 94.562%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.201 Acc 94.586%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.651%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.112 Acc 96.688%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.116 Acc 96.587%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.115 Acc 96.631%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.116 Acc 96.587%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.194 Acc 95.042%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.193 Acc 95.130%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.119 Acc 96.426%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.118 Acc 96.494%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.117 Acc 96.545%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.118 Acc 96.491%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.116 Acc 96.523%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.191 Acc 95.034%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.188 Acc 95.270%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.130 Acc 94.531%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.115 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.114 Acc 96.595%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.111 Acc 96.644%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.112 Acc 96.596%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.114 Acc 96.579%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.196 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.190 Acc 95.011%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.190 Acc 95.134%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.100 Acc 97.223%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.108 Acc 96.937%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.112 Acc 96.745%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.112 Acc 96.725%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.111 Acc 96.705%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.191 Acc 94.833%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 94.974%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.108 Acc 96.767%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.113 Acc 96.720%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.110 Acc 96.784%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.111 Acc 96.746%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.114 Acc 96.622%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.202 Acc 94.872%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.198 Acc 94.986%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.101 Acc 96.890%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.107 Acc 96.778%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.110 Acc 96.740%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.112 Acc 96.683%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.202 Acc 94.748%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.203 Acc 94.823%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.097 Acc 97.030%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.108 Acc 96.739%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.111 Acc 96.626%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.111 Acc 96.631%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.112 Acc 96.643%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.206 Acc 94.508%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.203 Acc 94.745%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.100 Acc 96.960%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.104 Acc 96.922%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.106 Acc 96.832%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.108 Acc 96.819%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.200 Acc 94.833%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.198 Acc 94.959%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.097 Acc 96.906%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.106 Acc 96.731%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.109 Acc 96.623%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.108 Acc 96.674%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.108 Acc 96.680%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.206 Acc 95.011%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.204 Acc 95.040%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.118 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.103 Acc 96.945%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.107 Acc 96.805%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.106 Acc 96.823%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.105 Acc 96.838%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.204 Acc 94.841%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.203 Acc 94.877%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.275 Acc 93.750%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.099 Acc 96.929%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.103 Acc 96.918%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.104 Acc 96.901%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.105 Acc 96.850%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.106 Acc 96.805%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.202 Acc 94.802%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.200 Acc 94.873%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.105 Acc 96.945%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.105 Acc 96.848%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.104 Acc 96.772%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.104 Acc 96.774%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.203 Acc 94.856%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.201 Acc 94.928%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.103 Acc 96.829%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.105 Acc 96.863%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.104 Acc 96.871%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.105 Acc 96.864%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.280 Acc 90.625%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.211 Acc 94.609%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.209 Acc 94.784%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.094 Acc 97.076%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.099 Acc 97.000%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.101 Acc 96.974%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.102 Acc 96.934%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.151 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.191 Acc 95.142%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.189 Acc 95.141%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.096 Acc 97.007%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.096 Acc 97.020%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.098 Acc 97.021%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.101 Acc 96.981%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.202 Acc 94.624%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.200 Acc 94.823%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 97.153%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.101 Acc 97.019%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.101 Acc 96.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.101 Acc 96.959%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.099 Acc 96.997%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.203 Acc 94.872%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.200 Acc 95.029%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.104 Acc 96.972%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.100 Acc 97.070%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.100 Acc 97.031%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.099 Acc 96.989%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.186 Acc 92.969%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.194 Acc 95.158%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.194 Acc 95.231%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.137 Acc 94.531%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.099 Acc 97.014%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.100 Acc 96.927%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.100 Acc 96.978%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.100 Acc 96.950%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.194 Acc 95.065%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.193 Acc 95.173%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.201 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.094 Acc 97.223%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.095 Acc 97.174%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.094 Acc 97.168%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.094 Acc 97.198%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.097 Acc 97.125%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.204 Acc 94.918%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.202 Acc 95.017%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.096 Acc 97.073%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.096 Acc 97.013%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.098 Acc 96.931%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.099 Acc 96.970%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.204 Acc 94.933%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.201 Acc 95.056%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.091 Acc 97.161%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.093 Acc 97.073%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.097 Acc 97.078%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.213 Acc 94.547%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.209 Acc 94.687%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.101 Acc 96.960%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.098 Acc 97.007%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.097 Acc 97.028%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.097 Acc 97.060%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.097 Acc 97.053%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.204 Acc 95.011%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.202 Acc 95.149%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.097 Acc 97.053%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.090 Acc 97.252%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.091 Acc 97.254%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.090 Acc 97.265%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.093 Acc 97.173%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.210 Acc 94.864%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.206 Acc 95.009%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.030 Acc 100.000%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.087 Acc 97.277%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.089 Acc 97.334%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.092 Acc 97.208%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.092 Acc 97.173%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.215 Acc 94.732%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.209 Acc 94.834%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.111 Acc 94.531%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.090 Acc 97.147%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.092 Acc 97.158%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.092 Acc 97.124%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.201 Acc 94.995%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.198 Acc 95.099%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.122 Acc 93.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.090 Acc 97.339%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.089 Acc 97.314%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.091 Acc 97.181%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.091 Acc 97.216%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.092 Acc 97.170%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.206 Acc 94.910%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.206 Acc 94.904%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.083 Acc 97.378%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.088 Acc 97.268%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.090 Acc 97.228%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.091 Acc 97.189%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.091 Acc 97.193%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.208 Acc 94.709%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.207 Acc 94.912%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.088 Acc 97.269%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.090 Acc 97.260%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.090 Acc 97.244%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.092 Acc 97.157%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.090 Acc 97.215%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.214 Acc 94.554%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.212 Acc 94.640%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.085 Acc 97.300%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.085 Acc 97.349%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.087 Acc 97.340%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.088 Acc 97.346%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.089 Acc 97.326%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.205 Acc 95.057%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.205 Acc 95.122%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.156 Acc 96.875%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.086 Acc 97.355%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.086 Acc 97.392%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.088 Acc 97.353%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.089 Acc 97.302%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.089 Acc 97.312%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.207 Acc 94.941%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.205 Acc 95.029%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.087 Acc 97.200%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.087 Acc 97.310%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.088 Acc 97.293%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.088 Acc 97.267%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.088 Acc 97.255%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.212 Acc 94.616%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.211 Acc 94.733%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.088 Acc 97.308%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.086 Acc 97.319%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.088 Acc 97.286%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.217 Acc 94.848%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.214 Acc 94.955%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.165 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.082 Acc 97.440%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.085 Acc 97.301%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.086 Acc 97.274%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.087 Acc 97.288%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.213 Acc 94.879%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.211 Acc 94.963%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.091 Acc 98.438%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.087 Acc 97.146%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.083 Acc 97.388%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.082 Acc 97.394%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.087 Acc 97.287%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.211 Acc 94.748%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.212 Acc 94.873%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.082 Acc 97.509%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.082 Acc 97.407%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.083 Acc 97.451%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.086 Acc 97.317%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.085 Acc 97.341%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.208 Acc 94.988%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.205 Acc 95.118%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.083 Acc 97.401%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.085 Acc 97.427%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.085 Acc 97.394%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.086 Acc 97.343%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.084 Acc 97.421%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.219 Acc 94.787%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.216 Acc 94.932%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.078 Acc 97.548%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.078 Acc 97.501%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.083 Acc 97.337%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.084 Acc 97.326%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.156 Acc 92.969%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.204 Acc 95.050%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.204 Acc 95.138%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.071 Acc 97.772%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.078 Acc 97.582%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.078 Acc 97.503%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.080 Acc 97.467%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.083 Acc 97.399%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.207 Acc 95.034%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.205 Acc 95.040%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.077 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.072 Acc 97.517%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.075 Acc 97.493%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.078 Acc 97.438%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.080 Acc 97.397%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.082 Acc 97.369%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.208 Acc 95.073%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.208 Acc 95.072%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.123 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.079 Acc 97.563%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.081 Acc 97.489%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.082 Acc 97.443%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.081 Acc 97.498%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.081 Acc 97.503%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.227 Acc 94.485%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.221 Acc 94.671%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.079 Acc 97.765%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.080 Acc 97.571%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.080 Acc 97.526%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.083 Acc 97.434%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.082 Acc 97.424%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.213 Acc 94.964%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.209 Acc 95.118%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.072 Acc 97.602%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.073 Acc 97.672%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.077 Acc 97.549%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.217 Acc 92.188%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.232 Acc 94.493%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.228 Acc 94.512%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.072 Acc 97.625%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.076 Acc 97.610%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.080 Acc 97.495%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.080 Acc 97.508%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.079 Acc 97.517%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.266 Acc 92.188%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.230 Acc 94.655%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.226 Acc 94.768%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.076 Acc 97.401%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.073 Acc 97.606%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.074 Acc 97.584%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.075 Acc 97.555%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.076 Acc 97.524%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.236 Acc 94.547%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.233 Acc 94.551%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.072 Acc 97.726%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.077 Acc 97.506%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.077 Acc 97.516%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.077 Acc 97.485%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.211 Acc 95.011%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.211 Acc 94.974%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.107 Acc 94.531%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.075 Acc 97.532%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.073 Acc 97.635%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.075 Acc 97.592%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.075 Acc 97.600%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.254 Acc 92.969%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.224 Acc 94.640%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.224 Acc 94.640%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.071 Acc 97.857%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.071 Acc 97.808%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.073 Acc 97.703%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.075 Acc 97.606%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.076 Acc 97.588%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.218 Acc 94.833%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.219 Acc 94.792%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.071 Acc 97.664%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.071 Acc 97.680%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.072 Acc 97.654%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.073 Acc 97.616%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.225 Acc 94.895%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.225 Acc 94.912%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.070 Acc 97.749%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.069 Acc 97.711%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.071 Acc 97.742%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.073 Acc 97.658%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.217 Acc 94.995%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.216 Acc 95.083%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.071 Acc 97.761%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.073 Acc 97.611%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.074 Acc 97.609%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.233 Acc 94.787%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.228 Acc 94.850%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.070 Acc 97.713%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.071 Acc 97.728%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.072 Acc 97.678%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.226 Acc 94.864%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.223 Acc 94.873%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.066 Acc 97.772%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.070 Acc 97.715%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.069 Acc 97.724%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.070 Acc 97.687%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.071 Acc 97.658%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.202 Acc 92.969%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.227 Acc 94.949%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.226 Acc 94.932%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.068 Acc 97.795%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.069 Acc 97.742%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.072 Acc 97.630%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.071 Acc 97.678%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.072 Acc 97.670%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.235 Acc 94.678%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.232 Acc 94.691%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.068 Acc 97.795%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.069 Acc 97.715%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.071 Acc 97.719%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.071 Acc 97.689%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.212 Acc 91.406%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.230 Acc 94.601%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.227 Acc 94.698%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.074 Acc 97.571%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.067 Acc 97.742%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.068 Acc 97.783%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.072 Acc 97.633%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.232 Acc 94.879%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.229 Acc 94.970%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.068 Acc 97.842%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.068 Acc 97.917%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.071 Acc 97.763%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.071 Acc 97.703%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.190 Acc 92.188%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.225 Acc 94.709%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.224 Acc 94.815%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.066 Acc 97.850%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.069 Acc 97.715%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.070 Acc 97.703%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.071 Acc 97.705%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.232 Acc 94.485%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.232 Acc 94.617%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.152 Acc 94.531%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.066 Acc 97.927%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.068 Acc 97.835%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.069 Acc 97.789%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.069 Acc 97.763%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.070 Acc 97.739%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.236 Acc 94.670%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.234 Acc 94.722%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.061 Acc 98.198%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.068 Acc 97.889%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.068 Acc 97.879%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.070 Acc 97.775%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.071 Acc 97.736%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.236 Acc 94.678%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.230 Acc 94.819%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.081 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.065 Acc 97.873%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.067 Acc 97.812%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.068 Acc 97.809%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.068 Acc 97.769%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.069 Acc 97.734%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.224 Acc 94.740%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.223 Acc 94.885%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.063 Acc 97.904%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.064 Acc 97.839%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.067 Acc 97.770%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.068 Acc 97.723%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.235 Acc 94.879%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.234 Acc 94.982%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.065 Acc 97.862%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.068 Acc 97.732%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.067 Acc 97.785%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.067 Acc 97.786%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.230 Acc 94.787%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.229 Acc 94.842%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.062 Acc 97.857%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.062 Acc 97.913%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.065 Acc 97.817%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.067 Acc 97.785%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.068 Acc 97.751%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.228 Acc 94.841%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.228 Acc 94.842%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.060 Acc 98.190%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.063 Acc 98.033%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.064 Acc 97.911%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.066 Acc 97.845%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.067 Acc 97.836%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.230 Acc 94.686%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.228 Acc 94.799%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.056 Acc 97.997%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.062 Acc 97.909%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.063 Acc 97.885%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.064 Acc 97.859%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.065 Acc 97.837%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.257 Acc 94.400%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.250 Acc 94.469%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.068 Acc 97.912%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.068 Acc 97.781%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.068 Acc 97.779%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.068 Acc 97.747%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.255 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.235 Acc 94.810%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.233 Acc 94.924%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.062 Acc 98.014%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.063 Acc 97.955%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.065 Acc 97.831%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.233 Acc 95.019%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.228 Acc 95.173%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.058 Acc 98.028%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.058 Acc 98.076%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.060 Acc 98.020%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.062 Acc 97.962%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.062 Acc 97.974%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.220 Acc 92.188%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.239 Acc 94.756%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.235 Acc 94.819%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.064 Acc 97.901%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.063 Acc 97.924%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.062 Acc 97.941%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.063 Acc 97.901%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.273 Acc 92.969%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.238 Acc 94.771%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.234 Acc 94.842%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.063 Acc 97.850%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.064 Acc 97.905%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.063 Acc 97.947%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.064 Acc 97.895%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.235 Acc 94.964%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.232 Acc 95.056%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.079 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.061 Acc 97.983%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.062 Acc 97.921%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.062 Acc 97.941%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.062 Acc 97.910%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.241 Acc 94.848%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.239 Acc 94.986%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.062 Acc 97.873%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.062 Acc 97.913%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.060 Acc 97.965%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.061 Acc 97.945%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.062 Acc 97.931%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.235 Acc 95.080%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.233 Acc 95.157%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.056 Acc 98.252%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.061 Acc 98.018%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.062 Acc 97.960%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.064 Acc 97.910%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.063 Acc 97.918%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.242 Acc 94.446%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.237 Acc 94.636%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.057 Acc 98.159%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.058 Acc 98.084%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.059 Acc 98.066%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.060 Acc 97.989%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.062 Acc 97.973%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.238 Acc 94.740%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.237 Acc 94.869%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.058 Acc 98.120%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.059 Acc 98.041%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.063 Acc 97.869%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.063 Acc 97.882%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.234 Acc 94.779%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.230 Acc 94.869%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.061 Acc 97.888%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.058 Acc 98.002%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.060 Acc 97.903%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.061 Acc 97.923%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.060 Acc 97.946%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.268 Acc 92.969%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.236 Acc 94.794%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.232 Acc 94.924%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.073 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.062 Acc 97.850%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.060 Acc 97.956%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.060 Acc 97.999%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.060 Acc 97.978%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.061 Acc 97.920%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.243 Acc 94.794%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.240 Acc 94.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.056 Acc 98.105%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.056 Acc 98.189%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.058 Acc 98.079%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.059 Acc 98.032%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.060 Acc 98.016%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.271 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.257 Acc 94.454%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.251 Acc 94.531%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.058 Acc 98.028%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.059 Acc 98.033%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.059 Acc 98.051%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.058 Acc 98.065%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.058 Acc 98.063%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.255 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.239 Acc 94.732%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.234 Acc 94.974%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.052 Acc 98.190%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.057 Acc 98.103%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.056 Acc 98.056%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.057 Acc 98.056%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.058 Acc 98.031%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.285 Acc 91.406%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.238 Acc 94.678%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.236 Acc 94.706%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.055 Acc 98.298%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.057 Acc 98.189%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.057 Acc 98.126%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.058 Acc 98.050%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.060 Acc 97.982%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.241 Acc 94.732%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.242 Acc 94.733%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.052 Acc 98.275%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.054 Acc 98.150%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.055 Acc 98.142%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.055 Acc 98.161%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.056 Acc 98.123%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.208 Acc 93.750%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.244 Acc 94.848%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.241 Acc 95.002%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.053 Acc 98.144%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.055 Acc 98.082%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.055 Acc 98.073%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.057 Acc 98.046%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.248 Acc 94.732%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.246 Acc 94.714%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.054 Acc 98.136%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.054 Acc 98.181%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.054 Acc 98.162%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.056 Acc 98.097%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.056 Acc 98.101%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.260 Acc 94.531%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.244 Acc 94.392%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.240 Acc 94.597%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.052 Acc 98.329%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.057 Acc 98.115%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.057 Acc 98.079%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.059 Acc 98.040%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.057 Acc 98.071%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.259 Acc 92.969%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.244 Acc 94.701%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.242 Acc 94.900%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.060 Acc 97.857%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.057 Acc 97.944%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.057 Acc 97.965%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.058 Acc 97.952%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.058 Acc 97.984%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.274 Acc 90.625%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.240 Acc 94.879%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.237 Acc 94.947%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.053 Acc 98.213%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.050 Acc 98.313%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.051 Acc 98.297%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.054 Acc 98.223%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.055 Acc 98.199%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.241 Acc 94.694%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.241 Acc 94.733%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.048 Acc 98.229%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.052 Acc 98.146%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.053 Acc 98.144%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.053 Acc 98.137%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.056 Acc 98.101%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.279 Acc 92.969%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.254 Acc 94.562%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.253 Acc 94.636%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.051 Acc 98.244%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.050 Acc 98.235%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.054 Acc 98.134%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.054 Acc 98.106%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.056 Acc 98.055%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.238 Acc 94.810%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.236 Acc 94.788%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.051 Acc 98.383%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.052 Acc 98.282%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.051 Acc 98.274%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.053 Acc 98.192%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.054 Acc 98.143%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.251 Acc 92.969%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.248 Acc 94.524%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.245 Acc 94.745%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.049 Acc 98.247%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.053 Acc 98.175%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.054 Acc 98.130%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.054 Acc 98.143%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.267 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.249 Acc 94.810%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.244 Acc 94.924%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.054 Acc 98.229%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.052 Acc 98.231%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.053 Acc 98.217%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.054 Acc 98.178%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.055 Acc 98.146%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.254 Acc 94.725%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.249 Acc 94.881%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.043 Acc 99.219%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [100/573] Loss: 0.055 Acc 98.120%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.052 Acc 98.228%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.052 Acc 98.219%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.054 Acc 98.204%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.054 Acc 98.158%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.277 Acc 91.406%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.257 Acc 94.585%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.255 Acc 94.601%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.053 Acc 98.252%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.051 Acc 98.298%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.052 Acc 98.274%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.054 Acc 98.186%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.054 Acc 98.188%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.260 Acc 94.864%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.258 Acc 94.881%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.046 Acc 98.383%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.051 Acc 98.270%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.052 Acc 98.201%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.052 Acc 98.174%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.054 Acc 98.146%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.217 Acc 92.188%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.250 Acc 94.817%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.243 Acc 94.982%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.048 Acc 98.376%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.053 Acc 98.191%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.055 Acc 98.169%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.053 Acc 98.225%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.293 Acc 92.969%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.253 Acc 94.261%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.248 Acc 94.566%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.052 Acc 98.128%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.050 Acc 98.224%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.052 Acc 98.136%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.053 Acc 98.128%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.053 Acc 98.126%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.246 Acc 94.771%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.243 Acc 94.947%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.043 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.049 Acc 98.383%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.052 Acc 98.290%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.053 Acc 98.269%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.052 Acc 98.270%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.052 Acc 98.300%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.251 Acc 94.794%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.248 Acc 94.974%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.082 Acc 99.219%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.047 Acc 98.252%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.049 Acc 98.309%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.049 Acc 98.336%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.051 Acc 98.274%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.052 Acc 98.233%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.232 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.260 Acc 94.547%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.257 Acc 94.706%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.049 Acc 98.244%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.048 Acc 98.266%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.050 Acc 98.225%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.050 Acc 98.221%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.051 Acc 98.219%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.246 Acc 94.647%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.242 Acc 94.827%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.050 Acc 98.221%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.050 Acc 98.248%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.050 Acc 98.233%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.051 Acc 98.230%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.268 Acc 94.895%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.263 Acc 94.990%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.051 Acc 98.260%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.049 Acc 98.270%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.051 Acc 98.238%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.052 Acc 98.215%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.053 Acc 98.183%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.236 Acc 92.969%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.248 Acc 94.616%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.248 Acc 94.718%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.048 Acc 98.391%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.050 Acc 98.309%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.051 Acc 98.256%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.052 Acc 98.208%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.051 Acc 98.222%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.262 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.251 Acc 94.647%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.249 Acc 94.714%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.062 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.047 Acc 98.383%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.049 Acc 98.356%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.049 Acc 98.352%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.051 Acc 98.289%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.052 Acc 98.233%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.256 Acc 92.969%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.262 Acc 94.763%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.258 Acc 94.862%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.043 Acc 98.577%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.045 Acc 98.476%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.047 Acc 98.344%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.049 Acc 98.286%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.050 Acc 98.269%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.281 Acc 91.406%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.251 Acc 94.926%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.244 Acc 95.083%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.048 Acc 98.356%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.049 Acc 98.349%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.049 Acc 98.346%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.049 Acc 98.322%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.300 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.254 Acc 94.841%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.251 Acc 94.916%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.029 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.047 Acc 98.283%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.049 Acc 98.266%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.050 Acc 98.227%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.050 Acc 98.225%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.050 Acc 98.268%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.149 Acc 96.875%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.256 Acc 94.787%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.253 Acc 94.916%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.046 Acc 98.461%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.046 Acc 98.434%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.048 Acc 98.386%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.049 Acc 98.313%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.050 Acc 98.263%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.306 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.247 Acc 94.872%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.242 Acc 95.025%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.045 Acc 98.530%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.048 Acc 98.352%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.048 Acc 98.336%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.049 Acc 98.315%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.051 Acc 98.235%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.248 Acc 92.188%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.252 Acc 94.624%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.249 Acc 94.772%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.047 Acc 98.267%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.047 Acc 98.364%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.047 Acc 98.352%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.046 Acc 98.393%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.047 Acc 98.383%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.254 Acc 94.438%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.253 Acc 94.566%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.046 Acc 98.352%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.046 Acc 98.371%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.048 Acc 98.334%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.048 Acc 98.350%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.048 Acc 98.347%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.263 Acc 94.787%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.257 Acc 94.866%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.045 Acc 98.399%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.046 Acc 98.441%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.046 Acc 98.443%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.048 Acc 98.366%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.266 Acc 94.686%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.262 Acc 94.807%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.043 Acc 98.523%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.044 Acc 98.519%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.046 Acc 98.466%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.046 Acc 98.441%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.047 Acc 98.413%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.265 Acc 94.593%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.261 Acc 94.706%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.046 Acc 98.360%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.044 Acc 98.422%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.046 Acc 98.425%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.048 Acc 98.385%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.049 Acc 98.358%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.257 Acc 94.732%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.254 Acc 94.866%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.045 Acc 98.345%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.046 Acc 98.387%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.047 Acc 98.378%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.047 Acc 98.379%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.047 Acc 98.411%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.251 Acc 94.787%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.246 Acc 94.893%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.041 Acc 98.507%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.043 Acc 98.453%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.044 Acc 98.416%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.045 Acc 98.414%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.307 Acc 91.406%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.265 Acc 94.678%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.261 Acc 94.772%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.028 Acc 100.000%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.047 Acc 98.476%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.048 Acc 98.403%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.049 Acc 98.365%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.047 Acc 98.431%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.270 Acc 92.969%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.251 Acc 94.601%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.251 Acc 94.671%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.045 Acc 98.383%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.045 Acc 98.410%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.046 Acc 98.378%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.046 Acc 98.389%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.046 Acc 98.366%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.252 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.257 Acc 94.624%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.250 Acc 94.831%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.042 Acc 98.530%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.044 Acc 98.434%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.045 Acc 98.409%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.047 Acc 98.338%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.047 Acc 98.353%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.268 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.261 Acc 94.640%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.260 Acc 94.764%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.043 Acc 98.492%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.044 Acc 98.461%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.047 Acc 98.334%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.047 Acc 98.356%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.046 Acc 98.388%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.216 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.259 Acc 94.678%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.254 Acc 94.733%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.042 Acc 98.523%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.044 Acc 98.472%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.045 Acc 98.414%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.046 Acc 98.413%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.335 Acc 91.406%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.269 Acc 94.500%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.263 Acc 94.780%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.037 Acc 98.675%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.040 Acc 98.630%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.042 Acc 98.545%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.044 Acc 98.472%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.261 Acc 94.531%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.263 Acc 94.725%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.261 Acc 94.850%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [100/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.043 Acc 98.465%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.044 Acc 98.445%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.046 Acc 98.408%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.046 Acc 98.406%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.220 Acc 92.188%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.258 Acc 94.508%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.251 Acc 94.733%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.040 Acc 98.675%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.042 Acc 98.609%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.041 Acc 98.630%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.042 Acc 98.586%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.236 Acc 93.750%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.259 Acc 94.825%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.256 Acc 94.811%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.041 Acc 98.584%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.043 Acc 98.469%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.043 Acc 98.482%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.044 Acc 98.439%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.045 Acc 98.413%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.260 Acc 94.701%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.260 Acc 94.842%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.045 Acc 98.461%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.046 Acc 98.410%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.047 Acc 98.349%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.046 Acc 98.377%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.046 Acc 98.366%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.263 Acc 94.562%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.258 Acc 94.737%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcedda52b8c4468c80b990ce4a16d1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8536e2b5567c499f933d1c6046d62456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.292 Acc 21.875%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.239 Acc 19.143%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.999%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.231 Acc 19.014%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.840 Acc 40.625%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.912 Acc 32.488%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.914 Acc 32.210%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.957 Acc 35.938%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.623 Acc 43.897%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.406 Acc 52.099%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.247 Acc 57.955%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.118 Acc 62.634%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.020 Acc 66.180%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.516 Acc 83.594%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.462 Acc 86.193%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.449 Acc 86.505%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.411 Acc 89.844%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.528 Acc 83.849%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.505 Acc 84.542%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.490 Acc 85.021%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.482 Acc 85.265%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.470 Acc 85.576%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.436 Acc 86.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.338 Acc 90.548%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.333 Acc 90.516%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.270 Acc 95.312%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.379 Acc 88.745%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.387 Acc 88.452%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.388 Acc 88.372%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.386 Acc 88.396%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.384 Acc 88.500%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.413 Acc 88.281%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.304 Acc 91.476%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.298 Acc 91.519%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.264 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.353 Acc 89.233%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.356 Acc 89.214%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.351 Acc 89.392%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.349 Acc 89.477%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.349 Acc 89.566%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.298 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.290 Acc 91.754%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.280 Acc 91.873%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.593 Acc 81.250%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.329 Acc 90.408%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.325 Acc 90.493%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.318 Acc 90.674%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.320 Acc 90.559%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.319 Acc 90.558%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.270 Acc 92.621%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.263 Acc 92.802%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.340 Acc 85.938%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.311 Acc 90.594%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.308 Acc 90.792%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.307 Acc 90.942%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.306 Acc 90.974%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.305 Acc 90.995%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.316 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.267 Acc 92.744%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.257 Acc 92.825%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.295 Acc 91.298%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.298 Acc 91.002%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.295 Acc 91.032%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.293 Acc 91.213%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.291 Acc 91.311%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.256 Acc 93.270%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.245 Acc 93.396%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.365 Acc 87.500%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.272 Acc 91.855%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.284 Acc 91.643%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.284 Acc 91.725%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.284 Acc 91.683%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.285 Acc 91.657%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.230 Acc 93.727%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.222 Acc 93.894%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.273 Acc 92.273%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.275 Acc 91.908%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.273 Acc 92.027%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.272 Acc 92.026%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.272 Acc 92.064%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.304 Acc 89.844%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.250 Acc 93.224%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.244 Acc 93.237%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.338 Acc 88.281%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.273 Acc 91.971%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.266 Acc 92.238%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.268 Acc 92.226%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.269 Acc 92.182%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.265 Acc 92.275%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.240 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.215 Acc 94.114%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.210 Acc 94.201%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.271 Acc 91.406%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.240 Acc 92.961%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.249 Acc 92.666%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.256 Acc 92.553%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.258 Acc 92.519%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.262 Acc 92.417%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.190 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.227 Acc 93.851%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.221 Acc 93.975%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.342 Acc 91.406%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.258 Acc 92.644%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.261 Acc 92.615%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.256 Acc 92.730%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.257 Acc 92.583%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.258 Acc 92.517%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.250 Acc 93.131%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.243 Acc 93.116%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.171 Acc 91.406%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.261 Acc 92.481%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.250 Acc 92.802%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.249 Acc 92.686%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.252 Acc 92.643%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.255 Acc 92.554%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.230 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.211 Acc 94.284%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.204 Acc 94.415%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.385 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.246 Acc 92.659%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.248 Acc 92.802%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.250 Acc 92.753%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.249 Acc 92.807%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.248 Acc 92.836%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.212 Acc 94.825%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.203 Acc 94.932%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.229 Acc 92.953%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.238 Acc 92.934%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.236 Acc 93.026%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.238 Acc 93.037%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.239 Acc 93.062%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.251 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.217 Acc 94.485%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.206 Acc 94.590%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.247 Acc 92.690%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.244 Acc 92.895%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.244 Acc 92.909%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.242 Acc 92.969%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.243 Acc 92.970%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.225 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.206 Acc 94.663%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.198 Acc 94.683%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.285 Acc 90.625%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.229 Acc 93.348%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.229 Acc 93.151%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.231 Acc 93.202%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.235 Acc 93.154%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.238 Acc 93.047%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.205 Acc 94.825%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.199 Acc 94.803%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.204 Acc 91.406%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.219 Acc 93.796%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.225 Acc 93.571%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.228 Acc 93.459%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.231 Acc 93.347%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.232 Acc 93.313%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.198 Acc 95.065%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.190 Acc 95.079%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.181 Acc 96.094%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.229 Acc 93.510%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.233 Acc 93.377%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.231 Acc 93.389%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.230 Acc 93.368%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.230 Acc 93.384%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.258 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.206 Acc 94.508%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.201 Acc 94.597%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.249 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.228 Acc 93.309%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.223 Acc 93.458%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.226 Acc 93.464%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.226 Acc 93.487%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.225 Acc 93.502%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.207 Acc 94.732%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.198 Acc 94.862%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.159 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.215 Acc 93.804%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.221 Acc 93.458%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.222 Acc 93.332%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.223 Acc 93.399%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.227 Acc 93.402%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.272 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.206 Acc 94.524%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.199 Acc 94.660%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.319 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.225 Acc 93.889%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.216 Acc 93.894%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.220 Acc 93.768%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.222 Acc 93.625%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.221 Acc 93.628%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.257 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.205 Acc 94.446%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.196 Acc 94.656%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.205 Acc 94.052%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.213 Acc 93.952%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.210 Acc 93.932%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.213 Acc 93.898%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.214 Acc 93.825%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.201 Acc 95.312%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.204 Acc 94.485%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.194 Acc 94.667%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.294 Acc 89.844%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.219 Acc 93.526%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.221 Acc 93.528%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.217 Acc 93.664%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.219 Acc 93.619%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.218 Acc 93.666%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.211 Acc 94.291%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.202 Acc 94.558%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.477 Acc 89.844%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.215 Acc 93.765%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.215 Acc 93.738%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.216 Acc 93.644%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.215 Acc 93.697%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.215 Acc 93.688%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.211 Acc 94.469%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.203 Acc 94.523%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.218 Acc 93.665%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.213 Acc 93.754%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.214 Acc 93.734%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.214 Acc 93.707%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.214 Acc 93.656%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.206 Acc 95.104%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.196 Acc 95.091%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.276 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.204 Acc 93.959%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.210 Acc 93.797%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.208 Acc 93.986%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.209 Acc 93.927%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.212 Acc 93.844%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.200 Acc 94.655%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.192 Acc 94.788%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.227 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.202 Acc 94.059%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.203 Acc 94.162%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.205 Acc 94.087%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.207 Acc 94.031%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.210 Acc 93.951%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.200 Acc 94.895%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.191 Acc 95.103%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.304 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.204 Acc 93.881%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.204 Acc 93.925%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.212 Acc 93.802%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.213 Acc 93.828%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.211 Acc 93.884%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.204 Acc 94.864%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.194 Acc 94.970%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.290 Acc 91.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.211 Acc 93.889%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.209 Acc 93.894%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.208 Acc 93.955%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.207 Acc 93.957%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.208 Acc 93.981%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.197 Acc 94.817%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.189 Acc 95.009%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.171 Acc 93.750%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.199 Acc 94.377%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.205 Acc 94.088%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.203 Acc 94.080%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.204 Acc 94.089%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.207 Acc 93.940%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.221 Acc 94.469%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.209 Acc 94.718%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.200 Acc 91.406%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.206 Acc 93.796%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.208 Acc 93.905%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.212 Acc 93.882%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.207 Acc 93.966%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.210 Acc 93.917%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.159 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.188 Acc 95.196%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.181 Acc 95.281%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.203 Acc 94.106%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.199 Acc 94.139%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.201 Acc 94.129%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.202 Acc 94.103%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.200 Acc 94.116%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.616%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.195 Acc 94.780%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.236 Acc 91.406%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.194 Acc 94.315%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.193 Acc 94.380%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.198 Acc 94.254%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.200 Acc 94.169%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.202 Acc 94.146%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.206 Acc 95.274%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.196 Acc 95.262%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.111 Acc 95.312%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.199 Acc 93.951%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.206 Acc 93.890%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.202 Acc 94.108%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.200 Acc 94.087%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.201 Acc 94.054%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.194 Acc 95.019%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.183 Acc 95.278%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.209 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.196 Acc 94.330%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.195 Acc 94.356%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.198 Acc 94.272%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.199 Acc 94.243%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.200 Acc 94.215%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.347 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.215 Acc 94.562%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.205 Acc 94.644%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.196 Acc 94.315%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.205 Acc 94.100%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.198 Acc 94.212%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.197 Acc 94.233%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.199 Acc 94.159%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.204 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.186 Acc 95.599%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.179 Acc 95.491%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.180 Acc 94.670%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.192 Acc 94.403%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.195 Acc 94.274%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.196 Acc 94.296%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.197 Acc 94.291%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.207 Acc 95.135%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.197 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.174 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.189 Acc 94.640%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.190 Acc 94.570%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.192 Acc 94.479%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.193 Acc 94.430%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.196 Acc 94.355%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.204 Acc 94.547%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.195 Acc 94.764%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.183 Acc 94.539%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.192 Acc 94.282%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.192 Acc 94.373%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.195 Acc 94.225%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.194 Acc 94.343%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.177 Acc 95.565%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.204 Acc 92.188%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.187 Acc 94.168%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.191 Acc 94.251%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.195 Acc 94.238%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.195 Acc 94.258%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.194 Acc 94.291%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.186 Acc 95.145%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.229 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.187 Acc 94.547%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.191 Acc 94.457%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.193 Acc 94.305%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.194 Acc 94.266%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.194 Acc 94.272%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.187 Acc 95.421%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.182 Acc 95.464%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.177 Acc 94.988%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.187 Acc 94.643%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.188 Acc 94.533%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.194 Acc 95.328%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.189 Acc 95.390%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.188 Acc 94.361%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.186 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.188 Acc 94.547%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.189 Acc 94.471%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.190 Acc 94.428%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.183 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.193 Acc 94.972%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.186 Acc 95.040%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.156 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.174 Acc 94.779%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.182 Acc 94.555%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.185 Acc 94.560%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.188 Acc 94.492%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.190 Acc 94.460%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.187 Acc 95.467%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.181 Acc 95.484%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.265 Acc 91.406%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.178 Acc 94.879%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.185 Acc 94.562%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.185 Acc 94.572%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.188 Acc 94.475%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.199 Acc 95.173%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.192 Acc 95.204%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.162 Acc 93.750%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.180 Acc 94.554%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.186 Acc 94.523%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.190 Acc 94.457%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.192 Acc 94.369%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.188 Acc 95.073%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.180 Acc 95.219%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.174 Acc 94.941%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.180 Acc 94.757%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.182 Acc 94.645%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.190 Acc 94.489%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.202 Acc 94.988%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.194 Acc 95.110%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.281 Acc 91.406%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.186 Acc 94.547%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.181 Acc 94.691%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.185 Acc 94.542%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.187 Acc 94.514%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.187 Acc 94.523%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.206 Acc 95.336%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.198 Acc 95.305%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.153 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.185 Acc 94.647%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.180 Acc 94.788%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.181 Acc 94.731%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.185 Acc 94.600%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.191 Acc 92.188%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.201 Acc 94.787%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.193 Acc 94.869%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.186 Acc 92.969%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.180 Acc 94.825%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.178 Acc 94.873%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.181 Acc 94.830%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.183 Acc 94.751%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.184 Acc 94.656%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.189 Acc 95.592%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.156 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.181 Acc 94.725%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.184 Acc 94.617%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.186 Acc 94.482%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.185 Acc 94.477%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.187 Acc 94.436%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.184 Acc 95.359%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.179 Acc 95.379%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.253 Acc 91.406%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.182 Acc 94.771%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.187 Acc 94.539%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.186 Acc 94.565%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.186 Acc 94.566%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.186 Acc 94.575%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.425%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.337 Acc 92.188%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.185 Acc 94.299%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.187 Acc 94.333%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.185 Acc 94.469%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.188 Acc 94.481%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.187 Acc 94.456%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.207 Acc 95.042%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.194 Acc 95.219%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.175 Acc 94.903%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.177 Acc 94.698%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.177 Acc 94.739%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.179 Acc 94.638%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.180 Acc 94.667%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.164 Acc 92.188%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.205 Acc 94.903%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.196 Acc 94.978%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.181 Acc 94.740%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.176 Acc 94.846%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.177 Acc 94.791%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.178 Acc 94.746%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.181 Acc 94.659%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.208 Acc 94.887%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.201 Acc 95.040%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.203 Acc 92.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.174 Acc 94.663%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.178 Acc 94.628%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.179 Acc 94.586%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.179 Acc 94.586%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.182 Acc 94.562%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.202 Acc 95.088%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.193 Acc 95.188%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.232 Acc 96.094%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.182 Acc 94.817%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.175 Acc 94.897%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.180 Acc 94.734%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.183 Acc 94.677%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.184 Acc 94.681%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.187 Acc 95.452%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.167 Acc 95.026%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.173 Acc 94.916%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.174 Acc 94.791%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.177 Acc 94.710%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.178 Acc 94.745%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.200 Acc 91.406%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.194 Acc 95.459%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.188 Acc 95.491%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.168 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.175 Acc 94.872%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.182 Acc 94.593%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.181 Acc 94.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.183 Acc 94.594%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.181 Acc 94.703%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.184 Acc 95.483%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.175 Acc 95.717%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.260 Acc 91.406%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.176 Acc 94.725%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.178 Acc 94.780%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.180 Acc 94.770%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.178 Acc 94.823%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.180 Acc 94.736%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.206 Acc 95.096%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.196 Acc 95.320%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.248 Acc 90.625%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.183 Acc 94.508%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.179 Acc 94.593%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.175 Acc 94.775%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.181 Acc 94.648%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.181 Acc 94.622%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.200 Acc 95.166%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.187 Acc 95.316%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.229 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.166 Acc 94.926%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.177 Acc 94.601%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.181 Acc 94.568%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.178 Acc 94.633%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.178 Acc 94.645%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.192 Acc 95.135%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.181 Acc 95.340%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.221 Acc 94.531%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.180 Acc 94.740%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.176 Acc 94.866%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.175 Acc 94.876%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.178 Acc 94.794%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.176 Acc 94.842%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.225 Acc 93.750%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.184 Acc 95.429%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.179 Acc 95.484%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.169 Acc 95.026%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.169 Acc 94.959%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.169 Acc 94.983%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.175 Acc 94.818%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.174 Acc 94.846%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.221 Acc 95.189%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.206 Acc 95.297%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.183 Acc 94.485%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.177 Acc 94.737%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.174 Acc 94.773%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.177 Acc 94.744%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.179 Acc 94.731%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.231 Acc 92.188%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.222 Acc 95.042%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.210 Acc 95.243%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.169 Acc 94.864%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.173 Acc 94.889%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.175 Acc 94.856%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.178 Acc 94.773%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.175 Acc 94.868%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.175 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.223 Acc 95.096%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.212 Acc 95.211%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.175 Acc 90.625%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.174 Acc 94.794%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.172 Acc 95.037%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.175 Acc 94.939%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.177 Acc 94.831%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.177 Acc 94.795%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.273 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.233 Acc 94.949%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.220 Acc 95.083%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.226 Acc 93.750%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.172 Acc 94.887%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.167 Acc 95.025%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.170 Acc 94.892%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.169 Acc 94.859%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.172 Acc 94.848%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.204 Acc 94.910%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.197 Acc 95.025%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.167 Acc 95.042%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.175 Acc 94.924%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.175 Acc 94.949%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.174 Acc 94.950%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.176 Acc 94.879%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.199 Acc 95.266%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.187 Acc 95.433%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.168 Acc 95.065%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.167 Acc 95.173%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.172 Acc 94.947%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.172 Acc 94.907%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.174 Acc 94.807%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.223 Acc 94.825%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.213 Acc 94.963%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.162 Acc 95.019%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.173 Acc 94.967%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.173 Acc 94.921%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.172 Acc 94.962%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.173 Acc 94.910%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.214 Acc 94.918%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.198 Acc 95.297%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.175 Acc 94.872%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.172 Acc 94.998%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.174 Acc 94.918%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.174 Acc 94.857%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.173 Acc 94.848%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.298 Acc 92.969%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.221 Acc 95.111%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.205 Acc 95.371%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.162 Acc 95.243%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.165 Acc 95.141%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.169 Acc 95.040%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.170 Acc 95.034%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.170 Acc 94.988%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.226 Acc 92.188%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.207 Acc 95.181%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.196 Acc 95.421%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.159 Acc 95.297%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.165 Acc 95.075%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.168 Acc 94.952%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.170 Acc 94.952%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.169 Acc 94.996%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.198 Acc 95.096%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.190 Acc 95.262%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.162 Acc 95.088%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.161 Acc 95.110%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.163 Acc 95.092%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.168 Acc 94.979%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.168 Acc 94.969%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.277 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.205 Acc 95.204%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.197 Acc 95.281%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.162 Acc 92.969%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.176 Acc 94.933%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.172 Acc 94.935%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.175 Acc 94.814%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.175 Acc 94.818%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.172 Acc 94.870%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.206 Acc 95.135%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.196 Acc 95.270%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.163 Acc 95.080%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.169 Acc 95.005%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.172 Acc 94.944%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.172 Acc 94.958%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.172 Acc 94.965%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.229 Acc 92.188%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.209 Acc 94.732%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.200 Acc 94.897%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.166 Acc 95.019%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.167 Acc 95.075%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.165 Acc 95.141%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.166 Acc 95.092%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.170 Acc 94.998%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.241 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.204 Acc 95.104%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.194 Acc 95.274%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.162 Acc 95.189%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.167 Acc 95.009%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.168 Acc 95.006%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.167 Acc 95.098%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.170 Acc 94.954%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.221 Acc 91.406%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.211 Acc 95.096%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.196 Acc 95.421%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.169 Acc 94.802%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.166 Acc 94.897%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.169 Acc 94.871%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.166 Acc 94.962%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.167 Acc 94.946%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.272 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.216 Acc 94.933%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.205 Acc 95.176%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.166 Acc 94.988%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.162 Acc 95.153%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.164 Acc 95.089%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.167 Acc 94.991%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.167 Acc 94.979%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.206 Acc 95.166%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.198 Acc 95.266%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.250 Acc 92.188%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.160 Acc 95.289%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.168 Acc 95.106%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.170 Acc 95.019%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.171 Acc 94.933%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.171 Acc 94.943%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.214 Acc 94.926%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.206 Acc 95.087%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.164 Acc 95.034%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.160 Acc 95.149%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.164 Acc 95.074%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.167 Acc 94.997%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.168 Acc 94.957%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.187 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.211 Acc 95.243%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.200 Acc 95.355%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.160 Acc 96.094%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.167 Acc 95.080%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.167 Acc 94.978%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.167 Acc 95.022%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.169 Acc 94.933%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.169 Acc 94.948%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.215 Acc 95.003%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.208 Acc 95.114%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.199 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.157 Acc 95.367%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.166 Acc 95.122%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.166 Acc 95.053%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.168 Acc 95.009%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.167 Acc 95.018%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.203 Acc 94.817%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.197 Acc 94.904%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.174 Acc 93.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.152 Acc 95.150%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.155 Acc 95.180%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.159 Acc 95.170%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.163 Acc 95.051%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.165 Acc 95.051%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.206 Acc 95.019%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.195 Acc 95.254%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.164 Acc 94.872%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.161 Acc 95.021%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.163 Acc 95.001%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.166 Acc 94.919%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.166 Acc 94.969%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.203 Acc 95.065%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.065%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.165 Acc 95.017%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.162 Acc 95.152%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.164 Acc 95.112%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.166 Acc 95.077%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.194 Acc 95.235%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.188 Acc 95.515%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.231 Acc 92.969%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.164 Acc 95.173%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.157 Acc 95.246%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.164 Acc 95.120%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.165 Acc 95.125%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.283 Acc 94.531%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.226 Acc 95.019%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.217 Acc 95.153%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.162 Acc 95.320%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.163 Acc 95.200%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.162 Acc 95.159%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.165 Acc 95.048%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.165 Acc 95.054%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.242 Acc 92.969%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.220 Acc 94.779%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.208 Acc 95.029%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.233 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.154 Acc 95.274%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.160 Acc 95.211%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.162 Acc 95.159%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.160 Acc 95.184%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.162 Acc 95.063%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.230 Acc 94.833%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.215 Acc 95.110%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.117 Acc 94.531%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.154 Acc 95.429%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.160 Acc 95.258%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.163 Acc 95.110%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.165 Acc 95.005%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.167 Acc 94.952%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.204 Acc 95.119%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.192 Acc 95.309%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.159 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.164 Acc 95.099%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.164 Acc 95.113%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.164 Acc 95.098%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.164 Acc 95.052%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.297 Acc 91.406%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.219 Acc 95.065%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.208 Acc 95.316%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.167 Acc 93.750%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.166 Acc 95.336%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.160 Acc 95.301%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.162 Acc 95.242%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.162 Acc 95.198%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.164 Acc 95.091%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.214 Acc 94.802%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.201 Acc 94.982%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.160 Acc 95.212%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.161 Acc 95.153%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.163 Acc 95.105%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.161 Acc 95.159%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.162 Acc 95.172%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.229 Acc 95.096%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.219 Acc 95.254%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.166 Acc 94.918%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.169 Acc 94.796%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.165 Acc 94.991%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.166 Acc 94.942%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.167 Acc 94.969%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.222 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.206 Acc 95.367%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.194 Acc 95.484%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.148 Acc 95.436%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.153 Acc 95.382%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.158 Acc 95.248%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.163 Acc 95.105%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.198 Acc 95.189%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.188 Acc 95.402%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.160 Acc 95.158%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.158 Acc 95.141%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.158 Acc 95.227%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.161 Acc 95.219%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.163 Acc 95.130%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.228 Acc 94.895%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.213 Acc 95.138%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.152 Acc 95.460%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.159 Acc 95.203%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.160 Acc 95.182%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.163 Acc 95.122%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.206 Acc 94.980%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.197 Acc 95.165%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.147 Acc 95.444%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.160 Acc 95.099%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.161 Acc 95.110%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.161 Acc 95.147%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.161 Acc 95.147%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.225 Acc 95.119%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.209 Acc 95.324%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.153 Acc 95.467%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.158 Acc 95.227%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.159 Acc 95.185%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.159 Acc 95.238%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.160 Acc 95.205%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.176 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.210 Acc 95.142%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.146 Acc 96.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.149 Acc 95.777%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.157 Acc 95.491%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.159 Acc 95.364%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.161 Acc 95.293%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.160 Acc 95.266%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.262 Acc 92.969%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.219 Acc 95.235%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.209 Acc 95.262%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.149 Acc 95.382%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.151 Acc 95.250%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.158 Acc 95.146%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.160 Acc 95.079%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.160 Acc 95.119%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.209 Acc 95.429%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.197 Acc 95.546%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.197 Acc 92.969%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.157 Acc 95.266%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.149 Acc 95.588%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.154 Acc 95.414%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.158 Acc 95.314%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.160 Acc 95.281%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.217 Acc 95.506%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.207 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.229 Acc 94.531%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.154 Acc 95.266%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.158 Acc 95.184%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.158 Acc 95.237%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.157 Acc 95.285%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.158 Acc 95.220%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.227 Acc 95.119%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.209 Acc 95.328%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.155 Acc 94.980%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.159 Acc 94.982%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.160 Acc 95.081%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.159 Acc 95.067%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.160 Acc 95.136%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.204 Acc 95.413%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.196 Acc 95.542%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.224 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.159 Acc 95.289%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.159 Acc 95.250%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.163 Acc 95.094%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.165 Acc 95.049%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.165 Acc 95.086%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.251 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.209 Acc 95.251%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.201 Acc 95.375%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.145 Acc 95.552%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.148 Acc 95.538%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.154 Acc 95.401%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.156 Acc 95.299%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.159 Acc 95.252%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.220 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.246 Acc 94.887%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.235 Acc 95.114%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.159 Acc 93.750%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.157 Acc 95.374%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.157 Acc 95.285%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.160 Acc 95.120%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.161 Acc 95.096%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.162 Acc 95.107%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.281 Acc 93.750%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.213 Acc 94.879%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.199 Acc 95.180%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.144 Acc 95.792%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.152 Acc 95.421%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.153 Acc 95.326%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.154 Acc 95.345%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.218 Acc 95.227%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.206 Acc 95.460%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.157 Acc 95.088%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.158 Acc 95.161%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.160 Acc 95.149%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.158 Acc 95.153%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.159 Acc 95.150%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.215 Acc 95.119%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.207 Acc 95.293%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.336 Acc 92.969%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.162 Acc 95.180%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.163 Acc 95.063%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.162 Acc 95.174%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.162 Acc 95.163%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.216 Acc 95.142%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.204 Acc 95.359%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.144 Acc 95.591%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.145 Acc 95.608%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.155 Acc 95.409%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.154 Acc 95.433%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.158 Acc 95.309%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.210 Acc 92.969%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.233 Acc 94.918%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.229 Acc 94.994%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.160 Acc 95.166%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.160 Acc 95.138%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.158 Acc 95.193%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.157 Acc 95.244%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.160 Acc 95.189%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.213 Acc 95.258%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.204 Acc 95.468%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.160 Acc 95.266%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.154 Acc 95.324%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.155 Acc 95.315%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.156 Acc 95.277%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.158 Acc 95.228%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.258 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.214 Acc 95.297%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.201 Acc 95.530%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.148 Acc 95.575%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.152 Acc 95.522%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.155 Acc 95.398%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.156 Acc 95.350%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.159 Acc 95.302%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.242 Acc 94.446%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.230 Acc 94.613%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.146 Acc 95.514%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.155 Acc 95.305%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.156 Acc 95.328%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.156 Acc 95.363%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.156 Acc 95.359%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.229 Acc 92.969%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.210 Acc 95.382%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.198 Acc 95.616%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.156 Acc 95.235%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.159 Acc 95.237%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.158 Acc 95.256%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.158 Acc 95.199%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.215 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.266 Acc 94.980%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.250 Acc 95.165%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.154 Acc 95.173%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.153 Acc 95.246%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.155 Acc 95.300%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.156 Acc 95.299%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.157 Acc 95.263%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.234 Acc 94.616%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.218 Acc 94.955%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.197 Acc 91.406%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.154 Acc 95.537%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.150 Acc 95.534%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.152 Acc 95.473%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.153 Acc 95.359%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.156 Acc 95.228%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.169 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.216 Acc 94.918%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.204 Acc 95.099%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.122 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.154 Acc 95.521%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.148 Acc 95.546%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.152 Acc 95.406%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.155 Acc 95.377%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.157 Acc 95.334%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.224 Acc 95.104%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.216 Acc 95.184%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.212 Acc 94.531%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.151 Acc 95.289%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.152 Acc 95.188%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.153 Acc 95.206%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.154 Acc 95.201%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.156 Acc 95.211%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.254 Acc 92.188%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.251 Acc 94.903%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.240 Acc 95.134%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.157 Acc 95.119%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.152 Acc 95.340%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.151 Acc 95.388%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.152 Acc 95.404%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.152 Acc 95.431%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.218 Acc 95.227%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.210 Acc 95.235%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.150 Acc 95.545%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.151 Acc 95.440%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.153 Acc 95.371%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.154 Acc 95.344%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.231 Acc 96.875%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.218 Acc 95.328%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.204 Acc 95.515%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.152 Acc 95.243%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.153 Acc 95.239%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.153 Acc 95.263%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.156 Acc 95.244%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.154 Acc 95.288%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.261 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.236 Acc 95.119%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.225 Acc 95.390%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.144 Acc 95.483%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.146 Acc 95.542%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.152 Acc 95.292%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.154 Acc 95.217%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.158 Acc 95.122%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.217 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.219 Acc 95.181%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.209 Acc 95.223%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.141 Acc 95.560%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.154 Acc 95.307%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.152 Acc 95.363%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.154 Acc 95.319%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.319 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.241 Acc 95.405%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.227 Acc 95.499%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.150 Acc 95.591%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.157 Acc 95.367%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.158 Acc 95.297%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.155 Acc 95.371%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.153 Acc 95.417%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.269 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.231 Acc 95.282%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.218 Acc 95.410%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.152 Acc 95.490%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.150 Acc 95.480%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.150 Acc 95.455%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.153 Acc 95.338%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.153 Acc 95.337%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.243 Acc 92.969%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.227 Acc 95.135%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.216 Acc 95.266%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.148 Acc 95.421%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.149 Acc 95.449%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.150 Acc 95.455%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.151 Acc 95.449%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.151 Acc 95.453%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.232 Acc 95.127%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.216 Acc 95.394%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.142 Acc 95.583%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.147 Acc 95.522%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.148 Acc 95.510%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.151 Acc 95.476%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.152 Acc 95.423%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.226 Acc 95.189%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.213 Acc 95.312%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.167 Acc 95.235%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.159 Acc 95.452%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.157 Acc 95.411%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.156 Acc 95.377%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.156 Acc 95.298%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.223 Acc 94.972%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.215 Acc 95.044%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.195 Acc 95.312%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.146 Acc 95.367%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.151 Acc 95.386%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.151 Acc 95.385%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.152 Acc 95.403%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.212 Acc 94.949%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.205 Acc 95.025%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.147 Acc 95.436%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.148 Acc 95.507%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.154 Acc 95.388%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.155 Acc 95.363%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.155 Acc 95.320%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.220 Acc 95.305%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.208 Acc 95.367%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.290 Acc 89.062%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.143 Acc 95.661%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.150 Acc 95.464%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.153 Acc 95.396%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.153 Acc 95.400%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.154 Acc 95.387%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.233 Acc 95.034%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.220 Acc 95.227%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.145 Acc 95.722%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.152 Acc 95.398%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.154 Acc 95.320%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.153 Acc 95.307%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.156 Acc 95.233%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.224 Acc 95.367%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.214 Acc 95.464%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.148 Acc 95.452%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.152 Acc 95.382%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.151 Acc 95.427%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.154 Acc 95.363%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.153 Acc 95.361%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.211 Acc 95.150%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.199 Acc 95.351%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.137 Acc 95.568%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.144 Acc 95.441%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.145 Acc 95.476%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.150 Acc 95.361%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.152 Acc 95.314%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.246 Acc 90.625%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.213 Acc 95.050%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.204 Acc 95.180%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.173 Acc 93.750%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.142 Acc 95.753%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.145 Acc 95.585%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.147 Acc 95.538%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.150 Acc 95.424%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.151 Acc 95.434%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.223 Acc 93.750%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.220 Acc 95.297%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.210 Acc 95.305%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.124 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.148 Acc 95.459%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.147 Acc 95.456%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.149 Acc 95.409%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.149 Acc 95.412%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.148 Acc 95.454%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.327 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.212 Acc 95.258%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.205 Acc 95.386%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.161 Acc 95.243%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.155 Acc 95.250%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.153 Acc 95.307%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.154 Acc 95.277%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.156 Acc 95.186%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.225 Acc 95.413%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.213 Acc 95.631%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.144 Acc 95.529%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.147 Acc 95.425%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.153 Acc 95.305%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.149 Acc 95.357%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.150 Acc 95.386%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.229 Acc 94.848%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.217 Acc 94.920%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.151 Acc 95.498%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.156 Acc 95.332%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.153 Acc 95.357%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.151 Acc 95.406%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.152 Acc 95.395%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.236 Acc 95.073%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.228 Acc 95.180%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.148 Acc 95.445%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.144 Acc 95.541%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.147 Acc 95.496%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.148 Acc 95.479%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.250 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.227 Acc 95.080%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.218 Acc 95.239%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.150 Acc 95.390%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.152 Acc 95.287%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.153 Acc 95.235%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.151 Acc 95.334%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.253 Acc 92.969%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.271 Acc 94.346%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.261 Acc 94.446%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.233 Acc 92.969%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.141 Acc 95.591%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.145 Acc 95.596%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.147 Acc 95.551%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.149 Acc 95.498%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.150 Acc 95.437%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.316 Acc 91.406%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.241 Acc 95.390%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.230 Acc 95.394%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.189 Acc 93.750%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.156 Acc 95.042%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.151 Acc 95.301%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.148 Acc 95.424%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.149 Acc 95.400%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.152 Acc 95.322%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.253 Acc 94.918%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.242 Acc 94.920%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.148 Acc 95.398%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.147 Acc 95.406%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.152 Acc 95.393%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.151 Acc 95.422%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.151 Acc 95.409%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.179 Acc 96.875%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.211 Acc 95.429%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.203 Acc 95.460%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.257 Acc 92.188%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.151 Acc 95.436%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.148 Acc 95.449%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.148 Acc 95.463%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.151 Acc 95.373%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.153 Acc 95.328%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.230 Acc 95.104%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.220 Acc 95.254%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.150 Acc 95.436%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.148 Acc 95.445%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.150 Acc 95.429%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.152 Acc 95.396%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.151 Acc 95.401%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.311 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.228 Acc 95.196%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.218 Acc 95.274%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.139 Acc 95.769%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.139 Acc 95.763%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.145 Acc 95.616%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.146 Acc 95.515%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.147 Acc 95.498%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.267 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.233 Acc 95.552%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.220 Acc 95.725%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.138 Acc 95.769%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.146 Acc 95.491%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.146 Acc 95.471%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.146 Acc 95.500%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.149 Acc 95.443%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.313 Acc 92.188%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.253 Acc 94.972%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.241 Acc 95.145%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.129 Acc 95.815%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.141 Acc 95.530%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.144 Acc 95.492%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.146 Acc 95.503%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.147 Acc 95.459%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.272 Acc 90.625%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.232 Acc 95.011%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.215 Acc 95.188%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.206 Acc 92.969%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.155 Acc 94.988%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.156 Acc 95.200%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.155 Acc 95.235%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.152 Acc 95.324%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.153 Acc 95.319%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.301 Acc 91.406%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.258 Acc 94.872%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.244 Acc 94.959%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.142 Acc 95.653%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.147 Acc 95.449%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.151 Acc 95.390%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.154 Acc 95.285%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.153 Acc 95.328%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.274 Acc 93.750%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.218 Acc 95.204%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.209 Acc 95.285%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.134 Acc 95.715%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.140 Acc 95.655%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.146 Acc 95.453%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.147 Acc 95.427%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.150 Acc 95.367%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.328 Acc 91.406%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.237 Acc 94.918%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.220 Acc 95.072%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.137 Acc 95.862%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.139 Acc 95.826%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.142 Acc 95.668%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.144 Acc 95.642%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.144 Acc 95.587%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.238 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.233 Acc 95.227%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.221 Acc 95.367%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.138 Acc 95.761%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.138 Acc 95.658%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.146 Acc 95.518%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.148 Acc 95.463%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.150 Acc 95.406%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.286 Acc 93.750%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.231 Acc 95.080%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.218 Acc 95.258%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.398 Acc 92.188%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.149 Acc 95.374%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.147 Acc 95.519%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.146 Acc 95.523%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.148 Acc 95.490%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.146 Acc 95.504%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.226 Acc 95.065%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.214 Acc 95.250%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.144 Acc 95.715%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.142 Acc 95.693%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.142 Acc 95.614%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.146 Acc 95.476%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.148 Acc 95.420%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.256 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.225 Acc 95.282%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.216 Acc 95.332%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.143 Acc 93.750%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.146 Acc 95.413%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.146 Acc 95.484%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.143 Acc 95.588%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.148 Acc 95.519%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.149 Acc 95.512%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.229 Acc 95.289%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.218 Acc 95.367%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.149 Acc 95.575%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.145 Acc 95.651%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.145 Acc 95.598%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.145 Acc 95.603%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.146 Acc 95.595%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.258 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.212 Acc 95.467%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.487%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.146 Acc 96.875%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.141 Acc 95.552%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.139 Acc 95.647%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.141 Acc 95.712%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.144 Acc 95.603%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.145 Acc 95.613%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.244 Acc 94.972%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.236 Acc 95.138%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.151 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.148 Acc 95.444%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.150 Acc 95.328%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.145 Acc 95.523%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.149 Acc 95.461%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.149 Acc 95.451%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.251 Acc 93.750%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.226 Acc 94.957%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.217 Acc 95.103%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.154 Acc 95.390%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.154 Acc 95.301%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.150 Acc 95.401%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.150 Acc 95.422%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.150 Acc 95.406%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.258 Acc 95.243%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.240 Acc 95.347%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.207 Acc 96.094%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.130 Acc 96.024%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.139 Acc 95.771%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.141 Acc 95.681%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.143 Acc 95.675%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.145 Acc 95.613%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.247 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.237 Acc 95.073%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.227 Acc 95.250%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.265 Acc 92.969%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.140 Acc 95.637%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.146 Acc 95.445%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.144 Acc 95.520%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.146 Acc 95.494%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.148 Acc 95.428%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.228 Acc 95.166%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.215 Acc 95.355%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.147 Acc 95.374%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.148 Acc 95.402%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.147 Acc 95.401%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.147 Acc 95.443%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.146 Acc 95.481%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.277 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.231 Acc 95.328%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.220 Acc 95.487%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.137 Acc 95.753%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.145 Acc 95.530%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.149 Acc 95.440%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.150 Acc 95.402%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.150 Acc 95.439%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.282 Acc 92.188%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.252 Acc 94.609%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.238 Acc 94.799%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.175 Acc 94.531%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.148 Acc 95.490%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.149 Acc 95.394%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.146 Acc 95.531%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.147 Acc 95.492%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.147 Acc 95.458%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.235 Acc 94.864%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.223 Acc 95.040%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.128 Acc 93.750%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.143 Acc 95.490%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.142 Acc 95.526%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.143 Acc 95.582%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.145 Acc 95.490%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.146 Acc 95.470%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.230 Acc 95.312%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.230 Acc 95.398%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.215 Acc 95.620%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.129 Acc 94.531%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.141 Acc 95.452%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.140 Acc 95.608%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.146 Acc 95.486%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.147 Acc 95.433%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.148 Acc 95.451%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.286 Acc 92.969%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.267 Acc 94.663%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.252 Acc 94.819%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.138 Acc 95.676%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.142 Acc 95.623%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.144 Acc 95.593%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.144 Acc 95.605%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.145 Acc 95.578%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.285 Acc 93.750%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.253 Acc 94.964%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.245 Acc 95.002%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.134 Acc 95.769%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.136 Acc 95.756%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.138 Acc 95.730%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.141 Acc 95.618%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.145 Acc 95.514%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.224 Acc 94.670%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.215 Acc 94.885%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.135 Acc 95.993%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.145 Acc 95.655%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.146 Acc 95.554%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.146 Acc 95.484%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.148 Acc 95.428%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.232 Acc 93.750%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.218 Acc 95.413%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.206 Acc 95.402%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.145 Acc 95.622%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.145 Acc 95.581%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.148 Acc 95.554%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.146 Acc 95.576%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.148 Acc 95.528%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.252 Acc 92.188%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.253 Acc 94.841%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.239 Acc 94.881%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.138 Acc 95.761%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.145 Acc 95.468%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.145 Acc 95.440%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.147 Acc 95.439%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.147 Acc 95.423%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.267 Acc 94.864%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.253 Acc 95.138%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.132 Acc 95.815%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.141 Acc 95.585%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.144 Acc 95.489%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.145 Acc 95.463%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.146 Acc 95.420%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.253 Acc 94.531%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.229 Acc 95.297%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.222 Acc 95.281%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.140 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.142 Acc 95.645%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.141 Acc 95.623%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.144 Acc 95.523%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.146 Acc 95.470%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.145 Acc 95.498%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.271 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.236 Acc 95.150%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.226 Acc 95.281%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.100 Acc 95.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.131 Acc 95.738%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.136 Acc 95.728%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.144 Acc 95.535%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.147 Acc 95.443%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.263 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.220 Acc 95.266%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.208 Acc 95.437%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.134 Acc 95.939%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.139 Acc 95.861%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.143 Acc 95.665%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.147 Acc 95.521%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.146 Acc 95.512%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.231 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.211 Acc 95.212%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.199 Acc 95.460%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.264 Acc 90.625%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.142 Acc 95.661%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.144 Acc 95.596%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.144 Acc 95.601%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.147 Acc 95.496%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.146 Acc 95.531%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.307 Acc 92.969%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.254 Acc 94.756%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.245 Acc 94.924%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.145 Acc 95.452%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.143 Acc 95.616%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.146 Acc 95.590%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.147 Acc 95.523%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.145 Acc 95.520%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.323 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.233 Acc 94.802%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.225 Acc 94.924%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.138 Acc 95.591%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.142 Acc 95.577%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.144 Acc 95.479%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.144 Acc 95.488%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.145 Acc 95.489%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.287 Acc 92.969%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.250 Acc 95.104%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.239 Acc 95.355%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.241 Acc 94.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.146 Acc 95.537%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.149 Acc 95.371%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.146 Acc 95.476%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.144 Acc 95.509%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.145 Acc 95.521%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.254 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.235 Acc 94.841%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.229 Acc 94.998%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.155 Acc 95.258%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.145 Acc 95.495%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.146 Acc 95.479%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.147 Acc 95.478%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.146 Acc 95.515%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.337 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.248 Acc 95.111%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.236 Acc 95.153%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.139 Acc 95.645%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.137 Acc 95.744%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.140 Acc 95.686%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.143 Acc 95.640%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.142 Acc 95.623%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.253 Acc 92.188%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.230 Acc 94.864%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.217 Acc 94.986%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.147 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.139 Acc 95.715%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.138 Acc 95.759%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.139 Acc 95.767%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.139 Acc 95.735%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.140 Acc 95.705%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.252 Acc 93.750%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.259 Acc 94.895%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.245 Acc 94.986%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.140 Acc 95.777%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.146 Acc 95.530%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.148 Acc 95.437%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.146 Acc 95.449%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.147 Acc 95.439%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.245 Acc 94.980%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.238 Acc 95.002%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.133 Acc 96.875%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.149 Acc 95.150%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.144 Acc 95.246%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.146 Acc 95.266%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.145 Acc 95.348%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.146 Acc 95.367%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.251 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.264 Acc 94.717%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.252 Acc 94.796%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.138 Acc 95.436%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.144 Acc 95.367%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.142 Acc 95.471%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.143 Acc 95.463%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.142 Acc 95.537%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.305 Acc 94.531%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.237 Acc 95.258%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.228 Acc 95.449%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.153 Acc 94.531%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.143 Acc 95.459%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.138 Acc 95.573%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.144 Acc 95.463%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.143 Acc 95.474%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.143 Acc 95.481%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.278 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.245 Acc 95.181%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.232 Acc 95.235%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.141 Acc 92.188%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.150 Acc 95.351%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.146 Acc 95.526%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.142 Acc 95.653%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.143 Acc 95.587%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.144 Acc 95.556%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.240 Acc 93.750%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.229 Acc 95.251%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.213 Acc 95.507%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.132 Acc 95.962%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.132 Acc 95.896%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.139 Acc 95.668%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.142 Acc 95.626%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.144 Acc 95.607%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.237 Acc 95.227%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.223 Acc 95.363%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.179 Acc 96.094%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.132 Acc 95.939%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.136 Acc 95.849%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.143 Acc 95.653%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.146 Acc 95.546%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.147 Acc 95.534%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.265 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.243 Acc 95.019%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.226 Acc 95.211%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.135 Acc 95.312%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.135 Acc 95.846%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.142 Acc 95.647%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.142 Acc 95.567%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.142 Acc 95.550%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.144 Acc 95.498%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.195 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.244 Acc 95.034%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.232 Acc 95.196%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.272 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.136 Acc 95.614%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.137 Acc 95.767%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.137 Acc 95.790%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.139 Acc 95.718%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.140 Acc 95.712%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.277 Acc 92.188%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.255 Acc 94.802%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.243 Acc 94.834%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.141 Acc 95.728%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.140 Acc 95.751%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.141 Acc 95.679%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.140 Acc 95.715%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.251 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.254 Acc 95.382%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.239 Acc 95.491%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd442e70148474499c761bba69a6c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.355 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.219 Acc 19.601%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.057 Acc 25.610%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.875 Acc 32.254%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.691 Acc 39.955%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.522 Acc 47.006%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.546 Acc 85.938%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.550 Acc 83.601%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.541 Acc 83.835%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.623 Acc 82.812%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.583 Acc 82.689%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.536 Acc 84.227%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.512 Acc 84.892%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.489 Acc 85.622%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.471 Acc 86.093%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.375 Acc 85.938%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.357 Acc 89.264%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.355 Acc 89.199%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.459 Acc 87.500%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.377 Acc 88.591%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.362 Acc 89.043%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.358 Acc 89.239%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.356 Acc 89.238%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.354 Acc 89.370%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.362 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.353 Acc 88.962%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.345 Acc 89.300%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.326 Acc 89.062%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.325 Acc 90.037%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.312 Acc 90.629%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.312 Acc 90.604%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.313 Acc 90.594%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.311 Acc 90.662%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.337 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.291 Acc 91.399%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.285 Acc 91.500%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.310 Acc 92.969%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.300 Acc 91.205%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.297 Acc 91.266%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.292 Acc 91.365%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.290 Acc 91.414%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.287 Acc 91.466%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.288 Acc 92.188%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.274 Acc 91.917%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.275 Acc 91.954%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.329 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.265 Acc 92.048%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.266 Acc 91.880%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.266 Acc 91.969%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.270 Acc 91.870%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.269 Acc 91.913%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.320 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.250 Acc 92.930%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.241 Acc 93.167%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.225 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.257 Acc 92.311%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.255 Acc 92.390%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.255 Acc 92.343%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.256 Acc 92.330%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.257 Acc 92.312%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.288 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.252 Acc 92.791%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.245 Acc 92.953%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.248 Acc 92.342%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.251 Acc 92.327%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.248 Acc 92.517%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.248 Acc 92.643%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.248 Acc 92.646%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.236 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.228 Acc 93.588%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.224 Acc 93.610%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.355 Acc 88.281%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.235 Acc 92.721%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.240 Acc 92.833%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.239 Acc 92.834%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.241 Acc 92.747%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.242 Acc 92.785%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.281 Acc 89.844%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.203 Acc 94.268%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.202 Acc 94.457%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.187 Acc 95.312%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.235 Acc 93.108%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.238 Acc 92.957%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.240 Acc 92.990%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.239 Acc 93.025%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.236 Acc 93.079%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.176 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.191 Acc 94.756%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.186 Acc 94.862%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.274 Acc 93.750%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.218 Acc 93.619%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.222 Acc 93.575%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.229 Acc 93.317%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.231 Acc 93.236%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.227 Acc 93.312%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.301 Acc 90.625%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.220 Acc 93.959%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.216 Acc 93.995%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.227 Acc 93.278%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.224 Acc 93.334%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.222 Acc 93.410%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.222 Acc 93.415%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.222 Acc 93.410%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.167 Acc 92.969%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.196 Acc 94.701%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.189 Acc 94.877%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.186 Acc 96.094%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.219 Acc 93.773%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.218 Acc 93.591%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.218 Acc 93.633%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.219 Acc 93.596%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.217 Acc 93.617%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.202 Acc 94.462%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.197 Acc 94.605%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.209 Acc 93.928%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.211 Acc 93.820%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.210 Acc 93.815%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.212 Acc 93.816%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.215 Acc 93.752%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.213 Acc 94.152%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.209 Acc 94.267%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.314 Acc 92.188%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.200 Acc 93.881%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.207 Acc 93.804%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.209 Acc 93.755%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.208 Acc 93.832%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.208 Acc 93.876%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.245 Acc 92.188%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.189 Acc 94.694%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.183 Acc 94.928%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.094 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.207 Acc 93.796%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.208 Acc 93.882%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.205 Acc 94.015%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.206 Acc 93.970%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.205 Acc 93.984%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.204 Acc 94.330%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.203 Acc 94.255%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.193 Acc 94.446%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.198 Acc 94.302%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.201 Acc 94.163%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.202 Acc 94.107%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.203 Acc 94.110%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.233 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.188 Acc 94.988%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.186 Acc 95.048%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.207 Acc 91.406%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.204 Acc 93.998%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.201 Acc 94.197%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.197 Acc 94.324%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.197 Acc 94.218%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.198 Acc 94.205%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.206 Acc 93.750%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.198 Acc 94.825%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.192 Acc 94.939%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.181 Acc 94.686%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.190 Acc 94.403%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.193 Acc 94.339%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.193 Acc 94.344%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.195 Acc 94.343%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.179 Acc 95.227%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.174 Acc 95.359%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.244 Acc 92.188%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.192 Acc 94.407%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.191 Acc 94.465%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.191 Acc 94.459%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.193 Acc 94.424%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.195 Acc 94.325%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.195 Acc 94.469%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.188 Acc 94.698%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.326 Acc 92.969%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.187 Acc 94.709%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.193 Acc 94.504%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.189 Acc 94.586%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.191 Acc 94.518%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.191 Acc 94.486%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.191 Acc 94.810%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.187 Acc 94.974%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.178 Acc 94.957%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.181 Acc 94.761%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.187 Acc 94.570%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.188 Acc 94.533%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.190 Acc 94.488%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.152 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.167 Acc 95.583%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.163 Acc 95.658%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.227 Acc 92.188%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.180 Acc 94.949%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.185 Acc 94.687%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.184 Acc 94.677%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.183 Acc 94.677%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.182 Acc 94.721%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.174 Acc 95.382%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.168 Acc 95.515%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.287 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.181 Acc 94.725%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.175 Acc 94.904%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.176 Acc 94.884%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.182 Acc 94.672%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.182 Acc 94.714%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.229 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.170 Acc 95.506%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.168 Acc 95.639%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.179 Acc 94.841%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.176 Acc 95.040%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.177 Acc 94.928%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.180 Acc 94.823%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.181 Acc 94.834%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.171 Acc 95.359%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.165 Acc 95.596%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.184 Acc 94.701%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.173 Acc 94.970%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.173 Acc 94.944%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.175 Acc 94.864%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.175 Acc 94.898%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.204 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.174 Acc 95.243%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.167 Acc 95.503%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.161 Acc 97.656%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.180 Acc 94.686%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.177 Acc 94.846%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.179 Acc 94.830%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.179 Acc 94.866%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.177 Acc 94.909%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.185 Acc 95.282%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.402%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.199 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.180 Acc 94.794%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.175 Acc 95.130%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.176 Acc 95.045%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.173 Acc 95.094%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.173 Acc 95.072%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.182 Acc 95.251%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.192 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.171 Acc 94.941%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.172 Acc 94.877%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.172 Acc 94.996%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.173 Acc 94.962%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.172 Acc 95.013%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.172 Acc 95.467%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.201 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.165 Acc 95.452%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.171 Acc 95.184%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.172 Acc 95.056%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.174 Acc 95.003%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.173 Acc 95.046%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.171 Acc 95.483%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.164 Acc 95.756%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.164 Acc 93.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.168 Acc 95.297%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.163 Acc 95.340%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.164 Acc 95.385%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.167 Acc 95.221%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.168 Acc 95.216%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.180 Acc 95.405%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.173 Acc 95.546%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.162 Acc 95.359%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.163 Acc 95.208%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.167 Acc 95.120%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.168 Acc 95.094%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.168 Acc 95.082%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.168 Acc 95.529%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.162 Acc 95.717%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.148 Acc 95.769%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.153 Acc 95.600%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.158 Acc 95.486%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.163 Acc 95.383%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.165 Acc 95.323%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.177 Acc 95.429%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.171 Acc 95.464%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.077 Acc 98.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.157 Acc 95.425%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.164 Acc 95.281%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.244%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.164 Acc 95.288%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.170 Acc 95.467%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.164 Acc 95.627%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.160 Acc 95.196%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.157 Acc 95.402%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.156 Acc 95.432%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.159 Acc 95.427%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.160 Acc 95.411%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.171 Acc 95.498%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.169 Acc 95.507%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.170 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.155 Acc 95.846%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.155 Acc 95.771%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.162 Acc 95.512%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.160 Acc 95.511%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.159 Acc 95.475%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.125 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.175 Acc 95.467%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.148 Acc 95.622%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.160 Acc 95.292%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.162 Acc 95.246%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.160 Acc 95.292%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.180 Acc 95.305%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.363%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.226 Acc 92.969%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.141 Acc 95.823%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.149 Acc 95.639%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.155 Acc 95.515%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.155 Acc 95.540%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.156 Acc 95.546%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.146 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.168 Acc 95.583%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.164 Acc 95.775%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.149 Acc 95.599%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.157 Acc 95.414%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.154 Acc 95.492%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.155 Acc 95.468%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.155 Acc 95.436%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.170 Acc 95.637%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.164 Acc 95.697%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.197 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.149 Acc 95.877%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.151 Acc 95.562%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.152 Acc 95.531%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.154 Acc 95.534%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.194 Acc 91.406%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.175 Acc 95.459%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.168 Acc 95.639%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.074 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.160 Acc 95.483%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.159 Acc 95.410%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.153 Acc 95.572%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.155 Acc 95.548%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.155 Acc 95.501%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.162 Acc 95.746%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.157 Acc 95.993%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.189 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.149 Acc 95.877%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.156 Acc 95.705%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.154 Acc 95.624%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.155 Acc 95.665%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.153 Acc 95.670%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.170 Acc 95.575%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.162 Acc 95.756%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.151 Acc 95.815%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.147 Acc 95.899%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.147 Acc 95.891%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.150 Acc 95.766%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.150 Acc 95.766%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.240 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.173 Acc 95.715%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.167 Acc 95.845%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.142 Acc 95.908%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.149 Acc 95.736%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.148 Acc 95.746%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.149 Acc 95.704%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.150 Acc 95.702%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.171 Acc 95.467%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.167 Acc 95.585%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.144 Acc 95.630%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.144 Acc 95.814%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.147 Acc 95.761%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.148 Acc 95.721%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.169 Acc 95.653%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.163 Acc 95.802%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.147 Acc 95.924%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.148 Acc 95.818%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.148 Acc 95.803%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.149 Acc 95.835%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.149 Acc 95.762%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.160 Acc 95.838%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.157 Acc 95.934%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.133 Acc 96.156%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.138 Acc 96.000%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.140 Acc 95.967%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.143 Acc 95.829%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.146 Acc 95.774%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.180 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.166 Acc 95.831%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.163 Acc 95.853%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.144 Acc 95.864%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.147 Acc 95.860%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.144 Acc 95.879%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.145 Acc 95.838%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.113 Acc 94.531%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.161 Acc 95.792%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.156 Acc 96.032%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.144 Acc 95.970%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.145 Acc 95.837%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.146 Acc 95.808%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.144 Acc 95.876%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.144 Acc 95.821%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.167 Acc 95.777%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.163 Acc 95.845%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.135 Acc 96.071%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.138 Acc 95.997%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.139 Acc 95.972%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.141 Acc 95.926%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.143 Acc 95.894%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.170 Acc 95.753%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.166 Acc 95.899%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.136 Acc 95.939%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.139 Acc 96.004%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.139 Acc 96.024%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.139 Acc 95.955%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.178 Acc 95.374%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.171 Acc 95.460%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.129 Acc 96.395%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.130 Acc 96.393%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.137 Acc 96.174%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.140 Acc 96.020%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.140 Acc 95.958%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.161 Acc 95.893%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.157 Acc 96.028%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.137 Acc 95.972%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.137 Acc 95.963%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.140 Acc 95.913%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.170 Acc 95.568%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.165 Acc 95.732%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.134 Acc 96.016%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.138 Acc 96.043%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.138 Acc 96.029%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.138 Acc 95.977%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.137 Acc 95.986%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.166 Acc 95.862%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.162 Acc 95.903%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.122 Acc 96.550%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.131 Acc 96.172%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.135 Acc 96.061%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.137 Acc 96.013%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.167 Acc 95.808%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.162 Acc 95.880%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.159 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.136 Acc 96.132%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.138 Acc 95.948%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.139 Acc 95.983%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.138 Acc 96.013%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.167 Acc 95.916%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.162 Acc 96.024%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.256 Acc 96.094%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.129 Acc 96.542%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.129 Acc 96.339%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.132 Acc 96.199%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.133 Acc 96.181%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.164 Acc 95.900%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.159 Acc 95.993%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.139 Acc 95.924%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.131 Acc 96.151%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.131 Acc 96.150%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.131 Acc 96.123%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.171 Acc 95.738%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.775%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.129 Acc 96.202%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.131 Acc 96.253%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.131 Acc 96.226%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.132 Acc 96.218%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.134 Acc 96.155%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.162 Acc 95.815%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.158 Acc 96.020%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.126 Acc 96.527%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.127 Acc 96.374%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.129 Acc 96.237%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.131 Acc 96.168%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.132 Acc 96.125%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.167 Acc 95.761%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.163 Acc 95.934%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.120 Acc 96.612%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.122 Acc 96.471%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.124 Acc 96.416%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.126 Acc 96.347%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.130 Acc 96.267%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.305%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.178 Acc 95.410%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.128 Acc 96.187%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.130 Acc 96.098%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.133 Acc 96.045%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.133 Acc 96.067%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.164 Acc 95.877%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.161 Acc 95.985%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.127 Acc 93.750%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.131 Acc 96.248%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.126 Acc 96.319%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.128 Acc 96.234%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.128 Acc 96.203%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.129 Acc 96.195%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.157 Acc 96.163%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.154 Acc 96.226%\n",
      "Saving..\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.115 Acc 96.782%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.121 Acc 96.657%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.123 Acc 96.574%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.126 Acc 96.480%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.127 Acc 96.409%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.174 Acc 95.676%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.168 Acc 95.802%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.110 Acc 98.438%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.122 Acc 96.519%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.123 Acc 96.502%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.124 Acc 96.356%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.127 Acc 96.291%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.127 Acc 96.296%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.134 Acc 97.656%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.172 Acc 95.831%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.168 Acc 95.931%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.112 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.126 Acc 96.295%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.126 Acc 96.311%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.124 Acc 96.379%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.125 Acc 96.374%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.286%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.104 Acc 96.875%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.162 Acc 96.001%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.161 Acc 96.067%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.125 Acc 96.381%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.128 Acc 96.356%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.127 Acc 96.285%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.128 Acc 96.254%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.178 Acc 95.599%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.172 Acc 95.682%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.115 Acc 96.682%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.115 Acc 96.653%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.119 Acc 96.543%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.123 Acc 96.407%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.124 Acc 96.376%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.168 Acc 95.738%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.164 Acc 95.919%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.109 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.122 Acc 96.411%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.124 Acc 96.471%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.125 Acc 96.343%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.126 Acc 96.308%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.126 Acc 96.334%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.137 Acc 94.531%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.178 Acc 95.753%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.752%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.120 Acc 96.357%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.119 Acc 96.389%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.119 Acc 96.418%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.122 Acc 96.355%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.125 Acc 96.307%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.172 Acc 95.746%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.166 Acc 95.880%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.103 Acc 94.531%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.133 Acc 96.009%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.124 Acc 96.346%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.123 Acc 96.394%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.126 Acc 96.326%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.172 Acc 95.748%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.114 Acc 96.697%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.114 Acc 96.685%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.116 Acc 96.626%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.117 Acc 96.542%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.118 Acc 96.510%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.134 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.176 Acc 95.552%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.171 Acc 95.721%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.115 Acc 96.581%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.118 Acc 96.486%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.121 Acc 96.384%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.123 Acc 96.382%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.122 Acc 96.399%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.173 Acc 95.738%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.167 Acc 95.837%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.108 Acc 96.867%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.110 Acc 96.782%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.113 Acc 96.701%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.116 Acc 96.668%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.119 Acc 96.579%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.172 Acc 95.955%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.166 Acc 96.004%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.100 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.114 Acc 96.716%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.117 Acc 96.649%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.118 Acc 96.604%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.120 Acc 96.526%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.171 Acc 95.761%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.169 Acc 95.810%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.114 Acc 96.813%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.115 Acc 96.743%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.118 Acc 96.621%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.118 Acc 96.614%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.119 Acc 96.530%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.086 Acc 97.656%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.167 Acc 95.838%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.162 Acc 95.997%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.212 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.115 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.114 Acc 96.618%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.116 Acc 96.584%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.117 Acc 96.544%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.118 Acc 96.540%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.156 Acc 96.248%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.153 Acc 96.343%\n",
      "Saving..\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.110 Acc 96.744%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.113 Acc 96.704%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.114 Acc 96.696%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.114 Acc 96.670%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.115 Acc 96.636%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.168 Acc 95.777%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.164 Acc 95.911%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.161 Acc 95.312%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.118 Acc 96.434%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.117 Acc 96.486%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.117 Acc 96.506%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.118 Acc 96.516%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.164 Acc 95.931%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.162 Acc 95.969%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.156 Acc 95.312%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.117 Acc 96.589%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.113 Acc 96.735%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.114 Acc 96.717%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.114 Acc 96.698%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.115 Acc 96.619%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.171 Acc 95.777%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.166 Acc 95.896%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.126 Acc 93.750%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.112 Acc 96.697%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.111 Acc 96.797%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.701%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.112 Acc 96.645%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.114 Acc 96.593%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.075 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.167 Acc 95.831%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.161 Acc 96.070%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.107 Acc 96.770%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.109 Acc 96.670%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.606%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.114 Acc 96.568%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.101 Acc 97.656%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.171 Acc 95.767%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.111 Acc 96.759%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.108 Acc 96.852%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.110 Acc 96.800%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.111 Acc 96.709%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.115 Acc 96.613%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.170 Acc 95.854%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.165 Acc 96.000%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.161 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.100 Acc 97.107%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.109 Acc 96.848%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.112 Acc 96.727%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.114 Acc 96.647%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.114 Acc 96.666%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.161 Acc 95.993%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.160 Acc 96.035%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.145 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.108 Acc 96.744%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.109 Acc 96.832%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.107 Acc 96.836%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.112 Acc 96.716%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.170 Acc 96.009%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.164 Acc 96.082%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.114 Acc 96.364%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.118 Acc 96.447%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.119 Acc 96.447%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.118 Acc 96.439%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.117 Acc 96.470%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.169 Acc 95.800%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.166 Acc 95.880%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.031 Acc 100.000%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.104 Acc 96.728%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.108 Acc 96.751%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.110 Acc 96.667%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.112 Acc 96.631%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.113 Acc 96.594%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.093 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.167 Acc 96.071%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.163 Acc 96.210%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.069 Acc 99.219%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.104 Acc 96.960%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.110 Acc 96.727%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.113 Acc 96.614%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.115 Acc 96.576%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.177 Acc 95.753%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.170 Acc 95.899%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.231 Acc 93.750%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.102 Acc 96.952%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.103 Acc 96.949%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.103 Acc 96.927%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.108 Acc 96.764%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.110 Acc 96.683%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.174 Acc 95.684%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.170 Acc 95.845%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.102 Acc 96.736%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.108 Acc 96.771%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.108 Acc 96.780%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.107 Acc 96.824%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.172 Acc 95.903%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.146 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.105 Acc 96.759%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.102 Acc 96.840%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.105 Acc 96.828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.107 Acc 96.768%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.108 Acc 96.718%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.172 Acc 95.815%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.166 Acc 95.969%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.104 Acc 96.689%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.105 Acc 96.786%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.105 Acc 96.787%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.107 Acc 96.799%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.108 Acc 96.750%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.178 Acc 95.429%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.095 Acc 97.146%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.106 Acc 96.863%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.107 Acc 96.805%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.091 Acc 96.875%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.169 Acc 95.831%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.165 Acc 96.059%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.155 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.098 Acc 97.045%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.100 Acc 96.961%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.106 Acc 96.820%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.107 Acc 96.811%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.175 Acc 95.924%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.168 Acc 95.969%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.075 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.100 Acc 97.045%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.099 Acc 97.100%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.101 Acc 97.039%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.103 Acc 97.021%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.106 Acc 96.905%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.171 Acc 95.985%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.167 Acc 96.020%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.099 Acc 97.061%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.102 Acc 97.042%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.104 Acc 97.015%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.102 Acc 96.996%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.103 Acc 96.990%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.086 Acc 97.656%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.173 Acc 95.831%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.167 Acc 96.020%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.104 Acc 96.976%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.102 Acc 97.054%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.103 Acc 97.018%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.103 Acc 96.984%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.105 Acc 96.887%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.170 Acc 95.919%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.102 Acc 96.860%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.103 Acc 96.856%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.104 Acc 96.839%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.104 Acc 96.857%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.105 Acc 96.852%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.171 Acc 96.001%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.166 Acc 96.113%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.105 Acc 96.929%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.102 Acc 96.968%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.103 Acc 96.889%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.104 Acc 96.847%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.181 Acc 95.846%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.179 Acc 95.771%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.106 Acc 96.960%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.103 Acc 96.941%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.107 Acc 96.810%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.104 Acc 96.894%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.104 Acc 96.902%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.107 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.175 Acc 95.838%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.172 Acc 95.919%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.100 Acc 97.192%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.104 Acc 96.941%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.104 Acc 96.883%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.102 Acc 96.928%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.173 Acc 95.916%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.169 Acc 96.047%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.098 Acc 97.099%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.099 Acc 97.072%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.101 Acc 97.035%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.102 Acc 97.009%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.166 Acc 96.063%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.161 Acc 96.148%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.143 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.098 Acc 97.061%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.098 Acc 97.030%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.099 Acc 97.005%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.100 Acc 96.972%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.101 Acc 96.956%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.869%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 95.942%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.100 Acc 97.076%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.101 Acc 97.085%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.099 Acc 97.127%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.102 Acc 97.021%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.103 Acc 96.955%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.071 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.173 Acc 95.761%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.171 Acc 95.779%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.093 Acc 97.192%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.097 Acc 97.089%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.099 Acc 96.949%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.100 Acc 96.939%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.099 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.183 Acc 95.784%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.178 Acc 95.829%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.136 Acc 94.531%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.097 Acc 96.906%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.098 Acc 96.937%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.098 Acc 97.044%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.098 Acc 97.043%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [105/200]Batch [500/573] Loss: 0.100 Acc 97.026%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 0.179 Acc 95.792%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.173 Acc 95.892%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.105 Acc 96.929%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.104 Acc 96.867%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.101 Acc 96.898%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.101 Acc 96.916%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.101 Acc 96.958%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.175 Acc 95.893%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.170 Acc 95.896%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.095 Acc 97.092%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.096 Acc 97.046%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.098 Acc 97.013%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.099 Acc 97.007%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.098 Acc 96.995%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.160 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.180 Acc 95.537%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.176 Acc 95.682%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.100 Acc 97.022%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.095 Acc 97.112%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.097 Acc 97.067%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.098 Acc 97.048%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.100 Acc 96.978%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.173 Acc 95.877%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.169 Acc 95.907%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.103 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.099 Acc 97.014%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.097 Acc 97.030%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.097 Acc 97.059%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.167 Acc 95.993%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.059 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.096 Acc 97.269%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.097 Acc 97.178%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.099 Acc 97.075%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.097 Acc 97.105%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.098 Acc 97.048%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.104 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.170 Acc 95.893%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.167 Acc 96.035%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.128 Acc 97.656%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.090 Acc 97.161%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.097 Acc 96.992%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.097 Acc 97.046%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.098 Acc 97.034%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.166 Acc 95.893%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.162 Acc 96.032%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.091 Acc 97.200%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.092 Acc 97.201%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.097 Acc 97.041%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.097 Acc 97.019%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.098 Acc 96.953%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 96.047%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.167 Acc 96.148%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.089 Acc 97.208%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.091 Acc 97.190%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.093 Acc 97.111%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.094 Acc 97.142%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.095 Acc 97.132%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.171 Acc 95.985%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.047 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.096 Acc 97.068%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.095 Acc 97.213%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.095 Acc 97.137%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.097 Acc 97.048%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.098 Acc 97.029%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.076 Acc 98.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.181 Acc 95.885%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.174 Acc 96.125%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.090 Acc 97.316%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.091 Acc 97.233%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.092 Acc 97.155%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.093 Acc 97.136%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.094 Acc 97.142%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.104 Acc 97.656%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 96.001%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.171 Acc 96.059%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.095 Acc 96.988%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.095 Acc 96.992%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.096 Acc 96.992%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.095 Acc 97.037%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.167 Acc 95.985%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.165 Acc 96.074%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.175 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.093 Acc 97.169%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.094 Acc 97.120%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.097 Acc 97.054%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.097 Acc 97.035%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.097 Acc 97.067%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.097 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.176 Acc 95.970%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 96.109%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.092 Acc 97.161%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.088 Acc 97.236%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.092 Acc 97.199%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.092 Acc 97.208%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.093 Acc 97.153%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.175 Acc 95.761%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.172 Acc 95.872%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.091 Acc 97.262%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.094 Acc 97.182%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.096 Acc 97.051%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.095 Acc 97.082%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.093 Acc 97.162%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.168 Acc 96.163%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.165 Acc 96.276%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.089 Acc 97.316%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.093 Acc 97.173%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.092 Acc 97.181%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.094 Acc 97.137%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.178 Acc 95.746%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.175 Acc 95.962%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.128 Acc 94.531%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.090 Acc 97.223%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.092 Acc 97.229%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.091 Acc 97.259%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.092 Acc 97.202%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.100 Acc 96.875%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.180 Acc 95.947%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.175 Acc 95.981%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.093 Acc 97.061%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.093 Acc 97.135%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.094 Acc 97.113%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.094 Acc 97.089%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.176 Acc 96.001%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.096 Acc 97.107%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.094 Acc 97.124%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.092 Acc 97.176%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.091 Acc 97.210%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.093 Acc 97.181%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.181 Acc 95.761%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.176 Acc 95.923%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.086 Acc 97.215%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.089 Acc 97.135%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.091 Acc 97.103%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.093 Acc 97.076%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.095 Acc 97.059%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.091 Acc 97.656%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.171 Acc 96.063%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 96.133%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.086 Acc 97.347%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.087 Acc 97.318%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.090 Acc 97.244%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.092 Acc 97.198%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.092 Acc 97.210%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.169 Acc 96.194%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.164 Acc 96.253%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.085 Acc 97.355%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.090 Acc 97.229%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.091 Acc 97.202%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.091 Acc 97.157%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.090 Acc 97.207%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.069 Acc 98.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.182 Acc 95.916%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.178 Acc 95.911%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.088 Acc 97.246%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.086 Acc 97.322%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.090 Acc 97.185%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.090 Acc 97.163%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.072 Acc 97.656%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.178 Acc 95.900%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.173 Acc 95.993%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.088 Acc 97.334%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.088 Acc 97.262%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.088 Acc 97.339%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.088 Acc 97.280%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.072 Acc 96.875%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.173 Acc 95.885%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.171 Acc 95.973%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.090 Acc 97.246%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.085 Acc 97.314%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.086 Acc 97.321%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.087 Acc 97.304%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.089 Acc 97.245%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.079 Acc 96.875%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.172 Acc 96.179%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.168 Acc 96.148%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.088 Acc 97.169%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.084 Acc 97.330%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.087 Acc 97.244%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.086 Acc 97.350%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.088 Acc 97.298%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.176 Acc 95.838%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.176 Acc 95.791%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.117 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.083 Acc 97.269%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.085 Acc 97.384%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.086 Acc 97.381%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.086 Acc 97.370%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.088 Acc 97.305%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.108 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.185 Acc 95.692%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.086 Acc 97.509%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.089 Acc 97.384%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.092 Acc 97.205%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.090 Acc 97.232%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.091 Acc 97.212%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.185 Acc 95.769%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.183 Acc 95.818%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.085 Acc 97.200%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.089 Acc 97.306%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.087 Acc 97.306%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.087 Acc 97.282%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.088 Acc 97.270%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.093 Acc 96.875%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.179 Acc 95.962%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.174 Acc 96.016%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.085 Acc 97.370%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.089 Acc 97.252%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.089 Acc 97.272%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.090 Acc 97.263%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.089 Acc 97.285%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.176 Acc 95.978%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.173 Acc 96.082%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.090 Acc 97.254%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.091 Acc 97.190%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.089 Acc 97.246%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.089 Acc 97.204%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.087 Acc 97.260%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.178 Acc 95.738%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.177 Acc 95.845%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.080 Acc 97.757%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.084 Acc 97.540%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.086 Acc 97.464%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.089 Acc 97.374%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.088 Acc 97.374%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.178 Acc 95.792%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.176 Acc 95.938%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.086 Acc 97.463%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.085 Acc 97.509%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.086 Acc 97.410%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.086 Acc 97.399%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.086 Acc 97.390%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.101 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.180 Acc 95.722%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.175 Acc 95.911%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.083 Acc 97.404%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.083 Acc 97.392%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.085 Acc 97.378%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.086 Acc 97.344%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.131 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.181 Acc 95.947%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.176 Acc 96.020%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.077 Acc 97.641%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.078 Acc 97.590%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.081 Acc 97.534%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.082 Acc 97.504%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.085 Acc 97.422%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.177 Acc 95.900%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.173 Acc 96.039%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.084 Acc 97.379%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.084 Acc 97.368%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.086 Acc 97.326%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.178 Acc 95.947%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.175 Acc 96.070%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.080 Acc 97.401%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.082 Acc 97.404%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.084 Acc 97.319%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.087 Acc 97.270%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.086 Acc 97.301%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.170 Acc 95.931%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.171 Acc 96.020%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.080 Acc 97.525%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.082 Acc 97.497%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.085 Acc 97.373%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.084 Acc 97.346%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.085 Acc 97.354%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.178 Acc 95.947%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.177 Acc 95.954%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.082 Acc 97.512%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.084 Acc 97.456%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.084 Acc 97.422%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.085 Acc 97.352%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.183 Acc 95.777%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.177 Acc 95.907%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.076 Acc 97.587%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.076 Acc 97.571%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.079 Acc 97.501%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.080 Acc 97.485%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.082 Acc 97.422%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.062 Acc 98.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.180 Acc 95.969%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.082 Acc 97.540%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.085 Acc 97.407%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.084 Acc 97.386%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.084 Acc 97.291%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.189 Acc 95.599%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.183 Acc 95.767%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.097 Acc 95.312%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.071 Acc 97.780%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.076 Acc 97.625%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.080 Acc 97.545%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.082 Acc 97.461%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.083 Acc 97.394%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.076 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.181 Acc 95.761%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.173 Acc 96.055%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.076 Acc 97.633%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.079 Acc 97.621%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.079 Acc 97.581%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.081 Acc 97.526%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.082 Acc 97.418%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.187 Acc 95.746%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.181 Acc 95.849%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.114 Acc 96.875%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.068 Acc 97.826%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.075 Acc 97.610%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.078 Acc 97.529%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.080 Acc 97.483%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.081 Acc 97.463%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.174 Acc 96.163%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.170 Acc 96.261%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.122 Acc 94.531%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.078 Acc 97.447%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.078 Acc 97.547%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.079 Acc 97.552%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.082 Acc 97.483%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.083 Acc 97.425%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.174 Acc 95.862%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.171 Acc 95.954%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.082 Acc 97.439%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.084 Acc 97.335%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.185 Acc 95.645%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.180 Acc 95.787%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.071 Acc 96.094%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.085 Acc 97.269%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.078 Acc 97.540%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.079 Acc 97.555%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.080 Acc 97.502%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.080 Acc 97.488%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.085 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.174 Acc 96.040%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.168 Acc 96.199%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.076 Acc 97.649%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.081 Acc 97.493%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.081 Acc 97.513%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.081 Acc 97.485%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.083 Acc 97.436%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.184 Acc 95.846%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.179 Acc 96.051%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.092 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.080 Acc 97.517%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.078 Acc 97.524%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.079 Acc 97.477%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.081 Acc 97.422%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.081 Acc 97.438%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.065 Acc 97.656%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.184 Acc 95.993%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.179 Acc 96.074%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.131 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.086 Acc 97.308%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.079 Acc 97.512%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.077 Acc 97.594%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.081 Acc 97.487%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.082 Acc 97.455%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.087 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.187 Acc 95.800%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.958%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.077 Acc 97.486%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.078 Acc 97.526%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.079 Acc 97.481%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.079 Acc 97.468%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.159 Acc 96.875%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.189 Acc 95.846%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.183 Acc 96.016%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.078 Acc 97.560%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.079 Acc 97.508%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.181 Acc 95.722%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.176 Acc 95.954%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.075 Acc 97.826%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.075 Acc 97.699%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.076 Acc 97.620%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.079 Acc 97.534%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.079 Acc 97.522%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.089 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.189 Acc 95.908%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.185 Acc 95.954%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.116 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.073 Acc 97.579%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.076 Acc 97.470%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.079 Acc 97.419%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.080 Acc 97.380%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.080 Acc 96.875%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.183 Acc 95.854%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.179 Acc 95.876%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.070 Acc 97.780%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.074 Acc 97.711%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.078 Acc 97.557%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.079 Acc 97.513%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.182 Acc 95.777%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.177 Acc 95.903%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.093 Acc 94.531%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.079 Acc 97.610%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.077 Acc 97.637%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.077 Acc 97.565%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.077 Acc 97.547%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.078 Acc 97.517%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.120 Acc 96.875%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.182 Acc 95.993%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.176 Acc 96.129%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.078 Acc 97.587%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.077 Acc 97.607%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.079 Acc 97.549%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.080 Acc 97.508%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.126 Acc 96.875%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.182 Acc 95.939%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.176 Acc 96.078%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.072 Acc 97.734%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.075 Acc 97.645%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.078 Acc 97.519%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.078 Acc 97.506%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.080 Acc 97.466%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.187 Acc 95.916%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.179 Acc 96.032%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.076 Acc 97.602%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.078 Acc 97.509%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.077 Acc 97.542%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.077 Acc 97.567%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.089 Acc 96.094%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.175 Acc 96.047%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.172 Acc 96.113%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.074 Acc 97.645%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.075 Acc 97.621%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.077 Acc 97.561%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.191 Acc 95.862%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.184 Acc 95.896%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.065 Acc 98.012%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.072 Acc 97.831%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.073 Acc 97.763%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.075 Acc 97.701%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.075 Acc 97.658%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.190 Acc 95.862%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.183 Acc 95.931%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.074 Acc 97.610%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.076 Acc 97.629%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.075 Acc 97.669%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.076 Acc 97.609%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.077 Acc 97.544%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.186 Acc 95.962%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.182 Acc 96.082%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.076 Acc 97.494%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.075 Acc 97.511%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.078 Acc 97.458%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.077 Acc 97.488%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.166 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.188 Acc 95.877%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.183 Acc 96.121%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.073 Acc 97.757%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.074 Acc 97.726%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.074 Acc 97.668%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.075 Acc 97.628%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.188 Acc 95.939%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.185 Acc 96.117%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.070 Acc 97.679%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.073 Acc 97.610%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.074 Acc 97.617%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.077 Acc 97.549%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.076 Acc 97.592%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.184 Acc 96.070%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.073 Acc 97.703%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.075 Acc 97.659%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.075 Acc 97.631%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.075 Acc 97.617%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.193 Acc 95.831%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.188 Acc 95.997%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.071 Acc 97.765%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.071 Acc 97.812%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.181 Acc 96.078%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.178 Acc 96.179%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.070 Acc 97.857%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.071 Acc 97.690%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.073 Acc 97.654%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.074 Acc 97.628%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.196 Acc 95.622%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.189 Acc 95.923%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.069 Acc 97.718%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.074 Acc 97.576%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.076 Acc 97.527%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.191 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.189 Acc 95.684%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.184 Acc 95.934%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.075 Acc 97.587%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.077 Acc 97.575%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.076 Acc 97.638%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.075 Acc 97.648%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.189 Acc 95.815%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.183 Acc 96.016%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.070 Acc 97.785%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.071 Acc 97.799%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.072 Acc 97.728%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.072 Acc 97.765%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.209 Acc 95.289%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.200 Acc 95.581%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.079 Acc 97.579%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.075 Acc 97.621%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.072 Acc 97.721%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.072 Acc 97.740%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.074 Acc 97.695%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.090 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.184 Acc 95.815%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.181 Acc 96.016%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.074 Acc 97.587%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.074 Acc 97.646%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.074 Acc 97.639%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.189 Acc 95.924%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.185 Acc 96.012%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.072 Acc 97.788%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.071 Acc 97.695%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.072 Acc 97.670%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.186 Acc 96.047%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.182 Acc 96.218%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.065 Acc 97.842%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.069 Acc 97.742%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.068 Acc 97.812%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.072 Acc 97.694%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.181 Acc 96.156%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.179 Acc 96.245%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.033 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.072 Acc 97.610%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.073 Acc 97.613%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.075 Acc 97.571%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.076 Acc 97.569%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.194 Acc 95.931%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.189 Acc 95.989%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [100/573] Loss: 0.065 Acc 98.028%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.069 Acc 97.897%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.068 Acc 97.879%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.069 Acc 97.865%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.071 Acc 97.781%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.086 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.180 Acc 96.016%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.177 Acc 96.144%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.067 Acc 97.865%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.068 Acc 97.843%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.070 Acc 97.807%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.071 Acc 97.769%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.072 Acc 97.756%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.101 Acc 96.875%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.184 Acc 96.047%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.181 Acc 96.140%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.076 Acc 97.618%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.071 Acc 97.711%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.071 Acc 97.713%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.073 Acc 97.673%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.190 Acc 95.908%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.185 Acc 96.098%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.073 Acc 97.757%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.070 Acc 97.804%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.070 Acc 97.773%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.071 Acc 97.721%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.072 Acc 97.691%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.184 Acc 95.862%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.181 Acc 96.024%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.070 Acc 97.742%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.071 Acc 97.659%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.072 Acc 97.682%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.072 Acc 97.641%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.195 Acc 95.599%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.193 Acc 95.623%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.084 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.073 Acc 97.587%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.071 Acc 97.685%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.070 Acc 97.719%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.808%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.915%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.065 Acc 97.981%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.068 Acc 97.882%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.067 Acc 97.918%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.069 Acc 97.814%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.070 Acc 97.787%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.199 Acc 95.653%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.193 Acc 95.763%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.095 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.070 Acc 97.734%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.069 Acc 97.854%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.070 Acc 97.781%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.070 Acc 97.777%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.071 Acc 97.742%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.188 Acc 95.831%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.187 Acc 95.927%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.100 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.067 Acc 97.912%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.067 Acc 97.799%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.070 Acc 97.721%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.071 Acc 97.703%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.194 Acc 95.846%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.190 Acc 95.927%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.070 Acc 97.618%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.071 Acc 97.641%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.070 Acc 97.667%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.072 Acc 97.705%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.206 Acc 95.537%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.197 Acc 95.752%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.068 Acc 97.788%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.069 Acc 97.773%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.071 Acc 97.700%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.072 Acc 97.711%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.072 Acc 97.680%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.188 Acc 95.946%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.071 Acc 97.857%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.072 Acc 97.683%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.073 Acc 97.628%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.073 Acc 97.617%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.073 Acc 97.619%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.194 Acc 95.931%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.189 Acc 96.016%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.039 Acc 97.656%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.067 Acc 97.896%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.067 Acc 97.778%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.069 Acc 97.748%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.202 Acc 95.854%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.194 Acc 95.927%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.068 Acc 97.765%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.066 Acc 97.851%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.066 Acc 97.859%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.066 Acc 97.863%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.068 Acc 97.789%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.210 Acc 95.661%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.204 Acc 95.779%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.065 Acc 97.919%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.067 Acc 97.816%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.070 Acc 97.723%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.194 Acc 96.117%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.190 Acc 96.117%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.066 Acc 97.888%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [200/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.068 Acc 97.719%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.069 Acc 97.719%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.069 Acc 97.739%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.194 Acc 95.831%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.189 Acc 95.981%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.066%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.066 Acc 97.812%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.069 Acc 97.734%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.070 Acc 97.747%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.193 Acc 95.862%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.191 Acc 95.899%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.064 Acc 98.012%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.066 Acc 97.936%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.068 Acc 97.830%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.069 Acc 97.740%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.070 Acc 97.736%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.193 Acc 95.823%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.190 Acc 95.864%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.061 Acc 97.966%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.064 Acc 97.851%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.065 Acc 97.807%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.067 Acc 97.763%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.070 Acc 97.722%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.134 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.195 Acc 95.808%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.191 Acc 95.837%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a834b66fe94d4a87e65b66a341bf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.322 Acc 10.156%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.241 Acc 18.951%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.241 Acc 18.983%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.239 Acc 18.958%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.239 Acc 18.953%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.237 Acc 19.176%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.057 Acc 27.344%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.027 Acc 27.235%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.028 Acc 27.282%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.171 Acc 20.312%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.858 Acc 34.878%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.637 Acc 43.653%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.484 Acc 49.359%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.381 Acc 53.335%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.296 Acc 56.501%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.860 Acc 75.781%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.828 Acc 73.507%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.825 Acc 73.465%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.846 Acc 73.438%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.813 Acc 74.103%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.764 Acc 75.952%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.734 Acc 76.993%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.705 Acc 77.991%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.679 Acc 78.825%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.438 Acc 85.938%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.445 Acc 86.549%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.435 Acc 86.738%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.401 Acc 87.500%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.530 Acc 83.385%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.513 Acc 83.889%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.509 Acc 84.191%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.500 Acc 84.451%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.495 Acc 84.649%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.426 Acc 87.500%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.400 Acc 88.382%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.386 Acc 88.522%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.394 Acc 87.500%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.445 Acc 86.394%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.443 Acc 86.350%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.433 Acc 86.732%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.431 Acc 86.752%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.428 Acc 86.792%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.353 Acc 89.844%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.346 Acc 90.022%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.336 Acc 90.186%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.352 Acc 88.281%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.391 Acc 88.041%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.395 Acc 87.885%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.398 Acc 87.876%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.400 Acc 87.839%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.394 Acc 88.035%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.335 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.324 Acc 90.470%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.313 Acc 90.718%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.377 Acc 88.281%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.379 Acc 88.622%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.372 Acc 88.588%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.367 Acc 88.754%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.367 Acc 88.772%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.369 Acc 88.777%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.351 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.293 Acc 91.445%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.282 Acc 91.752%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.423 Acc 87.500%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.360 Acc 89.086%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.353 Acc 89.296%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.348 Acc 89.423%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.346 Acc 89.487%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.346 Acc 89.496%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.321 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.283 Acc 91.909%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.274 Acc 92.016%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.336 Acc 89.844%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.323 Acc 89.975%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.332 Acc 90.011%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.330 Acc 90.114%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.331 Acc 90.101%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.330 Acc 90.118%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.278 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.274 Acc 92.474%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.261 Acc 92.743%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.300 Acc 89.844%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.337 Acc 89.882%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.323 Acc 90.108%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.318 Acc 90.282%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.317 Acc 90.376%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.314 Acc 90.450%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.250 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.291 Acc 91.770%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.278 Acc 92.071%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.690 Acc 84.375%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.309 Acc 90.756%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.310 Acc 90.738%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.305 Acc 90.851%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.309 Acc 90.732%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.309 Acc 90.736%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.273 Acc 92.311%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.261 Acc 92.568%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.492 Acc 87.500%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.305 Acc 90.787%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.307 Acc 90.854%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.307 Acc 90.804%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.303 Acc 90.894%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.298 Acc 91.068%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.241 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.246 Acc 93.417%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.235 Acc 93.404%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.210 Acc 93.750%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.282 Acc 91.422%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.289 Acc 91.262%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.289 Acc 91.313%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.286 Acc 91.439%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.287 Acc 91.425%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.250 Acc 93.023%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.239 Acc 93.264%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.279 Acc 88.281%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.287 Acc 91.476%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.283 Acc 91.639%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.283 Acc 91.632%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.282 Acc 91.658%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.281 Acc 91.682%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.252 Acc 93.054%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.243 Acc 93.179%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.248 Acc 90.625%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.274 Acc 91.491%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.268 Acc 92.001%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.272 Acc 91.967%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.272 Acc 91.907%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.271 Acc 91.844%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.230 Acc 93.704%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.224 Acc 93.762%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.274 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.252 Acc 92.304%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.258 Acc 92.176%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.261 Acc 92.120%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.265 Acc 92.086%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.267 Acc 92.060%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.231 Acc 92.188%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.240 Acc 93.502%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.232 Acc 93.622%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.169 Acc 95.312%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.257 Acc 92.466%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.260 Acc 92.257%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.262 Acc 92.289%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.262 Acc 92.263%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.262 Acc 92.237%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.243 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.238 Acc 93.425%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.231 Acc 93.626%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.402 Acc 87.500%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.265 Acc 92.350%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.259 Acc 92.281%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.258 Acc 92.278%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.254 Acc 92.396%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.257 Acc 92.311%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.221 Acc 92.969%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.231 Acc 93.827%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.224 Acc 93.867%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.315 Acc 90.625%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.262 Acc 92.296%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.258 Acc 92.417%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.257 Acc 92.538%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.254 Acc 92.511%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.254 Acc 92.492%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.177 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.220 Acc 94.261%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.213 Acc 94.298%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.215 Acc 92.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.245 Acc 92.737%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.242 Acc 92.903%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.245 Acc 92.823%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.244 Acc 92.854%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.245 Acc 92.861%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.220 Acc 94.291%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.213 Acc 94.399%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.237 Acc 92.984%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.240 Acc 92.922%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.241 Acc 92.891%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.241 Acc 92.910%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.243 Acc 92.900%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.206 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.201 Acc 94.817%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.194 Acc 94.908%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.286 Acc 89.844%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.238 Acc 93.038%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.236 Acc 92.949%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.238 Acc 92.961%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.241 Acc 92.920%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.240 Acc 92.947%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.216 Acc 93.750%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.217 Acc 94.137%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.208 Acc 94.244%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.324 Acc 89.062%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.226 Acc 93.286%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.233 Acc 93.167%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.234 Acc 93.080%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.236 Acc 93.060%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.237 Acc 93.111%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.237 Acc 92.188%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.210 Acc 94.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.204 Acc 94.562%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.335 Acc 89.062%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.235 Acc 93.015%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.230 Acc 93.128%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.227 Acc 93.249%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.227 Acc 93.228%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.229 Acc 93.204%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.215 Acc 94.361%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.207 Acc 94.380%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.366 Acc 89.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.228 Acc 93.502%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.226 Acc 93.501%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.230 Acc 93.348%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.231 Acc 93.343%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.230 Acc 93.352%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.213 Acc 94.438%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.205 Acc 94.586%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.226 Acc 92.188%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.222 Acc 93.526%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.219 Acc 93.587%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.221 Acc 93.480%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.225 Acc 93.405%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.225 Acc 93.380%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.243 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.213 Acc 94.083%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.203 Acc 94.314%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.301 Acc 95.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.217 Acc 93.642%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.220 Acc 93.439%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.220 Acc 93.558%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.220 Acc 93.522%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.222 Acc 93.500%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.202 Acc 94.941%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.193 Acc 95.009%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.212 Acc 94.531%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.202 Acc 94.137%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.217 Acc 93.672%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.219 Acc 93.631%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.219 Acc 93.592%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.219 Acc 93.631%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.202 Acc 94.794%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.196 Acc 94.877%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.232 Acc 93.487%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.219 Acc 93.781%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.219 Acc 93.807%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.218 Acc 93.773%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.217 Acc 93.759%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.202 Acc 94.732%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.193 Acc 94.842%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.222 Acc 93.441%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.215 Acc 93.680%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.214 Acc 93.690%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.215 Acc 93.707%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.218 Acc 93.649%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.200 Acc 94.756%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.192 Acc 94.831%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.200 Acc 94.307%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.204 Acc 94.131%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.211 Acc 93.981%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.209 Acc 93.966%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.212 Acc 93.895%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.201 Acc 94.709%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.192 Acc 94.850%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.162 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.210 Acc 93.765%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.205 Acc 94.080%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.209 Acc 93.926%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.210 Acc 93.902%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.210 Acc 93.903%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.196 Acc 94.787%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.189 Acc 94.842%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.199 Acc 92.188%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.198 Acc 94.222%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.197 Acc 94.282%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.201 Acc 94.157%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.202 Acc 94.099%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.203 Acc 94.060%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.187 Acc 95.196%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.180 Acc 95.254%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.238 Acc 92.969%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.204 Acc 94.090%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.207 Acc 93.960%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.204 Acc 94.113%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.205 Acc 94.097%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.206 Acc 94.065%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.185 Acc 95.382%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.178 Acc 95.371%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.198 Acc 94.183%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.204 Acc 93.999%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.202 Acc 94.090%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.201 Acc 94.190%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.202 Acc 94.190%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.194 Acc 95.005%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.100 Acc 98.438%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.195 Acc 94.500%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.196 Acc 94.395%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.197 Acc 94.324%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.201 Acc 94.202%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.200 Acc 94.247%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.210 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.191 Acc 95.057%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.185 Acc 95.095%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.205 Acc 93.982%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.199 Acc 94.174%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.198 Acc 94.228%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.198 Acc 94.229%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.200 Acc 94.219%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.191 Acc 95.073%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.182 Acc 95.138%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.219 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.198 Acc 94.454%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.196 Acc 94.442%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.192 Acc 94.472%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.192 Acc 94.453%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.193 Acc 94.397%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.192 Acc 95.096%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.183 Acc 95.192%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.186 Acc 94.686%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.193 Acc 94.516%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.192 Acc 94.568%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.193 Acc 94.500%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.196 Acc 94.414%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.176 Acc 95.312%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.191 Acc 95.065%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.182 Acc 95.270%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.173 Acc 94.763%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.184 Acc 94.609%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.185 Acc 94.568%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.192 Acc 94.445%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.198 Acc 94.825%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.191 Acc 94.994%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.276 Acc 94.531%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.189 Acc 94.748%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.192 Acc 94.539%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.191 Acc 94.560%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.194 Acc 94.467%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.193 Acc 94.466%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.198 Acc 94.856%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.191 Acc 94.935%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.187 Acc 94.926%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.184 Acc 94.710%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.190 Acc 94.535%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.189 Acc 94.586%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.221 Acc 92.188%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.184 Acc 95.382%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.178 Acc 95.476%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.281 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.182 Acc 94.624%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.185 Acc 94.601%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.188 Acc 94.557%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.188 Acc 94.568%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.188 Acc 94.580%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.270 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.199 Acc 94.980%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.191 Acc 95.075%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.142 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.185 Acc 94.570%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.190 Acc 94.481%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.187 Acc 94.591%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.186 Acc 94.635%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.188 Acc 94.623%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.187 Acc 95.413%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.178 Acc 95.480%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.285 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.171 Acc 94.995%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.168 Acc 94.924%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.174 Acc 94.780%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.180 Acc 94.726%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.185 Acc 94.622%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.188 Acc 95.204%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.246%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.315 Acc 92.188%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.179 Acc 94.732%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.177 Acc 94.799%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.179 Acc 94.835%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.181 Acc 94.777%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.180 Acc 94.785%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.182 Acc 95.421%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.499%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.272 Acc 95.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.176 Acc 95.019%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.179 Acc 94.850%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.186 Acc 94.700%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.187 Acc 94.761%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.183 Acc 94.818%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.174 Acc 95.777%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.165 Acc 95.899%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.226 Acc 94.531%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.158 Acc 95.189%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.175 Acc 94.974%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.183 Acc 94.804%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.179 Acc 94.931%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.179 Acc 94.895%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.175 Acc 95.668%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.168 Acc 95.721%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.131 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.162 Acc 95.235%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.176 Acc 94.842%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.175 Acc 94.967%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.175 Acc 95.009%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.177 Acc 94.915%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.181 Acc 95.459%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.174 Acc 95.456%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.182 Acc 94.895%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.182 Acc 94.796%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.180 Acc 94.770%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.178 Acc 94.796%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.179 Acc 94.793%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.250 Acc 92.969%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.189 Acc 95.606%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.181 Acc 95.759%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.176 Acc 95.003%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.176 Acc 94.897%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.177 Acc 94.915%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.179 Acc 94.876%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.179 Acc 94.863%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.184 Acc 95.498%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.179 Acc 95.561%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.282 Acc 93.750%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.171 Acc 94.903%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.174 Acc 94.908%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.175 Acc 94.874%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.176 Acc 94.880%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.175 Acc 94.887%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.177 Acc 95.661%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.171 Acc 95.709%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.166 Acc 95.359%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.169 Acc 95.208%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.167 Acc 95.201%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.170 Acc 95.116%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.173 Acc 95.013%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.175 Acc 95.606%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.167 Acc 95.686%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.161 Acc 95.359%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.165 Acc 95.274%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.169 Acc 95.146%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.171 Acc 95.125%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.172 Acc 95.158%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.223 Acc 92.969%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.529%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.171 Acc 95.585%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.169 Acc 95.166%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.170 Acc 95.134%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.173 Acc 95.123%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.171 Acc 95.153%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.171 Acc 95.068%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.187 Acc 95.367%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.180 Acc 95.472%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.171 Acc 94.988%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.171 Acc 95.048%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.169 Acc 95.133%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.167 Acc 95.170%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.169 Acc 95.138%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.184 Acc 95.552%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.176 Acc 95.608%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.177 Acc 95.080%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.174 Acc 95.099%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.172 Acc 94.991%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.170 Acc 95.046%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.170 Acc 95.043%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.170 Acc 95.845%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.158 Acc 92.188%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.158 Acc 95.351%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.156 Acc 95.526%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.161 Acc 95.325%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.167 Acc 95.219%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.180 Acc 95.351%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.174 Acc 95.452%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.275 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.157 Acc 95.560%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.164 Acc 95.270%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.166 Acc 95.216%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.165 Acc 95.233%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.165 Acc 95.231%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.168 Acc 95.854%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.163 Acc 95.927%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.158 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.166 Acc 95.305%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.165 Acc 95.324%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.164 Acc 95.279%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.164 Acc 95.211%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.166 Acc 95.186%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.160 Acc 93.750%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.171 Acc 95.699%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.162 Acc 95.829%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.162 Acc 95.343%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.156 Acc 95.472%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.159 Acc 95.359%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.162 Acc 95.332%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.162 Acc 95.362%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.823%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.170 Acc 95.969%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.155 Acc 95.606%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.159 Acc 95.449%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.161 Acc 95.419%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.161 Acc 95.422%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.162 Acc 95.339%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.173 Acc 95.730%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.166 Acc 95.829%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.197 Acc 93.750%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.160 Acc 95.243%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.157 Acc 95.292%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.162 Acc 95.260%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.162 Acc 95.259%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.180 Acc 95.297%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.174 Acc 95.487%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.130 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.155 Acc 95.630%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.159 Acc 95.417%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.159 Acc 95.432%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.161 Acc 95.365%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.161 Acc 95.384%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.390%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.176 Acc 95.511%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.132 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.158 Acc 95.483%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.155 Acc 95.495%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.159 Acc 95.549%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.161 Acc 95.451%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.162 Acc 95.389%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.179 Acc 95.614%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.172 Acc 95.600%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.151 Acc 95.552%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.159 Acc 95.442%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.158 Acc 95.470%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.160 Acc 95.403%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.413%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.178 Acc 95.511%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.158 Acc 95.637%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.156 Acc 95.620%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.157 Acc 95.562%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.157 Acc 95.533%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.158 Acc 95.509%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.190 Acc 95.173%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.182 Acc 95.367%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.162 Acc 95.212%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.156 Acc 95.414%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.158 Acc 95.367%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.157 Acc 95.361%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.158 Acc 95.367%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.167 Acc 95.678%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.185 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.163 Acc 95.328%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.156 Acc 95.390%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.155 Acc 95.393%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.154 Acc 95.425%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.155 Acc 95.420%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.193 Acc 95.166%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.184 Acc 95.347%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.146 Acc 95.730%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.147 Acc 95.701%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.154 Acc 95.577%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.155 Acc 95.574%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.156 Acc 95.545%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.182 Acc 95.893%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.173 Acc 95.977%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.154 Acc 95.583%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.152 Acc 95.678%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.152 Acc 95.595%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.154 Acc 95.558%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.154 Acc 95.528%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.176 Acc 95.800%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.169 Acc 95.814%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.081 Acc 96.094%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.149 Acc 95.591%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.148 Acc 95.674%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.152 Acc 95.502%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.153 Acc 95.443%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.154 Acc 95.476%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.167 Acc 93.750%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.186 Acc 95.421%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.180 Acc 95.476%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.149 Acc 95.684%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.150 Acc 95.715%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.152 Acc 95.632%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.153 Acc 95.604%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.176 Acc 95.599%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.146 Acc 95.676%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.153 Acc 95.620%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.148 Acc 95.646%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.150 Acc 95.624%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.131 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.177 Acc 95.792%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.239 Acc 95.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.155 Acc 95.514%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.150 Acc 95.577%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.148 Acc 95.658%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.150 Acc 95.640%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.150 Acc 95.635%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.184 Acc 95.575%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.178 Acc 95.655%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.252 Acc 91.406%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.151 Acc 95.606%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.154 Acc 95.522%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.151 Acc 95.598%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.147 Acc 95.685%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.152 Acc 95.564%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.182 Acc 95.529%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.546%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.153 Acc 95.490%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.154 Acc 95.604%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.148 Acc 95.689%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.150 Acc 95.613%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.149 Acc 95.637%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.186 Acc 95.800%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.177 Acc 95.833%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.141 Acc 96.009%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.138 Acc 96.037%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.143 Acc 95.907%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.147 Acc 95.768%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.182 Acc 95.363%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.147 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.145 Acc 95.908%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.146 Acc 95.748%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.148 Acc 95.671%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.151 Acc 95.583%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.149 Acc 95.652%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.091 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.174 Acc 96.001%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.169 Acc 96.039%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.150 Acc 93.750%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.135 Acc 96.194%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.142 Acc 95.981%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.144 Acc 95.850%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.146 Acc 95.772%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.148 Acc 95.674%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.138 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.176 Acc 95.931%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.169 Acc 96.051%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.160 Acc 96.875%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.130 Acc 96.364%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.136 Acc 96.191%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.141 Acc 96.070%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.144 Acc 95.965%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.143 Acc 95.935%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.151 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.173 Acc 95.838%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.166 Acc 95.954%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.142 Acc 96.047%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.145 Acc 95.880%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.149 Acc 95.759%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.149 Acc 95.747%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.148 Acc 95.751%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.185 Acc 95.730%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.179 Acc 95.748%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.147 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.137 Acc 95.962%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.145 Acc 95.744%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.143 Acc 95.798%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.145 Acc 95.745%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.145 Acc 95.777%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.183 Acc 95.722%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.176 Acc 95.779%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.069 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.149 Acc 95.931%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.143 Acc 95.989%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.142 Acc 95.925%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.143 Acc 95.918%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.144 Acc 95.836%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.175 Acc 95.722%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.168 Acc 95.884%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.148 Acc 95.560%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.147 Acc 95.740%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.143 Acc 95.800%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.144 Acc 95.803%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.144 Acc 95.826%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.098 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.174 Acc 95.877%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.170 Acc 95.849%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.143 Acc 95.900%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.141 Acc 96.032%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.144 Acc 95.933%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.144 Acc 95.895%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.143 Acc 95.886%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.174 Acc 96.055%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.167 Acc 96.125%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.127 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.151 Acc 95.661%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.145 Acc 95.821%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.142 Acc 95.907%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.142 Acc 95.910%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.173 Acc 95.746%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.166 Acc 95.872%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.130 Acc 96.140%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.140 Acc 95.888%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.141 Acc 95.819%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.141 Acc 95.831%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.140 Acc 95.868%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.118 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.166 Acc 95.862%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.160 Acc 95.989%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.131 Acc 96.303%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.133 Acc 96.137%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.134 Acc 96.073%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.138 Acc 95.979%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.139 Acc 95.938%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.174 Acc 95.722%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.168 Acc 95.903%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.213 Acc 92.969%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.133 Acc 96.109%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.140 Acc 95.861%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.139 Acc 95.863%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.140 Acc 95.934%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.139 Acc 95.978%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.176 Acc 95.900%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.168 Acc 96.008%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.127 Acc 96.248%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.135 Acc 96.078%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.140 Acc 95.905%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.138 Acc 95.930%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.209 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.184 Acc 95.738%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.148 Acc 95.312%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.130 Acc 96.055%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.133 Acc 95.954%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.138 Acc 95.894%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.136 Acc 96.022%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.137 Acc 95.989%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.179 Acc 95.692%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.171 Acc 95.876%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.131 Acc 96.202%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.132 Acc 96.070%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.137 Acc 95.964%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.140 Acc 95.862%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.140 Acc 95.880%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.645%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.176 Acc 95.896%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.141 Acc 95.846%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.136 Acc 95.967%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.139 Acc 95.936%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.137 Acc 95.974%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.180 Acc 95.684%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.174 Acc 95.806%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.189 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.141 Acc 95.823%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.134 Acc 96.008%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.138 Acc 95.948%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.134 Acc 96.039%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.135 Acc 96.014%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.174 Acc 95.893%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.167 Acc 96.004%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.132 Acc 95.955%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.132 Acc 96.086%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.131 Acc 96.153%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.131 Acc 96.172%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.133 Acc 96.117%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.169 Acc 95.927%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.128 Acc 96.411%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.130 Acc 96.304%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.130 Acc 96.198%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.132 Acc 96.146%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.133 Acc 96.080%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.124 Acc 94.531%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.176 Acc 95.653%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.170 Acc 95.752%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.195 Acc 96.094%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.126 Acc 96.179%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.135 Acc 96.016%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.135 Acc 95.933%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.135 Acc 95.930%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.134 Acc 96.010%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.186 Acc 95.722%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.177 Acc 95.802%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.282 Acc 91.406%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.122 Acc 96.233%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.126 Acc 96.265%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.130 Acc 96.198%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.131 Acc 96.133%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.132 Acc 96.122%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.178 Acc 95.707%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.173 Acc 95.752%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.139 Acc 96.148%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.132 Acc 96.169%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.132 Acc 96.176%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.134 Acc 96.131%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.123 Acc 93.750%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.174 Acc 95.896%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.185 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.123 Acc 96.496%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.126 Acc 96.343%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.131 Acc 96.195%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.132 Acc 96.127%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.133 Acc 96.108%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.166 Acc 95.993%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.161 Acc 96.020%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.121 Acc 96.279%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.128 Acc 96.308%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.130 Acc 96.190%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.133 Acc 96.084%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.133 Acc 96.027%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.129 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.169 Acc 95.815%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.162 Acc 95.923%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.139 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.118 Acc 96.658%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.121 Acc 96.416%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.125 Acc 96.320%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.126 Acc 96.310%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.130 Acc 96.229%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.180 Acc 96.016%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.172 Acc 96.028%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.125 Acc 96.272%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.122 Acc 96.397%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.126 Acc 96.221%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.127 Acc 96.168%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.128 Acc 96.151%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.169 Acc 95.938%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.130 Acc 96.295%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.126 Acc 96.401%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.129 Acc 96.296%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.128 Acc 96.335%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.128 Acc 96.311%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.183 Acc 95.916%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.178 Acc 95.965%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.173 Acc 96.094%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.122 Acc 96.403%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.127 Acc 96.265%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.126 Acc 96.340%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.127 Acc 96.281%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.128 Acc 96.233%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.179 Acc 95.692%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.177 Acc 95.569%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.124 Acc 96.194%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.126 Acc 96.234%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.127 Acc 96.244%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.130 Acc 96.207%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.129 Acc 96.223%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.637%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.174 Acc 95.798%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.141 Acc 95.908%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.132 Acc 96.140%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.128 Acc 96.236%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.129 Acc 96.187%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.204 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.192 Acc 95.707%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.184 Acc 95.771%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.199 Acc 90.625%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.126 Acc 96.225%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.123 Acc 96.234%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.126 Acc 96.166%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.128 Acc 96.150%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.129 Acc 96.123%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.082 Acc 96.094%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.183 Acc 95.939%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.177 Acc 96.043%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.130 Acc 96.442%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.130 Acc 96.174%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.129 Acc 96.239%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.189 Acc 95.854%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.181 Acc 95.872%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.130 Acc 95.970%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.127 Acc 96.133%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.129 Acc 96.200%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.129 Acc 96.230%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.129 Acc 96.254%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.171 Acc 96.032%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.162 Acc 96.121%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.109 Acc 94.531%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.124 Acc 96.401%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.126 Acc 96.301%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.124 Acc 96.386%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.126 Acc 96.339%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.161 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.189 Acc 95.429%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.185 Acc 95.577%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.182 Acc 92.188%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.130 Acc 96.241%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.128 Acc 96.182%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.125 Acc 96.216%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.126 Acc 96.209%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.181 Acc 95.614%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.173 Acc 95.732%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.126 Acc 95.312%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.113 Acc 96.682%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.121 Acc 96.416%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.122 Acc 96.400%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.125 Acc 96.265%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.124 Acc 96.257%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.169 Acc 95.939%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.163 Acc 96.070%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.120 Acc 96.426%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.122 Acc 96.374%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.121 Acc 96.418%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.124 Acc 96.320%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.185 Acc 95.962%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.177 Acc 96.090%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.111 Acc 96.736%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.115 Acc 96.580%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.120 Acc 96.447%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.123 Acc 96.339%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.124 Acc 96.304%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.174 Acc 95.815%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.165 Acc 95.962%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.118 Acc 96.450%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.119 Acc 96.482%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.120 Acc 96.442%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.122 Acc 96.409%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.123 Acc 96.345%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.146 Acc 93.750%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.182 Acc 95.537%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.175 Acc 95.779%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.166 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.112 Acc 96.666%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.115 Acc 96.482%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.120 Acc 96.371%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.123 Acc 96.261%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.126 Acc 96.237%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.164 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.178 Acc 95.645%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.171 Acc 95.783%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.121 Acc 96.419%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.115 Acc 96.545%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.119 Acc 96.480%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.121 Acc 96.431%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.124 Acc 96.378%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.113 Acc 96.094%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.187 Acc 95.630%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.179 Acc 95.759%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.119 Acc 96.527%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.118 Acc 96.521%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.119 Acc 96.517%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.119 Acc 96.465%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.199 Acc 95.893%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.193 Acc 95.872%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.121 Acc 96.444%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.120 Acc 96.429%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.120 Acc 96.415%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.121 Acc 96.395%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.174 Acc 95.978%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.165 Acc 96.067%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.116 Acc 96.581%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.115 Acc 96.607%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.118 Acc 96.553%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.119 Acc 96.474%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.121 Acc 96.384%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.176 Acc 95.869%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.170 Acc 96.028%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.112 Acc 96.666%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.112 Acc 96.564%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.116 Acc 96.483%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.116 Acc 96.437%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.117 Acc 96.490%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.100 Acc 96.094%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.182 Acc 95.985%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.174 Acc 96.012%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.149 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.120 Acc 96.372%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.121 Acc 96.354%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.119 Acc 96.405%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.120 Acc 96.402%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.120 Acc 96.432%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.177 Acc 95.893%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.171 Acc 95.997%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.089 Acc 95.312%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.112 Acc 96.612%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.119 Acc 96.444%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.117 Acc 96.457%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.120 Acc 96.474%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.119 Acc 96.480%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.184 Acc 95.645%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.178 Acc 95.759%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.113 Acc 96.697%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.114 Acc 96.665%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.117 Acc 96.548%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.117 Acc 96.557%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.119 Acc 96.468%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.193 Acc 95.730%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.186 Acc 95.752%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.111 Acc 96.689%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.116 Acc 96.556%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.121 Acc 96.392%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.122 Acc 96.392%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.120 Acc 96.424%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.204 Acc 95.769%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.194 Acc 95.826%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.143 Acc 95.312%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.120 Acc 96.581%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.117 Acc 96.556%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.115 Acc 96.561%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.116 Acc 96.491%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.119 Acc 96.449%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.201 Acc 95.552%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.194 Acc 95.542%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.275 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.119 Acc 96.496%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.118 Acc 96.490%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.118 Acc 96.480%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.119 Acc 96.437%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.118 Acc 96.462%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.201 Acc 95.591%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.194 Acc 95.623%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.204 Acc 92.188%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.110 Acc 96.689%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.115 Acc 96.556%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.114 Acc 96.584%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.116 Acc 96.532%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.116 Acc 96.552%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.208 Acc 95.320%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.200 Acc 95.379%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.116 Acc 96.666%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.119 Acc 96.576%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.118 Acc 96.535%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.118 Acc 96.509%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.118 Acc 96.515%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.192 Acc 95.699%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.184 Acc 95.787%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.116 Acc 96.395%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.116 Acc 96.424%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.117 Acc 96.423%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.116 Acc 96.513%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.116 Acc 96.457%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.193 Acc 95.715%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.183 Acc 95.822%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.109 Acc 96.566%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.112 Acc 96.587%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.112 Acc 96.564%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.114 Acc 96.503%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.113 Acc 96.538%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.186 Acc 95.924%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.175 Acc 96.078%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.218 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.107 Acc 96.682%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.110 Acc 96.696%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.114 Acc 96.626%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.113 Acc 96.641%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.114 Acc 96.608%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.205 Acc 95.483%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.195 Acc 95.507%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.138 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.110 Acc 96.708%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.111 Acc 96.636%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.111 Acc 96.626%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.114 Acc 96.583%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.182 Acc 95.916%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.176 Acc 95.938%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.103 Acc 96.790%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.110 Acc 96.622%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.111 Acc 96.605%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.114 Acc 96.577%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.100 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.166 Acc 95.939%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.160 Acc 96.016%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.108 Acc 96.758%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.113 Acc 96.613%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.114 Acc 96.602%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.149 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.170 Acc 96.067%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.190 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.107 Acc 96.968%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.108 Acc 96.786%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.111 Acc 96.732%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.112 Acc 96.684%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.115 Acc 96.610%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.193 Acc 95.862%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.187 Acc 95.938%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.114 Acc 96.682%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.108 Acc 96.821%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.108 Acc 96.789%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.109 Acc 96.795%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.110 Acc 96.725%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.176 Acc 95.831%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.168 Acc 95.950%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.115 Acc 96.689%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.115 Acc 96.533%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.115 Acc 96.577%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.113 Acc 96.637%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.113 Acc 96.611%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.178 Acc 95.893%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.170 Acc 95.969%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.110 Acc 96.697%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.113 Acc 96.603%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.111 Acc 96.709%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.113 Acc 96.620%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.111 Acc 96.663%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.188 Acc 95.452%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.182 Acc 95.608%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.106 Acc 96.744%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.110 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.109 Acc 96.753%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.111 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.111 Acc 96.719%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.199 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.185 Acc 95.908%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.177 Acc 95.923%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.107 Acc 96.914%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.112 Acc 96.743%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.111 Acc 96.766%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.111 Acc 96.737%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.113 Acc 96.685%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.188 Acc 95.614%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.180 Acc 95.791%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.101 Acc 96.805%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.100 Acc 96.937%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.107 Acc 96.758%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.111 Acc 96.581%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.112 Acc 96.557%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.148 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.193 Acc 95.823%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.185 Acc 95.931%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.108 Acc 96.782%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.107 Acc 96.776%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.110 Acc 96.743%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.111 Acc 96.685%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.196 Acc 95.521%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.190 Acc 95.519%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.085 Acc 99.219%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.105 Acc 96.890%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.105 Acc 96.898%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.108 Acc 96.833%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.107 Acc 96.799%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.110 Acc 96.753%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.191 Acc 95.630%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.184 Acc 95.705%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.107 Acc 96.736%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.107 Acc 96.688%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.109 Acc 96.631%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.110 Acc 96.624%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.109 Acc 96.605%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.124 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.188 Acc 95.701%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.108 Acc 96.798%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.104 Acc 96.848%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.105 Acc 96.810%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.104 Acc 96.830%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.106 Acc 96.794%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.179 Acc 95.911%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.105 Acc 96.906%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.104 Acc 96.840%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.106 Acc 96.823%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.105 Acc 96.811%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.107 Acc 96.750%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.199 Acc 95.769%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.189 Acc 95.853%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.095 Acc 97.130%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.102 Acc 96.968%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.104 Acc 96.909%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.109 Acc 96.809%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.107 Acc 96.847%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.168 Acc 92.969%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.194 Acc 95.808%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.185 Acc 95.864%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.102 Acc 96.774%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.108 Acc 96.801%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.108 Acc 96.813%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.107 Acc 96.820%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.108 Acc 96.813%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.193 Acc 95.506%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.183 Acc 95.763%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.130 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.104 Acc 96.860%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.104 Acc 96.805%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.107 Acc 96.761%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.108 Acc 96.744%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.108 Acc 96.744%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.150 Acc 96.094%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.205 Acc 95.746%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.194 Acc 95.841%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.125 Acc 95.312%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.108 Acc 96.968%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.104 Acc 96.904%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.103 Acc 96.879%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.105 Acc 96.822%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.133 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.195 Acc 95.429%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.187 Acc 95.573%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.130 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.101 Acc 97.161%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.104 Acc 96.910%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.106 Acc 96.808%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.107 Acc 96.809%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.109 Acc 96.736%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.187 Acc 95.877%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.179 Acc 95.993%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.126 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.101 Acc 97.030%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.103 Acc 96.988%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.104 Acc 96.958%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.106 Acc 96.856%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.105 Acc 96.853%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.192 Acc 95.746%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.182 Acc 95.919%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.101 Acc 96.697%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.104 Acc 96.731%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.104 Acc 96.763%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.105 Acc 96.797%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.104 Acc 96.827%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 96.001%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.181 Acc 96.016%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.174 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.097 Acc 97.084%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.100 Acc 96.909%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.101 Acc 96.815%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.102 Acc 96.791%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.147 Acc 96.094%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.181 Acc 95.924%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.172 Acc 96.051%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.146 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.100 Acc 97.014%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.102 Acc 96.867%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.104 Acc 96.780%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.105 Acc 96.761%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.191 Acc 95.730%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.104 Acc 97.022%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.102 Acc 96.984%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.102 Acc 97.013%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.101 Acc 96.994%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.101 Acc 97.034%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.116 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.191 Acc 95.800%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.184 Acc 95.853%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.080 Acc 96.094%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.102 Acc 96.759%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.103 Acc 96.786%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.103 Acc 96.813%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.105 Acc 96.793%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.104 Acc 96.836%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.196 Acc 95.746%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.187 Acc 95.841%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.161 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.096 Acc 96.968%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.097 Acc 96.941%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.101 Acc 96.857%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.101 Acc 96.854%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.102 Acc 96.831%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.191 Acc 95.978%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.183 Acc 96.051%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.092 Acc 97.300%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.101 Acc 96.922%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.103 Acc 96.865%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.104 Acc 96.833%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.200 Acc 95.568%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.192 Acc 95.565%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.093 Acc 97.656%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.100 Acc 96.898%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.100 Acc 96.898%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.104 Acc 96.842%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.104 Acc 96.803%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.196 Acc 95.568%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.094 Acc 97.053%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.100 Acc 96.859%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.100 Acc 96.896%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.099 Acc 96.883%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.101 Acc 96.842%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.178 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.196 Acc 95.777%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.190 Acc 95.697%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.101 Acc 96.890%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.099 Acc 96.852%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.101 Acc 96.857%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.101 Acc 96.865%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.103 Acc 96.838%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.190 Acc 96.024%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.183 Acc 96.004%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.101 Acc 96.999%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.102 Acc 96.999%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.102 Acc 96.958%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.102 Acc 96.959%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.101 Acc 96.959%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.196 Acc 95.591%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.187 Acc 95.802%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.100 Acc 96.960%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.100 Acc 96.945%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.099 Acc 96.971%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.103 Acc 96.845%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.199 Acc 95.738%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.191 Acc 95.818%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.091 Acc 97.254%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.096 Acc 97.065%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.098 Acc 97.018%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.098 Acc 97.023%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.099 Acc 96.975%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.190 Acc 95.900%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.181 Acc 95.946%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.098 Acc 97.053%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.101 Acc 96.984%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.102 Acc 96.880%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.101 Acc 96.891%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.102 Acc 96.856%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.197 Acc 95.722%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.189 Acc 95.759%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.100 Acc 96.999%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.104 Acc 96.898%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.103 Acc 96.870%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.102 Acc 96.883%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.102 Acc 96.889%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.097 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.194 Acc 95.622%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.185 Acc 95.791%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.036 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.094 Acc 96.976%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.097 Acc 96.929%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.101 Acc 96.898%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.099 Acc 96.982%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.100 Acc 96.922%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.207 Acc 95.506%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.202 Acc 95.573%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.096 Acc 97.107%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.095 Acc 97.143%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.099 Acc 96.958%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.098 Acc 97.025%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.099 Acc 96.979%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.199 Acc 95.653%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.193 Acc 95.767%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.099 Acc 96.887%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.096 Acc 96.948%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.098 Acc 96.931%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.098 Acc 96.947%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.186 Acc 95.880%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.102 Acc 96.844%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.099 Acc 96.859%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.102 Acc 96.865%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.100 Acc 96.930%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.205 Acc 95.560%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.198 Acc 95.542%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.090 Acc 97.215%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.096 Acc 97.114%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.094 Acc 97.105%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.097 Acc 97.026%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.110 Acc 96.875%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.194 Acc 95.746%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.112 Acc 93.750%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.088 Acc 97.254%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.091 Acc 97.201%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.096 Acc 97.096%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.098 Acc 96.981%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.144 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.191 Acc 95.838%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.182 Acc 95.973%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.099 Acc 96.968%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.100 Acc 96.863%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.098 Acc 96.927%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.097 Acc 96.949%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.099 Acc 96.908%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.193 Acc 95.777%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.186 Acc 95.849%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.092 Acc 97.246%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.095 Acc 97.087%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.097 Acc 97.012%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.199 Acc 95.637%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.193 Acc 95.787%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.035 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.090 Acc 97.293%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.094 Acc 97.108%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.096 Acc 97.033%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.097 Acc 96.984%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.184 Acc 95.722%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.179 Acc 95.814%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.101 Acc 96.736%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.097 Acc 96.972%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.096 Acc 96.997%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.096 Acc 97.000%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.096 Acc 97.017%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.132 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.184 Acc 95.869%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.180 Acc 95.950%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.094 Acc 97.231%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.094 Acc 97.097%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.094 Acc 97.155%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.094 Acc 97.091%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.096 Acc 97.020%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.189 Acc 95.792%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.182 Acc 95.868%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.093 Acc 97.277%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.095 Acc 97.062%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.094 Acc 97.098%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.095 Acc 97.095%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.096 Acc 97.071%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.273 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.200 Acc 95.722%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.193 Acc 95.713%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.091 Acc 97.151%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.093 Acc 97.116%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.093 Acc 97.146%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.096 Acc 97.070%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.196 Acc 95.924%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.188 Acc 95.997%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.094 Acc 97.177%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.097 Acc 97.046%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.097 Acc 96.932%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.097 Acc 96.988%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.097 Acc 96.975%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.212 Acc 93.750%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.186 Acc 95.815%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.179 Acc 95.942%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.085 Acc 97.463%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.092 Acc 97.225%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.093 Acc 97.148%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.094 Acc 97.136%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.095 Acc 97.078%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.191 Acc 96.001%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.184 Acc 95.969%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.137 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.086 Acc 97.262%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.091 Acc 97.248%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.091 Acc 97.171%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.093 Acc 97.120%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.094 Acc 97.106%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.183 Acc 95.947%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.179 Acc 95.954%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.091 Acc 97.100%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.091 Acc 97.064%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.094 Acc 97.031%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.093 Acc 97.086%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.209 Acc 95.568%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.200 Acc 95.705%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.092 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.088 Acc 97.192%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.097 Acc 96.989%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.096 Acc 96.986%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.096 Acc 97.036%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.207 Acc 95.398%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.200 Acc 95.565%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.090 Acc 97.061%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.096 Acc 96.898%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.095 Acc 96.981%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.095 Acc 97.011%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.096 Acc 96.969%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.197 Acc 95.792%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.189 Acc 95.911%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.089 Acc 97.246%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.093 Acc 97.170%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.093 Acc 97.140%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.092 Acc 97.175%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.093 Acc 97.156%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.182 Acc 95.753%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.174 Acc 95.899%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.092 Acc 97.277%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.091 Acc 97.217%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.092 Acc 97.179%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.092 Acc 97.163%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.093 Acc 97.123%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.202 Acc 95.792%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.194 Acc 95.849%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.082 Acc 97.424%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.088 Acc 97.209%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.088 Acc 97.238%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.091 Acc 97.130%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.091 Acc 97.120%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.198 Acc 95.707%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.190 Acc 95.826%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.091 Acc 97.192%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.090 Acc 97.182%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.091 Acc 97.225%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.092 Acc 97.191%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.092 Acc 97.167%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.191 Acc 95.746%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.186 Acc 95.833%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.086 Acc 97.208%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.089 Acc 97.143%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.091 Acc 97.119%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.091 Acc 97.103%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.092 Acc 97.062%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.209 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.210 Acc 95.282%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.204 Acc 95.254%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.091 Acc 97.123%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.086 Acc 97.248%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.090 Acc 97.197%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.089 Acc 97.167%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.092 Acc 97.132%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.197 Acc 95.908%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.190 Acc 95.892%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.082 Acc 97.362%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.085 Acc 97.260%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.087 Acc 97.161%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.089 Acc 97.154%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.090 Acc 97.103%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.191 Acc 96.024%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.184 Acc 96.059%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.088 Acc 97.194%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.090 Acc 97.119%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.091 Acc 97.105%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.195 Acc 95.792%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.190 Acc 95.771%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.087 Acc 97.092%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.088 Acc 97.186%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.091 Acc 97.090%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.091 Acc 97.105%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.092 Acc 97.128%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.197 Acc 95.514%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.191 Acc 95.538%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.082 Acc 97.563%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.084 Acc 97.415%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.088 Acc 97.270%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.089 Acc 97.252%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.199 Acc 95.877%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.194 Acc 95.802%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.088 Acc 97.223%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.088 Acc 97.178%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.089 Acc 97.129%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.090 Acc 97.161%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.090 Acc 97.167%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.204 Acc 95.545%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.198 Acc 95.585%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb75da2af4764a89a9b833909cc030a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.321 Acc 16.406%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.235 Acc 18.665%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.023 Acc 27.585%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.743 Acc 38.668%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.526 Acc 46.842%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.356 Acc 53.219%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.451 Acc 85.938%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.482 Acc 84.878%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.476 Acc 85.055%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.511 Acc 84.375%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.546 Acc 82.898%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.532 Acc 83.403%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.514 Acc 84.071%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.499 Acc 84.546%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.486 Acc 84.924%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.392 Acc 86.719%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.376 Acc 89.117%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.370 Acc 89.234%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.453 Acc 87.500%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.418 Acc 87.067%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.408 Acc 87.310%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.401 Acc 87.627%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.396 Acc 87.845%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.391 Acc 87.990%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.385 Acc 86.719%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.350 Acc 89.472%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.344 Acc 89.486%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.332 Acc 89.844%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.368 Acc 88.691%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.357 Acc 88.899%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.352 Acc 89.229%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.351 Acc 89.267%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.348 Acc 89.416%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.377 Acc 87.500%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.289 Acc 91.507%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.283 Acc 91.659%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.233 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.330 Acc 90.084%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.326 Acc 90.155%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.321 Acc 90.179%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.321 Acc 90.313%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.318 Acc 90.427%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.267 Acc 92.690%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.261 Acc 92.701%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.390 Acc 85.938%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.302 Acc 90.780%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.301 Acc 90.901%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.297 Acc 90.952%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.296 Acc 91.087%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.296 Acc 91.082%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.304 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.258 Acc 92.628%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.252 Acc 92.712%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.242 Acc 93.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.278 Acc 91.700%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.282 Acc 91.577%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.282 Acc 91.604%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.281 Acc 91.580%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.279 Acc 91.724%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.253 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.245 Acc 92.822%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.241 Acc 93.008%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.278 Acc 95.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.246 Acc 92.474%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.258 Acc 92.040%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.264 Acc 92.071%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.266 Acc 92.113%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.267 Acc 92.081%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.220 Acc 91.406%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.219 Acc 94.067%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.212 Acc 94.045%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.194 Acc 92.969%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.273 Acc 92.002%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.265 Acc 92.273%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.262 Acc 92.367%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.260 Acc 92.330%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.261 Acc 92.259%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.204 Acc 92.188%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.216 Acc 93.936%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.209 Acc 94.042%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.120 Acc 97.656%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.247 Acc 92.683%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.257 Acc 92.456%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.254 Acc 92.564%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.252 Acc 92.607%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.239 Acc 89.844%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.235 Acc 93.634%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.229 Acc 93.571%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.269 Acc 89.844%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.255 Acc 92.636%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.247 Acc 92.654%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.249 Acc 92.551%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.247 Acc 92.671%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.246 Acc 92.749%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.232 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.222 Acc 94.121%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.218 Acc 94.096%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.237 Acc 92.969%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.233 Acc 93.170%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.234 Acc 93.151%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.236 Acc 93.041%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.239 Acc 93.019%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.236 Acc 93.075%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.254 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.202 Acc 94.446%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.196 Acc 94.663%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.233 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.234 Acc 93.363%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.234 Acc 93.198%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.234 Acc 93.278%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.236 Acc 93.129%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.233 Acc 93.203%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.209 Acc 94.346%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.205 Acc 94.306%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.094 Acc 98.438%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.222 Acc 93.209%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.230 Acc 93.245%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.227 Acc 93.381%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.226 Acc 93.473%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.226 Acc 93.433%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.173 Acc 92.188%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.216 Acc 94.075%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.211 Acc 94.096%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.163 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.223 Acc 93.502%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.225 Acc 93.424%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.222 Acc 93.548%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.222 Acc 93.534%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.222 Acc 93.502%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.185 Acc 92.969%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.197 Acc 94.833%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.193 Acc 94.799%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.311 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.209 Acc 93.773%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.212 Acc 93.668%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.213 Acc 93.737%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.215 Acc 93.674%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.218 Acc 93.568%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.210 Acc 94.438%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.205 Acc 94.345%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.268 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.203 Acc 93.912%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.207 Acc 93.734%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.207 Acc 93.869%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.208 Acc 93.869%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.212 Acc 93.809%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.191 Acc 94.825%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.187 Acc 94.838%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.209 Acc 93.851%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.208 Acc 93.944%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.205 Acc 94.051%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.207 Acc 93.966%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.209 Acc 93.909%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.189 Acc 90.625%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.196 Acc 94.717%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.192 Acc 94.753%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.263 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.199 Acc 94.593%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.200 Acc 94.352%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.202 Acc 94.251%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.204 Acc 94.161%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.204 Acc 94.154%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.195 Acc 94.949%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.189 Acc 94.897%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.193 Acc 94.291%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.200 Acc 94.189%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.204 Acc 94.098%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.202 Acc 94.171%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.203 Acc 94.129%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.194 Acc 94.628%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.204 Acc 94.407%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.202 Acc 94.333%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.201 Acc 94.300%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.203 Acc 94.227%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.199 Acc 94.330%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.137 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.190 Acc 94.895%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.183 Acc 95.048%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.188 Acc 94.407%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.190 Acc 94.446%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.195 Acc 94.269%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.194 Acc 94.334%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.195 Acc 94.382%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.203 Acc 94.415%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.196 Acc 94.667%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.190 Acc 94.593%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.191 Acc 94.555%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.193 Acc 94.503%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.194 Acc 94.527%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.195 Acc 94.441%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.184 Acc 95.258%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.181 Acc 95.254%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.186 Acc 94.609%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.189 Acc 94.516%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.188 Acc 94.588%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.186 Acc 94.601%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.188 Acc 94.567%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.185 Acc 95.150%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.181 Acc 95.266%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.187 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.176 Acc 95.057%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.175 Acc 95.040%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.184 Acc 94.778%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.184 Acc 94.759%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.187 Acc 94.683%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.185 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.181 Acc 95.289%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.179 Acc 95.192%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.124 Acc 94.531%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.191 Acc 94.400%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.180 Acc 94.784%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.183 Acc 94.716%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.187 Acc 94.701%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.187 Acc 94.728%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.179 Acc 95.429%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.173 Acc 95.472%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.184 Acc 94.787%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.184 Acc 94.718%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.185 Acc 94.651%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.181 Acc 94.734%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.182 Acc 94.734%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.146 Acc 94.531%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.183 Acc 95.258%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.184%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.210 Acc 92.969%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.174 Acc 94.856%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.175 Acc 94.885%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.177 Acc 94.879%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.176 Acc 94.954%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.179 Acc 94.890%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.161 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.187 Acc 94.841%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.183 Acc 94.955%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.168 Acc 95.111%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.169 Acc 95.075%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.175 Acc 94.934%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.178 Acc 94.872%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.178 Acc 94.884%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.146 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.186 Acc 95.166%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.181 Acc 95.161%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.176 Acc 94.957%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.175 Acc 94.994%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.178 Acc 94.892%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.176 Acc 94.993%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.176 Acc 94.957%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.185 Acc 95.274%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.181 Acc 95.211%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.207 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.163 Acc 95.258%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.164 Acc 95.208%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.170 Acc 95.032%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.173 Acc 95.018%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.174 Acc 94.996%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.148 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.170 Acc 95.699%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.163 Acc 95.783%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.146 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.164 Acc 95.320%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.165 Acc 95.274%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.167 Acc 95.255%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.166 Acc 95.254%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.168 Acc 95.192%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.182 Acc 95.243%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.176 Acc 95.336%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.168 Acc 95.158%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.166 Acc 95.262%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.169 Acc 95.107%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.171 Acc 95.079%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.171 Acc 95.090%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.169 Acc 95.676%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.162 Acc 95.759%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.247 Acc 96.875%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.166 Acc 95.367%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.166 Acc 95.219%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.165 Acc 95.307%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.311%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.165 Acc 95.306%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.182 Acc 95.367%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.177 Acc 95.359%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.184 Acc 97.656%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.174 Acc 95.289%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.164 Acc 95.324%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.167 Acc 95.305%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.166 Acc 95.305%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.166 Acc 95.303%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.148 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.186 Acc 95.305%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.184 Acc 95.099%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.148 Acc 95.753%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.157 Acc 95.542%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.160 Acc 95.538%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.163 Acc 95.367%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.163 Acc 95.320%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.166 Acc 95.701%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.152 Acc 95.413%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.156 Acc 95.421%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.158 Acc 95.367%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.158 Acc 95.408%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.163 Acc 95.283%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.144 Acc 92.969%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.168 Acc 95.746%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.161 Acc 95.829%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.170 Acc 95.243%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.159 Acc 95.390%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.160 Acc 95.403%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.159 Acc 95.396%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.160 Acc 95.356%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.188 Acc 95.127%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.181 Acc 95.169%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.191 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.163 Acc 95.475%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.162 Acc 95.445%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.164 Acc 95.294%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.160 Acc 95.406%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.159 Acc 95.409%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.177 Acc 95.382%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.170 Acc 95.546%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.133 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.148 Acc 95.684%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.149 Acc 95.653%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.153 Acc 95.593%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.157 Acc 95.465%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.622%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.167 Acc 95.670%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.150 Acc 95.779%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.154 Acc 95.699%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.157 Acc 95.616%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.157 Acc 95.595%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.174 Acc 95.390%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.168 Acc 95.565%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.225 Acc 93.750%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.145 Acc 96.040%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.151 Acc 95.802%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.156 Acc 95.736%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.154 Acc 95.745%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.155 Acc 95.663%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.170 Acc 95.722%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.165 Acc 95.802%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.087 Acc 98.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.150 Acc 95.823%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.150 Acc 95.670%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.152 Acc 95.559%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.152 Acc 95.519%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.153 Acc 95.543%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.167 Acc 95.730%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.164 Acc 95.686%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.144 Acc 95.916%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.153 Acc 95.725%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.151 Acc 95.717%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.152 Acc 95.644%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.153 Acc 95.654%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.172 Acc 95.583%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.166 Acc 95.740%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.142 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.142 Acc 95.506%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.143 Acc 95.639%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.146 Acc 95.697%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.148 Acc 95.696%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.152 Acc 95.649%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.182 Acc 95.405%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.178 Acc 95.406%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.191 Acc 93.750%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.142 Acc 95.846%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.148 Acc 95.717%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.150 Acc 95.684%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.149 Acc 95.724%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.150 Acc 95.695%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.179 Acc 95.560%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.170 Acc 95.623%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.143 Acc 95.792%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.141 Acc 95.833%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.145 Acc 95.710%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.145 Acc 95.763%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.146 Acc 95.741%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.191 Acc 94.918%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.183 Acc 95.114%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.138 Acc 96.063%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.138 Acc 95.927%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.145 Acc 95.811%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.145 Acc 95.813%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.146 Acc 95.785%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.179 Acc 95.514%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.174 Acc 95.577%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.150 Acc 95.521%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.149 Acc 95.779%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.146 Acc 95.775%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.145 Acc 95.796%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.146 Acc 95.751%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.115 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.178 Acc 95.614%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.173 Acc 95.713%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.175 Acc 96.875%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.142 Acc 96.024%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.146 Acc 95.791%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.146 Acc 95.850%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.145 Acc 95.850%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.145 Acc 95.854%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.173 Acc 95.722%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.166 Acc 95.818%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.139 Acc 95.893%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.138 Acc 95.923%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.141 Acc 95.858%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.141 Acc 95.907%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.141 Acc 95.942%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.154 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.179 Acc 95.452%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.170 Acc 95.581%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.131 Acc 96.450%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.137 Acc 96.226%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.140 Acc 96.151%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.139 Acc 96.109%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.141 Acc 95.992%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.173 Acc 95.561%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.139 Acc 96.194%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.133 Acc 96.249%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.136 Acc 96.185%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.139 Acc 96.033%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.140 Acc 96.028%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.177 Acc 95.792%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.169 Acc 95.884%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.136 Acc 96.171%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.138 Acc 96.021%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.137 Acc 96.066%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.139 Acc 96.066%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.123 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.177 Acc 95.483%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.171 Acc 95.542%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.135 Acc 96.032%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.135 Acc 96.070%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.136 Acc 96.065%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.136 Acc 96.068%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.134 Acc 96.114%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.175 Acc 95.560%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.168 Acc 95.744%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.168 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.128 Acc 96.171%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.133 Acc 96.078%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.134 Acc 96.068%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.136 Acc 96.017%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.177 Acc 95.630%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.169 Acc 95.713%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.207 Acc 93.750%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.144 Acc 96.140%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.136 Acc 96.195%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.138 Acc 96.102%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.137 Acc 96.121%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.136 Acc 96.111%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.104 Acc 98.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.181 Acc 95.545%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.173 Acc 95.596%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.273 Acc 93.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.129 Acc 96.403%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.134 Acc 96.168%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.132 Acc 96.143%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.133 Acc 96.063%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.133 Acc 96.091%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.174 Acc 95.552%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.167 Acc 95.627%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.132 Acc 96.113%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.136 Acc 96.080%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.133 Acc 96.176%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.172 Acc 95.815%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.164 Acc 95.915%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.130 Acc 96.148%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.132 Acc 96.160%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.131 Acc 96.187%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.131 Acc 96.220%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.130 Acc 96.262%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.135 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.170 Acc 95.668%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.162 Acc 95.787%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.128 Acc 96.233%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.128 Acc 96.206%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.130 Acc 96.172%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.131 Acc 96.109%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.133 Acc 96.106%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.121 Acc 94.531%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.173 Acc 95.591%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.166 Acc 95.771%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.140 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.124 Acc 96.248%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.123 Acc 96.273%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.127 Acc 96.262%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.127 Acc 96.248%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.130 Acc 96.203%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.125 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.174 Acc 95.630%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.170 Acc 95.670%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.130 Acc 96.295%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.128 Acc 96.385%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.127 Acc 96.343%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.129 Acc 96.254%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.131 Acc 96.178%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.176 Acc 95.738%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.168 Acc 95.969%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.149 Acc 95.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.119 Acc 96.434%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.126 Acc 96.261%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.127 Acc 96.348%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.129 Acc 96.296%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.130 Acc 96.256%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.173 Acc 96.071%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.164 Acc 96.113%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.127 Acc 96.349%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.125 Acc 96.292%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.126 Acc 96.273%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.127 Acc 96.216%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.128 Acc 96.198%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.185 Acc 95.653%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.177 Acc 95.713%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.118 Acc 96.272%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.124 Acc 96.323%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.125 Acc 96.361%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.126 Acc 96.341%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.127 Acc 96.303%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.182 Acc 95.692%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.175 Acc 95.693%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.127 Acc 96.481%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.127 Acc 96.300%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.130 Acc 96.229%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.128 Acc 96.223%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.181 Acc 95.622%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.172 Acc 95.794%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.085 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.123 Acc 96.457%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.123 Acc 96.440%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.127 Acc 96.366%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.126 Acc 96.353%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.126 Acc 96.348%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.186 Acc 95.367%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.176 Acc 95.596%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.122 Acc 96.455%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.120 Acc 96.455%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.121 Acc 96.429%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.122 Acc 96.446%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.182 Acc 95.320%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.174 Acc 95.503%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.222 Acc 92.969%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.121 Acc 96.426%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.122 Acc 96.455%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.126 Acc 96.397%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.125 Acc 96.400%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.124 Acc 96.418%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.808%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.168 Acc 95.903%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.117 Acc 96.357%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.119 Acc 96.420%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.122 Acc 96.431%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.123 Acc 96.384%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.124 Acc 96.353%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.175 Acc 95.614%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.166 Acc 95.717%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.147 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.116 Acc 96.697%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.118 Acc 96.591%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.118 Acc 96.504%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.120 Acc 96.476%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.123 Acc 96.420%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.173 Acc 95.676%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.165 Acc 95.826%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.123 Acc 96.504%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.116 Acc 96.681%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.115 Acc 96.662%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.118 Acc 96.593%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.119 Acc 96.510%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.180 Acc 95.637%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.172 Acc 95.864%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.126 Acc 96.163%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.119 Acc 96.393%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.122 Acc 96.294%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.122 Acc 96.345%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.120 Acc 96.396%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.177 Acc 95.661%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.170 Acc 95.818%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.114 Acc 96.604%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.111 Acc 96.716%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.114 Acc 96.631%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.116 Acc 96.579%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.117 Acc 96.572%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.185 Acc 95.668%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.179 Acc 95.779%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.124 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.109 Acc 96.813%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.109 Acc 96.782%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.116 Acc 96.571%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.118 Acc 96.518%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.191 Acc 95.653%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.183 Acc 95.756%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.116 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.114 Acc 96.589%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.113 Acc 96.665%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.114 Acc 96.582%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.116 Acc 96.577%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.117 Acc 96.530%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.179 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.182 Acc 95.599%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.111 Acc 96.767%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.115 Acc 96.533%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.114 Acc 96.579%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.116 Acc 96.530%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.118 Acc 96.502%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.177 Acc 95.653%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.169 Acc 95.829%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.079 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.114 Acc 96.612%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.111 Acc 96.696%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.114 Acc 96.613%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.116 Acc 96.610%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.116 Acc 96.571%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.182 Acc 95.591%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.175 Acc 95.647%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.120 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.107 Acc 96.627%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.109 Acc 96.716%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.112 Acc 96.647%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.114 Acc 96.606%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.115 Acc 96.582%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.467%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.179 Acc 95.643%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.109 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.112 Acc 96.419%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.112 Acc 96.552%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.112 Acc 96.566%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.115 Acc 96.557%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.114 Acc 96.568%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.194 Acc 95.289%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.187 Acc 95.546%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.110 Acc 96.774%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.111 Acc 96.622%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.112 Acc 96.644%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.112 Acc 96.672%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.113 Acc 96.616%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.178 Acc 95.690%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.095 Acc 96.983%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.109 Acc 96.789%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.110 Acc 96.748%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.112 Acc 96.675%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.170 Acc 95.784%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.164 Acc 95.919%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.086 Acc 95.312%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.107 Acc 96.705%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.107 Acc 96.716%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.110 Acc 96.675%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.112 Acc 96.653%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.111 Acc 96.672%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.185 Acc 95.560%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.176 Acc 95.740%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.104 Acc 96.883%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.107 Acc 96.840%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.111 Acc 96.740%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.110 Acc 96.817%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.110 Acc 96.766%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.195 Acc 95.382%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.186 Acc 95.519%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.103 Acc 96.952%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.107 Acc 96.739%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.108 Acc 96.735%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.109 Acc 96.721%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.137 Acc 96.875%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.180 Acc 95.692%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.176 Acc 95.763%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.101 Acc 96.914%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.104 Acc 96.836%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.108 Acc 96.763%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.107 Acc 96.774%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.108 Acc 96.766%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.183 Acc 95.591%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.176 Acc 95.709%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.112 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.107 Acc 96.728%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.109 Acc 96.731%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.110 Acc 96.750%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.110 Acc 96.707%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.108 Acc 96.725%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.182 Acc 95.583%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.173 Acc 95.744%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.109 Acc 96.805%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.107 Acc 96.817%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.108 Acc 96.760%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.107 Acc 96.799%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.188 Acc 95.560%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.180 Acc 95.725%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.099 Acc 96.898%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.099 Acc 96.937%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.103 Acc 96.844%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.107 Acc 96.769%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.134 Acc 93.750%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.924%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.168 Acc 95.977%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.096 Acc 96.983%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.099 Acc 97.011%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.103 Acc 96.930%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.107 Acc 96.832%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.108 Acc 96.791%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.189 Acc 95.475%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.180 Acc 95.585%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.104 Acc 96.813%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.103 Acc 96.891%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.103 Acc 96.906%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.105 Acc 96.857%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.106 Acc 96.785%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.221 Acc 93.750%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.194 Acc 95.367%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.185 Acc 95.588%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.093 Acc 97.092%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.099 Acc 97.027%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.102 Acc 96.927%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.102 Acc 96.906%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.104 Acc 96.870%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.182 Acc 95.761%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.174 Acc 95.849%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.110 Acc 96.658%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.108 Acc 96.758%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.106 Acc 96.805%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.106 Acc 96.834%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.105 Acc 96.825%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.136 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.191 Acc 95.390%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.184 Acc 95.507%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.106 Acc 96.945%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.103 Acc 97.023%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.104 Acc 96.984%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.104 Acc 96.951%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.106 Acc 96.872%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.190 Acc 95.490%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.179 Acc 95.732%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.095 Acc 97.045%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.099 Acc 96.992%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.100 Acc 96.979%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.101 Acc 96.931%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.103 Acc 96.933%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.192 Acc 95.684%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.181 Acc 95.802%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.104 Acc 96.844%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.103 Acc 96.856%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.102 Acc 96.818%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.103 Acc 96.805%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.104 Acc 96.822%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.176 Acc 95.622%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.168 Acc 95.837%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.101 Acc 96.832%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.103 Acc 96.800%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.103 Acc 96.799%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.103 Acc 96.855%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.194 Acc 95.475%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.184 Acc 95.627%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.132 Acc 96.875%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.099 Acc 97.076%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.097 Acc 97.062%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.101 Acc 96.911%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.101 Acc 96.887%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.163 Acc 92.969%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.194 Acc 95.374%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.186 Acc 95.476%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.104 Acc 96.705%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.100 Acc 96.918%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.103 Acc 96.878%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.102 Acc 96.854%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.102 Acc 96.850%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.148 Acc 92.969%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.192 Acc 95.591%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.183 Acc 95.810%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.094 Acc 97.023%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.098 Acc 96.945%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.099 Acc 96.951%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.100 Acc 96.944%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.137 Acc 92.969%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.175 Acc 95.907%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.092 Acc 97.030%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.093 Acc 97.111%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.097 Acc 97.031%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.100 Acc 96.965%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.177 Acc 95.862%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.170 Acc 96.012%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.091 Acc 97.153%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.093 Acc 97.042%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.097 Acc 96.945%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.098 Acc 96.920%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.098 Acc 96.969%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.191 Acc 95.692%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.186 Acc 95.794%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.101 Acc 97.053%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.097 Acc 97.217%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.096 Acc 97.127%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.097 Acc 97.050%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.099 Acc 96.990%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.195 Acc 95.599%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.186 Acc 95.798%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.098 Acc 97.037%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.098 Acc 96.941%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.097 Acc 96.992%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.097 Acc 96.986%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.098 Acc 97.003%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.201 Acc 95.444%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.189 Acc 95.604%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.093 Acc 96.976%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.095 Acc 96.988%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.096 Acc 97.049%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.098 Acc 97.027%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.097 Acc 97.054%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.136 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.183 Acc 95.676%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.173 Acc 95.841%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.097 Acc 97.107%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.096 Acc 97.077%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.098 Acc 97.039%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.098 Acc 97.034%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.199 Acc 95.746%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.187 Acc 95.931%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.184 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.099 Acc 96.968%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.097 Acc 97.155%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.095 Acc 97.150%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.095 Acc 97.148%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.097 Acc 97.093%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.202 Acc 95.452%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.189 Acc 95.693%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.208 Acc 93.750%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.102 Acc 96.890%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.104 Acc 96.824%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.098 Acc 96.996%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.098 Acc 96.997%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.201 Acc 95.575%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.190 Acc 95.736%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.161 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.097 Acc 97.177%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.093 Acc 97.151%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.095 Acc 97.111%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.096 Acc 97.037%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.097 Acc 97.022%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.189 Acc 95.738%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.179 Acc 95.888%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.091 Acc 97.120%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.090 Acc 97.155%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.093 Acc 97.095%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.095 Acc 97.011%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.194 Acc 95.483%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.183 Acc 95.670%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.093 Acc 97.099%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.095 Acc 97.030%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.094 Acc 97.116%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.093 Acc 97.132%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.096 Acc 97.042%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.194 Acc 95.583%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.187 Acc 95.623%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.093 Acc 97.231%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.092 Acc 97.104%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.093 Acc 97.096%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.095 Acc 97.051%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.192 Acc 95.614%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.180 Acc 95.771%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.094 Acc 97.146%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.091 Acc 97.194%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.096 Acc 97.039%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.097 Acc 97.039%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.095 Acc 97.106%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.177 Acc 92.188%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.194 Acc 95.514%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.186 Acc 95.682%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.027 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.101 Acc 97.076%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.095 Acc 97.062%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.094 Acc 97.099%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.094 Acc 97.109%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.200 Acc 95.746%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.187 Acc 95.977%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.092 Acc 97.200%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.090 Acc 97.279%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.093 Acc 97.106%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.091 Acc 97.179%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.092 Acc 97.162%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.198 Acc 95.459%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.187 Acc 95.662%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.087 Acc 97.262%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.091 Acc 97.233%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.090 Acc 97.210%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.090 Acc 97.216%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.091 Acc 97.176%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.120 Acc 94.531%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.196 Acc 95.707%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.187 Acc 95.888%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.090 Acc 97.285%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.093 Acc 97.174%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.092 Acc 97.171%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.092 Acc 97.132%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.092 Acc 97.160%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.183 Acc 95.622%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.174 Acc 95.818%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.086 Acc 97.409%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.092 Acc 97.221%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.092 Acc 97.155%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.092 Acc 97.156%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.093 Acc 97.110%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.198 Acc 95.800%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.189 Acc 95.884%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.085 Acc 97.355%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.085 Acc 97.330%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.085 Acc 97.290%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.088 Acc 97.206%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.090 Acc 97.173%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.205 Acc 95.266%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.193 Acc 95.495%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.163 Acc 94.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.089 Acc 97.386%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.092 Acc 97.283%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.092 Acc 97.218%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.091 Acc 97.202%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.092 Acc 97.174%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.132 Acc 92.188%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.202 Acc 95.490%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.190 Acc 95.767%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.086 Acc 97.494%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.088 Acc 97.365%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.090 Acc 97.272%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.090 Acc 97.265%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.190 Acc 95.545%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.121 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.083 Acc 97.458%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.088 Acc 97.218%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.192 Acc 95.606%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.186 Acc 95.670%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.091 Acc 97.138%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.084 Acc 97.260%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.085 Acc 97.270%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.087 Acc 97.239%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.088 Acc 97.217%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.126 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.187 Acc 95.784%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.181 Acc 95.903%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.083 Acc 97.409%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.083 Acc 97.400%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.084 Acc 97.329%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.085 Acc 97.317%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.086 Acc 97.298%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.161 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.198 Acc 95.452%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.193 Acc 95.542%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.084 Acc 97.463%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.086 Acc 97.388%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.087 Acc 97.371%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.087 Acc 97.352%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.088 Acc 97.312%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.199 Acc 95.235%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.190 Acc 95.530%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.080 Acc 97.462%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.085 Acc 97.350%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.085 Acc 97.327%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.087 Acc 97.285%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.202 Acc 95.444%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.188 Acc 95.697%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.078 Acc 97.316%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.086 Acc 97.198%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.085 Acc 97.249%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.087 Acc 97.249%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.221 Acc 95.452%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.205 Acc 95.588%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.081 Acc 97.455%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.082 Acc 97.349%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.084 Acc 97.340%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.085 Acc 97.308%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.086 Acc 97.232%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.205 Acc 95.405%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.193 Acc 95.542%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.091 Acc 97.161%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.086 Acc 97.337%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.086 Acc 97.335%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.086 Acc 97.360%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.198 Acc 95.777%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.188 Acc 95.934%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.061 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.082 Acc 97.378%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.085 Acc 97.326%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.086 Acc 97.298%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.086 Acc 97.348%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.087 Acc 97.307%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.212 Acc 95.753%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.199 Acc 95.899%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.073 Acc 97.795%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.080 Acc 97.550%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.081 Acc 97.483%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.085 Acc 97.338%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.199 Acc 95.413%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.190 Acc 95.519%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.077 Acc 97.610%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.080 Acc 97.512%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.081 Acc 97.392%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.083 Acc 97.331%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.084 Acc 97.307%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.125 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.196 Acc 95.792%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.185 Acc 95.923%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.078 Acc 97.540%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.081 Acc 97.427%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.081 Acc 97.462%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.084 Acc 97.315%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.196 Acc 95.614%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.184 Acc 95.868%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.091 Acc 95.312%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.080 Acc 97.361%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.081 Acc 97.379%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.081 Acc 97.360%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.082 Acc 97.291%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.206 Acc 95.699%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.196 Acc 95.849%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.083 Acc 97.316%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.083 Acc 97.334%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.084 Acc 97.363%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.084 Acc 97.331%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.086 Acc 97.287%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.198 Acc 95.521%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.187 Acc 95.794%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.085 Acc 97.269%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.085 Acc 97.295%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.084 Acc 97.311%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.084 Acc 97.296%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.085 Acc 97.270%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.192 Acc 95.823%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.180 Acc 95.989%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.074 Acc 97.633%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.077 Acc 97.579%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.077 Acc 97.576%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.079 Acc 97.528%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.081 Acc 97.455%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.200 Acc 95.514%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.189 Acc 95.779%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.083 Acc 97.347%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.081 Acc 97.446%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.081 Acc 97.475%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.080 Acc 97.475%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.081 Acc 97.419%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.215 Acc 95.753%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.202 Acc 95.907%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.077 Acc 97.672%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.083 Acc 97.376%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.084 Acc 97.358%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.084 Acc 97.325%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.083 Acc 97.346%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.196 Acc 95.444%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.186 Acc 95.655%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.084 Acc 97.277%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.083 Acc 97.365%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.079 Acc 97.467%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.080 Acc 97.448%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.082 Acc 97.390%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.204 Acc 95.715%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.195 Acc 95.829%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.105 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.078 Acc 97.509%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.078 Acc 97.555%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.078 Acc 97.604%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.078 Acc 97.598%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.079 Acc 97.533%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.197 Acc 95.343%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.187 Acc 95.662%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.079 Acc 97.528%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.080 Acc 97.498%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.080 Acc 97.500%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.081 Acc 97.466%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.098 Acc 96.094%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.204 Acc 95.606%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.195 Acc 95.674%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.070 Acc 97.633%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.078 Acc 97.559%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.080 Acc 97.451%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.080 Acc 97.465%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.080 Acc 97.486%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.129 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.201 Acc 95.606%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.191 Acc 95.662%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.079 Acc 97.525%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.078 Acc 97.512%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.081 Acc 97.451%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.082 Acc 97.397%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.209 Acc 95.467%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.197 Acc 95.534%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.071 Acc 97.710%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.071 Acc 97.613%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.076 Acc 97.513%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.076 Acc 97.532%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.077 Acc 97.471%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.213 Acc 95.552%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.204 Acc 95.616%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.085 Acc 97.277%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.081 Acc 97.411%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.079 Acc 97.446%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.079 Acc 97.467%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.079 Acc 97.444%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.210 Acc 95.707%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.198 Acc 95.872%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.075 Acc 97.455%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.078 Acc 97.469%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.079 Acc 97.481%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.080 Acc 97.436%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.219 Acc 95.560%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.208 Acc 95.709%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.077 Acc 97.633%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.075 Acc 97.630%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.076 Acc 97.613%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.079 Acc 97.555%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.220 Acc 95.537%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.206 Acc 95.748%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.075 Acc 97.649%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.076 Acc 97.641%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.077 Acc 97.539%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.078 Acc 97.549%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.079 Acc 97.483%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.382%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.202 Acc 95.569%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.081 Acc 97.486%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.084 Acc 97.407%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.080 Acc 97.529%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.078 Acc 97.578%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.080 Acc 97.510%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.218 Acc 95.475%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.205 Acc 95.686%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.070 Acc 97.865%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.072 Acc 97.711%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.074 Acc 97.643%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.077 Acc 97.555%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.194 Acc 95.514%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.185 Acc 95.674%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.081 Acc 97.455%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.079 Acc 97.436%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.078 Acc 97.512%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.079 Acc 97.469%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.194 Acc 95.637%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.184 Acc 95.771%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.074 Acc 97.602%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.077 Acc 97.491%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.078 Acc 97.477%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.208 Acc 95.467%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.201 Acc 95.631%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.071 Acc 97.726%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.074 Acc 97.652%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.077 Acc 97.552%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.075 Acc 97.611%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.141 Acc 92.969%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.208 Acc 95.637%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.198 Acc 95.864%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.073 Acc 97.819%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.074 Acc 97.750%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.075 Acc 97.706%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.075 Acc 97.668%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.075 Acc 97.638%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.169 Acc 93.750%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.205 Acc 95.753%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.195 Acc 95.861%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.074 Acc 97.525%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.075 Acc 97.559%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.074 Acc 97.586%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.075 Acc 97.598%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.076 Acc 97.569%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.206 Acc 95.390%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.194 Acc 95.616%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.071 Acc 97.726%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.076 Acc 97.573%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.078 Acc 97.493%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.078 Acc 97.486%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.120 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.215 Acc 95.668%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.205 Acc 95.818%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.071 Acc 97.587%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.072 Acc 97.555%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.072 Acc 97.628%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.075 Acc 97.596%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.075 Acc 97.583%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.120 Acc 95.312%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.205 Acc 95.490%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.192 Acc 95.791%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.075 Acc 97.548%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.074 Acc 97.637%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.073 Acc 97.635%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.073 Acc 97.629%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.073 Acc 97.608%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.191 Acc 95.761%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.184 Acc 95.892%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.074 Acc 97.610%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.073 Acc 97.652%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.073 Acc 97.677%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.074 Acc 97.647%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.074 Acc 97.620%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.206 Acc 95.815%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.196 Acc 95.903%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.072 Acc 97.676%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.073 Acc 97.664%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.074 Acc 97.678%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.075 Acc 97.617%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.202 Acc 95.475%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.191 Acc 95.639%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.072 Acc 97.643%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.072 Acc 97.650%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.208 Acc 92.969%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.216 Acc 95.560%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.204 Acc 95.841%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.066 Acc 97.749%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.070 Acc 97.715%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.072 Acc 97.638%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.072 Acc 97.652%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.074 Acc 97.599%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.174 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.216 Acc 95.413%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.204 Acc 95.588%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.072 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.075 Acc 97.637%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.075 Acc 97.634%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.222 Acc 95.297%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.213 Acc 95.433%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.082 Acc 96.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.071 Acc 97.687%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.072 Acc 97.594%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.072 Acc 97.612%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.072 Acc 97.623%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.074 Acc 97.608%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.220 Acc 95.413%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.210 Acc 95.526%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.068 Acc 97.757%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.070 Acc 97.672%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.072 Acc 97.659%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.072 Acc 97.637%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.073 Acc 97.613%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.209 Acc 95.452%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.198 Acc 95.526%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.063 Acc 99.219%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.073 Acc 97.618%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.073 Acc 97.637%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.073 Acc 97.643%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.072 Acc 97.680%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.073 Acc 97.624%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.204 Acc 95.568%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.194 Acc 95.767%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.067 Acc 97.734%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.070 Acc 97.718%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.072 Acc 97.669%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.072 Acc 97.631%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.205 Acc 95.908%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.195 Acc 96.059%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.064 Acc 97.795%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.067 Acc 97.777%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.070 Acc 97.706%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.070 Acc 97.678%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.212 Acc 95.444%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.202 Acc 95.581%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.064 Acc 97.857%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.069 Acc 97.738%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.070 Acc 97.707%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.072 Acc 97.666%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.183 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.220 Acc 95.637%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.210 Acc 95.806%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.064 Acc 97.873%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.069 Acc 97.757%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.069 Acc 97.798%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.069 Acc 97.758%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.212 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.225 Acc 95.661%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.215 Acc 95.666%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.068 Acc 97.749%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.067 Acc 97.839%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.070 Acc 97.744%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.071 Acc 97.728%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.071 Acc 97.716%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.202 Acc 95.537%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.194 Acc 95.740%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.053 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.068 Acc 97.803%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.069 Acc 97.769%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.069 Acc 97.737%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.069 Acc 97.722%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.070 Acc 97.728%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.202 Acc 95.746%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.194 Acc 95.911%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.051 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.065 Acc 97.866%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.070 Acc 97.714%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.220 Acc 95.606%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.209 Acc 95.798%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.069 Acc 97.726%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.067 Acc 97.819%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.067 Acc 97.776%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.068 Acc 97.750%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.070 Acc 97.730%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.213 Acc 95.668%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.203 Acc 95.810%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.051 Acc 96.875%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.067 Acc 97.679%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.066 Acc 97.804%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.069 Acc 97.700%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.069 Acc 97.684%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.070 Acc 97.683%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.205 Acc 95.591%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.198 Acc 95.775%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.066 Acc 97.795%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.063 Acc 97.835%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.066 Acc 97.812%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.069 Acc 97.752%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.069 Acc 97.734%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.192 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.224 Acc 95.545%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.211 Acc 95.709%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.065 Acc 97.857%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.066 Acc 97.827%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.068 Acc 97.773%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.069 Acc 97.737%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.132 Acc 96.094%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.208 Acc 95.591%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.200 Acc 95.756%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.068 Acc 97.881%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.067 Acc 97.827%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.070 Acc 97.752%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.069 Acc 97.750%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.070 Acc 97.726%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.207 Acc 95.676%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.197 Acc 95.775%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.065 Acc 97.842%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.069 Acc 97.699%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.070 Acc 97.744%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.072 Acc 97.695%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.147 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.217 Acc 95.637%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.205 Acc 95.775%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.038 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.066 Acc 97.757%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.065 Acc 97.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.065 Acc 97.838%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.067 Acc 97.752%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.068 Acc 97.725%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.231 Acc 95.575%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.222 Acc 95.553%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.119 Acc 96.875%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.060 Acc 98.035%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.067 Acc 97.808%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.068 Acc 97.794%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.068 Acc 97.806%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.068 Acc 97.814%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.223 Acc 95.336%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.210 Acc 95.658%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.013 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.063 Acc 97.987%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.065 Acc 97.895%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.066 Acc 97.890%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.066 Acc 97.882%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.240 Acc 95.537%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.227 Acc 95.678%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.066 Acc 97.563%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.065 Acc 97.757%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.066 Acc 97.825%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.067 Acc 97.765%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.201 Acc 95.792%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.194 Acc 95.888%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.080 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.065 Acc 97.741%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.069 Acc 97.699%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.069 Acc 97.729%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.070 Acc 97.703%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.069 Acc 97.720%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.221 Acc 95.560%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.213 Acc 95.690%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.067 Acc 97.812%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.067 Acc 97.783%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.069 Acc 97.678%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.070 Acc 97.675%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.212 Acc 95.645%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.202 Acc 95.802%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.060 Acc 97.826%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.065 Acc 97.823%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.066 Acc 97.757%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.065 Acc 97.795%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.065 Acc 97.806%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.217 Acc 95.661%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.207 Acc 95.783%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.065 Acc 97.811%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.067 Acc 97.769%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.067 Acc 97.841%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.066 Acc 97.857%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.068 Acc 97.784%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.208 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.209 Acc 95.483%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.197 Acc 95.651%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.063 Acc 97.958%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.065 Acc 97.924%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.068 Acc 97.804%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.067 Acc 97.829%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.197 Acc 95.955%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.190 Acc 95.969%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.058 Acc 98.058%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.066 Acc 97.858%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.064 Acc 97.895%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.065 Acc 97.849%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.066 Acc 97.839%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.187 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.217 Acc 95.622%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.204 Acc 95.783%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.061 Acc 97.981%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.064 Acc 97.897%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.067 Acc 97.820%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.066 Acc 97.861%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.068 Acc 97.793%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.211 Acc 95.746%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.201 Acc 95.880%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.066 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.062 Acc 97.927%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.064 Acc 97.901%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.064 Acc 97.911%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.067 Acc 97.818%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.068 Acc 97.776%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.223 Acc 95.746%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.210 Acc 95.946%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.058 Acc 98.144%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.060 Acc 98.041%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.063 Acc 97.902%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.065 Acc 97.868%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.222 Acc 95.413%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.209 Acc 95.557%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.029 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.062 Acc 98.004%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.063 Acc 97.952%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.063 Acc 97.965%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.065 Acc 97.876%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.066 Acc 97.854%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.208 Acc 95.583%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.199 Acc 95.759%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.067 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.065 Acc 97.795%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.063 Acc 97.917%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.063 Acc 97.921%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.063 Acc 97.913%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.064 Acc 97.889%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.162 Acc 92.969%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.207 Acc 95.676%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.198 Acc 95.853%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.064 Acc 97.834%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.065 Acc 97.823%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.063 Acc 97.835%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.065 Acc 97.804%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.065 Acc 97.789%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.224 Acc 95.738%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.213 Acc 95.868%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.043%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.059 Acc 98.060%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.061 Acc 97.934%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.062 Acc 97.935%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.062 Acc 97.924%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.219 Acc 92.969%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.229 Acc 95.382%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.219 Acc 95.577%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.057 Acc 98.058%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.063 Acc 97.858%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.066 Acc 97.786%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.066 Acc 97.818%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.066 Acc 97.837%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.212 Acc 95.784%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.206 Acc 95.981%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.059 Acc 98.051%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.060 Acc 98.018%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.060 Acc 97.988%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.061 Acc 97.997%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.061 Acc 97.965%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.223 Acc 95.746%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.214 Acc 95.845%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ffe3c76f3843cb9b340569af0bcc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.309 Acc 10.156%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.213 Acc 20.227%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 1.997 Acc 28.895%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.762 Acc 37.972%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.580 Acc 44.933%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.431 Acc 50.535%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.645 Acc 78.125%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.597 Acc 81.969%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.587 Acc 82.035%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.846 Acc 75.781%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.662 Acc 79.517%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.633 Acc 80.372%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.612 Acc 81.102%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.584 Acc 81.871%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.564 Acc 82.493%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.355 Acc 89.062%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.406 Acc 88.181%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.400 Acc 88.188%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.424 Acc 88.281%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.455 Acc 85.442%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.454 Acc 85.681%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.444 Acc 86.132%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.434 Acc 86.481%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.425 Acc 86.800%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.326 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.355 Acc 89.457%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.349 Acc 89.700%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.372 Acc 85.156%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.384 Acc 88.297%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.384 Acc 88.378%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.382 Acc 88.372%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.378 Acc 88.513%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.372 Acc 88.674%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.323 Acc 91.406%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.304 Acc 91.066%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.299 Acc 91.247%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.335 Acc 89.844%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.344 Acc 89.643%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.337 Acc 89.548%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.341 Acc 89.470%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.338 Acc 89.659%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.335 Acc 89.730%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.291 Acc 91.406%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.277 Acc 92.110%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.271 Acc 92.156%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.268 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.336 Acc 89.851%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.328 Acc 90.174%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.327 Acc 90.249%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.318 Acc 90.475%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.316 Acc 90.500%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.273 Acc 90.625%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.277 Acc 91.847%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.275 Acc 91.810%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.217 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.287 Acc 91.267%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.292 Acc 91.317%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.293 Acc 91.201%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.290 Acc 91.278%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.295 Acc 91.146%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.243 Acc 91.406%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.273 Acc 92.412%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.269 Acc 92.351%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.291 Acc 91.406%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.277 Acc 91.499%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.282 Acc 91.531%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.282 Acc 91.484%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.282 Acc 91.480%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.282 Acc 91.537%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.216 Acc 88.281%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.245 Acc 92.953%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.242 Acc 92.980%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.237 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.271 Acc 91.778%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.271 Acc 91.888%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.274 Acc 91.824%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.277 Acc 91.671%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.277 Acc 91.713%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.288 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.245 Acc 93.363%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.242 Acc 93.136%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.163 Acc 91.406%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.270 Acc 91.948%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.261 Acc 92.316%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.265 Acc 92.229%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.265 Acc 92.213%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.264 Acc 92.177%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.234 Acc 93.564%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.230 Acc 93.470%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.254 Acc 92.466%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.257 Acc 92.281%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.256 Acc 92.416%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.257 Acc 92.388%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.256 Acc 92.425%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.261 Acc 92.188%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.243 Acc 93.147%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.234 Acc 93.322%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.246 Acc 90.625%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.254 Acc 92.876%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.249 Acc 92.806%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.254 Acc 92.707%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.252 Acc 92.628%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.253 Acc 92.621%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.213 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.209 Acc 94.322%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.204 Acc 94.356%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.321 Acc 93.750%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.248 Acc 92.922%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.247 Acc 92.821%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.244 Acc 92.839%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.245 Acc 92.825%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.244 Acc 92.816%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.229 Acc 93.851%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.225 Acc 93.816%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.205 Acc 94.531%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.249 Acc 92.938%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.242 Acc 93.093%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.241 Acc 93.080%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.238 Acc 93.136%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.238 Acc 93.045%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.234 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.213 Acc 94.276%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.208 Acc 94.380%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.236 Acc 93.100%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.236 Acc 93.054%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.235 Acc 93.166%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.235 Acc 93.169%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.234 Acc 93.223%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.256 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.224 Acc 93.611%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.218 Acc 93.676%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.288 Acc 90.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.233 Acc 93.232%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.232 Acc 93.260%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.231 Acc 93.374%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.228 Acc 93.466%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.231 Acc 93.368%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.194 Acc 94.763%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.188 Acc 94.831%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.311 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.234 Acc 93.286%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.224 Acc 93.482%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.220 Acc 93.605%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.222 Acc 93.571%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.225 Acc 93.494%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.211 Acc 92.969%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.220 Acc 94.067%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.214 Acc 94.255%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.169 Acc 96.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.208 Acc 94.036%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.216 Acc 93.905%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.219 Acc 93.792%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.217 Acc 93.773%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.216 Acc 93.781%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.232 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.200 Acc 94.678%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.194 Acc 94.796%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.183 Acc 94.531%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.214 Acc 93.704%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.215 Acc 93.789%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.216 Acc 93.708%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.216 Acc 93.746%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.218 Acc 93.748%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.200 Acc 94.748%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.196 Acc 94.726%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.201 Acc 94.005%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.209 Acc 93.991%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.209 Acc 93.950%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.209 Acc 93.958%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.214 Acc 93.836%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.187 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.186 Acc 95.111%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.181 Acc 95.118%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.138 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.198 Acc 94.261%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.200 Acc 94.263%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.203 Acc 94.189%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.208 Acc 94.048%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.208 Acc 94.034%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.169 Acc 92.188%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.203 Acc 94.423%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.198 Acc 94.512%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.195 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.208 Acc 93.889%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.210 Acc 93.925%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.208 Acc 93.906%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.207 Acc 93.943%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.207 Acc 93.962%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.199 Acc 94.593%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.196 Acc 94.551%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.196 Acc 94.423%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.199 Acc 94.333%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.198 Acc 94.269%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.203 Acc 94.163%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.201 Acc 94.190%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.194 Acc 94.856%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.188 Acc 94.951%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.236 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.202 Acc 94.485%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.195 Acc 94.422%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.198 Acc 94.269%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.200 Acc 94.268%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.202 Acc 94.191%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.171 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.187 Acc 95.073%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.182 Acc 95.114%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.194 Acc 94.454%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.193 Acc 94.446%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.196 Acc 94.448%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.194 Acc 94.447%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.197 Acc 94.357%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.213 Acc 92.188%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.198 Acc 94.655%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.193 Acc 94.660%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.179 Acc 93.750%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.192 Acc 94.438%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.199 Acc 94.376%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.197 Acc 94.435%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.196 Acc 94.409%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.196 Acc 94.396%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.186 Acc 95.042%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.181 Acc 95.106%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.183 Acc 92.969%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.196 Acc 94.346%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.198 Acc 94.306%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.191 Acc 94.518%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.194 Acc 94.442%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.195 Acc 94.444%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.186 Acc 95.243%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.179 Acc 95.351%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.176 Acc 93.750%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.182 Acc 94.848%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.187 Acc 94.671%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.187 Acc 94.599%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.187 Acc 94.543%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.188 Acc 94.561%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.190 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.191 Acc 94.895%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.184 Acc 94.994%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.184 Acc 94.686%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.189 Acc 94.586%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.188 Acc 94.518%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.189 Acc 94.584%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.189 Acc 94.553%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.184 Acc 95.258%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.178 Acc 95.254%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.219 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.183 Acc 94.833%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.185 Acc 94.671%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.184 Acc 94.695%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.188 Acc 94.582%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.186 Acc 94.623%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.177 Acc 95.250%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.184 Acc 94.616%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.188 Acc 94.586%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.191 Acc 94.599%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.188 Acc 94.627%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.187 Acc 94.640%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.187 Acc 95.042%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.182 Acc 95.002%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.176 Acc 94.887%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.831%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.180 Acc 94.861%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.180 Acc 94.843%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.181 Acc 94.812%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.175 Acc 95.410%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.174 Acc 93.750%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.177 Acc 94.926%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.182 Acc 94.955%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.181 Acc 94.962%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.181 Acc 94.890%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.181 Acc 94.891%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.161 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.187 Acc 95.119%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.181 Acc 95.130%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.173 Acc 94.957%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.179 Acc 94.873%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.180 Acc 94.804%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.180 Acc 94.761%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.179 Acc 94.754%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.179 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.184 Acc 95.166%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.178 Acc 95.340%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.238 Acc 93.750%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.180 Acc 94.918%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.180 Acc 94.846%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.843%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.181 Acc 94.872%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.180 Acc 94.873%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.173 Acc 92.188%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.196 Acc 94.539%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.192 Acc 94.648%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.327 Acc 93.750%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.174 Acc 94.895%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.181 Acc 94.873%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.177 Acc 94.960%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.176 Acc 94.985%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.175 Acc 94.987%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.184 Acc 95.390%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.178 Acc 95.367%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.138 Acc 94.531%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.171 Acc 95.196%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.169 Acc 95.118%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.170 Acc 95.092%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.172 Acc 95.034%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.173 Acc 95.047%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.183 Acc 95.065%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.178 Acc 95.239%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.137 Acc 98.438%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.163 Acc 95.080%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.174 Acc 94.928%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.171 Acc 95.022%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.173 Acc 95.112%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.173 Acc 95.085%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.173 Acc 95.413%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.167 Acc 95.623%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.418 Acc 90.625%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.167 Acc 94.995%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.168 Acc 95.083%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.169 Acc 95.058%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.170 Acc 95.042%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.172 Acc 95.010%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.182 Acc 95.305%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.176 Acc 95.266%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.164 Acc 95.135%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.168 Acc 95.095%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.074%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.170 Acc 95.125%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.171 Acc 95.118%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.421%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.171 Acc 95.390%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.199 Acc 92.969%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.173 Acc 94.949%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.168 Acc 95.103%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.168 Acc 95.079%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.168 Acc 95.137%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.167 Acc 95.146%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.182 Acc 95.359%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.177 Acc 95.421%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.124 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.165 Acc 95.374%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.165 Acc 95.359%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.170 Acc 95.253%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.170 Acc 95.196%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.169 Acc 95.213%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.187 Acc 95.243%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.179 Acc 95.351%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.114 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.162 Acc 95.266%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.159 Acc 95.476%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.160 Acc 95.416%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.162 Acc 95.377%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.165 Acc 95.341%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.152 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.190 Acc 95.374%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.184 Acc 95.367%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.155 Acc 95.475%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.164 Acc 95.250%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.160 Acc 95.341%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.161 Acc 95.318%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.162 Acc 95.291%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.117 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.176 Acc 95.475%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.172 Acc 95.425%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.193 Acc 95.312%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.163 Acc 95.413%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.168 Acc 95.176%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.165 Acc 95.266%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.163 Acc 95.344%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.164 Acc 95.345%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.128 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.170 Acc 95.591%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.163 Acc 95.744%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.160 Acc 95.421%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.157 Acc 95.507%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.159 Acc 95.437%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.160 Acc 95.414%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.161 Acc 95.414%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.088 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.179 Acc 95.336%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.417%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.096 Acc 96.875%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.164 Acc 95.243%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.164 Acc 95.246%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.161 Acc 95.287%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.163 Acc 95.266%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.161 Acc 95.339%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.182 Acc 95.351%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.177 Acc 95.363%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.155 Acc 95.506%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.154 Acc 95.546%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.157 Acc 95.489%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.157 Acc 95.484%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.159 Acc 95.461%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.102 Acc 96.875%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.178 Acc 95.336%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.173 Acc 95.402%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.089 Acc 98.438%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.148 Acc 95.753%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.155 Acc 95.569%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.155 Acc 95.564%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.157 Acc 95.542%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.157 Acc 95.540%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.127 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.185 Acc 95.266%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.180 Acc 95.301%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.122 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.152 Acc 95.630%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.152 Acc 95.666%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.154 Acc 95.593%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.158 Acc 95.488%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.158 Acc 95.531%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.144 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.172 Acc 95.676%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.165 Acc 95.763%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.156 Acc 95.421%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.155 Acc 95.449%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.154 Acc 95.538%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.153 Acc 95.624%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.153 Acc 95.646%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.180 Acc 92.969%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.192 Acc 95.096%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.186 Acc 95.095%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.142 Acc 96.009%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.146 Acc 95.833%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.146 Acc 95.832%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.151 Acc 95.727%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.150 Acc 95.777%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.177 Acc 95.459%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.172 Acc 95.522%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.171 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.151 Acc 95.730%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.154 Acc 95.763%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.155 Acc 95.699%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.154 Acc 95.712%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.155 Acc 95.660%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.165 Acc 95.869%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.161 Acc 95.915%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.151 Acc 95.612%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.151 Acc 95.614%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.153 Acc 95.622%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.152 Acc 95.621%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.130 Acc 95.312%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.182 Acc 95.545%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.174 Acc 95.553%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.144 Acc 95.978%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.150 Acc 95.697%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.151 Acc 95.640%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.150 Acc 95.700%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.150 Acc 95.765%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.128 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.176 Acc 95.707%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.172 Acc 95.666%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.140 Acc 95.900%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.145 Acc 95.965%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.144 Acc 95.871%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.149 Acc 95.764%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.149 Acc 95.707%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.135 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.174 Acc 95.484%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.147 Acc 95.947%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.148 Acc 95.934%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.149 Acc 95.806%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.147 Acc 95.763%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.149 Acc 95.780%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.138 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.184 Acc 95.343%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.178 Acc 95.375%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.141 Acc 96.009%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.147 Acc 95.775%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.144 Acc 95.839%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.148 Acc 95.743%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.149 Acc 95.648%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.174 Acc 95.707%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.168 Acc 95.658%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.299 Acc 93.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.134 Acc 96.248%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.136 Acc 96.137%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.142 Acc 95.907%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.144 Acc 95.872%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.145 Acc 95.807%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.172 Acc 95.467%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.168 Acc 95.499%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.201 Acc 96.094%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.147 Acc 95.900%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.149 Acc 95.829%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.147 Acc 95.832%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.143 Acc 95.911%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.145 Acc 95.893%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.078 Acc 96.875%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.171 Acc 95.684%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.168 Acc 95.756%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.086 Acc 98.438%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.142 Acc 95.962%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.143 Acc 95.861%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.143 Acc 95.881%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.144 Acc 95.887%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.145 Acc 95.858%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.175 Acc 95.560%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.170 Acc 95.600%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.191 Acc 96.094%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.722%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.139 Acc 95.977%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.142 Acc 95.920%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.144 Acc 95.874%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.146 Acc 95.847%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.183 Acc 95.591%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.176 Acc 95.588%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.141 Acc 95.885%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.143 Acc 95.833%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.142 Acc 95.785%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.143 Acc 95.850%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.143 Acc 95.879%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.181 Acc 95.374%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.174 Acc 95.557%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.152 Acc 95.885%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.148 Acc 95.814%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.144 Acc 95.876%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.144 Acc 95.903%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.142 Acc 95.910%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.165 Acc 95.869%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.160 Acc 95.864%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.131 Acc 96.233%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.136 Acc 96.051%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.138 Acc 96.016%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.141 Acc 95.938%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.141 Acc 95.967%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.129 Acc 94.531%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.178 Acc 95.668%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.175 Acc 95.592%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.131 Acc 96.241%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.136 Acc 96.012%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.136 Acc 96.125%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.138 Acc 96.029%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.139 Acc 96.033%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.181 Acc 95.722%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.174 Acc 95.794%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.106 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.141 Acc 95.978%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.138 Acc 96.028%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.141 Acc 96.006%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.143 Acc 95.928%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.141 Acc 95.986%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.179 Acc 95.684%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.174 Acc 95.565%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.146 Acc 95.715%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.138 Acc 95.892%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.136 Acc 95.938%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.137 Acc 95.963%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.138 Acc 95.988%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.170 Acc 95.748%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.136 Acc 95.978%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.135 Acc 96.067%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.137 Acc 96.022%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.139 Acc 95.936%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.115 Acc 97.656%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.179 Acc 95.622%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.172 Acc 95.752%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.066 Acc 99.219%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.134 Acc 96.264%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.134 Acc 96.230%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.134 Acc 96.234%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.136 Acc 96.107%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.136 Acc 96.102%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.106 Acc 96.094%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.168 Acc 95.643%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.095 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.130 Acc 96.152%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.134 Acc 96.083%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.134 Acc 96.065%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.136 Acc 96.081%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.107 Acc 95.312%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.167 Acc 95.885%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.162 Acc 95.927%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.072 Acc 99.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.129 Acc 96.380%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.132 Acc 96.241%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.131 Acc 96.205%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.135 Acc 96.113%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.136 Acc 96.064%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.115 Acc 96.094%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.173 Acc 95.784%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.167 Acc 95.822%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.109 Acc 96.094%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.127 Acc 96.496%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.131 Acc 96.323%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.133 Acc 96.179%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.135 Acc 96.084%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.069 Acc 97.656%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.168 Acc 95.893%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.162 Acc 95.931%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.137 Acc 96.279%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.138 Acc 96.160%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.136 Acc 96.120%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.134 Acc 96.109%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.134 Acc 96.084%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.179 Acc 95.661%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.175 Acc 95.600%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.140 Acc 97.656%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.140 Acc 96.109%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.138 Acc 96.109%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.138 Acc 96.078%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.139 Acc 96.000%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.137 Acc 96.064%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.181 Acc 95.800%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.176 Acc 95.783%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.121 Acc 96.604%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.128 Acc 96.292%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.131 Acc 96.268%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.130 Acc 96.246%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.131 Acc 96.215%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.168 Acc 95.707%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.164 Acc 95.892%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.132 Acc 96.187%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.132 Acc 96.164%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.129 Acc 96.203%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.132 Acc 96.133%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.133 Acc 96.131%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.173 Acc 95.521%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.120 Acc 96.558%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.126 Acc 96.377%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.128 Acc 96.377%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.128 Acc 96.320%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.129 Acc 96.298%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.126 Acc 92.969%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.174 Acc 95.614%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.169 Acc 95.662%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.118 Acc 96.566%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.125 Acc 96.397%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.126 Acc 96.416%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.131 Acc 96.289%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.131 Acc 96.231%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.179 Acc 95.483%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.173 Acc 95.596%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.123 Acc 96.210%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.122 Acc 96.343%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.124 Acc 96.369%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.126 Acc 96.347%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.127 Acc 96.335%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.123 Acc 96.875%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.166 Acc 96.009%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.162 Acc 96.070%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.124 Acc 96.388%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.133 Acc 96.122%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.131 Acc 96.178%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.132 Acc 96.151%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.182 Acc 95.784%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.175 Acc 95.833%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.292 Acc 94.531%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.125 Acc 96.233%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.124 Acc 96.292%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.128 Acc 96.239%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.126 Acc 96.308%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.128 Acc 96.275%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.139 Acc 96.875%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.177 Acc 95.577%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.130 Acc 96.310%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.128 Acc 96.261%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.127 Acc 96.249%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.128 Acc 96.226%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.129 Acc 96.201%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.071 Acc 96.094%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.171 Acc 95.769%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.165 Acc 95.907%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.124 Acc 96.481%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.132 Acc 96.238%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.127 Acc 96.307%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.126 Acc 96.341%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.126 Acc 96.329%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.081 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.182 Acc 95.869%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.174 Acc 95.903%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.127 Acc 96.272%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.125 Acc 96.401%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.126 Acc 96.358%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.128 Acc 96.289%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.186 Acc 95.529%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.178 Acc 95.573%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.150 Acc 96.094%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.122 Acc 96.318%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.122 Acc 96.397%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.126 Acc 96.286%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.124 Acc 96.329%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.127 Acc 96.247%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.117 Acc 96.094%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.172 Acc 95.947%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.165 Acc 96.012%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.120 Acc 95.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.124 Acc 96.426%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.125 Acc 96.420%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.122 Acc 96.452%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.124 Acc 96.419%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.124 Acc 96.393%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.082 Acc 96.875%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.178 Acc 95.722%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.170 Acc 95.787%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.190 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.129 Acc 96.078%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.122 Acc 96.253%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.122 Acc 96.322%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.121 Acc 96.337%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.122 Acc 96.334%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.145 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.185 Acc 95.444%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.181 Acc 95.468%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.120 Acc 96.419%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.126 Acc 96.343%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.124 Acc 96.309%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.124 Acc 96.242%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.124 Acc 96.254%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.114 Acc 97.656%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.166 Acc 95.978%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.161 Acc 95.993%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.092 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.124 Acc 96.496%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.124 Acc 96.335%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.121 Acc 96.436%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.123 Acc 96.401%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.134 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.179 Acc 95.575%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.173 Acc 95.775%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.111 Acc 96.566%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.116 Acc 96.541%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.118 Acc 96.538%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.120 Acc 96.495%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.121 Acc 96.501%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.199 Acc 95.328%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.193 Acc 95.324%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.118 Acc 96.612%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.120 Acc 96.475%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.122 Acc 96.470%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.120 Acc 96.520%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.122 Acc 96.482%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.175 Acc 95.583%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.170 Acc 95.682%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.117 Acc 96.488%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.118 Acc 96.479%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.120 Acc 96.411%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.121 Acc 96.420%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.084 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.178 Acc 95.753%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.171 Acc 95.822%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.113 Acc 96.774%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.115 Acc 96.786%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.115 Acc 96.724%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.116 Acc 96.643%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.118 Acc 96.601%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.126 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.179 Acc 95.645%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.171 Acc 95.759%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.117 Acc 96.419%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.121 Acc 96.350%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.119 Acc 96.457%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.121 Acc 96.415%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.121 Acc 96.392%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.181 Acc 95.668%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.176 Acc 95.670%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.176 Acc 96.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.119 Acc 96.627%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.115 Acc 96.657%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.114 Acc 96.667%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.118 Acc 96.557%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.120 Acc 96.496%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.078 Acc 98.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.171 Acc 95.908%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.165 Acc 95.911%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.114 Acc 96.426%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.118 Acc 96.416%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.118 Acc 96.457%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.116 Acc 96.552%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.117 Acc 96.513%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.180 Acc 95.668%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.174 Acc 95.725%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.112 Acc 96.689%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.116 Acc 96.692%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.115 Acc 96.711%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.117 Acc 96.608%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.119 Acc 96.571%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.087 Acc 96.875%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.184 Acc 95.622%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.178 Acc 95.647%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.124 Acc 94.531%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.109 Acc 96.542%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.108 Acc 96.549%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.111 Acc 96.623%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.113 Acc 96.585%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.115 Acc 96.579%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.183 Acc 95.575%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.178 Acc 95.608%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.113 Acc 96.558%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.114 Acc 96.661%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.111 Acc 96.763%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.112 Acc 96.686%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.114 Acc 96.633%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.096 Acc 98.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.172 Acc 95.970%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.166 Acc 96.020%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.106 Acc 96.898%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.110 Acc 96.727%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.112 Acc 96.683%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.115 Acc 96.624%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.116 Acc 96.552%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.132 Acc 97.656%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.181 Acc 95.661%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.175 Acc 95.631%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.051 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.107 Acc 96.914%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.113 Acc 96.692%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.115 Acc 96.628%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.116 Acc 96.591%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.192 Acc 95.475%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.185 Acc 95.604%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.106 Acc 96.937%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.112 Acc 96.747%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.110 Acc 96.808%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.112 Acc 96.744%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.113 Acc 96.664%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.128 Acc 97.656%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.176 Acc 95.529%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.169 Acc 95.627%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.106 Acc 96.782%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.109 Acc 96.688%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.113 Acc 96.605%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.115 Acc 96.559%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.114 Acc 96.562%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.183 Acc 95.343%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.176 Acc 95.382%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.103 Acc 96.860%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.110 Acc 96.708%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.113 Acc 96.654%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.113 Acc 96.635%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.114 Acc 96.625%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.142 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.175 Acc 95.862%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.169 Acc 95.876%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.104 Acc 97.084%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.109 Acc 96.821%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.113 Acc 96.683%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.114 Acc 96.624%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.174 Acc 95.661%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.167 Acc 95.802%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.096 Acc 97.239%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.102 Acc 97.003%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.105 Acc 96.924%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.108 Acc 96.830%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.109 Acc 96.799%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.095 Acc 96.094%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.183 Acc 95.614%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.178 Acc 95.748%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.107 Acc 97.084%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.106 Acc 96.968%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.107 Acc 96.922%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.111 Acc 96.803%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.113 Acc 96.728%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.111 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.184 Acc 95.645%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.178 Acc 95.709%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.105 Acc 96.860%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.108 Acc 96.770%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.109 Acc 96.735%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.110 Acc 96.704%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.113 Acc 96.668%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.115 Acc 96.875%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.187 Acc 95.661%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.178 Acc 95.833%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.103 Acc 96.890%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.104 Acc 96.891%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.108 Acc 96.810%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.109 Acc 96.776%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.110 Acc 96.744%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.175 Acc 95.800%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.168 Acc 95.845%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.106 Acc 96.782%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.108 Acc 96.844%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.110 Acc 96.771%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.110 Acc 96.774%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.111 Acc 96.744%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.116 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.182 Acc 95.715%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.175 Acc 95.837%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.115 Acc 96.875%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.105 Acc 96.883%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.105 Acc 96.844%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.111 Acc 96.686%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.096 Acc 96.875%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.189 Acc 95.568%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.179 Acc 95.728%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.151 Acc 96.875%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.104 Acc 96.852%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.103 Acc 96.883%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.105 Acc 96.761%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.108 Acc 96.709%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.110 Acc 96.685%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.172 Acc 95.784%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.165 Acc 95.880%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.126 Acc 98.438%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.106 Acc 96.968%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.107 Acc 96.906%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.108 Acc 96.911%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.107 Acc 96.879%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.108 Acc 96.817%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.123 Acc 96.875%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.182 Acc 95.545%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.175 Acc 95.623%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.105 Acc 96.829%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.103 Acc 96.922%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.106 Acc 96.870%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.107 Acc 96.865%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.109 Acc 96.820%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.179 Acc 95.715%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.172 Acc 95.837%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.123 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.101 Acc 96.813%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.103 Acc 96.747%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.107 Acc 96.711%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.106 Acc 96.700%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.108 Acc 96.650%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.180 Acc 95.893%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.172 Acc 95.861%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.100 Acc 97.037%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.100 Acc 97.011%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.104 Acc 96.901%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.105 Acc 96.869%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.107 Acc 96.834%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.125 Acc 96.094%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.183 Acc 95.715%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.176 Acc 95.713%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.094 Acc 97.161%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.103 Acc 96.957%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.105 Acc 96.932%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.106 Acc 96.857%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.107 Acc 96.834%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.134 Acc 96.094%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.187 Acc 95.328%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.181 Acc 95.515%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.152 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.104 Acc 96.790%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.106 Acc 96.770%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.105 Acc 96.823%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.105 Acc 96.834%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.107 Acc 96.792%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.102 Acc 97.656%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.185 Acc 95.637%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.178 Acc 95.771%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.100 Acc 96.976%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.095 Acc 97.042%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.101 Acc 96.901%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.105 Acc 96.828%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.106 Acc 96.791%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.189 Acc 95.405%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.182 Acc 95.608%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.098 Acc 97.246%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.097 Acc 97.287%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.098 Acc 97.168%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.102 Acc 97.058%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.102 Acc 97.008%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.076 Acc 98.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.184 Acc 95.583%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.176 Acc 95.682%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.100 Acc 95.312%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.097 Acc 97.115%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.097 Acc 97.034%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.101 Acc 96.994%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.103 Acc 96.904%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.104 Acc 96.898%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.101 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.189 Acc 95.429%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.183 Acc 95.522%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.135 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.099 Acc 97.068%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.101 Acc 97.062%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.102 Acc 96.981%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.101 Acc 96.988%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.104 Acc 96.908%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.192 Acc 95.653%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.183 Acc 95.740%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.103 Acc 96.852%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.105 Acc 96.758%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.106 Acc 96.776%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.106 Acc 96.764%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.106 Acc 96.778%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.113 Acc 96.875%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.181 Acc 95.459%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.172 Acc 95.701%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.103 Acc 97.045%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.104 Acc 96.887%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.104 Acc 96.922%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.104 Acc 96.887%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.106 Acc 96.810%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.173 Acc 95.800%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.165 Acc 95.868%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.089 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.100 Acc 97.014%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.098 Acc 96.980%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.100 Acc 96.888%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.103 Acc 96.832%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.102 Acc 96.861%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.054 Acc 98.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.180 Acc 95.715%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.173 Acc 95.783%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.099 Acc 96.983%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.101 Acc 96.980%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.104 Acc 96.888%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.103 Acc 96.894%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.182 Acc 96.001%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.173 Acc 96.051%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.076 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.094 Acc 97.138%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.097 Acc 97.038%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.102 Acc 96.893%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.102 Acc 96.869%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.105 Acc 96.777%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.181 Acc 95.684%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.177 Acc 95.713%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.093 Acc 97.177%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.097 Acc 97.058%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.102 Acc 96.966%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.102 Acc 96.939%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.103 Acc 96.883%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.186 Acc 95.545%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.178 Acc 95.655%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.092 Acc 97.239%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.096 Acc 97.108%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.100 Acc 96.987%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.102 Acc 96.912%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.116 Acc 97.656%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.184 Acc 95.661%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.833%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.095 Acc 97.092%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.099 Acc 97.015%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.098 Acc 96.979%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.102 Acc 96.924%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.102 Acc 96.914%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.098 Acc 96.875%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.194 Acc 95.792%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.184 Acc 95.837%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.096 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.092 Acc 97.432%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.095 Acc 97.275%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.097 Acc 97.140%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.098 Acc 97.070%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.099 Acc 97.022%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.184 Acc 95.692%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.174 Acc 95.822%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.102 Acc 96.960%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.101 Acc 96.953%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.100 Acc 96.997%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.099 Acc 97.031%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.099 Acc 97.012%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.190 Acc 95.715%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.181 Acc 95.798%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.106 Acc 96.728%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.102 Acc 96.824%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.103 Acc 96.776%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.103 Acc 96.811%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.105 Acc 96.799%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.076 Acc 97.656%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.196 Acc 95.653%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.187 Acc 95.752%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.195 Acc 92.969%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.106 Acc 96.852%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.101 Acc 97.120%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.098 Acc 97.145%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.098 Acc 97.083%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.100 Acc 97.054%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.192 Acc 95.374%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.182 Acc 95.596%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.094 Acc 97.192%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.094 Acc 97.178%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.096 Acc 97.153%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.098 Acc 97.072%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.098 Acc 97.040%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.080 Acc 98.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.187 Acc 95.521%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.181 Acc 95.651%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.091 Acc 97.215%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.097 Acc 97.108%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.097 Acc 97.057%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.097 Acc 97.117%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.099 Acc 97.051%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.102 Acc 96.094%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.194 Acc 95.467%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.186 Acc 95.643%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.095 Acc 96.898%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.096 Acc 96.976%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.098 Acc 96.987%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.097 Acc 96.994%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.098 Acc 96.961%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.119 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.182 Acc 95.643%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.094 Acc 97.200%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.097 Acc 97.069%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.100 Acc 96.982%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.098 Acc 97.043%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.073 Acc 98.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.182 Acc 95.815%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.175 Acc 95.880%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.095 Acc 96.960%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.093 Acc 97.104%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.094 Acc 97.114%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.097 Acc 97.083%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.124 Acc 97.656%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.196 Acc 95.707%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.187 Acc 95.725%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.093 Acc 96.991%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.095 Acc 97.044%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.095 Acc 97.037%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.097 Acc 97.020%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.083 Acc 97.656%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.183 Acc 95.645%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.176 Acc 95.697%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.140 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.092 Acc 97.123%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.095 Acc 97.062%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.096 Acc 97.080%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.096 Acc 97.079%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.098 Acc 97.656%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.183 Acc 95.637%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.176 Acc 95.713%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.101 Acc 98.438%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.089 Acc 97.416%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.094 Acc 97.209%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.095 Acc 97.199%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.094 Acc 97.189%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.094 Acc 97.178%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.188 Acc 95.645%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.179 Acc 95.736%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.112 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.096 Acc 96.991%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.094 Acc 97.174%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.094 Acc 97.127%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.095 Acc 97.107%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.098 Acc 97.032%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.109 Acc 96.875%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.187 Acc 95.738%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.178 Acc 95.857%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.145 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.090 Acc 97.200%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.094 Acc 97.174%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.093 Acc 97.166%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.094 Acc 97.173%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.096 Acc 97.139%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.092 Acc 96.875%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.184 Acc 95.614%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.177 Acc 95.666%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.088 Acc 97.239%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.089 Acc 97.260%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.091 Acc 97.207%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.094 Acc 97.089%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.094 Acc 97.081%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.188 Acc 95.722%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.181 Acc 95.841%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.083 Acc 97.556%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.087 Acc 97.419%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.089 Acc 97.293%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.092 Acc 97.157%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.094 Acc 97.129%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.077 Acc 98.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.189 Acc 95.560%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.177 Acc 95.740%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.087 Acc 97.287%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.090 Acc 97.210%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.092 Acc 97.113%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.092 Acc 97.146%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.088 Acc 96.875%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.177 Acc 95.810%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.114 Acc 96.094%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.087 Acc 97.370%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.092 Acc 97.349%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.093 Acc 97.259%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.096 Acc 97.146%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.096 Acc 97.125%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.184 Acc 95.599%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.177 Acc 95.705%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.088 Acc 97.401%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.091 Acc 97.341%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.092 Acc 97.285%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.091 Acc 97.241%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.093 Acc 97.185%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.097 Acc 97.656%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.196 Acc 95.606%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.188 Acc 95.635%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.092 Acc 97.037%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.090 Acc 97.170%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.093 Acc 97.046%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.095 Acc 97.029%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.096 Acc 96.987%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.125 Acc 97.656%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.207 Acc 95.336%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.196 Acc 95.484%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.090 Acc 97.138%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.090 Acc 97.104%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.091 Acc 97.137%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.092 Acc 97.120%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.093 Acc 97.115%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.137 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.192 Acc 95.552%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.186 Acc 95.651%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.085 Acc 97.316%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.086 Acc 97.330%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.090 Acc 97.184%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.092 Acc 97.146%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.090 Acc 97.171%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.077 Acc 97.656%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.197 Acc 95.506%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.187 Acc 95.666%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.076 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.093 Acc 97.115%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.091 Acc 97.159%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.092 Acc 97.153%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.092 Acc 97.146%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.093 Acc 97.129%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.190 Acc 95.692%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.180 Acc 95.853%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.088 Acc 97.277%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.088 Acc 97.299%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.093 Acc 97.158%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.094 Acc 97.095%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.095 Acc 97.051%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.097 Acc 96.875%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.200 Acc 95.336%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.190 Acc 95.538%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.089 Acc 97.239%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.092 Acc 97.143%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.092 Acc 97.168%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.093 Acc 97.087%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.093 Acc 97.092%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.089 Acc 96.875%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.193 Acc 95.583%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.182 Acc 95.763%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.172 Acc 96.094%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.082 Acc 97.463%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.093 Acc 97.109%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.092 Acc 97.154%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.083 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.189 Acc 95.661%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.182 Acc 95.728%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.099 Acc 95.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.090 Acc 97.099%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.091 Acc 97.077%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.090 Acc 97.140%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.088 Acc 97.167%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.090 Acc 97.149%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.191 Acc 95.738%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.184 Acc 95.849%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.087 Acc 97.177%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.088 Acc 97.194%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.090 Acc 97.212%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.090 Acc 97.245%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.091 Acc 97.188%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.066 Acc 96.875%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.199 Acc 95.490%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.186 Acc 95.728%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.185 Acc 94.531%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.088 Acc 97.256%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.089 Acc 97.228%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.091 Acc 97.224%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.092 Acc 97.181%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.113 Acc 97.656%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.198 Acc 95.568%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.190 Acc 95.697%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.091 Acc 97.061%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.090 Acc 97.097%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.090 Acc 97.202%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.090 Acc 97.209%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.133 Acc 98.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.198 Acc 95.707%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.190 Acc 95.721%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.080 Acc 97.486%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.087 Acc 97.345%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.089 Acc 97.243%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.090 Acc 97.268%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.108 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.203 Acc 95.173%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.192 Acc 95.390%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.086 Acc 97.246%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.086 Acc 97.198%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.089 Acc 97.181%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.089 Acc 97.216%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.090 Acc 97.202%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.207 Acc 95.405%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.198 Acc 95.553%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.090 Acc 97.239%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.088 Acc 97.268%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.090 Acc 97.251%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.090 Acc 97.195%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.091 Acc 97.149%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.132 Acc 97.656%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.190 Acc 95.506%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.181 Acc 95.643%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.085 Acc 97.362%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.087 Acc 97.310%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.088 Acc 97.288%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.088 Acc 97.284%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.088 Acc 97.260%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.193 Acc 95.467%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.184 Acc 95.635%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.083 Acc 97.362%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.089 Acc 97.201%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.088 Acc 97.251%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.088 Acc 97.241%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.090 Acc 97.235%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.118 Acc 96.875%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.189 Acc 95.692%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.181 Acc 95.771%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.084 Acc 97.370%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.089 Acc 97.260%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.089 Acc 97.282%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.089 Acc 97.269%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.089 Acc 97.262%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.197 Acc 95.444%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.187 Acc 95.596%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.117 Acc 94.531%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.083 Acc 97.409%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.085 Acc 97.334%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.087 Acc 97.228%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.088 Acc 97.212%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.089 Acc 97.182%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.123 Acc 96.094%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.200 Acc 95.637%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.190 Acc 95.787%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.081 Acc 97.300%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.084 Acc 97.310%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.084 Acc 97.366%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.084 Acc 97.385%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.087 Acc 97.294%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.193 Acc 95.699%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.184 Acc 95.783%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.108 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.078 Acc 97.517%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.082 Acc 97.357%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.084 Acc 97.290%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.083 Acc 97.366%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.085 Acc 97.329%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.199 Acc 95.614%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.188 Acc 95.791%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.082 Acc 97.494%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.085 Acc 97.299%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.088 Acc 97.251%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.086 Acc 97.294%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.087 Acc 97.271%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.198 Acc 95.653%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.189 Acc 95.767%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.087 Acc 97.316%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.090 Acc 97.186%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.092 Acc 97.127%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.092 Acc 97.119%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.090 Acc 97.160%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.133 Acc 96.875%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.195 Acc 95.351%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.187 Acc 95.522%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.055 Acc 98.438%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.078 Acc 97.525%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.083 Acc 97.322%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.088 Acc 97.224%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.089 Acc 97.248%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.127 Acc 98.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.196 Acc 95.684%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.186 Acc 95.931%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.082 Acc 97.409%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.084 Acc 97.338%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.085 Acc 97.358%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.086 Acc 97.346%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.123 Acc 97.656%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.199 Acc 95.336%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.191 Acc 95.487%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.081 Acc 97.478%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.084 Acc 97.419%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.088 Acc 97.301%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.086 Acc 97.323%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.086 Acc 97.319%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.118 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.205 Acc 95.722%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.194 Acc 95.759%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.085 Acc 97.215%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.085 Acc 97.275%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.087 Acc 97.225%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.085 Acc 97.329%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.086 Acc 97.294%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.111 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.201 Acc 95.421%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.191 Acc 95.596%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.083 Acc 97.478%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.084 Acc 97.388%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.084 Acc 97.433%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.085 Acc 97.360%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.086 Acc 97.324%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.135 Acc 98.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.208 Acc 95.320%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.200 Acc 95.484%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.081 Acc 97.339%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.083 Acc 97.396%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.083 Acc 97.428%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.084 Acc 97.372%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.086 Acc 97.284%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.098 Acc 97.656%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.187 Acc 95.761%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.179 Acc 95.911%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.086 Acc 97.177%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.084 Acc 97.291%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.084 Acc 97.332%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.084 Acc 97.337%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.084 Acc 97.340%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.102 Acc 97.656%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.205 Acc 95.514%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.192 Acc 95.736%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.077 Acc 97.509%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.080 Acc 97.392%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.084 Acc 97.282%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.087 Acc 97.196%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.086 Acc 97.202%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.108 Acc 96.875%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.220 Acc 95.676%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.207 Acc 95.787%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.046 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.076 Acc 97.602%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.079 Acc 97.563%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.083 Acc 97.381%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.085 Acc 97.337%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.084 Acc 97.371%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.056 Acc 98.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.201 Acc 95.490%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.190 Acc 95.759%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.187 Acc 93.750%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.088 Acc 97.198%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.086 Acc 97.265%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.088 Acc 97.234%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.114 Acc 97.656%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.208 Acc 95.467%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.196 Acc 95.565%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.203 Acc 89.844%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.080 Acc 97.277%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.079 Acc 97.338%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.081 Acc 97.399%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.083 Acc 97.329%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.084 Acc 97.291%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.107 Acc 97.656%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.201 Acc 95.568%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.192 Acc 95.779%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.066 Acc 97.656%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.080 Acc 97.532%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.081 Acc 97.493%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.083 Acc 97.448%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.082 Acc 97.441%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.081 Acc 98.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.191 Acc 95.777%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.182 Acc 95.896%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.078 Acc 97.579%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.080 Acc 97.560%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.081 Acc 97.473%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.083 Acc 97.425%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.208 Acc 95.475%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.199 Acc 95.612%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.076 Acc 97.556%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.083 Acc 97.353%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.083 Acc 97.341%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.083 Acc 97.365%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.089 Acc 97.656%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.201 Acc 95.753%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.190 Acc 95.849%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.080 Acc 97.525%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.081 Acc 97.442%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.082 Acc 97.469%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.084 Acc 97.407%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.083 Acc 97.439%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.205 Acc 95.606%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.194 Acc 95.713%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.077 Acc 97.525%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.082 Acc 97.411%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.081 Acc 97.459%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.081 Acc 97.432%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.082 Acc 97.404%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.126 Acc 97.656%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.200 Acc 95.707%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.189 Acc 95.849%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.141 Acc 94.531%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.080 Acc 97.563%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.082 Acc 97.415%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.083 Acc 97.387%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.083 Acc 97.362%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.104 Acc 97.656%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.195 Acc 95.637%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.188 Acc 95.721%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.078 Acc 97.424%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.080 Acc 97.431%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.081 Acc 97.397%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.082 Acc 97.374%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.094 Acc 96.875%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.197 Acc 95.637%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.189 Acc 95.779%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.078 Acc 97.424%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.081 Acc 97.334%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.082 Acc 97.379%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.081 Acc 97.440%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.082 Acc 97.377%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.203 Acc 95.398%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.191 Acc 95.573%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.079 Acc 97.401%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.081 Acc 97.396%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.081 Acc 97.379%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.080 Acc 97.450%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.106 Acc 96.875%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.206 Acc 95.560%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.194 Acc 95.697%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.078 Acc 97.625%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.080 Acc 97.586%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.079 Acc 97.597%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.079 Acc 97.592%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.081 Acc 97.555%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.082 Acc 97.656%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.436%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.188 Acc 95.484%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.079 Acc 97.432%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.077 Acc 97.501%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.078 Acc 97.508%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.080 Acc 97.450%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.081 Acc 97.429%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.090 Acc 96.875%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.198 Acc 95.684%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.190 Acc 95.767%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.072 Acc 97.811%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.075 Acc 97.651%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.078 Acc 97.567%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.085 Acc 97.656%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.201 Acc 95.637%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.192 Acc 95.682%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.075 Acc 97.625%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.079 Acc 97.458%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.078 Acc 97.501%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.079 Acc 97.485%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.081 Acc 97.450%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.132 Acc 96.875%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.204 Acc 95.351%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.193 Acc 95.522%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.075 Acc 97.556%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.078 Acc 97.431%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.078 Acc 97.469%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.079 Acc 97.456%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.079 Acc 97.478%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.112 Acc 96.875%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.203 Acc 95.661%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.195 Acc 95.756%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.076 Acc 97.664%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.078 Acc 97.602%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.079 Acc 97.550%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.078 Acc 97.516%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.079 Acc 97.513%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.145 Acc 96.875%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.209 Acc 95.436%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.200 Acc 95.655%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.074 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.072 Acc 97.757%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.080 Acc 97.528%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.079 Acc 97.519%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.079 Acc 97.496%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.079 Acc 97.475%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.206 Acc 95.359%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.200 Acc 95.472%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.076 Acc 97.641%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.080 Acc 97.458%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.080 Acc 97.428%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.080 Acc 97.426%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.080 Acc 97.416%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.099 Acc 96.094%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.213 Acc 95.537%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.202 Acc 95.658%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3569378e5fdb44eb92ce969047f8df3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.315 Acc 12.500%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.246 Acc 18.967%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.060 Acc 26.322%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.784 Acc 37.111%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.570 Acc 45.225%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.394 Acc 51.790%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.626 Acc 80.469%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.592 Acc 81.095%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.579 Acc 81.573%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.633 Acc 74.219%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.516 Acc 84.120%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.495 Acc 84.810%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.474 Acc 85.535%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.460 Acc 85.955%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.449 Acc 86.320%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.370 Acc 87.500%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.362 Acc 89.163%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.355 Acc 89.401%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.345 Acc 88.281%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.372 Acc 88.846%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.369 Acc 88.895%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.364 Acc 88.995%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.363 Acc 89.022%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.356 Acc 89.240%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.289 Acc 91.406%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.353 Acc 89.712%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.350 Acc 89.848%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.317 Acc 90.625%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.322 Acc 89.975%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.319 Acc 90.302%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.319 Acc 90.238%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.321 Acc 90.253%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.318 Acc 90.349%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.264 Acc 90.625%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.293 Acc 91.925%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.287 Acc 91.985%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.330 Acc 91.406%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.310 Acc 90.702%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.298 Acc 91.053%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.296 Acc 91.230%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.291 Acc 91.301%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.289 Acc 91.372%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.320 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.291 Acc 91.499%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.286 Acc 91.402%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.399 Acc 90.625%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.280 Acc 91.654%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.277 Acc 91.589%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.272 Acc 91.780%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.272 Acc 91.835%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.273 Acc 91.852%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.246 Acc 92.969%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.243 Acc 93.108%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.237 Acc 93.229%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.242 Acc 93.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.270 Acc 92.133%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.255 Acc 92.510%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.257 Acc 92.413%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.255 Acc 92.515%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.255 Acc 92.527%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.224 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.250 Acc 93.688%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.247 Acc 93.738%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.187 Acc 95.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.236 Acc 92.969%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.246 Acc 92.829%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.244 Acc 92.777%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.245 Acc 92.700%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.244 Acc 92.763%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.221 Acc 94.083%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.218 Acc 94.100%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.168 Acc 96.094%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.238 Acc 93.069%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.242 Acc 92.953%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.237 Acc 93.088%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.237 Acc 93.080%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.236 Acc 93.126%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.222 Acc 94.106%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.219 Acc 94.034%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.231 Acc 93.317%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.233 Acc 93.151%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.234 Acc 93.174%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.231 Acc 93.224%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.230 Acc 93.306%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.245 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.222 Acc 94.044%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.218 Acc 94.030%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.215 Acc 93.657%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.212 Acc 93.769%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.215 Acc 93.760%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.220 Acc 93.678%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.222 Acc 93.613%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.215 Acc 94.253%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.211 Acc 94.298%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.168 Acc 96.875%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.218 Acc 93.742%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.215 Acc 93.773%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.214 Acc 93.721%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.214 Acc 93.732%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.215 Acc 93.775%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.206 Acc 94.578%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.204 Acc 94.547%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.240 Acc 91.406%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.191 Acc 94.400%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.201 Acc 94.290%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.204 Acc 94.124%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.206 Acc 94.103%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.208 Acc 94.038%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.193 Acc 92.969%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.228 Acc 93.936%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.227 Acc 93.925%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.249 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.207 Acc 93.912%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.205 Acc 94.030%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.204 Acc 94.202%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.205 Acc 94.116%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.204 Acc 94.141%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.231 Acc 92.969%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.210 Acc 94.678%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.208 Acc 94.706%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.193 Acc 94.307%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.195 Acc 94.317%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.194 Acc 94.427%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.196 Acc 94.401%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.197 Acc 94.357%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.205 Acc 94.361%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.207 Acc 94.201%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.163 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.192 Acc 94.570%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.193 Acc 94.430%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.191 Acc 94.534%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.190 Acc 94.601%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.193 Acc 94.537%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.254 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.216 Acc 94.237%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.214 Acc 94.201%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.251 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.182 Acc 94.670%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.184 Acc 94.609%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.188 Acc 94.557%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.190 Acc 94.494%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.192 Acc 94.438%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.193 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.192 Acc 95.011%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.189 Acc 94.990%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.159 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.172 Acc 94.995%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.181 Acc 94.819%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.180 Acc 94.923%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.181 Acc 94.859%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.181 Acc 94.835%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.284 Acc 92.188%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.224 Acc 94.175%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.225 Acc 94.038%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.209 Acc 95.312%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.169 Acc 95.251%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.172 Acc 94.982%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.173 Acc 94.931%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.177 Acc 94.827%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.181 Acc 94.762%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.188 Acc 94.988%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.186 Acc 95.052%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.175 Acc 95.189%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.177 Acc 95.079%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.179 Acc 94.939%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.180 Acc 94.977%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.178 Acc 94.987%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.189 Acc 94.810%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.188 Acc 94.838%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.176 Acc 95.173%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.169 Acc 95.344%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.171 Acc 95.219%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.171 Acc 95.225%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.171 Acc 95.186%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.186 Acc 95.343%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.185 Acc 95.278%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.165 Acc 95.506%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.168 Acc 95.417%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.171 Acc 95.294%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.169 Acc 95.342%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.170 Acc 95.309%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.219 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.187 Acc 95.289%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.187 Acc 95.297%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.166 Acc 95.459%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.159 Acc 95.561%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.159 Acc 95.528%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.162 Acc 95.437%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.162 Acc 95.422%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.204 Acc 94.949%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.203 Acc 94.885%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.166 Acc 95.374%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.161 Acc 95.441%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.161 Acc 95.393%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.159 Acc 95.453%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.160 Acc 95.461%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.192 Acc 95.483%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.193 Acc 95.347%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.165 Acc 97.656%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.159 Acc 95.575%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.156 Acc 95.588%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.160 Acc 95.476%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.159 Acc 95.509%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.158 Acc 95.545%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.191 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.177 Acc 95.235%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.174 Acc 95.344%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.147 Acc 95.761%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.153 Acc 95.666%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.155 Acc 95.559%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.155 Acc 95.515%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.159 Acc 95.433%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.200 Acc 92.969%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.182 Acc 95.622%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.180 Acc 95.627%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.146 Acc 95.746%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.154 Acc 95.674%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.151 Acc 95.715%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.155 Acc 95.599%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.154 Acc 95.582%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.146 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.171 Acc 95.490%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.168 Acc 95.561%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.153 Acc 95.761%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.151 Acc 95.690%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.151 Acc 95.673%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.149 Acc 95.700%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.152 Acc 95.559%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.171 Acc 95.707%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.170 Acc 95.736%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.144 Acc 95.939%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.143 Acc 95.884%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.145 Acc 95.904%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.147 Acc 95.874%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.149 Acc 95.799%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.206 Acc 94.338%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.203 Acc 94.512%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.137 Acc 96.125%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.141 Acc 96.024%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.146 Acc 95.883%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.147 Acc 95.869%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.130 Acc 94.531%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.170 Acc 95.591%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.168 Acc 95.588%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.104 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.136 Acc 96.148%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.141 Acc 96.070%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.144 Acc 96.021%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.144 Acc 96.000%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.145 Acc 95.904%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.167 Acc 95.738%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.164 Acc 95.721%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.164 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.133 Acc 96.256%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.141 Acc 96.055%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.140 Acc 96.073%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.141 Acc 96.014%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.141 Acc 96.036%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.177 Acc 95.312%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.175 Acc 95.437%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.129 Acc 96.272%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.133 Acc 96.241%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.138 Acc 96.102%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.140 Acc 96.016%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.139 Acc 96.044%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.169 Acc 95.645%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.167 Acc 95.678%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.132 Acc 96.148%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.132 Acc 96.156%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.133 Acc 96.127%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.135 Acc 96.084%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.138 Acc 96.064%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.163 Acc 93.750%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.172 Acc 95.599%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.169 Acc 95.577%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.150 Acc 95.312%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.124 Acc 96.372%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.127 Acc 96.288%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.131 Acc 96.252%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.132 Acc 96.244%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.135 Acc 96.198%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.118 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.167 Acc 95.653%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.162 Acc 95.864%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.170 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.127 Acc 96.419%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.135 Acc 96.121%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.134 Acc 96.198%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.132 Acc 96.193%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.134 Acc 96.139%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.162 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.171 Acc 95.645%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.169 Acc 95.561%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.127 Acc 96.504%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.130 Acc 96.432%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.132 Acc 96.325%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.131 Acc 96.292%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.131 Acc 96.278%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.177 Acc 95.351%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.468%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.264 Acc 95.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.123 Acc 96.566%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.124 Acc 96.568%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.124 Acc 96.543%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.125 Acc 96.452%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.127 Acc 96.401%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.162 Acc 94.531%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.171 Acc 95.452%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.170 Acc 95.569%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.119 Acc 96.612%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.122 Acc 96.545%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.122 Acc 96.540%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.124 Acc 96.442%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.125 Acc 96.445%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.148 Acc 96.875%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.174 Acc 95.614%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.171 Acc 95.732%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.120 Acc 96.705%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.117 Acc 96.681%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.122 Acc 96.548%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.123 Acc 96.493%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.123 Acc 96.473%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.192 Acc 95.042%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.189 Acc 95.048%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.085 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.114 Acc 96.597%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.113 Acc 96.591%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.116 Acc 96.517%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.119 Acc 96.421%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.122 Acc 96.390%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.189 Acc 95.583%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.189 Acc 95.519%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.062 Acc 99.219%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.117 Acc 96.836%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.119 Acc 96.805%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.121 Acc 96.665%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.119 Acc 96.668%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.121 Acc 96.621%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.116 Acc 95.312%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.187 Acc 95.065%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.182 Acc 95.188%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.116 Acc 96.682%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.122 Acc 96.416%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.119 Acc 96.462%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.119 Acc 96.472%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.120 Acc 96.540%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.164 Acc 95.808%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.160 Acc 95.958%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.115 Acc 96.627%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.114 Acc 96.673%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.115 Acc 96.639%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.116 Acc 96.606%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.117 Acc 96.591%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.214 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.179 Acc 95.235%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.175 Acc 95.417%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.117 Acc 97.656%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.113 Acc 96.682%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.115 Acc 96.673%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.114 Acc 96.737%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.115 Acc 96.741%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.114 Acc 96.699%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.175 Acc 91.406%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.185 Acc 95.119%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.204%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.107 Acc 96.945%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.105 Acc 96.953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.109 Acc 96.841%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.111 Acc 96.772%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.112 Acc 96.750%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.203 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.181 Acc 95.514%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.175 Acc 95.507%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.110 Acc 96.805%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.105 Acc 96.867%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.108 Acc 96.815%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.110 Acc 96.748%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.111 Acc 96.728%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.194 Acc 95.142%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.191 Acc 95.145%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.109 Acc 96.666%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.113 Acc 96.572%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.111 Acc 96.665%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.112 Acc 96.725%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.113 Acc 96.694%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.184 Acc 95.297%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.182 Acc 95.417%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.099 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.105 Acc 96.945%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.108 Acc 96.859%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.111 Acc 96.800%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.111 Acc 96.778%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.110 Acc 96.746%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.170 Acc 95.746%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.167 Acc 95.748%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.106 Acc 97.037%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.107 Acc 96.964%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.106 Acc 96.966%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.106 Acc 96.982%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.105 Acc 96.962%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.180 Acc 95.421%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.176 Acc 95.569%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.224 Acc 92.969%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.101 Acc 97.061%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.102 Acc 96.945%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.104 Acc 96.906%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.105 Acc 96.894%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.106 Acc 96.877%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.180 Acc 95.467%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.176 Acc 95.456%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.100 Acc 97.027%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.104 Acc 96.885%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.105 Acc 96.856%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.105 Acc 96.858%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.175 Acc 95.537%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.171 Acc 95.616%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.228 Acc 94.531%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.095 Acc 97.277%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.099 Acc 97.116%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.101 Acc 96.974%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.104 Acc 96.961%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.103 Acc 96.983%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.182 Acc 95.390%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.179 Acc 95.328%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.098 Acc 97.138%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.098 Acc 97.050%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.097 Acc 97.083%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.099 Acc 96.998%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.100 Acc 96.976%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.156 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.178 Acc 95.467%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.174 Acc 95.553%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.091 Acc 97.223%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.091 Acc 97.236%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.097 Acc 97.088%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.098 Acc 97.019%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.099 Acc 97.026%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.179 Acc 95.359%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.179 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.098 Acc 97.231%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.098 Acc 97.170%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.097 Acc 97.158%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.097 Acc 97.152%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.097 Acc 97.109%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.178 Acc 95.475%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.175 Acc 95.480%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.089 Acc 97.236%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.091 Acc 97.166%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.095 Acc 97.120%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.096 Acc 97.071%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.176 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.178 Acc 95.560%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.174 Acc 95.526%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.085 Acc 97.525%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.090 Acc 97.303%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.092 Acc 97.197%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.095 Acc 97.074%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.097 Acc 97.068%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.123 Acc 95.312%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.186 Acc 95.483%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.181 Acc 95.557%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.086 Acc 97.300%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.093 Acc 97.186%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.091 Acc 97.246%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.092 Acc 97.233%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.093 Acc 97.201%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.170 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.180 Acc 95.514%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.176 Acc 95.484%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.123 Acc 95.312%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.087 Acc 97.334%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.089 Acc 97.199%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.091 Acc 97.183%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.093 Acc 97.117%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.175 Acc 95.599%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.173 Acc 95.581%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.082 Acc 97.494%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.087 Acc 97.314%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.087 Acc 97.295%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.089 Acc 97.235%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.092 Acc 97.178%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.176 Acc 95.429%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.173 Acc 95.499%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.056 Acc 99.219%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.082 Acc 97.540%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.084 Acc 97.431%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.086 Acc 97.334%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.088 Acc 97.315%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.089 Acc 97.321%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.180 Acc 95.429%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.178 Acc 95.515%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.048 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.090 Acc 97.246%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.089 Acc 97.213%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.090 Acc 97.184%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.091 Acc 97.169%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.092 Acc 97.176%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.189 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.173 Acc 95.637%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.173 Acc 95.682%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.081 Acc 97.517%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.085 Acc 97.442%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.087 Acc 97.368%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.089 Acc 97.263%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.089 Acc 97.280%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.179 Acc 95.530%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.029 Acc 100.000%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.079 Acc 97.478%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.084 Acc 97.376%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.086 Acc 97.397%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.086 Acc 97.389%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.087 Acc 97.341%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.185 Acc 96.094%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.183 Acc 95.405%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.182 Acc 95.355%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.079 Acc 97.672%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.083 Acc 97.439%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.084 Acc 97.368%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.084 Acc 97.374%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.085 Acc 97.360%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.483%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.180 Acc 95.522%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.082 Acc 97.471%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.084 Acc 97.417%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.086 Acc 97.395%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.086 Acc 97.383%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.232 Acc 94.431%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.227 Acc 94.465%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.083 Acc 97.386%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.085 Acc 97.376%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.084 Acc 97.428%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.084 Acc 97.422%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.085 Acc 97.376%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.176 Acc 95.545%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.173 Acc 95.678%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.080 Acc 97.463%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.077 Acc 97.520%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.078 Acc 97.511%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.079 Acc 97.502%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.082 Acc 97.436%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.181 Acc 95.444%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.180 Acc 95.503%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.071 Acc 97.757%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.077 Acc 97.579%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.077 Acc 97.545%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.080 Acc 97.475%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.179 Acc 95.537%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.177 Acc 95.398%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.071 Acc 97.679%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.075 Acc 97.700%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.077 Acc 97.643%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.078 Acc 97.616%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.184 Acc 95.367%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.182 Acc 95.324%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.087 Acc 96.094%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.077 Acc 97.494%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.078 Acc 97.532%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.078 Acc 97.545%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.078 Acc 97.528%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.080 Acc 97.482%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.175 Acc 95.637%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.172 Acc 95.604%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.032 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.067 Acc 97.873%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.074 Acc 97.676%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.076 Acc 97.591%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.079 Acc 97.495%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.079 Acc 97.471%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.191 Acc 95.189%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.188 Acc 95.157%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.059 Acc 99.219%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.069 Acc 97.788%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.068 Acc 97.730%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.075 Acc 97.568%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.076 Acc 97.598%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.076 Acc 97.603%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.176 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.188 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.187 Acc 95.250%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.074 Acc 97.509%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.074 Acc 97.563%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.076 Acc 97.534%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.077 Acc 97.525%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.194 Acc 95.297%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.191 Acc 95.344%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.073 Acc 97.741%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.074 Acc 97.680%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.072 Acc 97.739%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.074 Acc 97.680%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.075 Acc 97.645%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.196 Acc 95.390%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.192 Acc 95.460%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.070 Acc 97.881%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.068 Acc 97.963%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.070 Acc 97.882%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.072 Acc 97.773%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.074 Acc 97.681%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.498%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.177 Acc 95.585%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.071 Acc 97.703%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.072 Acc 97.652%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.071 Acc 97.682%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.072 Acc 97.664%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.074 Acc 97.602%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.177 Acc 96.875%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.190 Acc 95.575%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.188 Acc 95.507%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.071 Acc 97.679%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.073 Acc 97.680%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.071 Acc 97.713%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.074 Acc 97.631%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.184 Acc 95.251%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.183 Acc 95.278%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.065 Acc 97.865%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.069 Acc 97.761%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.070 Acc 97.763%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.070 Acc 97.758%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.071 Acc 97.748%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.184 Acc 95.467%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.185 Acc 95.239%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.072 Acc 97.571%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.068 Acc 97.722%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.066 Acc 97.815%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.069 Acc 97.783%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.071 Acc 97.744%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.129 Acc 96.875%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.184 Acc 95.320%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.180 Acc 95.394%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.092 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.069 Acc 97.734%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.069 Acc 97.700%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.072 Acc 97.631%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.071 Acc 97.678%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.198 Acc 95.235%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.196 Acc 95.289%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.064 Acc 97.950%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.067 Acc 97.882%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.070 Acc 97.711%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.070 Acc 97.700%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.193 Acc 95.552%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.189 Acc 95.526%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.065 Acc 97.819%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.067 Acc 97.816%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.064 Acc 97.882%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.065 Acc 97.839%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.069 Acc 97.775%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.174 Acc 95.753%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.173 Acc 95.725%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.028 Acc 100.000%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.068 Acc 97.819%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.065 Acc 97.866%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.068 Acc 97.789%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.069 Acc 97.806%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.068 Acc 97.798%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.174 Acc 95.777%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.172 Acc 95.763%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.122 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.063 Acc 97.888%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.064 Acc 97.940%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.063 Acc 97.981%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.064 Acc 97.933%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.065 Acc 97.885%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.206 Acc 95.057%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.199 Acc 95.130%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.061 Acc 98.136%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.064 Acc 97.994%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.068 Acc 97.859%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.067 Acc 97.871%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.067 Acc 97.859%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.181 Acc 95.777%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.180 Acc 95.612%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.060 Acc 98.074%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.064 Acc 97.866%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.064 Acc 97.864%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.065 Acc 97.871%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.067 Acc 97.829%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.199 Acc 95.421%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.195 Acc 95.402%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.076 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.064 Acc 98.113%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.064 Acc 97.987%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.062 Acc 98.007%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.061 Acc 98.042%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.063 Acc 97.990%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.195 Acc 95.173%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.195 Acc 95.270%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.061 Acc 98.053%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.063 Acc 97.931%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.065 Acc 97.893%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.171 Acc 95.312%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.201 Acc 94.972%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.201 Acc 94.943%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.067 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.062 Acc 97.909%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.065 Acc 97.832%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.187 Acc 95.227%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.187 Acc 95.231%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.063 Acc 97.811%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.063 Acc 97.866%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.065 Acc 97.835%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.064 Acc 97.880%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.064 Acc 97.865%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.191 Acc 95.374%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.191 Acc 95.336%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.105 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.061 Acc 98.012%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.062 Acc 97.948%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.062 Acc 97.957%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.061 Acc 97.976%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.063 Acc 97.910%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.152 Acc 96.094%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.192 Acc 95.266%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.188 Acc 95.274%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.061 Acc 97.741%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.061 Acc 97.889%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.063 Acc 97.882%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.063 Acc 97.892%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.063 Acc 97.907%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.199 Acc 94.872%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.196 Acc 94.974%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.058 Acc 98.120%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.060 Acc 98.107%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.058 Acc 98.116%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.060 Acc 98.011%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.062 Acc 97.926%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.195 Acc 95.560%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.190 Acc 95.550%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.022 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.056 Acc 98.260%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.058 Acc 98.165%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.058 Acc 98.129%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.059 Acc 98.056%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.060 Acc 98.046%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.174 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.200 Acc 95.196%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.194 Acc 95.219%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.056 Acc 98.221%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.055 Acc 98.212%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.057 Acc 98.147%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.057 Acc 98.137%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.059 Acc 98.055%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.196 Acc 95.127%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.191 Acc 95.328%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.053 Acc 98.182%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.054 Acc 98.181%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.058 Acc 98.110%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.059 Acc 98.091%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.060 Acc 98.035%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.189 Acc 95.444%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.186 Acc 95.456%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.053 Acc 98.283%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.052 Acc 98.317%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.055 Acc 98.178%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.057 Acc 98.116%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.059 Acc 98.041%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.196 Acc 95.297%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.192 Acc 95.243%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.057 Acc 98.066%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.057 Acc 98.053%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.059 Acc 97.983%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.059 Acc 98.007%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.058 Acc 98.029%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.145 Acc 96.094%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.201 Acc 95.266%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.199 Acc 95.258%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.049 Acc 98.275%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.052 Acc 98.228%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.055 Acc 98.162%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.058 Acc 98.093%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.058 Acc 98.034%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.169 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.205 Acc 95.057%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.203 Acc 95.103%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.011 Acc 100.000%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.054 Acc 98.175%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.055 Acc 98.146%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.056 Acc 98.113%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.057 Acc 98.073%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.056 Acc 98.094%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.203 Acc 95.343%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.200 Acc 95.417%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.051 Acc 98.314%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.052 Acc 98.263%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.055 Acc 98.139%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.056 Acc 98.126%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.056 Acc 98.118%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.191 Acc 95.676%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.189 Acc 95.585%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.024 Acc 99.219%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.052 Acc 98.182%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.054 Acc 98.134%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.055 Acc 98.113%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.054 Acc 98.176%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.056 Acc 98.141%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.209 Acc 95.034%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.205 Acc 95.005%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.111 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.051 Acc 98.182%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.053 Acc 98.189%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.054 Acc 98.199%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.054 Acc 98.196%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.055 Acc 98.163%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.175 Acc 96.094%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.194 Acc 95.436%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.190 Acc 95.569%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.052 Acc 98.144%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.052 Acc 98.189%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.052 Acc 98.206%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.053 Acc 98.206%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.055 Acc 98.177%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.148 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.210 Acc 95.421%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.204 Acc 95.464%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.047 Acc 98.291%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.054 Acc 98.092%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.054 Acc 98.108%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.054 Acc 98.106%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.054 Acc 98.115%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.206 Acc 94.957%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.204 Acc 95.056%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.051 Acc 98.283%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.051 Acc 98.259%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.052 Acc 98.235%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.053 Acc 98.184%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.053 Acc 98.210%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.205 Acc 95.034%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.056 Acc 98.151%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.053 Acc 98.286%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.055 Acc 98.222%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.054 Acc 98.249%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.052 Acc 98.302%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.214 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.199 Acc 95.166%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.195 Acc 95.258%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.046 Acc 98.407%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.048 Acc 98.422%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.050 Acc 98.331%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.051 Acc 98.289%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.053 Acc 98.250%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.106 Acc 95.312%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.200 Acc 95.459%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.197 Acc 95.491%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.051 Acc 98.190%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.054 Acc 98.099%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.053 Acc 98.162%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.054 Acc 98.149%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.054 Acc 98.151%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.198 Acc 95.459%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.196 Acc 95.402%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.049 Acc 98.290%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.050 Acc 98.301%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.050 Acc 98.307%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.133 Acc 96.875%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.198 Acc 95.204%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.196 Acc 95.223%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.049 Acc 98.314%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.052 Acc 98.200%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.053 Acc 98.194%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.053 Acc 98.221%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.054 Acc 98.172%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.186 Acc 95.452%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.185 Acc 95.417%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.045 Acc 98.507%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.049 Acc 98.418%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.048 Acc 98.380%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.051 Acc 98.243%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.051 Acc 98.258%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.202 Acc 95.483%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.198 Acc 95.414%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.044 Acc 98.468%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.047 Acc 98.391%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.048 Acc 98.360%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.052 Acc 98.296%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.197 Acc 95.467%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.190 Acc 95.503%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.048 Acc 98.340%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.049 Acc 98.282%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.049 Acc 98.280%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.051 Acc 98.261%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.103 Acc 96.875%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.208 Acc 95.606%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.202 Acc 95.546%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.049 Acc 98.399%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.050 Acc 98.371%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.051 Acc 98.284%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.052 Acc 98.278%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.051 Acc 98.302%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.126 Acc 95.312%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.197 Acc 95.251%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.191 Acc 95.305%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.048 Acc 98.391%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.046 Acc 98.403%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.049 Acc 98.339%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.049 Acc 98.334%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.049 Acc 98.303%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.201 Acc 95.073%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.197 Acc 95.033%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.044 Acc 98.538%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.045 Acc 98.484%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.047 Acc 98.432%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.049 Acc 98.348%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.049 Acc 98.364%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.138 Acc 96.875%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.197 Acc 95.637%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.196 Acc 95.522%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.047 Acc 98.484%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.047 Acc 98.426%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.046 Acc 98.399%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.048 Acc 98.356%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.049 Acc 98.321%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.208 Acc 95.173%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.206 Acc 95.161%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.045 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.045 Acc 98.468%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.046 Acc 98.472%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.048 Acc 98.380%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.048 Acc 98.371%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.048 Acc 98.375%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.216 Acc 94.531%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.205 Acc 95.606%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.200 Acc 95.612%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.046 Acc 98.484%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.047 Acc 98.465%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.049 Acc 98.401%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.048 Acc 98.461%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.048 Acc 98.428%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.128 Acc 96.094%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.207 Acc 95.429%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.043 Acc 98.484%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.046 Acc 98.399%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.048 Acc 98.383%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.049 Acc 98.328%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.049 Acc 98.328%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.180 Acc 95.312%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.201 Acc 95.251%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.199 Acc 95.285%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.039 Acc 98.670%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.042 Acc 98.593%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.045 Acc 98.489%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.046 Acc 98.459%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.047 Acc 98.425%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.154 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.193 Acc 95.514%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.193 Acc 95.476%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.047 Acc 98.360%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.045 Acc 98.356%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.048 Acc 98.323%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.048 Acc 98.317%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.048 Acc 98.317%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.233 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.218 Acc 95.266%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.212 Acc 95.243%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.047 Acc 99.219%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.047 Acc 98.445%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.048 Acc 98.472%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.047 Acc 98.432%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.047 Acc 98.453%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.047 Acc 98.442%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.222 Acc 95.212%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.221 Acc 95.091%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.044 Acc 98.561%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.044 Acc 98.488%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.045 Acc 98.500%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.045 Acc 98.482%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.048 Acc 98.403%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.219 Acc 94.779%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.215 Acc 94.803%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.042 Acc 98.530%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.045 Acc 98.465%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.045 Acc 98.430%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.044 Acc 98.451%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.045 Acc 98.423%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.120 Acc 97.656%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.211 Acc 95.367%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.208 Acc 95.386%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.043 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.040 Acc 98.623%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.041 Acc 98.624%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.043 Acc 98.518%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.045 Acc 98.478%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.046 Acc 98.462%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.208 Acc 95.212%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.205 Acc 95.173%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.046 Acc 98.538%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.043 Acc 98.593%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.044 Acc 98.523%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.045 Acc 98.465%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.046 Acc 98.450%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.216 Acc 94.717%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.211 Acc 94.881%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.040 Acc 98.639%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.041 Acc 98.612%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.042 Acc 98.583%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.045 Acc 98.506%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.045 Acc 98.483%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.212 Acc 95.158%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.212 Acc 95.013%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.047 Acc 98.314%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.048 Acc 98.313%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.048 Acc 98.339%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.047 Acc 98.340%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.047 Acc 98.358%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.226 Acc 95.312%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.227 Acc 95.173%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.225 Acc 95.079%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.041 Acc 98.584%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.042 Acc 98.577%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.043 Acc 98.526%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.044 Acc 98.447%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.045 Acc 98.420%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.116 Acc 96.875%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.194 Acc 95.730%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.191 Acc 95.616%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.012 Acc 99.219%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.038 Acc 98.662%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.039 Acc 98.682%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.041 Acc 98.609%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.041 Acc 98.589%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.043 Acc 98.545%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.112 Acc 96.094%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.214 Acc 95.080%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.210 Acc 95.106%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.040 Acc 98.693%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.039 Acc 98.655%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.041 Acc 98.567%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.043 Acc 98.562%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.044 Acc 98.492%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.199 Acc 95.630%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.195 Acc 95.612%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.037 Acc 98.741%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.040 Acc 98.637%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.043 Acc 98.537%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.043 Acc 98.509%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.224 Acc 94.756%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [200/204] Loss: 0.219 Acc 94.710%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.042 Acc 98.468%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.041 Acc 98.554%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.043 Acc 98.484%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.042 Acc 98.531%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.043 Acc 98.500%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.204 Acc 95.475%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.204 Acc 95.359%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.073 Acc 96.875%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.041 Acc 98.608%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.043 Acc 98.504%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.043 Acc 98.531%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.044 Acc 98.519%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.045 Acc 98.480%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.198 Acc 95.243%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.197 Acc 95.274%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.033 Acc 99.219%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.044 Acc 98.484%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.044 Acc 98.515%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.043 Acc 98.535%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.043 Acc 98.519%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.218 Acc 95.065%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.214 Acc 95.106%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.036 Acc 98.778%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.039 Acc 98.644%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.041 Acc 98.627%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.042 Acc 98.617%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.043 Acc 98.570%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.203 Acc 95.552%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.202 Acc 95.565%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.032 Acc 98.863%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.037 Acc 98.752%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.039 Acc 98.707%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.040 Acc 98.677%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.042 Acc 98.637%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.165 Acc 94.531%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.227 Acc 95.220%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.226 Acc 95.215%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.023 Acc 98.438%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.038 Acc 98.639%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.039 Acc 98.616%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.039 Acc 98.643%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.041 Acc 98.572%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.041 Acc 98.553%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.105 Acc 96.875%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.221 Acc 95.274%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.214 Acc 95.336%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.090 Acc 95.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.041 Acc 98.700%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.042 Acc 98.636%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.041 Acc 98.609%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.041 Acc 98.605%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.042 Acc 98.600%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.210 Acc 94.980%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.205 Acc 94.955%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.038 Acc 98.770%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.037 Acc 98.756%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.040 Acc 98.643%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.040 Acc 98.644%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.041 Acc 98.617%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.227 Acc 95.111%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.224 Acc 95.040%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.044 Acc 98.507%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.044 Acc 98.504%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.044 Acc 98.487%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.045 Acc 98.482%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.044 Acc 98.484%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.222 Acc 95.088%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.221 Acc 94.998%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.025 Acc 98.438%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.042 Acc 98.654%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.040 Acc 98.651%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.040 Acc 98.676%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.040 Acc 98.638%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.041 Acc 98.612%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.219 Acc 95.390%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.214 Acc 95.468%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.041 Acc 98.530%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.041 Acc 98.531%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.041 Acc 98.552%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.041 Acc 98.570%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.041 Acc 98.562%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.207 Acc 95.011%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.204 Acc 94.982%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.038 Acc 98.693%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.039 Acc 98.690%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.040 Acc 98.617%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.040 Acc 98.628%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.040 Acc 98.622%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.205 Acc 95.204%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.198 Acc 95.196%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.038 Acc 98.685%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.037 Acc 98.682%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.039 Acc 98.635%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.041 Acc 98.586%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.041 Acc 98.572%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.130 Acc 93.750%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.230 Acc 95.034%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.225 Acc 95.134%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.038 Acc 98.793%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.039 Acc 98.733%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.040 Acc 98.645%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.041 Acc 98.607%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.041 Acc 98.572%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.214 Acc 95.552%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.208 Acc 95.647%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.038 Acc 98.741%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.038 Acc 98.715%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.039 Acc 98.679%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.039 Acc 98.695%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.202 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.206 Acc 95.382%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [200/204] Loss: 0.205 Acc 95.340%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.042 Acc 98.592%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.041 Acc 98.574%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.041 Acc 98.583%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.040 Acc 98.599%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.040 Acc 98.607%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.190 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.218 Acc 95.158%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.214 Acc 95.079%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.039 Acc 98.615%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.038 Acc 98.612%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.039 Acc 98.614%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.040 Acc 98.589%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.041 Acc 98.567%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.150 Acc 95.312%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.222 Acc 95.421%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.214 Acc 95.476%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.035 Acc 98.755%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.038 Acc 98.682%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.038 Acc 98.666%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.039 Acc 98.630%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.039 Acc 98.659%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.151 Acc 96.094%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.215 Acc 95.591%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.209 Acc 95.666%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.027 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.036 Acc 98.770%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.035 Acc 98.760%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.037 Acc 98.689%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.038 Acc 98.699%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.038 Acc 98.676%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.292 Acc 92.969%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.223 Acc 95.398%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.219 Acc 95.425%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.034 Acc 98.894%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.036 Acc 98.853%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.037 Acc 98.772%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.037 Acc 98.763%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.039 Acc 98.695%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.228 Acc 95.258%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.224 Acc 95.153%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.036 Acc 98.840%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.034 Acc 98.888%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.037 Acc 98.757%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.038 Acc 98.701%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.038 Acc 98.689%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.229 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.237 Acc 94.701%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.230 Acc 94.900%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.038 Acc 98.662%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.036 Acc 98.776%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.036 Acc 98.759%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.037 Acc 98.741%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.037 Acc 98.718%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.196 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.227 Acc 95.220%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.222 Acc 95.246%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.034 Acc 98.846%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.033 Acc 98.845%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.035 Acc 98.767%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.036 Acc 98.729%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.203 Acc 95.359%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.200 Acc 95.231%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.034 Acc 98.824%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.036 Acc 98.795%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.035 Acc 98.840%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.035 Acc 98.835%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.036 Acc 98.773%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.213 Acc 95.359%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.207 Acc 95.410%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.040 Acc 98.615%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.037 Acc 98.690%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.037 Acc 98.728%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.038 Acc 98.673%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.039 Acc 98.615%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.209 Acc 95.622%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.204 Acc 95.530%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.028 Acc 99.025%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.033 Acc 98.869%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.038 Acc 98.665%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.038 Acc 98.664%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.195 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.211 Acc 95.305%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.208 Acc 95.258%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.033 Acc 98.786%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.033 Acc 98.884%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.033 Acc 98.902%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.034 Acc 98.858%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.035 Acc 98.802%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.214 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.209 Acc 95.614%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.205 Acc 95.581%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.035 Acc 98.817%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.035 Acc 98.873%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.034 Acc 98.879%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.036 Acc 98.831%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.036 Acc 98.806%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.202 Acc 95.475%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.200 Acc 95.472%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.035 Acc 98.871%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.037 Acc 98.783%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.039 Acc 98.661%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.038 Acc 98.673%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.037 Acc 98.720%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.222 Acc 95.374%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.218 Acc 95.336%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.039 Acc 98.700%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.038 Acc 98.772%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.036 Acc 98.796%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.037 Acc 98.778%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.037 Acc 98.777%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.233 Acc 96.094%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.219 Acc 95.282%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [165/200]Batch [200/204] Loss: 0.218 Acc 95.363%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.039 Acc 98.608%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.038 Acc 98.706%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.038 Acc 98.665%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.038 Acc 98.665%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.193 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.222 Acc 95.088%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.217 Acc 95.052%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.038 Acc 98.708%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.037 Acc 98.768%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.038 Acc 98.731%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.038 Acc 98.730%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.037 Acc 98.726%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.211 Acc 95.026%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.211 Acc 95.044%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.032 Acc 98.832%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.033 Acc 98.826%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.033 Acc 98.816%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.034 Acc 98.800%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.035 Acc 98.751%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.214 Acc 95.467%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.212 Acc 95.476%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.031 Acc 98.847%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.031 Acc 98.846%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.033 Acc 98.772%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.034 Acc 98.773%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.036 Acc 98.710%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.234 Acc 95.312%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.202 Acc 95.220%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.202 Acc 95.126%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.032 Acc 98.948%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.032 Acc 98.923%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.032 Acc 98.918%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.033 Acc 98.874%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.034 Acc 98.844%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.206 Acc 95.336%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.202 Acc 95.367%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.034 Acc 98.770%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.035 Acc 98.791%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.036 Acc 98.757%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.036 Acc 98.739%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.037 Acc 98.695%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.237 Acc 95.173%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.231 Acc 95.188%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.032 Acc 98.871%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.034 Acc 98.865%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.034 Acc 98.855%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.034 Acc 98.808%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.035 Acc 98.757%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.211 Acc 94.531%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.214 Acc 95.166%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.214 Acc 95.227%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.037 Acc 98.755%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.036 Acc 98.702%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.035 Acc 98.752%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.034 Acc 98.776%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.036 Acc 98.735%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.215 Acc 96.094%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.224 Acc 95.243%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.223 Acc 95.239%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.034 Acc 98.847%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.036 Acc 98.780%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.036 Acc 98.778%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.037 Acc 98.728%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.038 Acc 98.706%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.227 Acc 95.575%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.227 Acc 95.553%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.032 Acc 98.824%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.034 Acc 98.776%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.035 Acc 98.798%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.035 Acc 98.814%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.035 Acc 98.815%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.238 Acc 95.135%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.235 Acc 95.176%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.033 Acc 98.886%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.034 Acc 98.803%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.033 Acc 98.863%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.033 Acc 98.847%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.034 Acc 98.837%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.228 Acc 94.926%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.227 Acc 94.998%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.031 Acc 98.948%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.031 Acc 98.892%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.032 Acc 98.900%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.033 Acc 98.882%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.034 Acc 98.829%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.242 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.232 Acc 95.111%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.232 Acc 95.072%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.036 Acc 98.855%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.034 Acc 98.857%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.035 Acc 98.829%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.035 Acc 98.796%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.035 Acc 98.820%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.163 Acc 94.531%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.214 Acc 95.336%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.211 Acc 95.398%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.031 Acc 98.863%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.031 Acc 98.818%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.032 Acc 98.842%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.033 Acc 98.843%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.034 Acc 98.834%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.212 Acc 95.490%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.213 Acc 95.382%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.030 Acc 99.002%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.031 Acc 98.947%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.032 Acc 98.874%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.032 Acc 98.860%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.033 Acc 98.834%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.223 Acc 94.825%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [180/200]Batch [200/204] Loss: 0.220 Acc 94.994%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.034 Acc 98.809%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.034 Acc 98.846%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.033 Acc 98.845%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.034 Acc 98.815%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.035 Acc 98.781%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.202 Acc 94.531%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.204 Acc 95.266%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.204 Acc 95.332%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.030 Acc 99.080%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.030 Acc 99.032%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.032 Acc 98.912%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.033 Acc 98.915%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.033 Acc 98.904%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.225 Acc 95.212%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.224 Acc 95.188%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.032 Acc 99.010%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.031 Acc 98.967%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.033 Acc 98.917%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.032 Acc 98.922%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.209 Acc 96.875%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.222 Acc 95.166%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.222 Acc 95.138%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.034 Acc 98.809%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.033 Acc 98.850%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.035 Acc 98.811%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.035 Acc 98.780%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.036 Acc 98.762%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.170 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.221 Acc 95.158%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.219 Acc 95.270%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.033 Acc 99.010%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.033 Acc 98.939%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.034 Acc 98.907%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.034 Acc 98.934%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.034 Acc 98.888%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.221 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.220 Acc 95.514%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.215 Acc 95.596%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.027 Acc 99.049%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.030 Acc 98.978%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.032 Acc 98.933%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.032 Acc 98.889%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.033 Acc 98.840%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.190 Acc 96.094%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.228 Acc 95.351%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.221 Acc 95.410%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.031 Acc 98.963%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.030 Acc 98.954%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.031 Acc 98.931%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.031 Acc 98.944%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.206 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.232 Acc 95.374%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.226 Acc 95.309%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.072 Acc 98.438%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.033 Acc 98.987%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.033 Acc 98.904%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.033 Acc 98.855%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.033 Acc 98.823%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.034 Acc 98.818%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.273 Acc 95.312%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.241 Acc 95.003%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.235 Acc 95.157%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.030 Acc 98.956%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.033 Acc 98.902%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.033 Acc 98.876%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.033 Acc 98.868%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.229 Acc 95.374%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.222 Acc 95.347%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.038 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.026 Acc 99.072%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.029 Acc 99.021%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.030 Acc 98.977%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.031 Acc 98.944%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.032 Acc 98.933%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.219 Acc 95.498%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.216 Acc 95.522%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.026 Acc 99.165%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.031 Acc 98.977%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.032 Acc 98.903%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.034 Acc 98.862%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.235 Acc 95.328%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.227 Acc 95.363%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.031 Acc 98.847%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.031 Acc 98.830%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.032 Acc 98.845%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.031 Acc 98.872%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.032 Acc 98.852%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.278 Acc 96.094%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.224 Acc 95.282%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.220 Acc 95.289%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.028 Acc 99.080%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.029 Acc 98.974%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.031 Acc 98.928%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.031 Acc 98.917%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.032 Acc 98.891%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.231 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.220 Acc 95.483%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.217 Acc 95.456%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.031 Acc 99.025%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.030 Acc 99.071%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.030 Acc 99.027%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.031 Acc 98.983%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.032 Acc 98.930%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.253 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.225 Acc 95.173%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.220 Acc 95.239%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.034 Acc 98.762%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.033 Acc 98.818%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.032 Acc 98.907%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.032 Acc 98.903%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.032 Acc 98.912%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.233 Acc 95.444%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [195/200]Batch [200/204] Loss: 0.227 Acc 95.375%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.039 Acc 97.656%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.031 Acc 99.033%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.033 Acc 98.951%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.032 Acc 98.941%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.034 Acc 98.876%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.222 Acc 95.413%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.220 Acc 95.324%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.033 Acc 98.871%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.031 Acc 98.877%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.032 Acc 98.845%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.032 Acc 98.829%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.033 Acc 98.824%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.134 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.220 Acc 94.957%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.221 Acc 94.998%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.029 Acc 99.002%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.030 Acc 98.958%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.032 Acc 98.887%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.032 Acc 98.886%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.032 Acc 98.899%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.220 Acc 95.645%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.221 Acc 95.686%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.029 Acc 98.925%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.028 Acc 98.989%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.029 Acc 98.985%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.031 Acc 98.938%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.031 Acc 98.930%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.182 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.206 Acc 95.599%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.206 Acc 95.410%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fb6ca5819447aebd82c31b799f0d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.324 Acc 10.938%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.191 Acc 21.248%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 1.849 Acc 34.558%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 1.530 Acc 46.699%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 1.315 Acc 54.781%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 1.158 Acc 60.474%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 0.597 Acc 79.688%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 0.482 Acc 85.118%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 0.472 Acc 85.432%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 0.409 Acc 89.062%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 0.450 Acc 86.077%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.438 Acc 86.431%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.423 Acc 86.921%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.414 Acc 87.243%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.409 Acc 87.498%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.307 Acc 87.500%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.342 Acc 89.411%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.332 Acc 89.875%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.216 Acc 93.750%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.361 Acc 89.001%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.348 Acc 89.432%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.342 Acc 89.525%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.336 Acc 89.778%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.331 Acc 89.880%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.325 Acc 85.938%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.306 Acc 91.197%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.300 Acc 91.227%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.262 Acc 92.188%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.308 Acc 90.339%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.301 Acc 90.664%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.301 Acc 90.721%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.298 Acc 90.925%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.296 Acc 90.990%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.277 Acc 91.955%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.269 Acc 92.013%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.286 Acc 95.312%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.283 Acc 91.870%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.278 Acc 91.861%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.279 Acc 91.785%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.274 Acc 91.973%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.272 Acc 92.011%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.227 Acc 92.188%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.257 Acc 92.721%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.252 Acc 92.829%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.358 Acc 92.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.255 Acc 92.427%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.256 Acc 92.475%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.251 Acc 92.644%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.254 Acc 92.560%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.203 Acc 91.406%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.224 Acc 93.742%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.219 Acc 93.816%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.157 Acc 94.531%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.226 Acc 93.425%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.236 Acc 93.097%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.238 Acc 92.974%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.238 Acc 92.945%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.240 Acc 93.005%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.256 Acc 92.188%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.246 Acc 92.837%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.241 Acc 93.050%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.230 Acc 93.309%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.230 Acc 93.311%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.233 Acc 93.143%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.232 Acc 93.218%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.232 Acc 93.257%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.280 Acc 87.500%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.285 Acc 91.731%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.278 Acc 91.989%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.263 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.214 Acc 93.765%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.219 Acc 93.719%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.218 Acc 93.732%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.223 Acc 93.569%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.225 Acc 93.472%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.203 Acc 94.199%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.198 Acc 94.531%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.208 Acc 93.912%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.209 Acc 93.855%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.208 Acc 93.908%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.210 Acc 93.853%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.214 Acc 93.792%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.217 Acc 94.059%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.211 Acc 94.003%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.205 Acc 96.094%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.199 Acc 93.905%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.200 Acc 93.948%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.206 Acc 93.986%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.207 Acc 94.029%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.206 Acc 94.046%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.363 Acc 91.406%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.287 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.283 Acc 92.965%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.269 Acc 92.188%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.202 Acc 94.083%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.200 Acc 94.143%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.199 Acc 94.150%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.200 Acc 94.202%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.199 Acc 94.269%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.224 Acc 94.075%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.220 Acc 93.898%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.242 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.191 Acc 94.640%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.193 Acc 94.555%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.198 Acc 94.344%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.195 Acc 94.410%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.195 Acc 94.400%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.209 Acc 94.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.205 Acc 94.516%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.189 Acc 94.694%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.182 Acc 94.792%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.184 Acc 94.692%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.183 Acc 94.703%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.185 Acc 94.715%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.195 Acc 94.964%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.190 Acc 95.044%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.218 Acc 96.094%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.175 Acc 94.903%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.178 Acc 94.932%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.184 Acc 94.684%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.182 Acc 94.734%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.181 Acc 94.775%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.200 Acc 94.732%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.195 Acc 94.850%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.231 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.172 Acc 95.104%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.177 Acc 94.978%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.179 Acc 94.884%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.179 Acc 94.890%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.179 Acc 94.898%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.195 Acc 94.900%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.237 Acc 93.750%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.157 Acc 95.529%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.169 Acc 95.192%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.173 Acc 95.053%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.173 Acc 95.024%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.176 Acc 94.927%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.190 Acc 94.995%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.185 Acc 95.106%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.193 Acc 94.531%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.165 Acc 95.289%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.168 Acc 95.285%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.172 Acc 95.198%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.170 Acc 95.172%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.169 Acc 95.224%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.197 Acc 94.609%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.193 Acc 94.792%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.214 Acc 92.188%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.167 Acc 95.243%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.162 Acc 95.394%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.167 Acc 95.297%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.166 Acc 95.303%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.165 Acc 95.311%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.210 Acc 94.833%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.206 Acc 94.986%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.161 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.167 Acc 95.158%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.161 Acc 95.371%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.161 Acc 95.411%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.162 Acc 95.412%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.164 Acc 95.359%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.138 Acc 96.094%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.184 Acc 95.227%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.180 Acc 95.266%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.157 Acc 95.676%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.162 Acc 95.631%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.159 Acc 95.580%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.160 Acc 95.513%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.160 Acc 95.507%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.195 Acc 94.872%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.190 Acc 94.858%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.095 Acc 96.094%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.160 Acc 95.499%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.155 Acc 95.601%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.153 Acc 95.671%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.156 Acc 95.603%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.193 Acc 94.887%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.186 Acc 94.990%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.144 Acc 95.854%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.147 Acc 95.841%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.150 Acc 95.772%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.150 Acc 95.702%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.152 Acc 95.645%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.155 Acc 97.656%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.192 Acc 95.158%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.187 Acc 95.149%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.155 Acc 95.312%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.139 Acc 96.040%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.145 Acc 95.748%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.146 Acc 95.738%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.145 Acc 95.803%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.148 Acc 95.782%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.132 Acc 94.531%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.179 Acc 95.343%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.176 Acc 95.379%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.127 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.144 Acc 95.908%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.148 Acc 95.810%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.144 Acc 95.912%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.144 Acc 95.903%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.146 Acc 95.874%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.128 Acc 98.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.193 Acc 95.034%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.187 Acc 95.165%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.190 Acc 94.531%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.136 Acc 96.055%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.139 Acc 95.907%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.143 Acc 95.834%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.142 Acc 95.874%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.144 Acc 95.866%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.137 Acc 96.094%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.180 Acc 95.142%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.173 Acc 95.231%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.129 Acc 96.403%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.130 Acc 96.238%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.134 Acc 96.120%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.137 Acc 96.068%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.138 Acc 96.033%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.153 Acc 96.094%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.191 Acc 95.073%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.183 Acc 95.227%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.165 Acc 96.094%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.132 Acc 96.334%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.133 Acc 96.253%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.136 Acc 96.166%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.137 Acc 96.148%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.137 Acc 96.180%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.182 Acc 95.080%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.175 Acc 95.285%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.124 Acc 96.450%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.127 Acc 96.315%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.129 Acc 96.268%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.131 Acc 96.265%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.131 Acc 96.234%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.160 Acc 96.094%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.194 Acc 95.003%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.189 Acc 95.192%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.121 Acc 96.527%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.127 Acc 96.447%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.129 Acc 96.426%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.131 Acc 96.302%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.132 Acc 96.304%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.174 Acc 95.421%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.170 Acc 95.522%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.124 Acc 96.442%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.126 Acc 96.366%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.128 Acc 96.301%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.127 Acc 96.347%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.128 Acc 96.284%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.177 Acc 94.531%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.187 Acc 94.748%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.181 Acc 94.963%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.160 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.122 Acc 96.542%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.124 Acc 96.393%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.124 Acc 96.475%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.122 Acc 96.481%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.124 Acc 96.440%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.130 Acc 97.656%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.177 Acc 95.359%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.170 Acc 95.484%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.064 Acc 96.875%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.120 Acc 96.388%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.119 Acc 96.451%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.121 Acc 96.436%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.123 Acc 96.487%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.124 Acc 96.441%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.173 Acc 95.537%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.169 Acc 95.592%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.113 Acc 96.836%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.113 Acc 96.758%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.115 Acc 96.670%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.117 Acc 96.659%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.119 Acc 96.597%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.159 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.191 Acc 95.096%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.186 Acc 95.258%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.076 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.108 Acc 96.643%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.111 Acc 96.731%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.114 Acc 96.688%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.115 Acc 96.698%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.118 Acc 96.675%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.184 Acc 95.104%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.179 Acc 95.266%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.122 Acc 96.419%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.113 Acc 96.708%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.111 Acc 96.779%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.115 Acc 96.694%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.115 Acc 96.668%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.156 Acc 96.875%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.203 Acc 94.493%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.197 Acc 94.597%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.112 Acc 96.705%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.112 Acc 96.642%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.112 Acc 96.665%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.113 Acc 96.661%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.115 Acc 96.669%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.186 Acc 95.150%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.180 Acc 95.270%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.100 Acc 96.860%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.103 Acc 96.929%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.107 Acc 96.870%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.109 Acc 96.815%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.110 Acc 96.791%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.146 Acc 96.875%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.189 Acc 95.135%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.183 Acc 95.320%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.101 Acc 97.042%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.102 Acc 97.041%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.106 Acc 96.902%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.108 Acc 96.863%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.162 Acc 96.875%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.174 Acc 95.537%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.168 Acc 95.709%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.115 Acc 96.094%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.100 Acc 97.076%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.102 Acc 97.003%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.106 Acc 96.942%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.105 Acc 96.906%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.107 Acc 96.850%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.170 Acc 95.599%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.166 Acc 95.674%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.081 Acc 99.219%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.101 Acc 97.006%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.098 Acc 97.030%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.098 Acc 96.981%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.101 Acc 96.942%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.146 Acc 96.094%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.177 Acc 95.599%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.172 Acc 95.608%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.095 Acc 97.254%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.097 Acc 97.163%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.098 Acc 97.168%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.100 Acc 97.062%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.103 Acc 97.031%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.118 Acc 97.656%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.173 Acc 95.487%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.061 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.102 Acc 96.995%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.102 Acc 96.992%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.101 Acc 97.025%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.102 Acc 97.017%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.202 Acc 94.933%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.195 Acc 95.083%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.088 Acc 97.401%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.093 Acc 97.240%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.095 Acc 97.184%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.098 Acc 97.087%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.099 Acc 97.065%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.122 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.190 Acc 94.833%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.183 Acc 95.068%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.051 Acc 99.219%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.090 Acc 97.231%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.093 Acc 97.173%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.095 Acc 97.120%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.180 Acc 95.483%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.172 Acc 95.693%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.198 Acc 95.312%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.088 Acc 97.393%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.088 Acc 97.353%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.093 Acc 97.282%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.094 Acc 97.214%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.094 Acc 97.199%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.178 Acc 95.464%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.090 Acc 97.339%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.088 Acc 97.341%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.089 Acc 97.303%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.089 Acc 97.290%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.091 Acc 97.224%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.186 Acc 95.135%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.180 Acc 95.262%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.083 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.086 Acc 97.393%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.085 Acc 97.415%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.085 Acc 97.410%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.088 Acc 97.335%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.090 Acc 97.290%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.184 Acc 95.266%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.176 Acc 95.402%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.174 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.088 Acc 97.378%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.087 Acc 97.330%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.089 Acc 97.225%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.088 Acc 97.245%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.089 Acc 97.227%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.112 Acc 97.656%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.195 Acc 94.817%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.189 Acc 95.002%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.037 Acc 100.000%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.084 Acc 97.345%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.086 Acc 97.267%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.087 Acc 97.230%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.089 Acc 97.199%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.109 Acc 96.094%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.191 Acc 95.080%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.184 Acc 95.316%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.121 Acc 98.438%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.072 Acc 97.695%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.077 Acc 97.551%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.081 Acc 97.485%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.084 Acc 97.444%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.085 Acc 97.429%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.122 Acc 96.875%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.183 Acc 95.382%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.177 Acc 95.503%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.079 Acc 97.625%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.080 Acc 97.571%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.081 Acc 97.519%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.081 Acc 97.498%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.084 Acc 97.419%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.089 Acc 96.875%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.183 Acc 95.196%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.178 Acc 95.320%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.077 Acc 97.602%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.077 Acc 97.497%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.079 Acc 97.534%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.082 Acc 97.483%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.084 Acc 97.415%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.127 Acc 96.875%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.182 Acc 95.653%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.075 Acc 97.648%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.078 Acc 97.568%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.079 Acc 97.543%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.081 Acc 97.466%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.109 Acc 97.656%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.180 Acc 95.490%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.173 Acc 95.581%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.065 Acc 97.656%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.076 Acc 97.471%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.075 Acc 97.629%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.079 Acc 97.576%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.079 Acc 97.561%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.080 Acc 97.508%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.183 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.185 Acc 95.189%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.180 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.076 Acc 97.803%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.074 Acc 97.827%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.075 Acc 97.724%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.077 Acc 97.666%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.078 Acc 97.638%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.184 Acc 95.150%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.177 Acc 95.289%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.078 Acc 97.618%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.078 Acc 97.625%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.076 Acc 97.623%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.078 Acc 97.580%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.080 Acc 97.525%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.133 Acc 96.094%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.191 Acc 95.382%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.185 Acc 95.495%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.077 Acc 97.803%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.075 Acc 97.668%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.075 Acc 97.677%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.076 Acc 97.619%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.125 Acc 97.656%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.200 Acc 94.825%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.192 Acc 95.064%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.073 Acc 97.695%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.074 Acc 97.594%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.074 Acc 97.597%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.074 Acc 97.637%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.075 Acc 97.633%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.087 Acc 97.656%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.188 Acc 95.289%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.180 Acc 95.515%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.065 Acc 97.881%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.071 Acc 97.672%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.073 Acc 97.661%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.074 Acc 97.604%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.075 Acc 97.555%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.207 Acc 94.856%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.197 Acc 95.013%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.054 Acc 99.219%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.066 Acc 97.811%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.067 Acc 97.909%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.070 Acc 97.794%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.072 Acc 97.779%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.073 Acc 97.742%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.194 Acc 94.995%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.190 Acc 95.087%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.024 Acc 100.000%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.064 Acc 97.896%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.067 Acc 97.862%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.067 Acc 97.887%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.069 Acc 97.843%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.070 Acc 97.817%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.172 Acc 96.875%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.205 Acc 95.019%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.194 Acc 95.243%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.071 Acc 97.873%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.070 Acc 97.781%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.071 Acc 97.750%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.071 Acc 97.748%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.070 Acc 97.750%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.131 Acc 96.875%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.194 Acc 95.065%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.186 Acc 95.239%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.064 Acc 98.028%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.064 Acc 98.014%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.068 Acc 97.838%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.070 Acc 97.795%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.072 Acc 97.730%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.143 Acc 96.094%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.189%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.177 Acc 95.355%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.065 Acc 97.913%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.066 Acc 97.908%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.066 Acc 97.925%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.068 Acc 97.846%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.114 Acc 96.875%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.211 Acc 94.670%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.201 Acc 94.881%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.058 Acc 98.175%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.062 Acc 97.998%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.063 Acc 97.991%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.064 Acc 97.941%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.065 Acc 97.926%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.118 Acc 96.875%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.193 Acc 95.367%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.184 Acc 95.550%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.059 Acc 98.082%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.061 Acc 98.033%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.063 Acc 97.970%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.066 Acc 97.901%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.210 Acc 94.817%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.198 Acc 95.083%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.065 Acc 97.896%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.065 Acc 97.998%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.065 Acc 97.944%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.066 Acc 97.874%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.066 Acc 97.865%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.143 Acc 95.312%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.196 Acc 95.080%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.189 Acc 95.204%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.068 Acc 99.219%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.058 Acc 98.229%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.060 Acc 98.092%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.061 Acc 97.999%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.062 Acc 97.938%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.209 Acc 94.841%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.195 Acc 95.064%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.056 Acc 98.229%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.059 Acc 98.123%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.061 Acc 98.074%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.061 Acc 98.024%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.063 Acc 97.993%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.124 Acc 96.875%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.193 Acc 95.119%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.186 Acc 95.309%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.053 Acc 98.221%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.057 Acc 98.146%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.060 Acc 98.040%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.060 Acc 98.021%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.061 Acc 97.995%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.121 Acc 96.094%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.200 Acc 94.872%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.188 Acc 95.161%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.052 Acc 98.260%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.053 Acc 98.266%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.057 Acc 98.129%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.059 Acc 98.058%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.060 Acc 98.029%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.195 Acc 95.196%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.184 Acc 95.394%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.031 Acc 97.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.060 Acc 97.950%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.058 Acc 98.072%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.059 Acc 98.064%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.060 Acc 98.038%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.060 Acc 98.012%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.149 Acc 97.656%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.193 Acc 95.266%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.183 Acc 95.390%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.052 Acc 98.283%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.056 Acc 98.189%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.059 Acc 98.091%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.060 Acc 98.084%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.185 Acc 95.312%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.210 Acc 94.771%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.201 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.057 Acc 98.198%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.057 Acc 98.169%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.057 Acc 98.162%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.059 Acc 98.073%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.059 Acc 98.054%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.135 Acc 96.094%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.216 Acc 94.848%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.206 Acc 94.982%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.051 Acc 98.376%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.052 Acc 98.321%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.054 Acc 98.173%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.055 Acc 98.174%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.057 Acc 98.121%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.170 Acc 96.094%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.215 Acc 94.895%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.206 Acc 95.072%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.049 Acc 98.329%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.054 Acc 98.162%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.055 Acc 98.136%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.055 Acc 98.143%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.056 Acc 98.105%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.215 Acc 94.854%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.058 Acc 96.875%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.048 Acc 98.430%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.050 Acc 98.336%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.052 Acc 98.292%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.054 Acc 98.208%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.055 Acc 98.169%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.209 Acc 94.972%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.198 Acc 95.173%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.050 Acc 98.283%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.051 Acc 98.270%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.053 Acc 98.199%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.054 Acc 98.180%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.057 Acc 98.096%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.159 Acc 95.312%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.212 Acc 94.879%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.206 Acc 94.943%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.053 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.053 Acc 98.298%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.053 Acc 98.255%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.053 Acc 98.269%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.054 Acc 98.194%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.055 Acc 98.146%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.130 Acc 96.094%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.052 Acc 98.275%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.053 Acc 98.255%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.054 Acc 98.287%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.055 Acc 98.215%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.056 Acc 98.155%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.206 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.204 Acc 95.297%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.195 Acc 95.410%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.047 Acc 98.345%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.052 Acc 98.270%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.053 Acc 98.230%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.051 Acc 98.299%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.054 Acc 98.213%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.158 Acc 95.312%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.207 Acc 95.111%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.062 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.049 Acc 98.345%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.052 Acc 98.204%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.051 Acc 98.235%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.051 Acc 98.301%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.053 Acc 98.238%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.217 Acc 95.011%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.210 Acc 95.095%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.103 Acc 96.094%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.053 Acc 98.175%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.051 Acc 98.247%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.050 Acc 98.305%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.051 Acc 98.247%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.051 Acc 98.271%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.205 Acc 94.438%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.193 Acc 94.803%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.021 Acc 99.219%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.049 Acc 98.368%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.050 Acc 98.321%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.052 Acc 98.300%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.051 Acc 98.301%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.051 Acc 98.311%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.211 Acc 94.833%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.201 Acc 94.986%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.046 Acc 98.480%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.047 Acc 98.409%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.049 Acc 98.375%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.051 Acc 98.344%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.099 Acc 96.875%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.217 Acc 94.903%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.206 Acc 95.106%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.052 Acc 98.260%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.055 Acc 98.216%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.052 Acc 98.284%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.054 Acc 98.200%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.054 Acc 98.194%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.162 Acc 96.094%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.223 Acc 94.841%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.210 Acc 95.040%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.047 Acc 98.314%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.046 Acc 98.379%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.048 Acc 98.339%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.048 Acc 98.367%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.050 Acc 98.353%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.211 Acc 94.926%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.202 Acc 95.145%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.038 Acc 96.875%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.042 Acc 98.631%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.047 Acc 98.403%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.048 Acc 98.373%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.049 Acc 98.379%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.048 Acc 98.369%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.231 Acc 94.748%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.219 Acc 94.932%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.048 Acc 98.348%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.047 Acc 98.409%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.048 Acc 98.387%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.049 Acc 98.392%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.163 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.218 Acc 95.243%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.208 Acc 95.305%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.064 Acc 96.094%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.047 Acc 98.445%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.044 Acc 98.574%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.045 Acc 98.549%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.045 Acc 98.525%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.046 Acc 98.466%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.218 Acc 94.787%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.205 Acc 94.928%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.051 Acc 97.656%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.047 Acc 98.461%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.049 Acc 98.406%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.048 Acc 98.430%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.049 Acc 98.391%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.049 Acc 98.384%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.177 Acc 96.094%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.205 Acc 95.367%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.195 Acc 95.398%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.045 Acc 98.492%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.046 Acc 98.440%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.047 Acc 98.420%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.048 Acc 98.395%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.182 Acc 94.531%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.195 Acc 95.282%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.188 Acc 95.421%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.042 Acc 98.600%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.045 Acc 98.418%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.045 Acc 98.430%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.047 Acc 98.389%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.047 Acc 98.391%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.170 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.211 Acc 95.189%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.202 Acc 95.328%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.047 Acc 98.407%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.045 Acc 98.488%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.046 Acc 98.448%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.046 Acc 98.432%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.048 Acc 98.378%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.235 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.221 Acc 95.034%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.214 Acc 95.114%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.042 Acc 98.577%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.045 Acc 98.480%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.045 Acc 98.492%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.046 Acc 98.420%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.046 Acc 98.433%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.193 Acc 95.374%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.187 Acc 95.414%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.034 Acc 97.656%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.038 Acc 98.631%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.041 Acc 98.562%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.042 Acc 98.567%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.043 Acc 98.537%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.044 Acc 98.489%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.223 Acc 94.593%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.215 Acc 94.761%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.043 Acc 98.523%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.043 Acc 98.570%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.043 Acc 98.559%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.042 Acc 98.582%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.044 Acc 98.520%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.144 Acc 95.312%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.205 Acc 95.119%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.195 Acc 95.281%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.034 Acc 97.656%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.045 Acc 98.399%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.042 Acc 98.550%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.042 Acc 98.580%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.043 Acc 98.589%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.044 Acc 98.544%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.216 Acc 95.127%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.043 Acc 98.561%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.041 Acc 98.597%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.041 Acc 98.603%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.042 Acc 98.545%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.262 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.234 Acc 95.042%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.224 Acc 94.998%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.039 Acc 98.646%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.042 Acc 98.566%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.043 Acc 98.575%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.044 Acc 98.484%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.044 Acc 98.523%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.209 Acc 95.019%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.201 Acc 95.215%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.039 Acc 98.677%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.039 Acc 98.612%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.040 Acc 98.614%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.041 Acc 98.588%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.042 Acc 98.572%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.144 Acc 96.875%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.205 Acc 95.166%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.197 Acc 95.417%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.043 Acc 98.461%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.042 Acc 98.588%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.043 Acc 98.535%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.044 Acc 98.522%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.187 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.219 Acc 95.150%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.206 Acc 95.386%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.046 Acc 98.453%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.047 Acc 98.399%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.045 Acc 98.443%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.044 Acc 98.482%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.044 Acc 98.480%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.212 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.221 Acc 95.042%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.213 Acc 95.048%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.041 Acc 98.600%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.042 Acc 98.570%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.043 Acc 98.534%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.044 Acc 98.523%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.044 Acc 98.486%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.225 Acc 95.258%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.211 Acc 95.425%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.035 Acc 98.793%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.040 Acc 98.659%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.041 Acc 98.635%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.042 Acc 98.632%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.041 Acc 98.639%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.234 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.223 Acc 95.019%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.212 Acc 95.138%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.035 Acc 98.855%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.042 Acc 98.557%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.041 Acc 98.566%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.041 Acc 98.570%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.218 Acc 94.872%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.210 Acc 94.974%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.037 Acc 98.801%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.041 Acc 98.593%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.040 Acc 98.630%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.040 Acc 98.621%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.040 Acc 98.629%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.214 Acc 96.094%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.244 Acc 94.547%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.232 Acc 94.780%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.034 Acc 98.855%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.040 Acc 98.659%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.043 Acc 98.531%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.044 Acc 98.496%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.043 Acc 98.525%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.178 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.215 Acc 94.980%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.203 Acc 95.118%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.035 Acc 98.811%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.037 Acc 98.788%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.037 Acc 98.753%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.038 Acc 98.712%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.217 Acc 95.088%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.205 Acc 95.243%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.071 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.044 Acc 98.708%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.042 Acc 98.678%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.041 Acc 98.648%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.040 Acc 98.662%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.040 Acc 98.643%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.221 Acc 94.910%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.207 Acc 95.262%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.039 Acc 98.677%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.041 Acc 98.647%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.039 Acc 98.705%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.041 Acc 98.650%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.042 Acc 98.590%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.198 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.231 Acc 94.964%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.217 Acc 95.208%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.016 Acc 100.000%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.037 Acc 98.832%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.037 Acc 98.826%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.037 Acc 98.816%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.037 Acc 98.775%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.039 Acc 98.687%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.141 Acc 95.312%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.218 Acc 95.367%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.205 Acc 95.534%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.031 Acc 98.909%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.033 Acc 98.811%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.035 Acc 98.759%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.036 Acc 98.714%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.038 Acc 98.653%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.179 Acc 95.312%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.234 Acc 94.833%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.222 Acc 95.106%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.038 Acc 98.677%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.038 Acc 98.694%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.038 Acc 98.705%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.038 Acc 98.699%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.038 Acc 98.701%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.135 Acc 96.875%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.224 Acc 95.196%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.213 Acc 95.425%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.039 Acc 99.219%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.035 Acc 98.747%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.034 Acc 98.752%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.036 Acc 98.723%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.037 Acc 98.708%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.037 Acc 98.717%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.196 Acc 93.750%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.234 Acc 95.266%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.222 Acc 95.472%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.038 Acc 98.631%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.038 Acc 98.725%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.037 Acc 98.733%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.038 Acc 98.718%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.038 Acc 98.729%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.147 Acc 96.875%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.255 Acc 94.709%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.242 Acc 94.807%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.041 Acc 98.608%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.038 Acc 98.682%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.038 Acc 98.700%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.038 Acc 98.728%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.039 Acc 98.687%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.119 Acc 96.875%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.210 Acc 95.011%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.199 Acc 95.188%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.037 Acc 98.670%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.037 Acc 98.694%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.036 Acc 98.744%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.036 Acc 98.714%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.240 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.223 Acc 95.220%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.209 Acc 95.476%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.038 Acc 98.739%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.037 Acc 98.787%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.037 Acc 98.762%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.038 Acc 98.716%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.038 Acc 98.720%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.240 Acc 94.794%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.224 Acc 95.072%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.041 Acc 98.592%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.037 Acc 98.748%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.037 Acc 98.707%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.037 Acc 98.704%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.037 Acc 98.717%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [100/204] Loss: 0.232 Acc 94.462%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 0.218 Acc 94.807%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.036 Acc 98.724%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.036 Acc 98.764%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.037 Acc 98.736%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.038 Acc 98.706%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.038 Acc 98.706%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.214 Acc 95.026%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.203 Acc 95.301%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.027 Acc 99.064%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.030 Acc 99.028%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.033 Acc 98.910%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.035 Acc 98.810%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.036 Acc 98.779%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.279 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.224 Acc 94.949%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.212 Acc 95.176%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.029 Acc 98.994%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.033 Acc 98.869%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.032 Acc 98.905%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.033 Acc 98.858%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.034 Acc 98.835%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.156 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.228 Acc 94.980%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.214 Acc 95.270%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.035 Acc 98.793%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.033 Acc 98.853%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.036 Acc 98.754%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.037 Acc 98.734%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.036 Acc 98.751%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.194 Acc 92.969%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.226 Acc 95.096%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.215 Acc 95.289%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.027 Acc 99.080%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.031 Acc 98.951%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.031 Acc 98.957%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.031 Acc 98.958%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.034 Acc 98.873%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.174 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.217 Acc 94.980%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.206 Acc 95.184%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.029 Acc 99.072%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.031 Acc 98.966%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.032 Acc 98.902%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.032 Acc 98.917%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.033 Acc 98.873%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.142 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.212 Acc 95.127%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.204 Acc 95.278%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.015 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.033 Acc 98.824%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.033 Acc 98.850%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.034 Acc 98.822%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.034 Acc 98.835%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.035 Acc 98.820%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.226 Acc 95.119%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.214 Acc 95.340%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.032 Acc 98.940%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.031 Acc 98.931%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.032 Acc 98.871%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.033 Acc 98.812%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.035 Acc 98.787%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.216 Acc 94.640%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.208 Acc 94.900%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.033 Acc 98.925%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.034 Acc 98.861%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.034 Acc 98.845%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.035 Acc 98.833%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.035 Acc 98.832%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.286 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.229 Acc 94.554%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.219 Acc 94.838%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.012 Acc 100.000%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.031 Acc 98.878%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.031 Acc 98.935%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.031 Acc 98.923%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.032 Acc 98.895%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.032 Acc 98.857%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.251 Acc 94.848%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.238 Acc 95.204%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.037 Acc 98.739%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.036 Acc 98.764%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.034 Acc 98.819%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.034 Acc 98.815%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.034 Acc 98.818%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.232 Acc 94.616%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.218 Acc 94.799%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.031 Acc 98.900%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.032 Acc 98.855%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.033 Acc 98.847%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.033 Acc 98.849%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.235 Acc 94.995%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.220 Acc 95.157%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.029 Acc 98.979%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.032 Acc 98.954%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.033 Acc 98.876%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.033 Acc 98.915%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.033 Acc 98.910%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.136 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.228 Acc 94.763%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.215 Acc 95.083%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.032 Acc 98.786%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.029 Acc 98.888%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.031 Acc 98.879%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.031 Acc 98.880%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.032 Acc 98.857%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.228 Acc 95.196%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.213 Acc 95.468%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.030 Acc 98.971%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.032 Acc 98.896%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.031 Acc 98.946%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.032 Acc 98.907%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.032 Acc 98.902%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.305 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [135/200]Batch [100/204] Loss: 0.223 Acc 95.359%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.211 Acc 95.460%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.110 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.028 Acc 99.080%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.033 Acc 98.923%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.033 Acc 98.889%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.033 Acc 98.870%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.033 Acc 98.888%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.222 Acc 94.941%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.209 Acc 95.211%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.031 Acc 98.878%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.030 Acc 98.904%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.031 Acc 98.920%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.031 Acc 98.911%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.031 Acc 98.885%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.222 Acc 95.150%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.208 Acc 95.359%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.028 Acc 98.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.033 Acc 98.933%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.033 Acc 98.919%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.033 Acc 98.897%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.033 Acc 98.886%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.032 Acc 98.912%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.244 Acc 94.964%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.229 Acc 95.075%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.030 Acc 98.909%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.033 Acc 98.896%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.031 Acc 98.951%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.031 Acc 98.950%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.032 Acc 98.907%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.227 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.231 Acc 95.088%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.220 Acc 95.192%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.025 Acc 99.141%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.027 Acc 99.001%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.027 Acc 98.993%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.029 Acc 98.950%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.030 Acc 98.921%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.242 Acc 94.547%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.226 Acc 94.784%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.014 Acc 100.000%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.029 Acc 98.909%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.031 Acc 98.877%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.031 Acc 98.897%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.032 Acc 98.878%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.032 Acc 98.865%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.245 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.237 Acc 94.957%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.226 Acc 95.227%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.005 Acc 100.000%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.028 Acc 98.987%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.030 Acc 98.978%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.030 Acc 98.975%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.030 Acc 98.936%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.031 Acc 98.926%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.230 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.226 Acc 94.926%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.212 Acc 95.141%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.026 Acc 99.103%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.029 Acc 99.014%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.030 Acc 98.991%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.030 Acc 98.960%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.257 Acc 94.833%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.240 Acc 95.037%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.029 Acc 99.080%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.030 Acc 99.017%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.030 Acc 98.975%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.030 Acc 98.965%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.031 Acc 98.954%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.279 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.236 Acc 94.980%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.226 Acc 95.188%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.032 Acc 98.909%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.030 Acc 98.916%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.031 Acc 98.871%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.032 Acc 98.843%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.032 Acc 98.865%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.140 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.224 Acc 95.135%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.212 Acc 95.332%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.025 Acc 98.438%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.033 Acc 99.002%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.030 Acc 98.982%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.031 Acc 98.909%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.031 Acc 98.937%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.364 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.253 Acc 94.794%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.235 Acc 95.033%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.032 Acc 98.863%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.030 Acc 98.958%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.030 Acc 98.925%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.029 Acc 98.979%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.029 Acc 98.986%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.219 Acc 95.359%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.208 Acc 95.553%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.026 Acc 99.018%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.027 Acc 99.052%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.028 Acc 99.021%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.029 Acc 99.001%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.029 Acc 98.983%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.266 Acc 95.312%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.227 Acc 94.972%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.217 Acc 95.196%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.056 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.027 Acc 99.110%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.026 Acc 99.067%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.027 Acc 99.058%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.027 Acc 99.073%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.028 Acc 99.013%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.282 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.256 Acc 94.864%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.245 Acc 94.932%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.036 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.027 Acc 99.080%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.029 Acc 99.001%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.031 Acc 98.967%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.030 Acc 98.954%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.030 Acc 98.991%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [150/200]Batch [100/204] Loss: 0.215 Acc 94.910%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.200 Acc 95.274%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 0.028 Acc 99.018%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.027 Acc 99.040%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.028 Acc 99.022%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.029 Acc 98.972%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.254 Acc 94.825%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.241 Acc 94.970%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.041 Acc 99.219%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.030 Acc 98.925%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.030 Acc 98.912%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.030 Acc 98.907%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.031 Acc 98.913%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.031 Acc 98.904%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.223 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.233 Acc 94.964%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.220 Acc 95.165%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.027 Acc 99.103%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.029 Acc 99.032%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.030 Acc 98.998%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.030 Acc 98.987%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.030 Acc 98.983%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.236 Acc 95.189%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.219 Acc 95.507%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.031 Acc 98.948%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.030 Acc 99.005%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.030 Acc 99.019%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.030 Acc 99.006%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.030 Acc 98.968%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.190 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.232 Acc 94.988%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.220 Acc 95.161%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.012 Acc 99.219%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.026 Acc 99.103%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.026 Acc 99.106%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.026 Acc 99.114%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.027 Acc 99.074%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.188 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.230 Acc 95.166%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.218 Acc 95.258%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.014 Acc 99.219%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.029 Acc 98.987%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.030 Acc 99.009%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.028 Acc 99.037%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.028 Acc 99.059%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.028 Acc 99.036%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.216 Acc 95.212%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.202 Acc 95.515%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.013 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.022 Acc 99.203%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.025 Acc 99.172%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.025 Acc 99.169%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.025 Acc 99.158%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.027 Acc 99.113%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.192 Acc 96.094%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.242 Acc 95.026%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.228 Acc 95.169%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.019 Acc 99.319%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.024 Acc 99.122%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.026 Acc 99.076%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.026 Acc 99.078%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.027 Acc 99.066%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.224 Acc 96.094%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.235 Acc 95.498%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.223 Acc 95.666%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.025 Acc 99.049%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.028 Acc 98.989%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.029 Acc 98.957%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.029 Acc 98.975%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.028 Acc 99.029%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.204 Acc 95.312%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.232 Acc 95.096%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.222 Acc 95.250%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.030 Acc 99.118%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.030 Acc 99.040%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.028 Acc 99.118%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.028 Acc 99.069%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.028 Acc 99.055%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.245 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.254 Acc 94.895%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.241 Acc 95.060%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.023 Acc 99.226%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.029 Acc 98.985%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.029 Acc 99.004%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.029 Acc 98.996%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.229 Acc 95.050%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.213 Acc 95.417%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.025 Acc 99.226%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.026 Acc 99.114%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.027 Acc 99.092%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.027 Acc 99.060%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.234 Acc 94.848%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.220 Acc 95.138%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.027 Acc 99.134%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.028 Acc 99.044%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.027 Acc 99.040%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.026 Acc 99.049%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.027 Acc 99.010%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.254 Acc 94.531%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.249 Acc 94.756%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.232 Acc 95.114%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.027 Acc 99.219%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.031 Acc 98.987%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.027 Acc 99.075%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.030 Acc 98.980%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.029 Acc 99.006%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.029 Acc 98.988%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.206 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.230 Acc 94.995%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.216 Acc 95.320%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.028 Acc 99.056%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.026 Acc 99.145%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.026 Acc 99.154%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.026 Acc 99.133%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.027 Acc 99.102%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.155 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [165/200]Batch [100/204] Loss: 0.242 Acc 95.297%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.226 Acc 95.390%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.021 Acc 100.000%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.023 Acc 99.157%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.024 Acc 99.106%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.025 Acc 99.136%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.026 Acc 99.082%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.027 Acc 99.071%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.241 Acc 94.918%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.224 Acc 95.145%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.024 Acc 99.141%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.026 Acc 99.102%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.027 Acc 99.082%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.027 Acc 99.082%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.242 Acc 94.361%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.226 Acc 94.652%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.027 Acc 99.087%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.027 Acc 99.063%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.027 Acc 99.055%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.028 Acc 99.045%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.028 Acc 99.041%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.232 Acc 94.957%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.218 Acc 95.200%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.028 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.024 Acc 99.103%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.025 Acc 99.145%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.024 Acc 99.214%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.025 Acc 99.186%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.027 Acc 99.121%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.286 Acc 92.188%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.249 Acc 95.019%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.232 Acc 95.281%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.029 Acc 99.087%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.026 Acc 99.122%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.027 Acc 99.089%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.027 Acc 99.071%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.028 Acc 99.050%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.225 Acc 95.220%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.209 Acc 95.332%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.028 Acc 97.656%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.025 Acc 99.172%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.023 Acc 99.199%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.024 Acc 99.193%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.024 Acc 99.170%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.024 Acc 99.159%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.231 Acc 95.312%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.255 Acc 94.802%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.240 Acc 95.075%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.087 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.031 Acc 98.894%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.028 Acc 99.013%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.028 Acc 99.014%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.029 Acc 99.020%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.028 Acc 99.049%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.237 Acc 95.135%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.220 Acc 95.382%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.007 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.020 Acc 99.404%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.022 Acc 99.312%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.024 Acc 99.224%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.024 Acc 99.170%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.026 Acc 99.097%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.216 Acc 95.312%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.230 Acc 94.941%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.215 Acc 95.184%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.021 Acc 99.226%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.024 Acc 99.153%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.025 Acc 99.123%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.026 Acc 99.123%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.027 Acc 99.091%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.201 Acc 96.094%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.254 Acc 94.756%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.241 Acc 94.893%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.038 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.027 Acc 99.072%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.024 Acc 99.188%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.024 Acc 99.193%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.024 Acc 99.191%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.025 Acc 99.139%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.250 Acc 95.312%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.242 Acc 95.057%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.226 Acc 95.239%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.016 Acc 99.219%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.024 Acc 99.118%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.025 Acc 99.156%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.025 Acc 99.143%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.025 Acc 99.122%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 96.094%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.248 Acc 95.343%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.229 Acc 95.476%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.025 Acc 99.056%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.023 Acc 99.168%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.024 Acc 99.159%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.025 Acc 99.156%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.025 Acc 99.164%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.243 Acc 96.094%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.245 Acc 95.003%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.228 Acc 95.278%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.011 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.026 Acc 99.141%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.024 Acc 99.203%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.024 Acc 99.185%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.025 Acc 99.154%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.025 Acc 99.124%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.241 Acc 94.980%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.227 Acc 95.227%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.026 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.025 Acc 99.141%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.025 Acc 99.180%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.025 Acc 99.168%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.025 Acc 99.161%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.248 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.245 Acc 94.972%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.229 Acc 95.204%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.072 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.025 Acc 99.118%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.024 Acc 99.203%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.025 Acc 99.203%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.025 Acc 99.168%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.025 Acc 99.147%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [180/200]Batch [100/204] Loss: 0.230 Acc 95.127%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.213 Acc 95.336%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.007 Acc 100.000%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.023 Acc 99.265%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.022 Acc 99.300%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.022 Acc 99.278%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.023 Acc 99.267%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.024 Acc 99.248%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.231 Acc 95.135%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.217 Acc 95.320%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.033 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.022 Acc 99.250%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.023 Acc 99.223%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.024 Acc 99.172%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.024 Acc 99.178%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.025 Acc 99.156%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.256 Acc 96.094%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.249 Acc 94.903%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.235 Acc 95.044%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.023 Acc 99.103%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.024 Acc 99.141%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.024 Acc 99.167%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.025 Acc 99.136%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.176 Acc 92.188%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.225 Acc 94.864%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.213 Acc 95.180%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.023 Acc 99.172%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.025 Acc 99.122%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.026 Acc 99.102%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.027 Acc 99.094%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.026 Acc 99.127%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.212 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.253 Acc 95.235%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.237 Acc 95.429%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.022 Acc 99.157%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.023 Acc 99.137%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.025 Acc 99.102%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.026 Acc 99.092%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.025 Acc 99.105%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.246 Acc 95.104%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.233 Acc 95.363%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.017 Acc 99.366%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.021 Acc 99.246%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.024 Acc 99.136%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.025 Acc 99.119%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.024 Acc 99.153%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.291 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.249 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.233 Acc 95.573%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.024 Acc 99.180%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.026 Acc 99.106%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.027 Acc 99.092%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.026 Acc 99.121%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.026 Acc 99.131%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.322 Acc 93.750%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.251 Acc 95.034%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.237 Acc 95.223%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.020 Acc 99.265%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.020 Acc 99.331%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.022 Acc 99.252%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.023 Acc 99.223%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.023 Acc 99.198%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.238 Acc 94.949%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.225 Acc 95.176%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.020 Acc 99.319%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.020 Acc 99.285%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.021 Acc 99.276%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.023 Acc 99.234%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.025 Acc 99.161%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.250 Acc 95.374%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.234 Acc 95.468%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.020 Acc 99.288%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.021 Acc 99.246%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.023 Acc 99.172%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.023 Acc 99.184%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.024 Acc 99.169%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.271 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.235 Acc 95.196%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.221 Acc 95.460%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.024 Acc 98.438%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.020 Acc 99.428%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.021 Acc 99.308%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.021 Acc 99.291%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.022 Acc 99.227%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.023 Acc 99.183%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.302 Acc 92.969%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.243 Acc 95.073%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.229 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.004 Acc 100.000%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.024 Acc 99.126%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.024 Acc 99.157%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.023 Acc 99.188%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.024 Acc 99.176%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.025 Acc 99.141%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.237 Acc 95.282%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.227 Acc 95.367%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.021 Acc 99.335%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.023 Acc 99.260%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.023 Acc 99.222%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.245 Acc 95.312%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.254 Acc 94.740%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.235 Acc 95.103%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.021 Acc 99.335%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.022 Acc 99.262%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.022 Acc 99.268%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.022 Acc 99.254%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.023 Acc 99.227%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.246 Acc 96.094%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.251 Acc 94.910%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.238 Acc 95.219%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.024 Acc 99.257%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.022 Acc 99.281%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.021 Acc 99.284%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.021 Acc 99.275%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.021 Acc 99.245%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [195/200]Batch [100/204] Loss: 0.246 Acc 94.957%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.232 Acc 95.239%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.009 Acc 100.000%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.026 Acc 99.172%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.025 Acc 99.149%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.025 Acc 99.125%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.025 Acc 99.145%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.024 Acc 99.163%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.191 Acc 94.531%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.236 Acc 95.235%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.224 Acc 95.495%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.018 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.023 Acc 99.234%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.023 Acc 99.246%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.022 Acc 99.265%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.022 Acc 99.266%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.023 Acc 99.251%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.210 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.264 Acc 95.088%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.248 Acc 95.165%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.017 Acc 99.219%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.026 Acc 99.141%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.023 Acc 99.211%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.024 Acc 99.169%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.024 Acc 99.190%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.023 Acc 99.214%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.267 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.259 Acc 94.964%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.243 Acc 95.208%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.017 Acc 99.474%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.020 Acc 99.355%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.020 Acc 99.369%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.021 Acc 99.328%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.021 Acc 99.315%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.262 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.293 Acc 93.920%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.270 Acc 94.290%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba61029e3b8f4f579817542977b908d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2024ee24a84ae4bd7c9144d41029f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.303 Acc 11.719%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 8.025 Acc 15.401%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 5.146 Acc 17.339%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 4.179 Acc 17.953%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 3.695 Acc 18.214%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 3.404 Acc 18.318%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.255 Acc 17.969%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.236 Acc 18.843%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.234 Acc 19.049%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.235 Acc 19.025%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 18.939%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 18.862%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.230 Acc 15.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.237 Acc 19.067%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.235 Acc 19.080%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.235 Acc 19.093%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.315 Acc 10.938%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.235 Acc 19.640%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 19.174%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.212 Acc 21.094%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.240 Acc 18.727%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.239 Acc 18.862%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.239 Acc 18.857%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.238 Acc 18.900%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.222 Acc 17.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.230 Acc 19.276%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.234 Acc 19.080%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.235 Acc 19.007%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.169 Acc 29.688%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.242 Acc 18.487%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.241 Acc 18.404%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.238 Acc 18.690%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.238 Acc 18.732%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.204 Acc 25.781%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.239 Acc 16.406%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.242 Acc 18.533%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.236 Acc 18.854%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.238 Acc 18.851%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.254 Acc 15.625%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.241 Acc 18.673%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.239 Acc 19.049%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.237 Acc 19.072%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.225 Acc 19.562%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.174 Acc 26.562%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 6213550647.636 Acc 17.164%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 37551639969.051 Acc 13.402%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 25104879750.669 Acc 12.129%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 18855689582.073 Acc 11.415%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 15094789924.211 Acc 11.185%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 7.187 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 7.676 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 7.696 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 6041380.000 Acc 10.156%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 5473234.931 Acc 11.231%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 4976875.229 Acc 11.497%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 4544429.591 Acc 11.734%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 4206809.904 Acc 11.822%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 3938327.651 Acc 11.948%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 11.669 Acc 9.375%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 12.234 Acc 11.108%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 12.264 Acc 11.093%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2507511.750 Acc 10.938%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2311833.406 Acc 13.436%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2187310.575 Acc 13.623%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2092788.024 Acc 13.647%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2018538.674 Acc 13.714%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 1942253.055 Acc 13.864%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 17.163 Acc 9.375%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 17.601 Acc 11.108%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 17.640 Acc 11.093%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 1888615.250 Acc 12.500%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 1459795.185 Acc 14.070%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 1393741.603 Acc 14.109%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 1340408.878 Acc 14.210%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 1313410.556 Acc 14.238%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 1260194.836 Acc 14.203%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 22.430 Acc 9.375%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 22.853 Acc 11.108%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 22.899 Acc 11.093%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 908454.750 Acc 12.500%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 956601.303 Acc 14.202%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 930840.723 Acc 14.265%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 901913.691 Acc 14.314%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 875672.090 Acc 14.288%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 844684.134 Acc 14.310%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 27.390 Acc 9.375%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 27.907 Acc 11.108%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 27.959 Acc 11.093%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 526005.688 Acc 17.969%\n",
      "Train Epoch [ 15/200]Batch [100/573] Loss: 612044.314 Acc 14.356%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 600380.545 Acc 14.152%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 577658.191 Acc 14.091%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 563275.872 Acc 14.105%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 543114.875 Acc 14.014%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 32.159 Acc 9.375%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 32.872 Acc 11.108%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 32.929 Acc 11.093%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 447300.031 Acc 13.281%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 407633.550 Acc 14.016%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 395274.217 Acc 13.724%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 386481.198 Acc 13.652%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 373672.679 Acc 13.636%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 358889.282 Acc 13.585%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 36.693 Acc 9.375%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 37.637 Acc 11.108%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 37.699 Acc 11.093%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 292437.875 Acc 10.156%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 253033.740 Acc 13.622%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 241545.837 Acc 13.717%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 232323.333 Acc 13.806%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 222294.857 Acc 13.741%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 216782.666 Acc 13.772%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 41.517 Acc 9.375%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 42.568 Acc 11.108%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 42.636 Acc 11.093%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 160903.500 Acc 12.500%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 161151.500 Acc 13.784%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 164359.385 Acc 13.577%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 153657.264 Acc 13.632%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 156148.302 Acc 13.418%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 149851.187 Acc 13.341%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 45.191 Acc 9.375%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 46.436 Acc 11.108%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 46.506 Acc 11.093%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 63205.645 Acc 17.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 94403.536 Acc 13.390%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 88352.827 Acc 13.371%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 90885.111 Acc 13.294%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 86646.933 Acc 13.285%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 83086.624 Acc 13.217%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 46.909 Acc 9.375%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 48.046 Acc 11.108%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 48.111 Acc 11.093%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 45848.961 Acc 10.938%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 70149.331 Acc 12.972%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 61051.910 Acc 12.955%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 53685.090 Acc 12.848%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 55921.962 Acc 12.808%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 51164.849 Acc 12.782%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 44.300 Acc 9.375%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 45.207 Acc 11.108%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 45.251 Acc 11.093%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 18917.396 Acc 18.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 35828.784 Acc 12.693%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 30236.849 Acc 12.484%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 30473.959 Acc 12.453%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 29109.716 Acc 12.387%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 27399.590 Acc 12.321%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 39.009 Acc 9.375%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 39.796 Acc 11.108%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 39.818 Acc 11.093%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 11112.469 Acc 15.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 18974.805 Acc 11.974%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 20543.330 Acc 11.917%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 19506.000 Acc 12.009%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 18980.794 Acc 11.986%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 17907.474 Acc 11.981%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 32.365 Acc 9.375%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 33.266 Acc 11.108%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 33.257 Acc 11.093%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 6967.160 Acc 10.156%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 9300.033 Acc 11.603%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 8596.181 Acc 11.855%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 8409.276 Acc 12.043%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 8291.172 Acc 11.867%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 9299.169 Acc 11.911%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 25.181 Acc 9.375%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 26.245 Acc 11.108%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 26.205 Acc 11.093%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 3703.797 Acc 14.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 7592.864 Acc 12.005%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 7847.532 Acc 11.758%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 7758.796 Acc 11.760%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 12206.384 Acc 11.746%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 11231.750 Acc 11.719%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 19.585 Acc 9.375%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 20.732 Acc 11.108%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 20.670 Acc 11.093%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 1433.439 Acc 13.281%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 4798.989 Acc 11.858%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 4252.188 Acc 11.835%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 4642.637 Acc 11.724%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 4589.142 Acc 11.699%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 4551.210 Acc 11.737%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 14.822 Acc 9.375%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 15.905 Acc 11.108%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 15.842 Acc 11.093%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2972.569 Acc 12.500%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 4132.033 Acc 11.255%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 4028.600 Acc 11.544%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 3535.654 Acc 11.490%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 3507.258 Acc 11.584%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 3769.963 Acc 11.638%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 9.964 Acc 9.375%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 10.976 Acc 11.108%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 10.913 Acc 11.093%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2050.243 Acc 12.500%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 1782.913 Acc 12.028%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2166.118 Acc 11.929%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2018.950 Acc 13.427%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 1912.508 Acc 14.838%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 1785.121 Acc 15.533%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 8.076 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 8.969 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 8.913 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2006.777 Acc 18.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 1798.753 Acc 18.735%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 1725.513 Acc 18.847%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 1608.431 Acc 18.836%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 1537.532 Acc 18.756%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 1564.648 Acc 18.725%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 7.050 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 7.792 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 7.745 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 389.863 Acc 18.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2761.735 Acc 18.796%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 1745.843 Acc 18.672%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 1553.086 Acc 18.763%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 1545.196 Acc 18.649%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 1349.591 Acc 18.697%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 5.983 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 6.571 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 6.534 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 473.417 Acc 18.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 605.824 Acc 18.719%\n",
      "Train Epoch [ 30/200]Batch [200/573] Loss: 648.914 Acc 18.633%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 914.802 Acc 18.779%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 1035.822 Acc 18.768%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 970.848 Acc 18.655%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 4.877 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 5.303 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 5.276 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 22.792 Acc 21.094%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 957.913 Acc 18.464%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 1108.719 Acc 18.552%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 932.388 Acc 18.675%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 825.785 Acc 18.701%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 731.564 Acc 18.783%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 3.778 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 4.045 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 4.029 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 213.059 Acc 14.062%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 540.039 Acc 19.075%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 470.664 Acc 19.166%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 437.730 Acc 18.937%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 378.047 Acc 18.912%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 348.678 Acc 18.794%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.610 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.704 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.699 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 67.964 Acc 21.094%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 297.568 Acc 19.021%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 306.675 Acc 19.282%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 294.340 Acc 19.129%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 384.530 Acc 19.089%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 334.494 Acc 18.869%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 552.268 Acc 13.281%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 168.669 Acc 18.835%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 409.513 Acc 19.123%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 323.366 Acc 18.903%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 459.588 Acc 18.859%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 405.835 Acc 18.971%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.241 Acc 16.406%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 77.093 Acc 18.711%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 89.257 Acc 18.661%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 80.736 Acc 18.921%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 73.796 Acc 18.990%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 106.043 Acc 18.897%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.274 Acc 14.844%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 137.352 Acc 18.742%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 112.779 Acc 18.917%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 101.378 Acc 19.093%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 90.553 Acc 19.085%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 1202.635 Acc 18.931%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.223 Acc 20.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 292.400 Acc 18.866%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 276.161 Acc 18.991%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 239.156 Acc 19.059%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 243.641 Acc 19.042%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 217.404 Acc 19.021%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 431.644 Acc 15.625%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 79.793 Acc 18.541%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 54.305 Acc 18.789%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 50.986 Acc 18.677%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 53.645 Acc 18.842%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 52.200 Acc 18.876%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.272 Acc 20.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 35.276 Acc 18.557%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 28.471 Acc 18.855%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 22.003 Acc 18.971%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 34.963 Acc 19.064%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 37.115 Acc 19.015%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.241 Acc 17.188%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 53.433 Acc 19.230%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 43.128 Acc 19.131%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 10003096496.770 Acc 17.940%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 7536548727.768 Acc 16.180%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 6032569618.667 Acc 15.173%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.317 Acc 14.062%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.331 Acc 16.120%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.335 Acc 15.986%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 569269.500 Acc 5.469%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 579362.330 Acc 11.231%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 643076.310 Acc 11.692%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 526277.091 Acc 12.124%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 481483.459 Acc 12.186%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 435967.312 Acc 12.389%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.255 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.276 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.279 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 64445.195 Acc 16.406%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 149227.716 Acc 14.356%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 162712.317 Acc 14.358%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 148853.404 Acc 14.569%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 135026.937 Acc 14.807%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 129305.400 Acc 14.802%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 162876.094 Acc 17.188%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 82774.223 Acc 15.934%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 80779.525 Acc 15.909%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 81335.672 Acc 16.079%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 73378.340 Acc 16.231%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 66883.069 Acc 16.481%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 55375.816 Acc 19.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 63703.041 Acc 16.530%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 50863.328 Acc 16.768%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 48562.225 Acc 16.936%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 51873.907 Acc 17.164%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 49557.751 Acc 17.145%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 5269.593 Acc 13.281%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 184730.553 Acc 17.737%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 110343.663 Acc 17.887%\n",
      "Train Epoch [ 45/200]Batch [300/573] Loss: 84608.275 Acc 17.958%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 70553.611 Acc 18.014%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 77614.448 Acc 18.129%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 614.554 Acc 20.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 22879.371 Acc 18.533%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 24199.475 Acc 18.280%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 21720.314 Acc 18.394%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 18364.042 Acc 18.317%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 18364.888 Acc 18.373%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 16937.070 Acc 14.844%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 9163.843 Acc 18.270%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 12376.207 Acc 18.396%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 12386.037 Acc 18.387%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 14070.509 Acc 18.430%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 13757.779 Acc 18.454%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 844.195 Acc 25.781%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 11278.502 Acc 18.665%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 12148.474 Acc 18.563%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 12554.099 Acc 18.540%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 12026.046 Acc 18.635%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 10750.558 Acc 18.583%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 138.299 Acc 23.438%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 7370.496 Acc 18.843%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 7857.298 Acc 19.185%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 7251.319 Acc 18.945%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 6661.829 Acc 18.929%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 6775.552 Acc 18.806%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2710.559 Acc 15.625%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 11205.681 Acc 18.487%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 8512.851 Acc 18.509%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 6558.431 Acc 18.745%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 5883.780 Acc 18.775%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 6326.969 Acc 18.830%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 3028.367 Acc 21.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 4226.843 Acc 18.696%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 3221.334 Acc 18.614%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2778.574 Acc 18.760%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 3063.038 Acc 18.791%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2835.049 Acc 18.844%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 16252.369 Acc 16.406%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2951.769 Acc 18.843%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2902.062 Acc 18.563%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 3313.646 Acc 18.711%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2957.822 Acc 18.758%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 3180.259 Acc 18.842%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.250 Acc 15.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 5956.408 Acc 18.649%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 3933.581 Acc 19.174%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 3413.799 Acc 18.984%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 3387.115 Acc 19.029%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 3093.462 Acc 18.943%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.261 Acc 17.188%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 610.716 Acc 19.554%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 1228.969 Acc 19.310%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 1564.979 Acc 18.937%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 1476.887 Acc 18.974%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 1366.051 Acc 18.971%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.172 Acc 22.656%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 1317.795 Acc 19.175%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 1261.057 Acc 18.917%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 1080.701 Acc 18.823%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 1297.026 Acc 18.892%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 1262.169 Acc 18.928%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 26588.791 Acc 19.531%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 728.036 Acc 19.036%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 769.429 Acc 19.049%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 609.208 Acc 18.784%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 808.209 Acc 18.779%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 662.029 Acc 18.811%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 225.114 Acc 19.052%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 287.306 Acc 18.983%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 558.531 Acc 18.779%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 504.395 Acc 18.738%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 534.971 Acc 18.834%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.262 Acc 17.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 998.951 Acc 18.943%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 1092.295 Acc 18.890%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 58/200]Batch [300/573] Loss: 927.867 Acc 18.784%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 765.131 Acc 18.900%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 648.897 Acc 18.854%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2196.799 Acc 16.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 4488.168 Acc 19.694%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2384.479 Acc 18.929%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 1645.912 Acc 19.015%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 1317.479 Acc 18.824%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 1150.323 Acc 18.918%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.278 Acc 20.312%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 952.202 Acc 18.649%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 1113.443 Acc 18.711%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 1490.714 Acc 18.965%\n",
      "Train Epoch [ 60/200]Batch [400/573] Loss: 1189.772 Acc 18.980%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 966.603 Acc 19.034%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 799797.549 Acc 18.835%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 403273.636 Acc 19.030%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 269365.957 Acc 18.869%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 202506.780 Acc 18.925%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 167984.569 Acc 18.878%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.223 Acc 17.188%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 5.043 Acc 18.866%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 32.773 Acc 18.762%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 26.656 Acc 18.823%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 51.914 Acc 18.918%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 42.235 Acc 18.922%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.225 Acc 19.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.239 Acc 18.588%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.237 Acc 18.989%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 10.731 Acc 18.847%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 9.036 Acc 18.879%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.239 Acc 18.642%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.238 Acc 18.731%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.906 Acc 18.963%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 12.178 Acc 18.898%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 19.594 Acc 18.872%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.193 Acc 21.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.234 Acc 19.044%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.236 Acc 18.649%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.236 Acc 18.926%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.236 Acc 18.943%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 297.967 Acc 19.407%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 150.840 Acc 19.119%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 101.471 Acc 19.015%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 76.724 Acc 18.951%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 61.856 Acc 19.001%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.281 Acc 16.406%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.238 Acc 18.742%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.238 Acc 18.777%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.284 Acc 11.719%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.241 Acc 18.572%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.240 Acc 18.785%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.239 Acc 19.004%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.238 Acc 18.975%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.255 Acc 20.312%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.241 Acc 18.804%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.240 Acc 18.626%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 146.738 Acc 18.859%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 117.896 Acc 18.833%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.274 Acc 15.625%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.239 Acc 18.929%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.199 Acc 24.219%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.234 Acc 19.059%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.237 Acc 18.738%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.238 Acc 18.734%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.234 Acc 22.656%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.236 Acc 18.929%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.238 Acc 18.736%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.237 Acc 18.878%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.225 Acc 21.875%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.234 Acc 19.214%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.233 Acc 19.034%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 4.269 Acc 19.019%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 3.864 Acc 18.954%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.208 Acc 21.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.236 Acc 19.268%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.238 Acc 18.856%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.234 Acc 19.154%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.235 Acc 19.028%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.237 Acc 18.975%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.205 Acc 24.219%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.236 Acc 18.893%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.236 Acc 18.921%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.234 Acc 14.062%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 61.817 Acc 19.114%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 32.174 Acc 19.228%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 22.228 Acc 19.064%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 17.244 Acc 18.986%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 14.248 Acc 18.989%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.238 Acc 17.188%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.236 Acc 18.952%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.237 Acc 18.955%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.277 Acc 14.062%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.239 Acc 18.789%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.239 Acc 18.797%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.239 Acc 18.770%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.212 Acc 23.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.987%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.238 Acc 19.034%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.188 Acc 27.344%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.235 Acc 18.448%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 18.806%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.185 Acc 22.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.235 Acc 19.251%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.238 Acc 18.906%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.893%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.195 Acc 22.656%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.243 Acc 18.727%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.240 Acc 18.703%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.238 Acc 18.867%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.270 Acc 17.188%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.230 Acc 19.779%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.233 Acc 19.481%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 17.491 Acc 19.048%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 17.530 Acc 18.993%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.251 Acc 17.188%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.240 Acc 18.619%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.237 Acc 18.956%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.237 Acc 18.971%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.290 Acc 20.312%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.240 Acc 18.827%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.238 Acc 19.127%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.238 Acc 19.100%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.238 Acc 18.982%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.238 Acc 18.932%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.305 Acc 17.188%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 1012774983.521 Acc 19.206%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 508906833.984 Acc 18.937%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 339834796.860 Acc 18.802%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 255087965.283 Acc 18.888%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 204172712.573 Acc 18.953%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.259 Acc 18.750%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.237 Acc 18.881%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.239 Acc 18.688%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.239 Acc 18.742%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 519.081 Acc 18.961%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.161 Acc 25.000%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.242 Acc 18.835%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.238 Acc 18.972%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 849.208 Acc 18.965%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 637.994 Acc 18.881%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 511.095 Acc 18.957%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.244 Acc 18.750%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.237 Acc 18.719%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.237 Acc 18.859%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.237 Acc 18.810%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.251 Acc 14.844%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.236 Acc 18.982%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.236 Acc 19.014%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.235 Acc 18.893%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.305 Acc 15.625%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.237 Acc 19.014%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.237 Acc 19.056%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.219 Acc 21.875%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.240 Acc 18.781%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.237 Acc 18.799%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.270 Acc 17.969%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.240 Acc 18.889%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.238 Acc 18.952%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.238 Acc 18.879%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.219 Acc 21.094%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.236 Acc 18.766%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.237 Acc 18.789%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.259 Acc 13.281%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.239 Acc 18.851%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 217.008 Acc 18.830%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 163.449 Acc 18.908%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 131.272 Acc 18.851%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.269 Acc 18.750%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.246 Acc 18.317%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.241 Acc 18.766%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.240 Acc 18.906%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.238 Acc 19.005%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.213 Acc 20.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.241 Acc 18.719%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.238 Acc 19.014%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.237 Acc 18.805%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.250 Acc 14.062%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.231 Acc 19.531%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 365.787 Acc 19.500%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 245.005 Acc 19.202%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 184.466 Acc 19.050%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 148.094 Acc 18.864%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.246 Acc 21.875%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.237 Acc 18.781%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.235 Acc 18.960%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.237 Acc 18.807%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.834%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.213 Acc 25.000%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.236 Acc 18.889%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.235 Acc 19.004%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.236 Acc 18.919%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.845%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.230 Acc 12.500%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.236 Acc 18.862%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.236 Acc 18.916%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.236 Acc 19.000%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.214 Acc 21.094%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.240 Acc 18.588%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [103/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.236 Acc 18.962%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.236 Acc 18.934%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.203 Acc 26.562%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.240 Acc 18.502%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.239 Acc 18.812%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.237 Acc 18.727%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.236 Acc 18.956%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.237 Acc 19.005%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.277 Acc 9.375%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.236 Acc 19.175%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.234 Acc 19.259%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.238 Acc 18.872%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.243 Acc 14.844%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.240 Acc 18.824%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.238 Acc 18.900%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.282 Acc 16.406%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.236 Acc 19.174%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.237 Acc 18.964%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.242 Acc 18.557%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.238 Acc 18.794%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.237 Acc 18.806%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.210 Acc 17.969%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 109777.650 Acc 18.905%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 55163.013 Acc 19.080%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 36837.175 Acc 18.973%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 27651.406 Acc 18.836%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 22132.610 Acc 18.876%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.231 Acc 21.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.237 Acc 18.928%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.237 Acc 18.777%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.217 Acc 24.219%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.233 Acc 19.361%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.237 Acc 19.061%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.237 Acc 18.792%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.288 Acc 14.844%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.237 Acc 18.603%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.236 Acc 19.158%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.236 Acc 19.054%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.243 Acc 19.531%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.237 Acc 18.704%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.238 Acc 18.763%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.190 Acc 25.781%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.242 Acc 18.851%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.237 Acc 19.069%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.237 Acc 19.093%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 18.976%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.292 Acc 18.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.236 Acc 18.987%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.237 Acc 18.857%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.883%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.223 Acc 19.531%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.240 Acc 18.851%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.239 Acc 18.828%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.238 Acc 18.884%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.238 Acc 18.950%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.213 Acc 22.656%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.234 Acc 19.183%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [118/200]Batch [200/573] Loss: 2.235 Acc 19.209%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.234 Acc 19.160%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.241 Acc 12.500%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.238 Acc 18.796%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.244%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.238 Acc 18.880%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.238 Acc 18.820%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.236 Acc 19.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.237 Acc 18.747%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.236 Acc 19.014%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [120/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.242 Acc 19.531%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.235 Acc 18.951%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.238 Acc 18.975%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.250 Acc 17.969%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.237 Acc 19.170%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.236 Acc 19.077%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.255 Acc 19.531%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.240 Acc 18.738%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.239 Acc 18.799%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.239 Acc 18.721%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.239 Acc 18.822%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.253 Acc 18.750%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.236 Acc 18.975%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.237 Acc 18.872%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.216 Acc 17.188%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.234 Acc 19.036%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.237 Acc 18.857%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.237 Acc 18.830%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.230 Acc 17.188%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.234 Acc 19.369%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.238 Acc 18.948%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.235 Acc 19.082%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 18.917%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.234 Acc 22.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.237 Acc 18.990%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.215 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.210 Acc 21.094%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.236 Acc 19.013%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.237 Acc 19.127%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.236 Acc 19.111%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.224 Acc 17.188%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.235 Acc 19.291%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.236 Acc 19.111%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.237 Acc 18.978%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.286 Acc 17.969%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.237 Acc 19.098%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.238 Acc 18.997%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.825%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.298 Acc 15.625%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.234 Acc 18.998%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.707%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.238 Acc 18.768%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.238 Acc 18.738%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.918%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.173 Acc 25.000%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.233 Acc 19.423%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.236 Acc 19.162%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [133/200]Batch [300/573] Loss: 2.235 Acc 19.186%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.209 Acc 25.781%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.235 Acc 19.276%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.235 Acc 18.983%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.238 Acc 18.881%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.296 Acc 14.844%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.236 Acc 19.199%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.237 Acc 19.209%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.237 Acc 19.080%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.238 Acc 18.834%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.237 Acc 18.869%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.228 Acc 20.312%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.238 Acc 18.645%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.239 Acc 18.817%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.238 Acc 18.869%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.249 Acc 22.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.234 Acc 18.943%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.236 Acc 18.808%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.238 Acc 18.794%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.266 Acc 17.969%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.240 Acc 18.332%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.239 Acc 18.657%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.236 Acc 19.041%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.236 Acc 18.953%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.237 Acc 18.859%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.227 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.189 Acc 19.531%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.241 Acc 18.448%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.240 Acc 18.424%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.240 Acc 18.628%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.237 Acc 18.916%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.965%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.161 Acc 25.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.240 Acc 18.363%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.237 Acc 18.832%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.243 Acc 21.875%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.237 Acc 19.237%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.235 Acc 19.286%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.234 Acc 19.209%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.236 Acc 18.980%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.248 Acc 16.406%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.240 Acc 18.936%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.240 Acc 18.832%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.239 Acc 18.871%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.238 Acc 18.831%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.258 Acc 15.625%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.237 Acc 18.804%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.236 Acc 18.976%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.237 Acc 18.910%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.254 Acc 18.750%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.241 Acc 18.781%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.238 Acc 18.807%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.237 Acc 18.992%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.243 Acc 18.711%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.239 Acc 18.723%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.194 Acc 19.531%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.235 Acc 19.059%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.237 Acc 18.699%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.755%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.795%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.283 Acc 17.188%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.836%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.267 Acc 17.969%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.239 Acc 18.711%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [148/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.188 Acc 24.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.234 Acc 19.732%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.235 Acc 19.341%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.235 Acc 19.202%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.236 Acc 19.173%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.239 Acc 17.969%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.235 Acc 19.446%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.238 Acc 19.045%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.238 Acc 18.855%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.238 Acc 18.914%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.159 Acc 28.906%\n",
      "Train Epoch [151/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.237 Acc 19.069%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.196 Acc 23.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.238 Acc 18.974%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.240 Acc 18.769%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.239 Acc 18.777%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.238 Acc 18.914%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.227 Acc 24.219%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.241 Acc 18.680%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.260 Acc 17.969%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.241 Acc 18.560%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.241 Acc 18.644%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.239 Acc 18.787%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.290 Acc 14.844%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.239 Acc 18.858%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.235 Acc 19.166%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.234 Acc 18.967%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.235 Acc 19.095%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.236 Acc 19.095%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.237 Acc 19.032%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.213 Acc 17.188%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.235 Acc 18.943%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.236 Acc 18.863%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.235 Acc 18.914%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.260 Acc 15.625%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.237 Acc 19.106%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.238 Acc 18.662%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.238 Acc 18.752%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.238 Acc 18.858%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.269 Acc 14.062%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.234 Acc 18.680%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.235 Acc 18.773%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.238 Acc 18.649%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.237 Acc 18.818%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.237 Acc 18.884%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.256 Acc 17.969%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.239 Acc 18.827%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.237 Acc 19.061%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.237 Acc 18.849%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.236 Acc 18.971%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.238 Acc 18.680%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.239 Acc 18.805%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.265 Acc 15.625%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.240 Acc 18.905%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.237 Acc 18.983%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.971%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.237 Acc 18.935%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.191 Acc 21.094%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.234 Acc 19.144%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.235 Acc 19.061%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.237 Acc 18.971%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.236 Acc 19.071%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [163/200]Batch [500/573] Loss: 2.237 Acc 19.003%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.189 Acc 26.562%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.239 Acc 18.905%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.236 Acc 18.983%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.236 Acc 19.020%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.236 Acc 19.021%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.242 Acc 17.188%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.239 Acc 18.619%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.240 Acc 18.528%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.238 Acc 18.792%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.237 Acc 18.871%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.216 Acc 17.969%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.233 Acc 18.866%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.872%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.262 Acc 20.312%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.240 Acc 18.781%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.839%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.236 Acc 18.957%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.237 Acc 19.001%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.239 Acc 18.738%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.238 Acc 18.937%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.238 Acc 18.842%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.233 Acc 17.969%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.236 Acc 19.206%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.238 Acc 19.026%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.238 Acc 19.020%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.220 Acc 16.406%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.235 Acc 19.018%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.237 Acc 18.993%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.204 Acc 21.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.236 Acc 18.518%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.237 Acc 18.637%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.237 Acc 18.768%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.236 Acc 18.934%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.196 Acc 20.312%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.244 Acc 17.946%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.240 Acc 18.595%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.238 Acc 18.854%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.237 Acc 19.059%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.233 Acc 19.399%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.235 Acc 19.194%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.200 Acc 22.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.238 Acc 19.059%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.237 Acc 19.127%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.276 Acc 14.844%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.243 Acc 18.294%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.237 Acc 19.046%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.238 Acc 18.886%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.236 Acc 18.869%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.237 Acc 18.981%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.257 Acc 17.188%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.237 Acc 19.284%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.235 Acc 19.232%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.238 Acc 18.955%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.877%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.238 Acc 18.926%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.204 Acc 20.312%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.235 Acc 19.315%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.239 Acc 18.929%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.238 Acc 18.952%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.238 Acc 18.832%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.247 Acc 17.969%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.242 Acc 18.533%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.241 Acc 18.738%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.240 Acc 18.869%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.238 Acc 18.873%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.235 Acc 17.969%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.239 Acc 18.796%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.236 Acc 18.886%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.222 Acc 21.094%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.236 Acc 19.245%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.238 Acc 18.984%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.223 Acc 16.406%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.232 Acc 19.168%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.234 Acc 18.991%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.236 Acc 18.911%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.235 Acc 18.968%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.235 Acc 18.995%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.298 Acc 14.062%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.238 Acc 19.005%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.239 Acc 18.846%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.230 Acc 15.625%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.239 Acc 18.588%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.239 Acc 21.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.239 Acc 18.552%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.238 Acc 18.579%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.238 Acc 18.701%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.238 Acc 18.839%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.245 Acc 19.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.236 Acc 19.010%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.245 Acc 17.969%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.923%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.235 Acc 22.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.238 Acc 19.137%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.236 Acc 19.294%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.237 Acc 19.064%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.196 Acc 21.875%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.236 Acc 18.936%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.239 Acc 18.769%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.237 Acc 19.000%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.176 Acc 21.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 18.777%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.237 Acc 18.907%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.229 Acc 17.188%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.230 Acc 19.624%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.237 Acc 19.100%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.235 Acc 19.173%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.235 Acc 19.091%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.236 Acc 19.035%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.272 Acc 21.875%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.233 Acc 19.516%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.232 Acc 19.469%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.234 Acc 19.254%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.236 Acc 19.004%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.278 Acc 12.500%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.236 Acc 19.353%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.235 Acc 19.022%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.237 Acc 18.854%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [193/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.298 Acc 11.719%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.235 Acc 19.508%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.235 Acc 19.426%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.237 Acc 19.194%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.237 Acc 19.021%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.238 Acc 18.897%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.279 Acc 15.625%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.232 Acc 19.717%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.234 Acc 19.220%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 19.243%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.237 Acc 18.856%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.272 Acc 19.531%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.237 Acc 18.835%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.236 Acc 18.878%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.237 Acc 18.911%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.343 Acc 10.938%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.239 Acc 18.603%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.239 Acc 18.684%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.238 Acc 18.871%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.237 Acc 18.967%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.248 Acc 17.188%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.238 Acc 18.804%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.237 Acc 18.987%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.223 Acc 20.312%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.238 Acc 18.895%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1759680e0042e3a502d2a7b97c3753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.326 Acc 11.719%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.245 Acc 18.077%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.244 Acc 18.447%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.233 Acc 18.906%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.184 Acc 20.852%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.076 Acc 24.880%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.586 Acc 47.656%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.498 Acc 50.534%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.496 Acc 50.389%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.369 Acc 50.781%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.109 Acc 62.856%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 0.979 Acc 67.868%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 0.874 Acc 71.732%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.800 Acc 74.232%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.744 Acc 76.084%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.484 Acc 84.375%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.564 Acc 82.163%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.555 Acc 82.533%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.568 Acc 79.688%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.452 Acc 86.363%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.451 Acc 86.178%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.436 Acc 86.597%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.429 Acc 86.836%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.421 Acc 87.088%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.469 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.410 Acc 87.508%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.409 Acc 87.376%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.468 Acc 86.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.385 Acc 88.397%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.370 Acc 88.748%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.364 Acc 89.065%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.364 Acc 89.016%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.362 Acc 89.083%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.264 Acc 91.406%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.297 Acc 91.414%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.293 Acc 91.414%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.219 Acc 90.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.333 Acc 90.053%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.333 Acc 90.073%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.330 Acc 90.108%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.328 Acc 90.087%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.325 Acc 90.187%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.323 Acc 90.625%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.295 Acc 91.545%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.289 Acc 91.814%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.238 Acc 92.969%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.317 Acc 90.780%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.310 Acc 90.749%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.310 Acc 90.804%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.306 Acc 90.839%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.306 Acc 90.848%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.257 Acc 89.062%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.277 Acc 91.847%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.270 Acc 92.184%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.296 Acc 92.969%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.279 Acc 91.460%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.287 Acc 91.212%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.284 Acc 91.287%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.286 Acc 91.241%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.289 Acc 91.275%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.258 Acc 90.625%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.292 Acc 91.592%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.287 Acc 91.682%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.285 Acc 89.062%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.281 Acc 91.716%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.275 Acc 91.760%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.279 Acc 91.679%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.283 Acc 91.628%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.280 Acc 91.676%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.279 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.260 Acc 92.760%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.255 Acc 92.926%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.254 Acc 89.844%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.268 Acc 92.273%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.276 Acc 92.044%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.273 Acc 91.897%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.272 Acc 91.952%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.269 Acc 92.105%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.315 Acc 90.625%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.294 Acc 91.576%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.292 Acc 91.604%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.283 Acc 91.406%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.271 Acc 92.002%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.270 Acc 92.016%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.267 Acc 92.071%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.266 Acc 92.115%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.264 Acc 92.191%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.223 Acc 94.013%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.221 Acc 94.065%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.258 Acc 92.497%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.258 Acc 92.347%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.253 Acc 92.515%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.252 Acc 92.591%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.255 Acc 92.512%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.257 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.253 Acc 92.891%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.251 Acc 93.035%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.154 Acc 96.094%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.229 Acc 93.255%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.241 Acc 92.868%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.244 Acc 92.795%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.245 Acc 92.752%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.246 Acc 92.716%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.226 Acc 94.531%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.223 Acc 93.943%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.218 Acc 93.948%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.294 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.229 Acc 93.270%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.235 Acc 93.089%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.238 Acc 93.052%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.239 Acc 92.926%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.239 Acc 92.938%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.238 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.227 Acc 93.998%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.224 Acc 93.956%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.331 Acc 90.625%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.238 Acc 93.062%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.235 Acc 93.190%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.238 Acc 93.112%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.238 Acc 93.056%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.237 Acc 93.089%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.200 Acc 92.188%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.223 Acc 93.967%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.219 Acc 94.088%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.264 Acc 96.875%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.241 Acc 93.356%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.240 Acc 93.171%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.239 Acc 93.158%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.236 Acc 93.169%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.237 Acc 93.182%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.271 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.207 Acc 94.415%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.202 Acc 94.496%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.235 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.234 Acc 93.294%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.233 Acc 93.256%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.233 Acc 93.189%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.233 Acc 93.204%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.231 Acc 93.245%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.301 Acc 91.406%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.223 Acc 93.912%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.220 Acc 93.902%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.346 Acc 90.625%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.226 Acc 93.611%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.226 Acc 93.525%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.225 Acc 93.467%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.224 Acc 93.475%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.226 Acc 93.373%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.241 Acc 92.188%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.205 Acc 94.415%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.200 Acc 94.516%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.223 Acc 92.969%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.222 Acc 93.495%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.216 Acc 93.509%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.218 Acc 93.418%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.220 Acc 93.440%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.222 Acc 93.396%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.264 Acc 89.844%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.239 Acc 93.541%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.232 Acc 93.703%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.183 Acc 96.094%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.211 Acc 93.588%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.216 Acc 93.513%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.219 Acc 93.483%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.219 Acc 93.493%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.220 Acc 93.507%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.275 Acc 91.406%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.232 Acc 93.595%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.229 Acc 93.680%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.251 Acc 92.188%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.211 Acc 93.874%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.216 Acc 93.766%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.215 Acc 93.807%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.216 Acc 93.760%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.216 Acc 93.703%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.247 Acc 92.969%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.199 Acc 94.632%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.196 Acc 94.753%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.367 Acc 90.625%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.210 Acc 93.998%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.212 Acc 93.707%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.211 Acc 93.727%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.210 Acc 93.748%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.213 Acc 93.636%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.201 Acc 93.750%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.194 Acc 95.042%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.191 Acc 95.087%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.102 Acc 97.656%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.213 Acc 93.564%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.211 Acc 93.758%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.213 Acc 93.719%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.213 Acc 93.717%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.213 Acc 93.753%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.235 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.202 Acc 94.763%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.194 Acc 94.873%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.205 Acc 96.094%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.197 Acc 94.346%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.202 Acc 94.220%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.203 Acc 94.178%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.205 Acc 94.120%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.206 Acc 94.101%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.187 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.200 Acc 94.763%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.196 Acc 94.866%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.197 Acc 94.485%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.196 Acc 94.407%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.203 Acc 94.222%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.202 Acc 94.223%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.205 Acc 94.127%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.178 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.200 Acc 94.493%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.193 Acc 94.796%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.194 Acc 94.284%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.200 Acc 94.127%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.204 Acc 94.025%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.204 Acc 94.071%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.202 Acc 94.070%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.195 Acc 94.941%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.192 Acc 94.967%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.190 Acc 94.338%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.192 Acc 94.372%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.194 Acc 94.326%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.196 Acc 94.292%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.199 Acc 94.274%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.212 Acc 92.188%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.195 Acc 94.678%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.188 Acc 94.799%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.192 Acc 94.531%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.193 Acc 94.485%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.195 Acc 94.407%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.197 Acc 94.316%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.199 Acc 94.223%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.201 Acc 94.177%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.211 Acc 94.291%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.207 Acc 94.469%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.314 Acc 90.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.187 Acc 94.678%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.195 Acc 94.339%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.194 Acc 94.393%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.194 Acc 94.389%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.175 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.197 Acc 94.779%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.192 Acc 94.920%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.177 Acc 95.312%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.185 Acc 94.616%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.188 Acc 94.426%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.192 Acc 94.329%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.194 Acc 94.370%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.195 Acc 94.346%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.238 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.217 Acc 94.315%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.213 Acc 94.356%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.214 Acc 94.531%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.185 Acc 94.825%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.190 Acc 94.566%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.190 Acc 94.549%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.189 Acc 94.596%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.191 Acc 94.503%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.259 Acc 92.188%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.199 Acc 94.562%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.194 Acc 94.706%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.200 Acc 92.969%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.185 Acc 94.485%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.187 Acc 94.543%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.192 Acc 94.485%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.190 Acc 94.496%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.188 Acc 94.562%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.189 Acc 95.088%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.184 Acc 95.204%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.286 Acc 94.531%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.181 Acc 94.810%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.182 Acc 94.900%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.185 Acc 94.757%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.185 Acc 94.705%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.187 Acc 94.634%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.247 Acc 92.188%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.206 Acc 94.570%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.202 Acc 94.694%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.173 Acc 95.173%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.180 Acc 94.963%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.184 Acc 94.741%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.184 Acc 94.751%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.186 Acc 94.653%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.190 Acc 94.972%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.183 Acc 95.138%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.170 Acc 94.910%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.177 Acc 94.757%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.177 Acc 94.848%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.179 Acc 94.812%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.184 Acc 94.661%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.207 Acc 92.188%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.202 Acc 94.678%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.196 Acc 94.741%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.179 Acc 94.725%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.181 Acc 94.710%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.182 Acc 94.762%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.183 Acc 94.714%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.183 Acc 94.664%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.256 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.191 Acc 95.042%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.189 Acc 95.029%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.177 Acc 94.957%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.170 Acc 94.982%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.175 Acc 94.934%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.177 Acc 94.942%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.179 Acc 94.901%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.172 Acc 94.531%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.181 Acc 95.258%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.180 Acc 95.332%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.237 Acc 92.969%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.179 Acc 94.624%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.177 Acc 94.788%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.176 Acc 94.967%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.179 Acc 94.864%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.178 Acc 94.867%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.181 Acc 95.483%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.175 Acc 95.581%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.215 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.175 Acc 94.933%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.172 Acc 94.978%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.175 Acc 94.921%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.177 Acc 94.909%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.179 Acc 94.860%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.205 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.185 Acc 95.235%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.179 Acc 95.301%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.177 Acc 93.750%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.168 Acc 95.111%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.174 Acc 94.963%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.172 Acc 94.988%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.176 Acc 94.929%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.177 Acc 94.842%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.187 Acc 94.964%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.182 Acc 95.246%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.160 Acc 95.475%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.170 Acc 95.240%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.172 Acc 95.125%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.173 Acc 95.027%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.129 Acc 96.094%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.173 Acc 95.545%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.171 Acc 95.639%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.154 Acc 95.312%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.162 Acc 95.390%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.166 Acc 95.173%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.172 Acc 95.066%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.171 Acc 95.005%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.172 Acc 95.012%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.196 Acc 94.972%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.194 Acc 94.955%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.205 Acc 95.312%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.173 Acc 95.189%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.168 Acc 95.254%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.165 Acc 95.198%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.167 Acc 95.168%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.169 Acc 95.127%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.190 Acc 90.625%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.192 Acc 94.887%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.184 Acc 95.196%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.162 Acc 96.094%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.174 Acc 94.787%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.169 Acc 95.064%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.170 Acc 95.053%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.171 Acc 95.026%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.171 Acc 95.018%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.189 Acc 95.235%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.185 Acc 95.340%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.154 Acc 95.575%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.163 Acc 95.359%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.161 Acc 95.367%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.164 Acc 95.254%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.166 Acc 95.239%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.193 Acc 91.406%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.186 Acc 95.227%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.182 Acc 95.274%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.164 Acc 95.390%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.164 Acc 95.250%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.164 Acc 95.284%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.167 Acc 95.194%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.166 Acc 95.214%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.187 Acc 95.158%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.182 Acc 95.239%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.158 Acc 95.529%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.162 Acc 95.344%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.164 Acc 95.328%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.165 Acc 95.248%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.167 Acc 95.178%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.165 Acc 93.750%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.188 Acc 95.088%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.184 Acc 95.204%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.182 Acc 92.969%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.155 Acc 95.614%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.160 Acc 95.437%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.162 Acc 95.357%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.163 Acc 95.311%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.164 Acc 95.250%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.197 Acc 95.181%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.191 Acc 95.153%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.150 Acc 95.552%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.155 Acc 95.588%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.155 Acc 95.577%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.160 Acc 95.416%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.162 Acc 95.339%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.209 Acc 94.756%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.206 Acc 94.694%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.157 Acc 95.312%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.163 Acc 95.192%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.164 Acc 95.162%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.163 Acc 95.235%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.162 Acc 95.208%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.194 Acc 94.949%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.189 Acc 95.002%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.168 Acc 95.034%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.161 Acc 95.173%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.159 Acc 95.253%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.160 Acc 95.268%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.163 Acc 95.270%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.233 Acc 92.188%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.196 Acc 95.088%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.191 Acc 95.208%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.121 Acc 96.875%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.161 Acc 95.490%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.162 Acc 95.262%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.160 Acc 95.336%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.160 Acc 95.314%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.160 Acc 95.330%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.132 Acc 95.312%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.179 Acc 95.398%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.173 Acc 95.561%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.085 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.160 Acc 95.305%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.160 Acc 95.367%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.157 Acc 95.460%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.157 Acc 95.463%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.158 Acc 95.464%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.184 Acc 95.359%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.179 Acc 95.452%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.152 Acc 92.969%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.159 Acc 95.475%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.159 Acc 95.281%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.158 Acc 95.336%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.158 Acc 95.350%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.157 Acc 95.384%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.129 Acc 93.750%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.186 Acc 95.429%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.180 Acc 95.585%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.214 Acc 92.969%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.163 Acc 95.196%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.163 Acc 95.367%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.160 Acc 95.419%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.160 Acc 95.435%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.157 Acc 95.521%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.186 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.195 Acc 95.019%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.191 Acc 95.141%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.156 Acc 95.429%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.154 Acc 95.476%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.155 Acc 95.429%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.155 Acc 95.418%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.156 Acc 95.426%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.167 Acc 95.312%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.180 Acc 95.498%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.174 Acc 95.526%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.131 Acc 95.312%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.152 Acc 95.684%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.152 Acc 95.596%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.156 Acc 95.427%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.155 Acc 95.451%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.156 Acc 95.484%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.172 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.173 Acc 95.715%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.169 Acc 95.697%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.152 Acc 95.575%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.153 Acc 95.631%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.151 Acc 95.645%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.154 Acc 95.611%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.156 Acc 95.548%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.184 Acc 95.436%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.179 Acc 95.472%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.204 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.137 Acc 96.016%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.142 Acc 95.876%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.148 Acc 95.691%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.149 Acc 95.687%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.152 Acc 95.640%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.193 Acc 94.531%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.194 Acc 94.910%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.188 Acc 95.044%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.128 Acc 95.312%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.153 Acc 95.429%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.150 Acc 95.604%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.151 Acc 95.533%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.154 Acc 95.468%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.153 Acc 95.493%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.176 Acc 92.969%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.183 Acc 95.614%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.178 Acc 95.635%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.145 Acc 95.939%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.151 Acc 95.713%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.151 Acc 95.655%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.151 Acc 95.634%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.151 Acc 95.592%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.188 Acc 95.274%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.183 Acc 95.332%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.149 Acc 95.753%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.148 Acc 95.791%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.152 Acc 95.634%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.152 Acc 95.650%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.152 Acc 95.590%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.146 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.181 Acc 95.521%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.177 Acc 95.546%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.203 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.142 Acc 95.769%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.149 Acc 95.713%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.148 Acc 95.746%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.146 Acc 95.761%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.149 Acc 95.702%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.135 Acc 95.312%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.199 Acc 94.918%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.195 Acc 94.893%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.145 Acc 95.483%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.142 Acc 95.686%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.146 Acc 95.572%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.147 Acc 95.628%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.147 Acc 95.613%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.195 Acc 94.895%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.190 Acc 94.970%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.231 Acc 94.531%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.137 Acc 95.846%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.144 Acc 95.690%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.145 Acc 95.733%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.147 Acc 95.659%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.148 Acc 95.704%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.206 Acc 92.188%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.188 Acc 95.196%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.184%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.144 Acc 95.692%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.146 Acc 95.829%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.145 Acc 95.821%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.147 Acc 95.800%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.147 Acc 95.787%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.210 Acc 92.188%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.206 Acc 94.655%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.204 Acc 94.714%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.186 Acc 93.750%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.143 Acc 95.831%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.143 Acc 95.725%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.145 Acc 95.775%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.146 Acc 95.741%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.148 Acc 95.715%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.175 Acc 95.312%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.185 Acc 95.212%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.180 Acc 95.398%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.103 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.142 Acc 95.846%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.144 Acc 95.748%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.144 Acc 95.829%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.142 Acc 95.874%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.143 Acc 95.824%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.204 Acc 94.531%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.180 Acc 95.545%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.175 Acc 95.670%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.133 Acc 96.279%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.136 Acc 96.191%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.138 Acc 96.037%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.141 Acc 95.915%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.142 Acc 95.886%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.136 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.168 Acc 95.908%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.163 Acc 95.962%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.096 Acc 95.312%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.130 Acc 96.202%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.137 Acc 96.090%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.139 Acc 95.985%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.141 Acc 95.879%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.144 Acc 95.819%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.127 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.190 Acc 95.367%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.187 Acc 95.375%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.134 Acc 96.086%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.130 Acc 96.222%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.138 Acc 96.024%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.139 Acc 95.926%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.141 Acc 95.894%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.192 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.201 Acc 94.771%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.199 Acc 94.831%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.206 Acc 96.094%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.127 Acc 96.233%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.136 Acc 96.012%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.140 Acc 95.904%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.141 Acc 95.915%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.141 Acc 95.885%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.166 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.199 Acc 95.104%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.193 Acc 95.200%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.131 Acc 96.016%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.139 Acc 95.841%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.138 Acc 95.894%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.139 Acc 95.858%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.141 Acc 95.841%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.192 Acc 95.367%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.186 Acc 95.363%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.178 Acc 92.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.138 Acc 95.978%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.137 Acc 96.004%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.140 Acc 96.018%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.140 Acc 95.957%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.140 Acc 95.985%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.181 Acc 95.359%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.176 Acc 95.394%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.200 Acc 93.750%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.128 Acc 96.171%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.135 Acc 95.927%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.135 Acc 95.998%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.138 Acc 95.981%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.140 Acc 95.919%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.215 Acc 92.969%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.192 Acc 95.196%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.188 Acc 95.215%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.126 Acc 96.086%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.134 Acc 95.981%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.135 Acc 96.013%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.139 Acc 95.928%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.139 Acc 95.886%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.188 Acc 95.351%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.181 Acc 95.472%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.152 Acc 95.312%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.138 Acc 95.753%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.138 Acc 95.958%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.135 Acc 96.104%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.136 Acc 96.047%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.137 Acc 96.025%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.140 Acc 94.531%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.189 Acc 95.235%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.184 Acc 95.320%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.130 Acc 96.101%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.132 Acc 96.016%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.136 Acc 95.938%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.136 Acc 95.965%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.136 Acc 95.964%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.139 Acc 93.750%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.179 Acc 95.784%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.174 Acc 95.802%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.105 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.127 Acc 96.140%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.131 Acc 96.000%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.134 Acc 95.954%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.136 Acc 95.918%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.138 Acc 95.899%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.188 Acc 95.413%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.185 Acc 95.437%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.125 Acc 96.303%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.135 Acc 95.993%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.136 Acc 96.018%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.136 Acc 96.020%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.136 Acc 96.020%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.186 Acc 95.243%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.181 Acc 95.402%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.126 Acc 96.357%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.128 Acc 96.269%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.132 Acc 96.127%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.133 Acc 96.088%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.134 Acc 96.078%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.139 Acc 96.094%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.186 Acc 95.282%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.184 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.096 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.131 Acc 96.364%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.127 Acc 96.358%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.127 Acc 96.309%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.131 Acc 96.174%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.133 Acc 96.125%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.152 Acc 95.312%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.189 Acc 95.343%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.183 Acc 95.363%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.127 Acc 96.372%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.132 Acc 96.125%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.130 Acc 96.159%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.133 Acc 96.070%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.132 Acc 96.103%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.183 Acc 95.498%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.178 Acc 95.530%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.078 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.134 Acc 96.094%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.130 Acc 96.129%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.129 Acc 96.169%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.130 Acc 96.130%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.180 Acc 95.452%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.174 Acc 95.585%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.128 Acc 96.241%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.128 Acc 96.339%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.132 Acc 96.146%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.132 Acc 96.109%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.135 Acc 96.020%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.178 Acc 93.750%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.202 Acc 94.879%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.201 Acc 94.904%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.176 Acc 92.969%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.133 Acc 95.985%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.131 Acc 96.070%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.133 Acc 96.000%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.134 Acc 95.961%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.134 Acc 95.961%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.160 Acc 92.969%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.186 Acc 95.320%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.183 Acc 95.379%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.128 Acc 96.210%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.126 Acc 96.284%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.129 Acc 96.249%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.129 Acc 96.211%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.131 Acc 96.142%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.198 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.190 Acc 95.119%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.187 Acc 95.262%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.126 Acc 96.148%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.130 Acc 96.144%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.129 Acc 96.182%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.127 Acc 96.238%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.130 Acc 96.175%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.141 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.180 Acc 95.692%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.175 Acc 95.682%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.258 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.127 Acc 96.218%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.127 Acc 96.304%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.126 Acc 96.296%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.128 Acc 96.224%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.130 Acc 96.178%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.199 Acc 95.212%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.191 Acc 95.297%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.048 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.116 Acc 96.767%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.123 Acc 96.467%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.126 Acc 96.382%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.128 Acc 96.296%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.130 Acc 96.236%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.191 Acc 95.220%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.184 Acc 95.386%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.169 Acc 94.531%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.127 Acc 96.303%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.126 Acc 96.245%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.125 Acc 96.172%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.127 Acc 96.213%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.128 Acc 96.178%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.204 Acc 94.918%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.198 Acc 94.963%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.122 Acc 96.388%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.123 Acc 96.296%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.127 Acc 96.179%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.127 Acc 96.209%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.128 Acc 96.223%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.145 Acc 93.750%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.198 Acc 95.080%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.193 Acc 95.169%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.153 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.120 Acc 96.364%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.120 Acc 96.447%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.123 Acc 96.333%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.125 Acc 96.201%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.127 Acc 96.178%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.265 Acc 92.188%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.191 Acc 95.351%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.188 Acc 95.215%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.075 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.127 Acc 96.334%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.124 Acc 96.416%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.126 Acc 96.335%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.124 Acc 96.343%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.126 Acc 96.304%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.151 Acc 94.531%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.185 Acc 95.436%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.181 Acc 95.476%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.146 Acc 94.531%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.131 Acc 96.109%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.130 Acc 96.105%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.129 Acc 96.159%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.127 Acc 96.238%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.126 Acc 96.268%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.201 Acc 92.188%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.189 Acc 95.343%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.188 Acc 95.262%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.112 Acc 96.651%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.122 Acc 96.369%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.124 Acc 96.326%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.201 Acc 94.771%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.200 Acc 94.788%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.122 Acc 96.171%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.129 Acc 96.082%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.128 Acc 96.159%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.127 Acc 96.158%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.127 Acc 96.220%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.250 Acc 93.750%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.189 Acc 95.374%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.186 Acc 95.359%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.129 Acc 96.133%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.123 Acc 96.278%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.123 Acc 96.263%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.124 Acc 96.247%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.183 Acc 95.429%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.179 Acc 95.519%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.134 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.125 Acc 96.241%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.121 Acc 96.479%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.123 Acc 96.395%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.123 Acc 96.402%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.123 Acc 96.395%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.183 Acc 95.599%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.178 Acc 95.631%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.139 Acc 92.969%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.120 Acc 96.457%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.119 Acc 96.498%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.122 Acc 96.447%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.125 Acc 96.345%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.125 Acc 96.276%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.124 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.180 Acc 95.792%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.174 Acc 95.868%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.120 Acc 96.697%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.118 Acc 96.568%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.118 Acc 96.540%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.118 Acc 96.571%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.121 Acc 96.449%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.194 Acc 95.142%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.190 Acc 95.219%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.119 Acc 96.620%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.117 Acc 96.560%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.120 Acc 96.501%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.121 Acc 96.454%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.121 Acc 96.452%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.176 Acc 95.692%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.172 Acc 95.822%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.118 Acc 96.542%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.118 Acc 96.510%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.119 Acc 96.473%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.122 Acc 96.433%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.121 Acc 96.429%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.125 Acc 93.750%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.201 Acc 95.011%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.195 Acc 95.204%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.180 Acc 92.969%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.111 Acc 96.713%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.116 Acc 96.525%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.119 Acc 96.417%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.122 Acc 96.306%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.189 Acc 92.969%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.194 Acc 95.158%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.188 Acc 95.227%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.119 Acc 96.511%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.118 Acc 96.529%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.122 Acc 96.382%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.122 Acc 96.402%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.120 Acc 96.441%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.170 Acc 92.188%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.191 Acc 95.599%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.186 Acc 95.585%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.154 Acc 94.531%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.112 Acc 96.658%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.114 Acc 96.502%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.118 Acc 96.400%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.117 Acc 96.433%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.118 Acc 96.432%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.159 Acc 93.750%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.188 Acc 95.367%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.183 Acc 95.526%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.269 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.124 Acc 96.233%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.124 Acc 96.253%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.123 Acc 96.239%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.120 Acc 96.376%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.121 Acc 96.356%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.182 Acc 95.552%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.178 Acc 95.577%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.048 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.116 Acc 96.542%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.112 Acc 96.700%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.116 Acc 96.527%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.118 Acc 96.439%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.117 Acc 96.434%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.172 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.202 Acc 95.382%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.195 Acc 95.417%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.108 Acc 96.581%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.115 Acc 96.459%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.119 Acc 96.418%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.116 Acc 96.485%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.119 Acc 96.448%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.159 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.193 Acc 95.359%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.187 Acc 95.515%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.113 Acc 96.457%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.117 Acc 96.409%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.117 Acc 96.429%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.116 Acc 96.452%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.116 Acc 96.459%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.217 Acc 92.969%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.199 Acc 95.034%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.194 Acc 95.114%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.111 Acc 96.581%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.111 Acc 96.599%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.113 Acc 96.587%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.117 Acc 96.495%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.117 Acc 96.496%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.160 Acc 94.531%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.182 Acc 95.676%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.178 Acc 95.647%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.125 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.109 Acc 96.527%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.112 Acc 96.521%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.115 Acc 96.444%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.116 Acc 96.421%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.116 Acc 96.429%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.117 Acc 93.750%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.186 Acc 95.390%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.181 Acc 95.515%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.115 Acc 96.612%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.114 Acc 96.529%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.113 Acc 96.577%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.115 Acc 96.567%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.116 Acc 96.574%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.184 Acc 95.483%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.177 Acc 95.449%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.122 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.117 Acc 96.581%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.118 Acc 96.498%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.113 Acc 96.569%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.114 Acc 96.505%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.114 Acc 96.485%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.189 Acc 95.436%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.180 Acc 95.643%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.060 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.115 Acc 96.488%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.109 Acc 96.801%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.115 Acc 96.618%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.117 Acc 96.528%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.118 Acc 96.501%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.184 Acc 93.750%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.194 Acc 95.243%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.187 Acc 95.336%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.125 Acc 93.750%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.108 Acc 96.597%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.109 Acc 96.556%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.110 Acc 96.639%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.112 Acc 96.561%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.114 Acc 96.538%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.198 Acc 95.336%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.192 Acc 95.437%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.108 Acc 96.682%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.110 Acc 96.646%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.111 Acc 96.662%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.113 Acc 96.612%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.114 Acc 96.562%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.151 Acc 95.312%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.193 Acc 95.475%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.189 Acc 95.445%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.230 Acc 93.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.117 Acc 96.535%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.115 Acc 96.723%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.113 Acc 96.670%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.115 Acc 96.554%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.117 Acc 96.485%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.199 Acc 92.969%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.201 Acc 94.794%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.200 Acc 94.772%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.110 Acc 96.732%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.112 Acc 96.596%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.112 Acc 96.619%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.179 Acc 95.475%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.175 Acc 95.530%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.151 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.109 Acc 96.720%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.104 Acc 96.848%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.108 Acc 96.693%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.109 Acc 96.674%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.111 Acc 96.652%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.139 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.195 Acc 95.282%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.190 Acc 95.289%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.131 Acc 93.750%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.114 Acc 96.488%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.112 Acc 96.595%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.113 Acc 96.545%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.115 Acc 96.444%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.115 Acc 96.466%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.184 Acc 95.444%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.178 Acc 95.561%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.074 Acc 96.875%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.113 Acc 96.545%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.111 Acc 96.569%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.112 Acc 96.612%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.112 Acc 96.605%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.169 Acc 92.969%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.206 Acc 95.065%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.112 Acc 96.357%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.108 Acc 96.599%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.110 Acc 96.571%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.110 Acc 96.618%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.112 Acc 96.580%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.155 Acc 93.750%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.180 Acc 95.684%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.176 Acc 95.655%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.100 Acc 96.991%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.104 Acc 96.739%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.109 Acc 96.566%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.111 Acc 96.517%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.111 Acc 96.519%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.193 Acc 95.498%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.191 Acc 95.472%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.110 Acc 96.658%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.113 Acc 96.549%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.111 Acc 96.608%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.110 Acc 96.657%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.111 Acc 96.607%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.191 Acc 95.514%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.187 Acc 95.507%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.120 Acc 94.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.112 Acc 96.496%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.111 Acc 96.583%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.111 Acc 96.597%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.111 Acc 96.612%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.111 Acc 96.605%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.140 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.206 Acc 94.779%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.205 Acc 94.862%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.105 Acc 96.767%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.107 Acc 96.603%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.111 Acc 96.488%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.110 Acc 96.563%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.109 Acc 96.627%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.188 Acc 95.441%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.144 Acc 96.094%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.101 Acc 96.798%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.102 Acc 96.817%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.106 Acc 96.753%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.108 Acc 96.655%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.107 Acc 96.666%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.197 Acc 95.196%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.194 Acc 95.215%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.112 Acc 96.558%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.108 Acc 96.665%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.111 Acc 96.577%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.109 Acc 96.641%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.110 Acc 96.625%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.195 Acc 95.328%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.188 Acc 95.487%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.124 Acc 93.750%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.118 Acc 96.488%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.110 Acc 96.739%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.109 Acc 96.709%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.110 Acc 96.661%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.111 Acc 96.636%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.140 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.193 Acc 95.521%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.188 Acc 95.569%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.103 Acc 94.531%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.108 Acc 96.689%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.106 Acc 96.762%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.108 Acc 96.714%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.108 Acc 96.735%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.109 Acc 96.722%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.153 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.182 Acc 95.467%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.178 Acc 95.538%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.104 Acc 96.821%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.109 Acc 96.675%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.109 Acc 96.709%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.108 Acc 96.713%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.156 Acc 93.750%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.179 Acc 95.721%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.155 Acc 93.750%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.098 Acc 97.014%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.101 Acc 96.844%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.103 Acc 96.797%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.105 Acc 96.743%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.106 Acc 96.702%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.177 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.195 Acc 95.343%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.192 Acc 95.375%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.111 Acc 96.665%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.108 Acc 96.680%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.108 Acc 96.743%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.108 Acc 96.755%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.199 Acc 94.995%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.194 Acc 95.087%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.094 Acc 97.130%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.103 Acc 96.857%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.108 Acc 96.700%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.108 Acc 96.696%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.195 Acc 95.475%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.190 Acc 95.534%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.130 Acc 99.219%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.095 Acc 96.983%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.104 Acc 96.769%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.105 Acc 96.793%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.104 Acc 96.799%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.157 Acc 96.094%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.206 Acc 95.142%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.203 Acc 95.110%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.100 Acc 97.030%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.103 Acc 96.867%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.105 Acc 96.826%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.106 Acc 96.811%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.091 Acc 94.531%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.175 Acc 95.738%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.169 Acc 95.903%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.120 Acc 96.875%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.097 Acc 96.821%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.096 Acc 96.953%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.100 Acc 96.872%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.104 Acc 96.776%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.103 Acc 96.780%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.187 Acc 95.599%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.182 Acc 95.647%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.101 Acc 96.798%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.101 Acc 96.894%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.104 Acc 96.826%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.104 Acc 96.863%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.105 Acc 96.771%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.104 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.180 Acc 95.862%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.175 Acc 95.818%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.095 Acc 96.798%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.101 Acc 96.770%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.103 Acc 96.771%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.105 Acc 96.741%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.105 Acc 96.730%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.143 Acc 93.750%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.182 Acc 95.452%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.177 Acc 95.596%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.066 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.096 Acc 97.146%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.098 Acc 96.988%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.100 Acc 96.950%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.103 Acc 96.863%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.104 Acc 96.841%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.198 Acc 95.336%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.194 Acc 95.289%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.080 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.097 Acc 96.952%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.097 Acc 97.108%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.099 Acc 97.009%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.101 Acc 96.937%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.166 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.206 Acc 95.003%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.204 Acc 95.052%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.105 Acc 96.723%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.103 Acc 96.766%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.102 Acc 96.846%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.103 Acc 96.794%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.189 Acc 94.531%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.194 Acc 95.498%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.192 Acc 95.464%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.064 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.100 Acc 96.844%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.101 Acc 96.844%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.103 Acc 96.841%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.105 Acc 96.786%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.189 Acc 95.421%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.183 Acc 95.468%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.102 Acc 96.798%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.099 Acc 96.879%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.102 Acc 96.802%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.103 Acc 96.797%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.104 Acc 96.777%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.214 Acc 93.750%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.207 Acc 95.080%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.203 Acc 95.083%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.106 Acc 96.770%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.106 Acc 96.723%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.105 Acc 96.761%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.192 Acc 95.367%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.189 Acc 95.355%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.162 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.103 Acc 96.921%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.098 Acc 96.995%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.100 Acc 96.924%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.100 Acc 96.939%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.101 Acc 96.845%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.158 Acc 93.750%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.196 Acc 95.336%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.192 Acc 95.386%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.127 Acc 94.531%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.095 Acc 97.099%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.095 Acc 96.995%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.099 Acc 96.857%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.101 Acc 96.807%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.101 Acc 96.794%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.206 Acc 95.196%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.201 Acc 95.285%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.100 Acc 96.952%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.099 Acc 96.871%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.100 Acc 96.805%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.102 Acc 96.801%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.102 Acc 96.819%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.217 Acc 94.531%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.204 Acc 95.127%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.200 Acc 95.157%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.100 Acc 96.774%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.098 Acc 96.879%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.098 Acc 96.849%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.100 Acc 96.822%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.102 Acc 96.806%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.192 Acc 95.398%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.098 Acc 97.037%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.098 Acc 97.003%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.099 Acc 96.984%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.098 Acc 96.998%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.098 Acc 96.990%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.191 Acc 92.188%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.211 Acc 95.142%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.204 Acc 95.340%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.097 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.093 Acc 97.130%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.093 Acc 97.034%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.100 Acc 96.852%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.101 Acc 96.856%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.101 Acc 96.863%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.203 Acc 95.080%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.196 Acc 95.281%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.098 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.098 Acc 96.929%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.096 Acc 96.972%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.099 Acc 96.937%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.099 Acc 96.928%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.100 Acc 96.931%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.187 Acc 95.630%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.178 Acc 95.787%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.101 Acc 97.068%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.098 Acc 97.085%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.100 Acc 97.059%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.100 Acc 96.996%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.099 Acc 97.018%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.189 Acc 95.784%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.183 Acc 95.845%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.064 Acc 98.438%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.093 Acc 97.006%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.093 Acc 97.027%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.091 Acc 97.080%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.094 Acc 96.992%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.095 Acc 96.984%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.168 Acc 93.750%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.200 Acc 95.328%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.194 Acc 95.355%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.088 Acc 96.875%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.089 Acc 97.208%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.091 Acc 97.209%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.094 Acc 97.062%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.097 Acc 96.941%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.100 Acc 96.894%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.197 Acc 95.343%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.187 Acc 95.530%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.093 Acc 97.138%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.093 Acc 97.023%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.097 Acc 96.930%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.095 Acc 97.004%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.098 Acc 96.950%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.136 Acc 94.531%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.190 Acc 95.413%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.184 Acc 95.503%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.099 Acc 96.805%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.101 Acc 96.821%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.098 Acc 96.958%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.098 Acc 96.970%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.097 Acc 96.997%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.207 Acc 94.918%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.202 Acc 95.056%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.139 Acc 93.750%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.094 Acc 97.092%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.090 Acc 97.093%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.095 Acc 97.049%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.097 Acc 96.939%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.247 Acc 91.406%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.213 Acc 94.740%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.209 Acc 94.955%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.089 Acc 97.169%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.093 Acc 97.120%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.093 Acc 97.059%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.096 Acc 97.002%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.098 Acc 96.922%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.200 Acc 95.289%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.193 Acc 95.425%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.127 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.086 Acc 97.378%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.095 Acc 97.065%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.097 Acc 96.989%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.096 Acc 97.025%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.096 Acc 97.023%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.147 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.195 Acc 95.390%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.187 Acc 95.534%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.089 Acc 97.656%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.094 Acc 97.068%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.092 Acc 97.108%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.095 Acc 97.039%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.097 Acc 96.959%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.098 Acc 96.920%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.128 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.192 Acc 95.421%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.187 Acc 95.460%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.135 Acc 94.531%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.088 Acc 97.200%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.092 Acc 97.089%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.095 Acc 97.026%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.095 Acc 97.043%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.095 Acc 97.022%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.160 Acc 92.188%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.192 Acc 95.405%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.185 Acc 95.550%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.094 Acc 97.053%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.093 Acc 97.124%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.093 Acc 97.067%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.095 Acc 97.035%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.095 Acc 97.034%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.194 Acc 95.390%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.189 Acc 95.452%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.050 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.088 Acc 97.208%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.088 Acc 97.213%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.092 Acc 97.083%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.093 Acc 97.050%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.095 Acc 97.028%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.209 Acc 95.026%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.204 Acc 95.149%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.175 Acc 93.750%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.088 Acc 97.030%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.091 Acc 97.065%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.095 Acc 96.994%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.096 Acc 96.996%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.095 Acc 97.053%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.165 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.198 Acc 95.343%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.191 Acc 95.503%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.060 Acc 98.438%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.082 Acc 97.393%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.088 Acc 97.155%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.092 Acc 97.106%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.095 Acc 97.002%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.094 Acc 97.048%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.157 Acc 93.750%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.206 Acc 95.173%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.203 Acc 95.332%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.092 Acc 97.014%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.095 Acc 97.038%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.093 Acc 97.101%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.095 Acc 97.041%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.095 Acc 97.011%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.204 Acc 95.150%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.200 Acc 95.285%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.089 Acc 97.285%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.091 Acc 97.145%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.093 Acc 97.109%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.093 Acc 97.096%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.152 Acc 92.969%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.204 Acc 95.220%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.199 Acc 95.293%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.070 Acc 98.438%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.083 Acc 97.293%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.091 Acc 97.011%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.094 Acc 96.930%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.092 Acc 96.996%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.093 Acc 96.961%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.188 Acc 95.552%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.185 Acc 95.503%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.092 Acc 97.331%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.093 Acc 97.279%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.093 Acc 97.197%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.094 Acc 97.132%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.095 Acc 97.062%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.103 Acc 96.094%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.196 Acc 95.429%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.191 Acc 95.585%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.056 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.095 Acc 96.968%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.096 Acc 96.980%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.092 Acc 97.070%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.092 Acc 97.101%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.091 Acc 97.106%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.141 Acc 93.750%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.186 Acc 95.436%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.178 Acc 95.635%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.090 Acc 96.875%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.087 Acc 97.184%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.087 Acc 97.252%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.091 Acc 97.140%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.094 Acc 97.068%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.202 Acc 95.026%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.195 Acc 95.258%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.084 Acc 97.277%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.092 Acc 97.108%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.092 Acc 97.116%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.092 Acc 97.097%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.092 Acc 97.117%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.179 Acc 93.750%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.202 Acc 95.336%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.194 Acc 95.519%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.042 Acc 97.656%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.082 Acc 97.478%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.088 Acc 97.213%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.088 Acc 97.249%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.089 Acc 97.179%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.092 Acc 97.073%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.191 Acc 95.583%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.187 Acc 95.713%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.080 Acc 97.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.095 Acc 96.898%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.091 Acc 97.151%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.092 Acc 97.064%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.091 Acc 97.097%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.092 Acc 97.103%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.174 Acc 92.969%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.190 Acc 95.730%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.179 Acc 95.829%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.085 Acc 97.300%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.086 Acc 97.310%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.089 Acc 97.176%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.090 Acc 97.175%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.089 Acc 97.185%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.161 Acc 94.531%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.201 Acc 95.421%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.194 Acc 95.522%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.087 Acc 97.215%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.089 Acc 97.201%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.088 Acc 97.231%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.090 Acc 97.175%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.090 Acc 97.179%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.184 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.201 Acc 95.080%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.193 Acc 95.258%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.084 Acc 97.324%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.086 Acc 97.283%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.087 Acc 97.238%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.088 Acc 97.177%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.090 Acc 97.148%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.143 Acc 94.531%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.199 Acc 95.088%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.192 Acc 95.270%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.045 Acc 99.219%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.090 Acc 97.077%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.091 Acc 97.088%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.090 Acc 97.144%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.090 Acc 97.151%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.183 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.200 Acc 95.212%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.193 Acc 95.332%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.086 Acc 97.192%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.085 Acc 97.353%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.088 Acc 97.262%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.089 Acc 97.232%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.089 Acc 97.196%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.182 Acc 93.750%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.231 Acc 94.779%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.224 Acc 94.881%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.091 Acc 96.937%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.089 Acc 97.042%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.086 Acc 97.173%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.085 Acc 97.198%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.089 Acc 97.118%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.206 Acc 95.382%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.202 Acc 95.336%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.085 Acc 97.246%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.086 Acc 97.268%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.089 Acc 97.173%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.090 Acc 97.152%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.091 Acc 97.149%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.158 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.190 Acc 95.560%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.188 Acc 95.592%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.098 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.088 Acc 97.386%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.087 Acc 97.287%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.087 Acc 97.298%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.088 Acc 97.237%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.088 Acc 97.209%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.147 Acc 93.750%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.198 Acc 95.583%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.189 Acc 95.721%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.087 Acc 97.300%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.086 Acc 97.407%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.087 Acc 97.324%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.089 Acc 97.253%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.088 Acc 97.263%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.220 Acc 95.235%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.212 Acc 95.421%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.082 Acc 97.239%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.083 Acc 97.345%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.085 Acc 97.288%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.086 Acc 97.265%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.088 Acc 97.185%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.219 Acc 94.957%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.215 Acc 95.029%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.085 Acc 97.386%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.085 Acc 97.252%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.090 Acc 97.142%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.190 Acc 94.531%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.206 Acc 95.282%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.202 Acc 95.246%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.084 Acc 97.401%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.086 Acc 97.194%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.088 Acc 97.202%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.087 Acc 97.217%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.168 Acc 94.531%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.359%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.190 Acc 95.406%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.061 Acc 99.219%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.084 Acc 97.393%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.086 Acc 97.341%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.087 Acc 97.288%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.088 Acc 97.284%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.088 Acc 97.255%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.148 Acc 93.750%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.208 Acc 95.537%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.202 Acc 95.557%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.080 Acc 97.393%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.083 Acc 97.353%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.085 Acc 97.392%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.085 Acc 97.364%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.087 Acc 97.337%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.167 Acc 94.531%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.205 Acc 95.336%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.199 Acc 95.460%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.081 Acc 97.347%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.085 Acc 97.330%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.089 Acc 97.212%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.089 Acc 97.185%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.088 Acc 97.215%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.170 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.214 Acc 95.003%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.209 Acc 95.239%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.253 Acc 93.750%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.091 Acc 97.324%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.087 Acc 97.373%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.085 Acc 97.324%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.086 Acc 97.286%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.086 Acc 97.255%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.215 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.215 Acc 94.918%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.212 Acc 95.013%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.107 Acc 96.875%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.083 Acc 97.440%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.087 Acc 97.260%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.086 Acc 97.207%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.088 Acc 97.183%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.091 Acc 97.100%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.269 Acc 93.750%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.225 Acc 94.926%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.216 Acc 95.017%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.082 Acc 96.094%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.086 Acc 97.169%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.086 Acc 97.147%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.087 Acc 97.145%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.085 Acc 97.212%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.087 Acc 97.184%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.222 Acc 92.188%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.198 Acc 95.405%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.191 Acc 95.546%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.081 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.086 Acc 97.123%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.086 Acc 97.143%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.084 Acc 97.272%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.083 Acc 97.339%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.084 Acc 97.305%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.211 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.211 Acc 95.196%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.202 Acc 95.367%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.080 Acc 97.370%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.084 Acc 97.279%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.088 Acc 97.202%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.087 Acc 97.235%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.086 Acc 97.270%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.194 Acc 93.750%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.211 Acc 95.181%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.205 Acc 95.258%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.079 Acc 97.424%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.083 Acc 97.376%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.084 Acc 97.335%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.084 Acc 97.299%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.199 Acc 95.490%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.193 Acc 95.588%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.022 Acc 99.219%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.082 Acc 97.401%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.085 Acc 97.221%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.084 Acc 97.257%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.085 Acc 97.241%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.086 Acc 97.215%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.192 Acc 95.459%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.185 Acc 95.666%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.083 Acc 97.386%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.082 Acc 97.396%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.082 Acc 97.340%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.082 Acc 97.337%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.083 Acc 97.305%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.206 Acc 95.150%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.200 Acc 95.305%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.083 Acc 97.401%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.085 Acc 97.380%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.085 Acc 97.415%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.085 Acc 97.345%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.085 Acc 97.327%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.145 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.195 Acc 95.390%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.189 Acc 95.573%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.058 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.082 Acc 97.392%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.084 Acc 97.350%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.086 Acc 97.343%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.087 Acc 97.301%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.211 Acc 95.336%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.205 Acc 95.359%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c34f402dcd4576b71fc37be7f33b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.363 Acc 6.250%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 3.402 Acc 17.976%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.826 Acc 18.151%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.631 Acc 18.452%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.533 Acc 18.538%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.474 Acc 18.700%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.226 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.230 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.231 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.185 Acc 27.344%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.239 Acc 18.982%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.236 Acc 18.781%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 18.965%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.238 Acc 18.906%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.221 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.295 Acc 17.188%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.235 Acc 18.920%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.235 Acc 18.929%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.237 Acc 18.802%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.315 Acc 11.719%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 19.022%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 19.027%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.271 Acc 15.625%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.231 Acc 19.647%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.237 Acc 18.896%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.261 Acc 16.406%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.243 Acc 18.325%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.201 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.269 Acc 15.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.233 Acc 19.562%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.234 Acc 19.345%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.236 Acc 19.134%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.248 Acc 17.969%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.237 Acc 18.897%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.240 Acc 18.649%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.238 Acc 18.776%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.235 Acc 19.052%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.236 Acc 18.913%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.236 Acc 18.950%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.234 Acc 19.066%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.234 Acc 18.981%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.220 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.221 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.189 Acc 25.781%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.234 Acc 18.998%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.234 Acc 18.940%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.234 Acc 18.859%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.234 Acc 18.805%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.233 Acc 18.920%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.221 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.222 Acc 21.094%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 2.234 Acc 18.905%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 2.232 Acc 18.921%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 2.230 Acc 19.196%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 2.230 Acc 18.974%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 2.232 Acc 18.985%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 2.217 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 2.216 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 2.218 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 2.221 Acc 18.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 2.225 Acc 18.835%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 2.222 Acc 19.154%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 2.232 Acc 18.924%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 2.234 Acc 18.822%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 2.234 Acc 18.879%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2.213 Acc 21.875%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2.235 Acc 19.578%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2.238 Acc 18.940%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2.237 Acc 18.856%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 2.238 Acc 18.828%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 2.272 Acc 14.062%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 2.234 Acc 19.346%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 2.235 Acc 19.076%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 2.237 Acc 18.926%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 2.237 Acc 18.986%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 2.261 Acc 17.969%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 2.239 Acc 18.777%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 2.239 Acc 18.879%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 2.238 Acc 18.895%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 2.163 Acc 28.125%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 2.240 Acc 19.137%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 2.238 Acc 19.111%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 2.236 Acc 19.098%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 2.238 Acc 18.953%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 2.283 Acc 14.062%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 2.237 Acc 18.719%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 2.236 Acc 18.952%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 2.237 Acc 18.766%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 2.238 Acc 18.865%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 2.244 Acc 17.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 2.234 Acc 18.611%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 2.234 Acc 18.874%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 2.237 Acc 18.884%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 2.265 Acc 11.719%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 2.241 Acc 18.827%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 2.239 Acc 18.622%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 2.239 Acc 18.625%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 2.238 Acc 18.865%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 2.283 Acc 14.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 2.235 Acc 19.067%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 2.238 Acc 18.637%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 2.238 Acc 18.711%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 2.238 Acc 18.723%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 2.238 Acc 18.865%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 2.279 Acc 15.625%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 2.497 Acc 19.160%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 2.367 Acc 19.162%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 2.324 Acc 19.074%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 2.303 Acc 18.968%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 2.290 Acc 18.884%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 2.207 Acc 22.656%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 2.235 Acc 19.021%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 2.236 Acc 19.088%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 2.219 Acc 18.750%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 2.237 Acc 19.034%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 2.256 Acc 20.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 2.234 Acc 19.261%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 2.232 Acc 14.062%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 2.237 Acc 19.139%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2.205 Acc 24.219%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 2.235 Acc 19.512%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 2.236 Acc 19.272%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 2.236 Acc 19.077%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 2.236 Acc 18.987%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2.230 Acc 19.531%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 2.234 Acc 19.245%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 2.236 Acc 18.922%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2.249 Acc 19.531%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 2.239 Acc 18.673%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 2.239 Acc 18.747%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 2.237 Acc 19.014%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 2.211 Acc 18.750%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2.233 Acc 19.129%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 2.236 Acc 18.914%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 2.237 Acc 18.842%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 2.283 Acc 16.406%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 2.240 Acc 18.394%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 2.237 Acc 18.902%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 2.237 Acc 18.907%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 2.209 Acc 24.219%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 2.235 Acc 18.928%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 2.235 Acc 18.933%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 2.248 Acc 25.000%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 2.239 Acc 18.824%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 2.238 Acc 18.779%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 2.265 Acc 16.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 2.239 Acc 19.108%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 2.236 Acc 19.225%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 2.237 Acc 19.124%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 2.238 Acc 18.950%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 2.287 Acc 11.719%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 2.238 Acc 19.052%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 2.238 Acc 19.038%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 2.237 Acc 18.978%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 2.238 Acc 18.896%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.201 Acc 22.656%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 2.239 Acc 18.908%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.251 Acc 15.625%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 2.237 Acc 18.580%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 2.236 Acc 18.933%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 2.236 Acc 18.953%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.204 Acc 20.312%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 2.241 Acc 18.557%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 2.238 Acc 19.090%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 2.237 Acc 18.962%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 2.284 Acc 18.750%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 2.233 Acc 19.230%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 2.238 Acc 18.786%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 2.237 Acc 19.005%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.233 Acc 22.656%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 2.239 Acc 18.676%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 2.237 Acc 18.797%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.294 Acc 14.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 2.236 Acc 18.940%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 2.238 Acc 18.854%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 2.238 Acc 18.806%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 2.161 Acc 22.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 2.240 Acc 19.531%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 2.240 Acc 18.920%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 2.236 Acc 19.279%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 2.243 Acc 20.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 2.238 Acc 19.067%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 2.237 Acc 19.255%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 2.238 Acc 19.007%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 2.236 Acc 19.040%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 2.170 Acc 30.469%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 2.236 Acc 19.129%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 2.236 Acc 19.236%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 2.237 Acc 19.168%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 2.238 Acc 18.937%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 2.221 Acc 19.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 2.237 Acc 18.684%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 2.238 Acc 18.911%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 2.238 Acc 18.869%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 2.234 Acc 20.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 2.234 Acc 19.446%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 2.235 Acc 19.181%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 2.236 Acc 18.872%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 2.217 Acc 17.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 2.241 Acc 18.758%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 2.244 Acc 19.531%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 2.240 Acc 18.626%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 2.240 Acc 18.591%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 2.202 Acc 17.969%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 2.229 Acc 19.624%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 2.235 Acc 18.960%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 2.235 Acc 18.924%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 2.236 Acc 18.912%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2.260 Acc 17.969%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 2.239 Acc 18.951%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 2.237 Acc 18.987%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 2.224 Acc 17.188%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 2.234 Acc 19.647%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 2.239 Acc 18.972%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2.237 Acc 18.932%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 2.236 Acc 19.056%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 2.194 Acc 18.750%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2.234 Acc 19.021%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 2.238 Acc 18.825%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2.237 Acc 18.853%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.253 Acc 15.625%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 2.234 Acc 19.237%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 2.235 Acc 19.224%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 2.237 Acc 18.953%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.225 Acc 17.969%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 2.238 Acc 18.711%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 2.237 Acc 18.950%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 2.237 Acc 18.904%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 2.238 Acc 18.883%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.242 Acc 18.750%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 2.234 Acc 19.361%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 2.235 Acc 19.290%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 2.237 Acc 18.881%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 2.236 Acc 19.006%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 2.298 Acc 13.281%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 2.239 Acc 18.441%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 2.238 Acc 18.680%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 2.236 Acc 18.851%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 2.236 Acc 18.964%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.227 Acc 17.969%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 2.231 Acc 19.144%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 2.237 Acc 18.856%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.235 Acc 18.750%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 2.238 Acc 18.657%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 2.239 Acc 18.707%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 2.237 Acc 18.975%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2.231 Acc 15.625%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 2.235 Acc 18.897%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2.237 Acc 18.777%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.295 Acc 14.062%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 2.232 Acc 19.407%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 2.235 Acc 19.061%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 2.237 Acc 18.923%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 2.238 Acc 18.864%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.212 Acc 21.875%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 2.237 Acc 18.992%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.273 Acc 16.406%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 2.240 Acc 18.951%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 2.236 Acc 19.110%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.256 Acc 20.312%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.233 Acc 18.982%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.235 Acc 18.870%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.236 Acc 18.854%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.259 Acc 14.844%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.234 Acc 19.106%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.234 Acc 19.213%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.235 Acc 19.173%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 2.236 Acc 18.997%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.241 Acc 22.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.240 Acc 18.858%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.182 Acc 24.219%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 2.238 Acc 18.878%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 2.238 Acc 18.893%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 2.237 Acc 18.964%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.242 Acc 20.312%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.234 Acc 18.858%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.235 Acc 18.859%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.236 Acc 18.864%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.237 Acc 18.840%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.219 Acc 19.531%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.235 Acc 19.183%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.236 Acc 18.895%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.217 Acc 17.188%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.238 Acc 18.472%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.239 Acc 18.707%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.238 Acc 18.755%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.249 Acc 18.750%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.234 Acc 18.765%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.237 Acc 18.668%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.238 Acc 18.620%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.237 Acc 18.768%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.937%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.187 Acc 23.438%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.232 Acc 19.152%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.235 Acc 19.049%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.235 Acc 19.215%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.236 Acc 19.054%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.211 Acc 17.969%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.236 Acc 18.765%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 19.084%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.238 Acc 18.838%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.237 Acc 18.871%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.267 Acc 18.750%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.229 Acc 19.624%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.234 Acc 19.100%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 2.237 Acc 18.861%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 2.237 Acc 18.876%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.214 Acc 20.312%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.238 Acc 18.692%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.204 Acc 21.875%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.241 Acc 18.742%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.239 Acc 18.867%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.238 Acc 18.886%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.264 Acc 17.969%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.239 Acc 18.912%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.237 Acc 18.750%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.236 Acc 18.830%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.238 Acc 18.756%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.837%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.179 Acc 25.000%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 2.243 Acc 18.533%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 2.238 Acc 18.746%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 2.237 Acc 18.923%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.235 Acc 21.875%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.236 Acc 18.991%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.227 Acc 20.312%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.241 Acc 18.564%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.240 Acc 18.614%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.239 Acc 18.864%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.236 Acc 18.984%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.239 Acc 18.595%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.238 Acc 18.784%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.237 Acc 18.828%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.238 Acc 18.844%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.221 Acc 23.438%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.236 Acc 19.284%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.240 Acc 18.890%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.236 Acc 19.013%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.273 Acc 14.844%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.242 Acc 18.394%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.239 Acc 18.864%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.848%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.234 Acc 15.625%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.238 Acc 18.371%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.236 Acc 18.908%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.237 Acc 18.982%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.228 Acc 21.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.239 Acc 19.137%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.235 Acc 19.158%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 2.236 Acc 19.068%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 2.237 Acc 18.965%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.271 Acc 16.406%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.239 Acc 18.645%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.239 Acc 18.724%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.238 Acc 18.845%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.262 Acc 19.531%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.237 Acc 18.975%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.238 Acc 18.870%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.248 Acc 18.750%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 2.239 Acc 18.672%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 2.237 Acc 18.858%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.199 Acc 20.312%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.238 Acc 18.699%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.239 Acc 18.675%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.791%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.218 Acc 20.312%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.242 Acc 18.626%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.237 Acc 18.944%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 2.237 Acc 18.945%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 2.238 Acc 18.892%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 2.238 Acc 18.923%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.241 Acc 18.750%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.235 Acc 18.773%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.235 Acc 19.076%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.239 Acc 18.629%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.238 Acc 18.792%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.249 Acc 15.625%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.236 Acc 19.144%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.236 Acc 19.123%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.238 Acc 18.881%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.217 Acc 18.750%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.234 Acc 19.307%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.236 Acc 19.056%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.196 Acc 26.562%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.237 Acc 18.942%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.236 Acc 19.079%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.887%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.184 Acc 19.531%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.237 Acc 19.098%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.238 Acc 18.817%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.239 Acc 18.692%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.834%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.222 Acc 19.531%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.241 Acc 18.781%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.240 Acc 18.816%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.239 Acc 18.779%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.254 Acc 17.969%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.242 Acc 18.216%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.239 Acc 18.490%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 2.238 Acc 18.768%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 2.237 Acc 18.848%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.209 Acc 26.562%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.233 Acc 19.137%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.235 Acc 18.758%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.237 Acc 18.714%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.237 Acc 18.832%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.884%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.241 Acc 16.406%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.233 Acc 19.446%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.235 Acc 19.092%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.238 Acc 18.854%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.237 Acc 18.844%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.229 Acc 16.406%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.241 Acc 18.858%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 2.239 Acc 19.038%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.244 Acc 17.188%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.242 Acc 18.278%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.240 Acc 18.610%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.243 Acc 20.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.240 Acc 18.765%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.235 Acc 19.057%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.236 Acc 19.004%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.238 Acc 18.921%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.186 Acc 26.562%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.237 Acc 19.009%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.198 Acc 23.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.243 Acc 18.835%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 2.242 Acc 18.637%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.239 Acc 18.771%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.246 Acc 17.188%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.241 Acc 18.699%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.238 Acc 18.968%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.204 Acc 23.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.239 Acc 18.464%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.241 Acc 18.233%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.239 Acc 18.490%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.252 Acc 20.312%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.235 Acc 18.991%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.236 Acc 18.941%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.251 Acc 17.188%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.234 Acc 19.400%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.234 Acc 19.442%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.236 Acc 19.155%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.273 Acc 17.969%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.238 Acc 18.984%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.238 Acc 18.828%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.206 Acc 23.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.233 Acc 19.516%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.235 Acc 19.263%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.236 Acc 19.072%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.232 Acc 20.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 2.235 Acc 19.044%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 2.238 Acc 18.995%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 2.237 Acc 18.976%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 2.238 Acc 18.941%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 2.237 Acc 18.981%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.190 Acc 24.219%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.232 Acc 19.717%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.236 Acc 19.286%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 19.142%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.236 Acc 19.116%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.215 Acc 18.750%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.237 Acc 19.090%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.238 Acc 18.975%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.238 Acc 18.950%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.237 Acc 19.003%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.254 Acc 17.969%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.235 Acc 19.044%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.236 Acc 18.766%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.237 Acc 18.708%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 18.785%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.240 Acc 15.625%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.232 Acc 19.663%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.236 Acc 19.317%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.236 Acc 19.093%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.236 Acc 19.017%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.269 Acc 16.406%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.237 Acc 18.834%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 18.859%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.256 Acc 18.750%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.240 Acc 18.758%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.229 Acc 21.094%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.239 Acc 18.943%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.238 Acc 18.964%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.238 Acc 18.815%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.238 Acc 18.805%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 2.235 Acc 19.178%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.237 Acc 18.957%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.286 Acc 13.281%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.235 Acc 18.866%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.018%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.237 Acc 18.988%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.243 Acc 19.531%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.239 Acc 18.750%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.238 Acc 18.913%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.237 Acc 19.004%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 19.091%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.236 Acc 19.071%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.283 Acc 17.188%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.240 Acc 18.820%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.238 Acc 18.890%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.236 Acc 18.990%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.195 Acc 16.406%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.235 Acc 19.261%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.236 Acc 19.135%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.236 Acc 19.243%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.238 Acc 19.036%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.237 Acc 18.978%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.254 Acc 21.094%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.240 Acc 18.448%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.239 Acc 18.633%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.238 Acc 18.953%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.246 Acc 17.969%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.238 Acc 19.106%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.238 Acc 18.797%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.239 Acc 18.703%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.238 Acc 18.858%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.220 Acc 17.188%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.235 Acc 19.154%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.235 Acc 19.222%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.235 Acc 19.192%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.236 Acc 19.001%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.243 Acc 18.750%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.234 Acc 19.106%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.235 Acc 18.991%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.236 Acc 18.895%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.237 Acc 18.922%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.231 Acc 18.750%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.238 Acc 18.998%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 19.018%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.238 Acc 18.793%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.240 Acc 16.406%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.240 Acc 18.680%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.238 Acc 18.836%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.238 Acc 18.879%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.238 Acc 18.920%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.213 Acc 21.875%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.240 Acc 18.688%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.240 Acc 18.692%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.239 Acc 18.768%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.239 Acc 18.758%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.278 Acc 17.969%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.239 Acc 18.882%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.238 Acc 18.931%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.224 Acc 18.750%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.237 Acc 19.160%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.236 Acc 19.026%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 18.939%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.833%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.240 Acc 17.969%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.909%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.239 Acc 18.779%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.177 Acc 23.438%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.232 Acc 19.129%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.235 Acc 19.010%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 2.235 Acc 19.056%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.235 Acc 18.955%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.238 Acc 19.531%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.232 Acc 19.330%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.234 Acc 19.216%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.235 Acc 19.120%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.236 Acc 19.035%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.234 Acc 19.531%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.235 Acc 19.202%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.236 Acc 19.027%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.210 Acc 19.531%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.236 Acc 19.036%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.235 Acc 19.018%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.238 Acc 18.876%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.222 Acc 17.188%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.237 Acc 18.750%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.238 Acc 18.792%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.263 Acc 16.406%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.237 Acc 18.882%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.237 Acc 18.841%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.237 Acc 18.861%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.238 Acc 18.850%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.228 Acc 18.750%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.238 Acc 18.549%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.237 Acc 18.867%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.195 Acc 25.000%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.235 Acc 19.349%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.237 Acc 19.121%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.276 Acc 17.188%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.241 Acc 18.456%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.238 Acc 18.847%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.236 Acc 19.082%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.222 Acc 15.625%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.237 Acc 18.912%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.239 Acc 18.874%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.239 Acc 18.773%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.238 Acc 18.931%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.238 Acc 18.917%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.214 Acc 21.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.234 Acc 19.199%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.234 Acc 19.127%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.235 Acc 19.043%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.237 Acc 18.994%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.271 Acc 14.844%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.769%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.238 Acc 18.762%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.238 Acc 18.792%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.208 Acc 21.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.234 Acc 19.284%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.236 Acc 19.080%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.235 Acc 19.189%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.237 Acc 19.058%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.237 Acc 18.943%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.247 Acc 20.312%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.244 Acc 18.263%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.995%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.222 Acc 20.312%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.233 Acc 19.191%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.235 Acc 18.972%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.237 Acc 18.727%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.237 Acc 18.920%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.237 Acc 18.940%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.238 Acc 18.963%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 2.238 Acc 18.890%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.216 Acc 23.438%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.241 Acc 18.704%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.236 Acc 18.847%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.236 Acc 18.932%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.237 Acc 18.855%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.186 Acc 24.219%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.233 Acc 19.114%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.236 Acc 18.925%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.237 Acc 18.914%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.237 Acc 18.968%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.292 Acc 13.281%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 2.235 Acc 18.881%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.238 Acc 19.061%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.236 Acc 19.126%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.222 Acc 18.750%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.244 Acc 18.564%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.241 Acc 18.664%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.239 Acc 18.750%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.238 Acc 18.861%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.237 Acc 18.906%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.240 Acc 21.094%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.237 Acc 18.665%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.236 Acc 18.851%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.236 Acc 18.901%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.238 Acc 18.862%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.267 Acc 14.062%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.240 Acc 18.742%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.236 Acc 18.967%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.251 Acc 14.062%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.234 Acc 19.237%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.236 Acc 19.131%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.236 Acc 19.121%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.237 Acc 19.095%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.237 Acc 18.957%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.188 Acc 18.750%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.240 Acc 18.448%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.236 Acc 18.762%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.235 Acc 19.041%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.238 Acc 18.912%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.247 Acc 15.625%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.240 Acc 18.711%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.239 Acc 18.785%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.236 Acc 18.910%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.255 Acc 20.312%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.234 Acc 19.267%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.237 Acc 19.051%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.227 Acc 23.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.238 Acc 18.936%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.237 Acc 19.049%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.238 Acc 18.914%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.236 Acc 18.946%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.211 Acc 25.000%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.241 Acc 18.509%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.241 Acc 18.623%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.238 Acc 18.826%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.237 Acc 18.962%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.259 Acc 18.750%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.240 Acc 19.052%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.239 Acc 18.952%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.942%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.238 Acc 18.951%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.198 Acc 20.312%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.237 Acc 19.253%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.239 Acc 18.937%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.239 Acc 18.763%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.238 Acc 18.824%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 2.238 Acc 18.839%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.255 Acc 15.625%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.237 Acc 18.917%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.237 Acc 18.972%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.992%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.226 Acc 21.094%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.243 Acc 18.572%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.239 Acc 18.653%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.174 Acc 21.875%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.237 Acc 18.967%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.911%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.236 Acc 18.943%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.215 Acc 16.406%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.917%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.235 Acc 19.033%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.236 Acc 19.029%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.236 Acc 19.018%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.229 Acc 17.188%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.242 Acc 18.673%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.238 Acc 19.003%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.235 Acc 19.083%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.236 Acc 19.015%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.276 Acc 18.750%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.234 Acc 19.624%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.235 Acc 19.236%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.236 Acc 19.019%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.214 Acc 24.219%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.237 Acc 19.144%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.236 Acc 19.033%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.221 Acc 20.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.241 Acc 18.256%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.240 Acc 18.576%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.239 Acc 18.697%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.242 Acc 15.625%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.238 Acc 18.874%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.235 Acc 18.976%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.939%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.250 Acc 15.625%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.239 Acc 18.711%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.237 Acc 19.073%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.237 Acc 18.991%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.238 Acc 18.886%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.191 Acc 22.656%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.235 Acc 19.052%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.234 Acc 19.306%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.235 Acc 19.272%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.235 Acc 19.149%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.236 Acc 19.006%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.279 Acc 19.531%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.233 Acc 19.462%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.234 Acc 19.251%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.236 Acc 19.064%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.238 Acc 18.893%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.281 Acc 14.062%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.233 Acc 19.377%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.235 Acc 19.119%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.237 Acc 18.968%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.250 Acc 17.188%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.238 Acc 18.905%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.239 Acc 18.595%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.239 Acc 18.638%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.738%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.294 Acc 13.281%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.236 Acc 19.100%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.238 Acc 18.867%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.223 Acc 17.969%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.236 Acc 19.237%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.233 Acc 19.399%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.236 Acc 19.155%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.249 Acc 17.188%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.241 Acc 18.536%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.237 Acc 18.885%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 18.901%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.259 Acc 20.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.240 Acc 18.611%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.237 Acc 18.797%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.281 Acc 16.406%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.237 Acc 18.936%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.236 Acc 19.248%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.237 Acc 19.121%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.237 Acc 18.957%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.226 Acc 17.188%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.238 Acc 18.897%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.237 Acc 18.894%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.895%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.237 Acc 18.801%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.237 Acc 18.786%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.238 Acc 18.658%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.231 Acc 19.531%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.235 Acc 18.959%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.235 Acc 19.088%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.235 Acc 19.082%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.237 Acc 18.926%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.283 Acc 19.531%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.233 Acc 19.384%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.236 Acc 19.216%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.237 Acc 19.147%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.237 Acc 19.042%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.236 Acc 14.062%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.005%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.237 Acc 18.723%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.237 Acc 18.952%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.273 Acc 14.062%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.242 Acc 18.448%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.241 Acc 18.870%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.238 Acc 18.906%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.226 Acc 23.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.240 Acc 18.526%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.235 Acc 19.057%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.237 Acc 18.838%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.237 Acc 18.854%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.231 Acc 17.969%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.236 Acc 19.005%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 18.917%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.236 Acc 18.970%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.233 Acc 17.188%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.235 Acc 19.245%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.236 Acc 19.053%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.239 Acc 18.890%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.263 Acc 19.531%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.238 Acc 18.913%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.236 Acc 18.963%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.182 Acc 22.656%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.232 Acc 18.912%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.236 Acc 18.987%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.236 Acc 18.815%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.760%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.236 Acc 19.162%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.236 Acc 18.997%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.253 Acc 18.750%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.234 Acc 19.083%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.234 Acc 18.952%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 18.916%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.294 Acc 14.062%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.235 Acc 18.843%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.239 Acc 18.684%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.239 Acc 18.908%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 2.239 Acc 18.867%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.948%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.245 Acc 21.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.240 Acc 18.715%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.239 Acc 18.877%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.238 Acc 18.887%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.236 Acc 14.062%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.237 Acc 18.877%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.234 Acc 17.969%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.239 Acc 18.735%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.236 Acc 18.979%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.236 Acc 19.074%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.236 Acc 19.023%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf8a61684ab45849204ce483e439362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.316 Acc 8.594%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 4.569 Acc 16.793%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 3.410 Acc 18.066%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 3.022 Acc 18.285%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.826 Acc 18.317%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.709 Acc 18.443%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.228 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.225 Acc 20.266%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.233 Acc 19.356%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 19.069%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 19.070%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.237 Acc 19.007%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.259 Acc 15.625%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.235 Acc 18.704%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.236 Acc 18.874%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.235 Acc 18.978%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.273 Acc 15.625%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.238 Acc 18.796%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.239 Acc 18.762%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.237 Acc 18.997%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 19.040%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.948%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.260 Acc 14.844%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.235 Acc 18.889%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.236 Acc 18.587%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.236 Acc 18.690%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.236 Acc 18.816%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.235 Acc 18.744%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.196 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.222 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.214 Acc 19.531%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.238 Acc 18.363%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.232 Acc 18.913%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.234 Acc 18.929%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.233 Acc 18.869%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.233 Acc 18.948%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.191 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.218 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.219 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.221 Acc 20.312%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.223 Acc 19.438%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.226 Acc 19.007%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.226 Acc 18.914%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.223 Acc 18.958%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.214 Acc 19.431%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 1.984 Acc 38.281%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.006 Acc 31.405%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.011 Acc 31.110%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.061 Acc 32.031%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.009 Acc 29.308%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 1.903 Acc 34.161%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 1.782 Acc 38.800%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 1.644 Acc 43.990%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 1.514 Acc 48.728%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.747 Acc 77.344%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.795 Acc 75.472%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.792 Acc 75.649%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.725 Acc 74.219%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.726 Acc 77.027%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.686 Acc 78.327%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.651 Acc 79.384%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.628 Acc 80.243%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.607 Acc 80.930%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.495 Acc 82.031%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.497 Acc 85.063%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.497 Acc 85.005%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.477 Acc 85.938%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.493 Acc 84.855%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.470 Acc 85.588%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.462 Acc 85.930%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.457 Acc 86.105%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.448 Acc 86.391%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.477 Acc 87.500%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.479 Acc 86.703%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.476 Acc 86.633%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.297 Acc 88.281%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.403 Acc 87.670%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.394 Acc 88.099%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.393 Acc 88.164%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.392 Acc 88.186%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.393 Acc 88.138%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.388 Acc 89.844%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.371 Acc 88.869%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.367 Acc 88.977%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.413 Acc 88.281%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.363 Acc 89.032%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.363 Acc 89.117%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.364 Acc 89.140%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.362 Acc 89.135%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.363 Acc 89.089%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.362 Acc 90.625%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.371 Acc 89.565%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.361 Acc 89.754%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.268 Acc 92.969%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.345 Acc 89.581%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.351 Acc 89.443%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.351 Acc 89.519%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.349 Acc 89.555%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.347 Acc 89.594%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.319 Acc 91.406%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.350 Acc 89.689%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.344 Acc 89.879%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.218 Acc 92.969%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.327 Acc 89.991%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.321 Acc 90.170%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.328 Acc 90.072%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.330 Acc 90.062%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.332 Acc 90.043%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.287 Acc 89.844%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.297 Acc 91.793%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.288 Acc 91.939%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.344 Acc 89.844%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.330 Acc 89.937%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.327 Acc 90.034%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.324 Acc 90.207%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.321 Acc 90.327%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.321 Acc 90.360%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.355 Acc 88.281%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.314 Acc 91.677%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.310 Acc 91.756%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.348 Acc 89.844%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.303 Acc 90.865%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.306 Acc 90.897%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.317 Acc 90.677%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.318 Acc 90.522%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.317 Acc 90.570%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.304 Acc 90.625%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.276 Acc 91.932%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.267 Acc 92.067%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.289 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.294 Acc 91.275%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.297 Acc 91.157%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.300 Acc 91.030%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.301 Acc 90.991%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.301 Acc 90.991%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.312 Acc 93.750%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.275 Acc 92.280%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.265 Acc 92.413%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.259 Acc 92.188%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.283 Acc 91.414%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.301 Acc 91.018%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.296 Acc 91.274%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.296 Acc 91.307%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.296 Acc 91.336%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.311 Acc 89.844%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.254 Acc 93.031%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.246 Acc 93.124%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.211 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.286 Acc 91.267%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.284 Acc 91.449%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.294 Acc 91.206%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.297 Acc 91.174%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.297 Acc 91.208%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.285 Acc 88.281%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.246 Acc 93.023%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.240 Acc 93.276%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.173 Acc 92.969%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.268 Acc 91.940%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.280 Acc 91.589%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.282 Acc 91.596%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.285 Acc 91.613%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.284 Acc 91.614%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.247 Acc 92.984%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.239 Acc 93.206%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.159 Acc 96.875%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.286 Acc 92.048%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.280 Acc 91.912%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.285 Acc 91.707%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.283 Acc 91.771%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.281 Acc 91.798%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.279 Acc 89.844%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.248 Acc 93.301%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.240 Acc 93.319%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.249 Acc 90.625%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.270 Acc 92.296%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.268 Acc 92.343%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.273 Acc 92.055%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.274 Acc 92.045%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.273 Acc 92.060%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.331 Acc 90.625%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.262 Acc 92.884%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.251 Acc 93.132%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.244 Acc 90.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.265 Acc 92.443%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.267 Acc 92.292%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.270 Acc 92.265%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.270 Acc 92.262%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.273 Acc 92.177%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.248 Acc 93.201%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.242 Acc 93.233%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.257 Acc 92.242%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.260 Acc 92.425%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.269 Acc 92.307%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.266 Acc 92.373%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.265 Acc 92.414%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.245 Acc 93.038%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.241 Acc 93.155%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.173 Acc 94.531%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.266 Acc 92.188%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.264 Acc 92.351%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.266 Acc 92.312%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.266 Acc 92.242%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.265 Acc 92.309%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.207 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.219 Acc 94.230%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.211 Acc 94.372%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.244 Acc 91.406%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.263 Acc 92.497%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.268 Acc 92.222%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.264 Acc 92.419%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.263 Acc 92.464%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.263 Acc 92.484%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.332 Acc 89.844%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.227 Acc 93.719%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.222 Acc 94.045%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.114 Acc 97.656%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.252 Acc 92.946%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.256 Acc 92.712%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.257 Acc 92.595%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.258 Acc 92.571%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.260 Acc 92.517%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.184 Acc 91.406%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.207 Acc 94.407%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.201 Acc 94.566%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.221 Acc 91.406%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.245 Acc 92.822%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.245 Acc 92.852%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.248 Acc 92.771%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.249 Acc 92.749%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.249 Acc 92.705%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.216 Acc 94.330%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.206 Acc 94.457%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.230 Acc 92.969%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.247 Acc 92.891%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.252 Acc 92.724%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.246 Acc 92.896%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.248 Acc 92.836%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.248 Acc 92.833%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.195 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.220 Acc 94.075%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.211 Acc 94.263%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.338 Acc 92.188%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.243 Acc 93.093%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.242 Acc 93.109%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.244 Acc 93.021%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.248 Acc 92.963%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.250 Acc 92.833%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.344 Acc 90.625%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.230 Acc 94.377%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.224 Acc 94.450%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.282 Acc 92.188%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.235 Acc 93.123%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.243 Acc 92.918%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.241 Acc 93.041%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.241 Acc 93.064%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.242 Acc 93.081%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.242 Acc 92.188%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.230 Acc 93.657%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.221 Acc 93.886%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.316 Acc 92.188%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.231 Acc 93.209%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.234 Acc 93.237%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.236 Acc 93.200%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.234 Acc 93.154%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.238 Acc 93.050%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.226 Acc 92.969%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.234 Acc 93.750%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.227 Acc 93.839%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.161 Acc 96.094%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.228 Acc 93.603%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.235 Acc 93.291%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.234 Acc 93.231%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.236 Acc 93.230%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.234 Acc 93.232%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.326 Acc 90.625%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.217 Acc 94.307%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.208 Acc 94.422%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.344 Acc 91.406%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.228 Acc 93.139%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.229 Acc 93.218%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.231 Acc 93.233%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.229 Acc 93.325%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.229 Acc 93.370%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.240 Acc 93.595%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.229 Acc 93.894%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.255 Acc 94.531%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.234 Acc 93.178%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.236 Acc 93.167%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.236 Acc 93.182%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.237 Acc 93.210%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.235 Acc 93.262%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.234 Acc 92.188%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.187 Acc 95.003%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.180 Acc 95.204%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.150 Acc 94.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.217 Acc 93.881%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.226 Acc 93.521%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.228 Acc 93.343%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.230 Acc 93.339%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.230 Acc 93.337%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.181 Acc 93.750%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.252 Acc 93.116%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.244 Acc 93.249%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.223 Acc 93.588%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.227 Acc 93.400%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.223 Acc 93.553%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.229 Acc 93.397%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.228 Acc 93.455%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.173 Acc 93.750%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.198 Acc 94.694%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.189 Acc 94.998%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.242 Acc 92.188%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.229 Acc 93.170%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.226 Acc 93.505%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.225 Acc 93.532%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.226 Acc 93.520%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.228 Acc 93.479%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.234 Acc 94.028%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.229 Acc 94.111%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.168 Acc 94.531%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.213 Acc 93.704%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.213 Acc 93.762%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.217 Acc 93.638%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.217 Acc 93.752%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.218 Acc 93.706%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.211 Acc 92.188%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.211 Acc 94.392%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.205 Acc 94.504%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.222 Acc 93.735%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.219 Acc 93.633%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.218 Acc 93.662%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.225 Acc 93.551%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.222 Acc 93.647%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.255 Acc 92.969%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.201 Acc 94.933%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.192 Acc 95.048%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.210 Acc 94.044%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.214 Acc 93.886%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.214 Acc 93.893%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.215 Acc 93.828%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.219 Acc 93.720%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.283 Acc 92.188%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.223 Acc 94.067%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.215 Acc 94.232%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.280 Acc 92.969%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.196 Acc 94.222%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.207 Acc 94.030%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.213 Acc 93.867%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.217 Acc 93.793%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.217 Acc 93.758%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.182 Acc 92.969%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.199 Acc 94.524%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.191 Acc 94.912%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.204 Acc 94.524%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.211 Acc 94.119%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.212 Acc 94.030%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.214 Acc 93.964%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.213 Acc 93.971%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.182 Acc 92.188%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.192 Acc 94.841%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.186 Acc 94.970%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.194 Acc 94.338%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.213 Acc 93.933%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.213 Acc 93.869%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.214 Acc 93.857%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.214 Acc 93.900%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.236 Acc 92.188%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.217 Acc 94.763%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.209 Acc 94.943%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.196 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.225 Acc 93.696%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.219 Acc 93.812%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.218 Acc 93.856%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.218 Acc 93.867%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.215 Acc 93.914%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.280 Acc 90.625%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.231 Acc 93.425%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.224 Acc 93.680%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.203 Acc 94.160%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.204 Acc 94.146%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.209 Acc 93.994%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.211 Acc 93.994%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.214 Acc 93.842%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.119 Acc 95.312%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.193 Acc 95.173%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.185 Acc 95.320%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.202 Acc 92.188%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.216 Acc 93.634%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.218 Acc 93.723%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.217 Acc 93.797%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.216 Acc 93.814%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.214 Acc 93.839%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.218 Acc 94.531%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.213 Acc 94.558%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.202 Acc 92.969%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.217 Acc 93.974%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.209 Acc 93.968%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.212 Acc 93.994%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.209 Acc 94.009%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.208 Acc 94.048%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.230 Acc 93.750%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.208 Acc 94.779%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.203 Acc 94.827%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.165 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.199 Acc 94.315%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.196 Acc 94.508%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.196 Acc 94.435%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.203 Acc 94.186%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.206 Acc 94.098%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.213 Acc 95.312%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.200 Acc 94.794%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.194 Acc 95.021%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.166 Acc 93.750%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.200 Acc 94.315%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.204 Acc 94.111%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.208 Acc 94.017%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.206 Acc 94.179%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.205 Acc 94.085%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.153 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.197 Acc 94.972%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.188 Acc 95.235%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.199 Acc 94.338%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.203 Acc 94.127%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.203 Acc 94.121%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.205 Acc 94.122%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.207 Acc 94.095%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.218 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.198 Acc 95.119%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.192 Acc 95.169%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.192 Acc 94.732%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.197 Acc 94.446%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.203 Acc 94.326%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.199 Acc 94.401%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.198 Acc 94.375%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.187 Acc 95.057%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.185 Acc 95.114%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.206 Acc 93.765%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.211 Acc 93.781%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.207 Acc 93.901%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.207 Acc 93.976%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.206 Acc 94.024%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.176 Acc 94.531%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.195 Acc 95.127%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.187 Acc 95.188%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.201 Acc 94.044%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.201 Acc 94.069%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.199 Acc 94.207%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.203 Acc 94.159%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.203 Acc 94.162%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.175 Acc 94.531%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.192 Acc 95.034%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.187 Acc 95.138%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.201 Acc 94.694%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.203 Acc 94.426%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.200 Acc 94.461%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.200 Acc 94.403%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.198 Acc 94.371%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.181 Acc 92.969%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.196 Acc 94.640%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.193 Acc 94.768%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.185 Acc 94.531%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.208 Acc 94.183%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.208 Acc 94.135%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.201 Acc 94.334%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.201 Acc 94.270%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.203 Acc 94.196%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.164 Acc 92.188%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.203 Acc 94.717%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.197 Acc 94.904%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.186 Acc 94.655%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.186 Acc 94.621%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.191 Acc 94.573%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.192 Acc 94.525%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.194 Acc 94.452%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.142 Acc 95.312%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.187 Acc 95.490%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.180 Acc 95.565%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.148 Acc 94.531%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.194 Acc 94.330%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.196 Acc 94.271%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.200 Acc 94.103%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.199 Acc 94.159%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.198 Acc 94.169%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.259 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.213 Acc 94.508%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.206 Acc 94.729%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.179 Acc 92.969%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.188 Acc 94.485%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.192 Acc 94.329%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.197 Acc 94.298%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.197 Acc 94.327%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.196 Acc 94.361%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.199 Acc 95.080%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.192 Acc 95.075%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.195 Acc 91.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.190 Acc 94.230%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.192 Acc 94.240%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.196 Acc 94.163%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.195 Acc 94.227%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.195 Acc 94.254%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.148 Acc 95.312%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.202 Acc 94.910%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.196 Acc 95.114%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.377 Acc 90.625%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.192 Acc 94.205%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.194 Acc 94.220%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.192 Acc 94.307%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.194 Acc 94.263%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.190 Acc 95.173%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.184 Acc 95.301%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.153 Acc 95.312%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.181 Acc 94.810%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.186 Acc 94.784%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.187 Acc 94.653%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.187 Acc 94.642%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.188 Acc 94.591%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.193 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.195 Acc 94.972%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.190 Acc 95.029%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.134 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.188 Acc 94.632%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.189 Acc 94.504%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.193 Acc 94.456%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.191 Acc 94.475%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.195 Acc 94.380%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.187 Acc 92.969%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.197 Acc 94.841%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.190 Acc 94.974%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.178 Acc 93.750%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.183 Acc 94.732%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.181 Acc 94.749%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.185 Acc 94.661%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.186 Acc 94.656%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.190 Acc 94.558%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.186 Acc 95.227%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.185 Acc 95.173%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.179 Acc 94.856%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.182 Acc 94.900%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.181 Acc 94.869%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.186 Acc 94.738%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.188 Acc 94.711%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.187 Acc 95.406%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.197 Acc 94.531%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.181 Acc 94.771%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.183 Acc 94.648%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.183 Acc 94.643%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.184 Acc 94.596%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.188 Acc 94.545%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.188 Acc 96.094%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.189 Acc 95.104%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.183 Acc 95.262%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.177 Acc 94.949%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.181 Acc 94.726%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.188 Acc 94.565%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.186 Acc 94.644%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.188 Acc 94.595%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.211 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.177 Acc 95.575%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.173 Acc 95.588%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.178 Acc 94.841%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.186 Acc 94.691%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.186 Acc 94.721%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.189 Acc 94.545%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.125 Acc 96.875%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.193 Acc 95.421%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.189 Acc 95.402%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.221 Acc 92.188%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.178 Acc 94.787%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.186 Acc 94.617%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.189 Acc 94.536%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.193 Acc 94.539%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.190 Acc 94.573%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.173 Acc 95.312%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.188 Acc 95.305%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.184 Acc 95.441%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.165 Acc 92.969%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.190 Acc 94.500%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.178 Acc 94.838%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.179 Acc 94.840%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.183 Acc 94.732%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.183 Acc 94.767%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.168 Acc 95.312%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.179 Acc 95.622%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.175 Acc 95.670%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.188 Acc 94.531%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.187 Acc 94.709%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.181 Acc 94.858%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.183 Acc 94.793%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.185 Acc 94.722%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.187 Acc 94.633%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.122 Acc 94.531%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.183 Acc 95.382%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.178 Acc 95.484%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.342 Acc 92.188%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.172 Acc 94.879%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.178 Acc 94.656%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.185 Acc 94.521%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.188 Acc 94.442%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.185 Acc 94.544%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.150 Acc 94.531%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.182 Acc 95.444%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.179 Acc 95.515%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.234 Acc 94.531%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.166 Acc 95.127%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.180 Acc 94.768%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.182 Acc 94.791%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.182 Acc 94.833%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.181 Acc 94.838%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.201 Acc 94.531%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.186 Acc 95.483%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.184 Acc 95.437%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.283 Acc 94.531%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.182 Acc 94.647%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.182 Acc 94.803%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.180 Acc 94.858%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.182 Acc 94.742%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.184 Acc 94.667%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.116 Acc 96.094%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.178 Acc 95.800%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.173 Acc 95.775%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.151 Acc 94.531%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.173 Acc 95.050%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.174 Acc 94.974%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.175 Acc 94.970%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.181 Acc 94.868%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.180 Acc 94.865%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.211 Acc 94.701%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.208 Acc 94.667%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.178 Acc 96.094%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.172 Acc 95.065%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.176 Acc 95.029%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.179 Acc 94.936%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.180 Acc 94.915%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.181 Acc 94.877%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.121 Acc 95.312%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.177 Acc 95.645%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.176 Acc 95.530%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.183 Acc 93.750%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.166 Acc 94.964%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.172 Acc 94.866%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.178 Acc 94.773%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.180 Acc 94.751%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.182 Acc 94.737%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.190 Acc 92.969%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.202 Acc 95.251%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.188 Acc 95.460%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.180 Acc 96.094%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.171 Acc 94.910%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.178 Acc 94.885%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.178 Acc 94.892%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.176 Acc 94.880%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.177 Acc 94.860%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.114 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.179 Acc 95.449%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.203 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.172 Acc 94.972%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.173 Acc 94.947%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.178 Acc 94.830%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.181 Acc 94.790%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.180 Acc 94.796%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.171 Acc 94.531%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.178 Acc 95.645%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.174 Acc 95.721%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.224 Acc 92.969%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.175 Acc 95.065%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.172 Acc 95.040%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.174 Acc 95.037%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.175 Acc 94.927%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.175 Acc 94.951%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.233 Acc 92.969%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.202 Acc 95.343%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.194 Acc 95.421%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.243 Acc 92.969%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.169 Acc 95.266%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.172 Acc 95.083%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.173 Acc 95.056%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.173 Acc 95.067%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.175 Acc 95.015%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.155 Acc 96.094%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.188 Acc 95.405%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.185 Acc 95.468%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.133 Acc 96.094%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.173 Acc 95.065%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.170 Acc 95.029%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.173 Acc 95.032%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.176 Acc 94.968%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.177 Acc 94.901%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.213 Acc 94.446%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.204 Acc 94.648%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.095 Acc 96.875%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.178 Acc 94.787%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.175 Acc 94.908%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.173 Acc 94.949%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.173 Acc 95.020%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.173 Acc 95.060%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.190 Acc 95.405%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.184 Acc 95.456%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.173 Acc 94.887%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.175 Acc 94.694%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.178 Acc 94.687%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.177 Acc 94.777%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.176 Acc 94.876%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.197 Acc 96.094%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.186 Acc 95.583%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.184 Acc 95.655%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.166 Acc 95.312%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.178 Acc 94.903%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.174 Acc 94.924%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.172 Acc 94.936%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.173 Acc 94.931%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.173 Acc 94.930%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.209 Acc 96.094%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.189 Acc 95.382%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.186 Acc 95.484%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.171 Acc 95.065%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.166 Acc 95.204%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.172 Acc 95.087%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.172 Acc 95.024%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.171 Acc 95.030%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.110 Acc 95.312%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.176 Acc 95.838%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.173 Acc 95.903%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.191 Acc 96.094%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.181 Acc 94.825%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.173 Acc 94.963%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.174 Acc 94.970%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.172 Acc 94.995%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.171 Acc 95.019%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.207 Acc 94.531%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.203 Acc 94.995%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.197 Acc 95.130%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.095 Acc 94.531%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.169 Acc 94.670%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.166 Acc 94.963%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.166 Acc 95.061%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.168 Acc 95.049%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.171 Acc 95.005%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.224 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.211 Acc 94.980%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.203 Acc 95.095%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.139 Acc 94.531%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.175 Acc 94.794%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.176 Acc 94.846%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.177 Acc 94.879%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.177 Acc 94.866%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.177 Acc 94.863%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.175 Acc 92.188%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.184 Acc 95.529%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.181 Acc 95.550%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.123 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.162 Acc 95.359%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.166 Acc 95.184%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.172 Acc 95.048%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.173 Acc 94.975%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.175 Acc 94.913%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.144 Acc 96.094%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.174 Acc 95.676%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.173 Acc 95.662%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.108 Acc 96.875%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.160 Acc 95.413%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.166 Acc 95.239%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.169 Acc 95.178%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.172 Acc 95.133%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.172 Acc 95.052%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.250 Acc 91.406%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.204 Acc 94.941%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.200 Acc 94.974%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.164 Acc 95.135%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.166 Acc 95.270%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.168 Acc 95.188%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.169 Acc 95.139%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.168 Acc 95.167%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.190 Acc 95.220%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.187 Acc 95.270%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.211 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.149 Acc 95.568%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.163 Acc 95.320%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.165 Acc 95.224%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.166 Acc 95.190%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.168 Acc 95.111%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.092 Acc 97.656%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.173 Acc 95.506%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.169 Acc 95.709%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.159 Acc 92.188%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.167 Acc 94.903%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.167 Acc 95.021%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.164 Acc 95.100%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.165 Acc 95.092%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.167 Acc 95.079%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.110 Acc 96.094%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.177 Acc 95.885%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.169 Acc 95.849%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.127 Acc 95.312%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.157 Acc 95.429%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.166 Acc 95.118%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.169 Acc 95.001%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.170 Acc 94.964%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.170 Acc 94.971%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.191 Acc 95.630%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.186 Acc 95.728%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.172 Acc 95.312%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.165 Acc 95.212%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.165 Acc 95.122%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.166 Acc 95.110%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.168 Acc 95.118%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.168 Acc 95.033%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.117 Acc 96.875%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.205 Acc 94.872%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.199 Acc 94.939%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.166 Acc 95.150%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.166 Acc 95.122%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.167 Acc 95.185%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.169 Acc 95.125%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.168 Acc 95.124%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.188 Acc 95.498%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.185 Acc 95.414%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.259 Acc 92.188%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.155 Acc 95.367%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.160 Acc 95.208%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.164 Acc 95.203%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.164 Acc 95.170%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.166 Acc 95.105%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.173 Acc 94.531%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.192 Acc 95.429%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.190 Acc 95.394%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.090 Acc 98.438%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.166 Acc 95.266%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.167 Acc 95.122%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.161 Acc 95.287%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.165 Acc 95.211%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.167 Acc 95.079%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.209 Acc 93.750%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.204 Acc 95.158%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.199 Acc 95.274%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.157 Acc 95.490%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.161 Acc 95.433%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.160 Acc 95.429%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.164 Acc 95.262%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.165 Acc 95.255%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.185 Acc 95.568%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.184 Acc 95.565%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.158 Acc 95.398%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.160 Acc 95.309%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.164 Acc 95.271%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.163 Acc 95.274%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.164 Acc 95.255%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.167 Acc 96.094%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.211 Acc 94.895%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.208 Acc 95.149%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.250 Acc 91.406%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.172 Acc 94.848%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.165 Acc 95.075%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.163 Acc 95.227%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.163 Acc 95.229%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.164 Acc 95.219%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.190 Acc 95.421%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.186 Acc 95.480%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.094 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.159 Acc 95.421%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.157 Acc 95.476%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.163 Acc 95.162%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.164 Acc 95.149%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.164 Acc 95.155%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.163 Acc 95.312%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.202 Acc 95.282%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.198 Acc 95.309%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.160 Acc 95.382%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.160 Acc 95.464%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.159 Acc 95.424%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.162 Acc 95.357%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.163 Acc 95.292%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.225 Acc 95.312%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.206 Acc 95.034%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.200 Acc 95.169%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.067 Acc 97.656%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.149 Acc 95.545%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.159 Acc 95.219%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.162 Acc 95.188%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.160 Acc 95.274%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.162 Acc 95.241%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.188 Acc 95.606%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.182 Acc 95.725%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.129 Acc 95.312%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.168 Acc 95.073%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.164 Acc 95.122%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.161 Acc 95.248%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.163 Acc 95.237%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.161 Acc 95.292%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.105 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.182 Acc 95.552%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.174 Acc 95.635%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.160 Acc 95.328%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.161 Acc 95.367%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.161 Acc 95.341%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.160 Acc 95.340%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.160 Acc 95.350%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.177 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.187 Acc 95.367%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.185 Acc 95.355%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.161 Acc 95.343%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.159 Acc 95.379%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.158 Acc 95.375%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.157 Acc 95.455%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.160 Acc 95.364%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.185 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.213 Acc 95.413%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.208 Acc 95.309%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.213 Acc 95.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.164 Acc 95.127%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.159 Acc 95.347%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.160 Acc 95.367%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.158 Acc 95.394%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.160 Acc 95.337%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.186 Acc 95.312%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.214 Acc 94.732%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.212 Acc 94.799%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.221 Acc 95.312%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.152 Acc 95.220%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.159 Acc 95.188%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.159 Acc 95.263%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.156 Acc 95.355%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.157 Acc 95.376%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.172 Acc 96.094%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.199 Acc 95.467%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.188 Acc 95.557%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.139 Acc 95.312%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.148 Acc 95.614%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.153 Acc 95.445%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.158 Acc 95.310%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.160 Acc 95.248%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.163 Acc 95.247%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.202 Acc 91.406%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.182 Acc 95.343%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.176 Acc 95.441%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.104 Acc 95.312%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.152 Acc 95.413%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.155 Acc 95.398%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.157 Acc 95.333%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.159 Acc 95.340%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.159 Acc 95.341%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.183 Acc 96.094%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.191 Acc 95.614%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.187 Acc 95.686%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.102 Acc 96.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.165 Acc 95.073%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.158 Acc 95.293%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.158 Acc 95.232%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.159 Acc 95.311%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.161 Acc 95.252%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.157 Acc 94.531%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.191 Acc 95.405%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.187 Acc 95.515%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.113 Acc 96.094%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.145 Acc 95.637%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.155 Acc 95.600%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.154 Acc 95.614%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.154 Acc 95.527%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.158 Acc 95.414%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.154 Acc 96.094%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.189 Acc 95.475%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.185 Acc 95.491%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.143 Acc 95.924%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.143 Acc 95.903%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.149 Acc 95.767%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.153 Acc 95.622%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.155 Acc 95.548%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.196 Acc 95.312%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.203 Acc 95.483%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.197 Acc 95.515%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.183 Acc 92.969%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.149 Acc 95.483%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.154 Acc 95.437%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.155 Acc 95.468%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.159 Acc 95.404%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.158 Acc 95.414%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.248 Acc 93.750%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.231 Acc 94.183%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.224 Acc 94.282%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.113 Acc 96.875%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.160 Acc 95.173%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.152 Acc 95.472%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.154 Acc 95.460%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.154 Acc 95.496%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.155 Acc 95.448%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.176 Acc 95.676%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.171 Acc 95.763%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.188 Acc 91.406%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.157 Acc 95.227%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.153 Acc 95.437%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.154 Acc 95.411%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.157 Acc 95.340%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.158 Acc 95.309%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.170 Acc 96.875%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.196 Acc 95.158%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.193 Acc 95.188%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.156 Acc 95.429%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.150 Acc 95.421%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.151 Acc 95.450%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.154 Acc 95.390%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.157 Acc 95.317%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.154 Acc 93.750%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.177 Acc 95.738%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.174 Acc 95.763%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.144 Acc 95.846%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.150 Acc 95.701%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.152 Acc 95.632%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.152 Acc 95.566%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.155 Acc 95.481%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.157 Acc 95.312%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.228 Acc 94.957%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.226 Acc 94.862%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.113 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.160 Acc 95.104%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.157 Acc 95.157%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.156 Acc 95.328%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.159 Acc 95.309%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.161 Acc 95.298%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.155 Acc 95.312%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.188 Acc 95.591%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.185 Acc 95.487%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.160 Acc 96.875%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.144 Acc 95.614%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.151 Acc 95.538%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.153 Acc 95.536%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.154 Acc 95.501%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.157 Acc 95.394%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.164 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.192 Acc 95.336%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.191 Acc 95.344%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.128 Acc 97.656%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.142 Acc 95.908%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.150 Acc 95.569%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.150 Acc 95.629%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.150 Acc 95.620%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.152 Acc 95.542%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.156 Acc 96.875%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.211 Acc 95.057%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.207 Acc 95.239%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.162 Acc 95.235%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.150 Acc 95.592%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.150 Acc 95.588%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.152 Acc 95.544%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.154 Acc 95.504%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.140 Acc 95.312%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.191 Acc 95.413%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.186 Acc 95.484%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.139 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.144 Acc 95.606%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.150 Acc 95.429%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.151 Acc 95.424%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.154 Acc 95.369%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.154 Acc 95.381%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.195 Acc 95.003%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.188 Acc 95.188%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.154 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.152 Acc 95.475%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.157 Acc 95.476%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.154 Acc 95.489%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.153 Acc 95.527%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.153 Acc 95.529%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.112 Acc 95.312%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.184 Acc 95.568%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.179 Acc 95.647%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.307 Acc 91.406%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.148 Acc 95.552%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.151 Acc 95.484%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.152 Acc 95.486%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.152 Acc 95.455%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.154 Acc 95.392%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.184 Acc 96.094%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.193 Acc 95.761%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.186 Acc 95.767%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.158 Acc 96.875%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.146 Acc 95.869%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.151 Acc 95.732%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.151 Acc 95.621%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.151 Acc 95.564%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.152 Acc 95.518%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.152 Acc 94.531%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.192 Acc 95.436%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.184 Acc 95.581%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.136 Acc 97.656%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.156 Acc 95.467%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.157 Acc 95.441%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.156 Acc 95.481%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.158 Acc 95.379%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.157 Acc 95.383%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.166 Acc 92.969%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.181 Acc 95.258%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.182 Acc 95.359%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.144 Acc 93.750%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.150 Acc 95.436%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.147 Acc 95.612%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.147 Acc 95.645%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.148 Acc 95.692%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.150 Acc 95.578%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.196 Acc 92.969%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.191 Acc 95.150%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.186 Acc 95.359%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.032 Acc 99.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.142 Acc 95.637%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.145 Acc 95.662%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.149 Acc 95.549%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.154 Acc 95.449%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.154 Acc 95.429%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.139 Acc 95.312%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.178 Acc 95.862%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.177 Acc 95.814%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.129 Acc 96.101%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.137 Acc 96.012%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.145 Acc 95.704%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.150 Acc 95.599%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.147 Acc 95.621%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.179 Acc 96.094%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.196 Acc 95.351%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.194 Acc 95.386%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.069 Acc 97.656%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.150 Acc 95.537%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.152 Acc 95.491%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.152 Acc 95.453%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.154 Acc 95.427%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.153 Acc 95.473%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.202 Acc 95.312%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.193 Acc 95.459%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.188 Acc 95.476%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.184 Acc 94.531%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.156 Acc 95.475%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.154 Acc 95.519%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.150 Acc 95.569%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.151 Acc 95.519%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.152 Acc 95.518%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.307 Acc 93.750%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.216 Acc 95.220%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.207 Acc 95.309%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.118 Acc 96.094%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.147 Acc 95.560%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.151 Acc 95.592%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.148 Acc 95.559%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.147 Acc 95.620%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.150 Acc 95.576%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.128 Acc 96.875%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.188 Acc 95.692%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.180 Acc 95.748%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.204 Acc 96.094%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.136 Acc 95.924%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.143 Acc 95.658%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.143 Acc 95.671%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.147 Acc 95.576%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.148 Acc 95.557%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.197 Acc 92.969%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.215 Acc 95.142%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.211 Acc 95.169%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.157 Acc 96.094%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.135 Acc 96.086%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.137 Acc 95.965%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.142 Acc 95.894%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.144 Acc 95.825%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.147 Acc 95.737%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.213 Acc 95.034%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.207 Acc 95.118%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.203 Acc 95.312%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.128 Acc 96.086%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.139 Acc 95.736%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.144 Acc 95.723%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.145 Acc 95.661%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.147 Acc 95.595%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.162 Acc 95.312%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.199 Acc 95.243%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.194 Acc 95.390%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.144 Acc 95.815%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.144 Acc 95.709%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.147 Acc 95.632%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.147 Acc 95.649%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.201 Acc 95.166%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.199 Acc 95.285%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.084 Acc 98.438%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.146 Acc 95.529%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.146 Acc 95.612%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.144 Acc 95.665%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.145 Acc 95.630%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.148 Acc 95.574%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.202 Acc 95.537%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.196 Acc 95.635%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.209 Acc 94.531%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.141 Acc 95.599%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.144 Acc 95.655%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.150 Acc 95.494%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.151 Acc 95.406%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.153 Acc 95.381%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.209 Acc 95.312%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.210 Acc 94.864%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.204 Acc 95.013%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.147 Acc 95.777%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.144 Acc 95.767%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.146 Acc 95.637%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.146 Acc 95.646%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.146 Acc 95.693%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.242 Acc 93.750%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.206 Acc 95.483%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.202 Acc 95.484%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.142 Acc 95.568%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.141 Acc 95.577%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.142 Acc 95.678%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.145 Acc 95.620%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.148 Acc 95.546%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.149 Acc 95.312%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.203 Acc 95.073%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.192 Acc 95.246%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.155 Acc 95.444%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.149 Acc 95.631%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.149 Acc 95.569%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.148 Acc 95.577%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.148 Acc 95.571%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.188 Acc 96.875%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.193 Acc 95.552%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.189 Acc 95.542%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.169 Acc 94.531%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.142 Acc 95.769%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.147 Acc 95.581%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.147 Acc 95.541%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.146 Acc 95.548%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.147 Acc 95.531%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.138 Acc 95.312%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.205 Acc 95.452%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.203 Acc 95.534%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.182 Acc 96.875%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.142 Acc 95.869%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.145 Acc 95.806%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.144 Acc 95.839%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.144 Acc 95.784%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.144 Acc 95.751%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.176 Acc 96.875%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.182 Acc 95.630%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.178 Acc 95.616%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.141 Acc 96.094%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.141 Acc 95.715%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.145 Acc 95.635%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.145 Acc 95.614%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.146 Acc 95.603%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.147 Acc 95.574%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.181 Acc 95.312%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.199 Acc 95.390%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.197 Acc 95.351%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.075 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.156 Acc 95.498%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.152 Acc 95.515%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.150 Acc 95.588%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.148 Acc 95.630%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.147 Acc 95.624%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.172 Acc 95.312%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.185 Acc 95.692%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.185 Acc 95.794%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.113 Acc 95.312%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.137 Acc 95.614%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.140 Acc 95.705%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.142 Acc 95.647%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.145 Acc 95.562%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.146 Acc 95.554%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.209 Acc 92.969%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.221 Acc 94.833%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.217 Acc 94.967%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.222 Acc 91.406%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.150 Acc 95.459%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.143 Acc 95.709%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.142 Acc 95.746%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.144 Acc 95.696%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.145 Acc 95.670%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.180 Acc 96.094%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.212 Acc 95.645%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.204 Acc 95.709%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.135 Acc 95.831%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.137 Acc 95.802%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.143 Acc 95.697%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.145 Acc 95.663%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.146 Acc 95.635%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.194 Acc 95.614%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.189 Acc 95.658%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.132 Acc 96.109%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.141 Acc 95.849%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.141 Acc 95.967%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.143 Acc 95.885%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.145 Acc 95.766%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.158 Acc 94.531%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.201 Acc 95.119%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.197 Acc 95.095%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.335 Acc 92.969%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.143 Acc 95.738%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.147 Acc 95.647%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.147 Acc 95.694%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.145 Acc 95.716%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.146 Acc 95.690%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.197 Acc 95.606%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.191 Acc 95.573%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.172 Acc 94.531%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.136 Acc 95.908%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.139 Acc 95.864%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.144 Acc 95.723%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.145 Acc 95.700%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.148 Acc 95.645%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.206 Acc 95.312%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.202 Acc 95.111%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.195 Acc 95.145%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.201 Acc 94.531%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.145 Acc 95.583%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.143 Acc 95.616%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.146 Acc 95.551%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.147 Acc 95.566%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.149 Acc 95.550%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.156 Acc 96.094%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.217 Acc 95.181%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.208 Acc 95.250%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.142 Acc 94.531%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.140 Acc 95.823%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.136 Acc 95.934%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.145 Acc 95.720%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.146 Acc 95.727%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.146 Acc 95.696%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.192 Acc 95.312%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.207 Acc 95.382%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.205 Acc 95.429%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.152 Acc 96.875%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.130 Acc 96.210%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.136 Acc 96.032%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.138 Acc 95.941%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.138 Acc 95.942%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.140 Acc 95.893%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.201 Acc 92.969%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.203 Acc 95.243%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.199 Acc 95.239%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.174 Acc 96.094%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.129 Acc 95.962%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.135 Acc 95.969%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.135 Acc 96.042%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.141 Acc 95.839%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.141 Acc 95.849%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.150 Acc 93.750%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.192 Acc 95.599%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.185 Acc 95.728%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.147 Acc 95.537%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.138 Acc 95.845%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.139 Acc 95.800%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.141 Acc 95.766%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.143 Acc 95.727%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.180 Acc 94.531%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.212 Acc 94.794%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.203 Acc 94.967%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.166 Acc 94.531%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.149 Acc 95.676%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.147 Acc 95.744%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.145 Acc 95.764%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.144 Acc 95.726%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.144 Acc 95.735%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.203 Acc 95.715%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.195 Acc 95.759%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.108 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.131 Acc 96.264%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.137 Acc 96.047%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.140 Acc 95.933%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.142 Acc 95.800%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.140 Acc 95.819%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.160 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.193 Acc 95.498%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.187 Acc 95.569%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.124 Acc 96.171%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.126 Acc 96.168%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.129 Acc 96.148%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.134 Acc 96.082%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.134 Acc 96.047%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.207 Acc 95.490%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.200 Acc 95.627%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.156 Acc 96.094%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.140 Acc 95.761%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.139 Acc 95.814%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.142 Acc 95.694%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.141 Acc 95.710%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.146 Acc 95.601%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.277 Acc 92.969%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.223 Acc 95.220%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.216 Acc 95.390%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.177 Acc 94.531%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.139 Acc 95.815%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.140 Acc 95.791%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.144 Acc 95.738%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.144 Acc 95.724%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.144 Acc 95.705%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.276 Acc 92.188%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.210 Acc 95.490%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.205 Acc 95.573%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.137 Acc 96.094%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.141 Acc 95.919%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.143 Acc 95.816%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.143 Acc 95.757%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.143 Acc 95.715%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.257 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.223 Acc 95.173%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.218 Acc 95.208%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.084 Acc 97.656%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.134 Acc 95.970%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.137 Acc 95.903%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.139 Acc 95.852%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.142 Acc 95.745%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.141 Acc 95.782%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.246 Acc 92.188%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.214 Acc 95.320%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.204 Acc 95.371%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.274 Acc 92.969%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.132 Acc 96.047%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.136 Acc 96.000%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.135 Acc 96.050%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.138 Acc 95.965%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.140 Acc 95.913%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.203 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.218 Acc 95.498%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.213 Acc 95.476%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.179 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.139 Acc 95.831%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.142 Acc 95.826%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.137 Acc 95.915%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.140 Acc 95.868%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.141 Acc 95.838%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.260 Acc 91.406%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.198 Acc 95.189%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.194 Acc 95.312%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.143 Acc 94.531%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.138 Acc 95.939%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.139 Acc 95.896%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.141 Acc 95.720%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.140 Acc 95.729%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.140 Acc 95.746%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.142 Acc 94.531%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.194 Acc 95.382%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.191 Acc 95.390%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.145 Acc 96.094%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.138 Acc 95.800%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.136 Acc 95.958%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.139 Acc 95.909%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.140 Acc 95.825%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.140 Acc 95.807%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.184 Acc 94.531%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.193 Acc 95.475%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.191 Acc 95.484%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.130 Acc 96.179%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.134 Acc 96.024%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.138 Acc 95.920%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.140 Acc 95.846%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.140 Acc 95.846%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.114 Acc 96.094%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.188 Acc 95.792%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.181 Acc 95.841%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.203 Acc 95.312%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.122 Acc 96.558%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.131 Acc 96.156%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.132 Acc 96.107%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.134 Acc 96.049%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.135 Acc 96.020%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.111 Acc 96.094%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.185 Acc 95.707%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.186 Acc 95.693%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.107 Acc 97.656%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.140 Acc 95.893%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.138 Acc 95.892%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.136 Acc 95.917%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.138 Acc 95.876%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.138 Acc 95.907%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.198 Acc 96.094%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.187 Acc 95.846%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.184 Acc 95.818%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.124 Acc 96.094%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.131 Acc 95.970%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.137 Acc 95.903%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.140 Acc 95.764%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.138 Acc 95.848%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.141 Acc 95.771%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.239 Acc 92.188%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.190 Acc 95.707%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.185 Acc 95.814%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.119 Acc 96.094%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.128 Acc 96.032%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.131 Acc 95.985%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.133 Acc 95.993%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.137 Acc 95.881%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.136 Acc 95.847%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.188 Acc 93.750%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.214 Acc 95.367%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.208 Acc 95.324%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.108 Acc 93.750%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.134 Acc 96.086%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.135 Acc 96.063%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.134 Acc 95.990%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.135 Acc 95.998%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.136 Acc 95.899%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.226 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.199 Acc 95.506%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.194 Acc 95.530%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.173 Acc 92.969%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.132 Acc 96.194%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.137 Acc 95.973%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.137 Acc 95.951%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.137 Acc 95.952%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.138 Acc 95.952%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.133 Acc 94.531%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.192 Acc 95.498%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.188 Acc 95.670%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.127 Acc 96.202%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.139 Acc 95.829%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.137 Acc 95.865%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.135 Acc 95.963%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.135 Acc 95.980%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.201 Acc 95.312%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.211 Acc 95.305%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.205 Acc 95.414%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.099 Acc 97.656%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.149 Acc 95.483%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.141 Acc 95.616%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.137 Acc 95.728%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.138 Acc 95.747%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.140 Acc 95.734%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.217 Acc 93.750%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.215 Acc 95.297%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.204 Acc 95.456%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.134 Acc 94.531%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.130 Acc 96.105%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.132 Acc 96.013%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.135 Acc 95.909%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.138 Acc 95.829%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.224 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.201 Acc 95.452%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.193 Acc 95.503%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.123 Acc 96.303%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.131 Acc 96.016%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.134 Acc 95.934%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.134 Acc 95.963%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.220 Acc 94.887%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.208 Acc 95.072%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.140 Acc 94.531%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.136 Acc 95.846%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.142 Acc 95.752%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.139 Acc 95.852%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.137 Acc 95.920%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.137 Acc 95.904%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.219 Acc 95.026%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.215 Acc 95.106%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.100 Acc 97.656%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.131 Acc 96.040%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.136 Acc 95.931%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.135 Acc 95.922%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.136 Acc 95.848%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.139 Acc 95.841%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.131 Acc 95.312%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.205 Acc 95.506%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.198 Acc 95.612%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.088 Acc 96.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.131 Acc 96.086%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.135 Acc 95.938%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.135 Acc 95.974%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.137 Acc 95.965%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.135 Acc 95.974%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.173 Acc 96.094%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.198 Acc 95.831%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.193 Acc 95.864%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.124 Acc 96.326%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.130 Acc 96.191%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.134 Acc 96.034%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.133 Acc 96.022%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.132 Acc 96.003%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.286 Acc 93.750%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.214 Acc 95.398%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.210 Acc 95.421%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.130 Acc 95.838%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.132 Acc 95.896%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.136 Acc 95.808%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.139 Acc 95.790%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.138 Acc 95.818%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.235 Acc 95.312%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.217 Acc 95.699%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.211 Acc 95.728%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.136 Acc 96.094%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.126 Acc 96.264%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.130 Acc 96.098%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.135 Acc 95.967%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.135 Acc 95.957%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.135 Acc 95.986%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.165 Acc 95.312%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.198 Acc 95.699%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.195 Acc 95.861%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.116 Acc 95.312%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.128 Acc 96.094%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.135 Acc 95.959%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.133 Acc 95.990%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.134 Acc 95.941%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.216 Acc 92.969%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.257 Acc 94.640%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.245 Acc 94.834%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.259 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.131 Acc 95.955%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.133 Acc 95.958%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.132 Acc 96.016%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.134 Acc 95.940%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.135 Acc 95.904%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.200 Acc 95.490%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.195 Acc 95.542%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.202 Acc 91.406%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.130 Acc 95.800%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.129 Acc 96.067%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.132 Acc 96.031%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.134 Acc 95.979%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.134 Acc 95.975%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.290 Acc 90.625%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.246 Acc 94.601%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.240 Acc 94.698%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.049 Acc 98.438%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.129 Acc 96.016%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.133 Acc 95.958%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.133 Acc 95.972%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.135 Acc 95.961%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.135 Acc 95.955%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.169 Acc 94.531%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.210 Acc 95.792%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.208 Acc 95.713%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.128 Acc 96.117%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.135 Acc 95.861%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.133 Acc 95.956%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.136 Acc 95.961%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.136 Acc 95.971%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.165 Acc 96.094%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.188 Acc 95.784%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.183 Acc 95.740%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.132 Acc 95.993%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.133 Acc 96.031%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.135 Acc 95.973%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.135 Acc 95.952%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.163 Acc 96.875%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.205 Acc 95.614%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.198 Acc 95.643%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.150 Acc 96.875%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.129 Acc 96.094%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.139 Acc 95.779%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.141 Acc 95.751%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.137 Acc 95.840%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.137 Acc 95.838%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.153 Acc 94.531%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.203 Acc 95.459%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.195 Acc 95.616%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.131 Acc 96.875%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.123 Acc 96.334%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.127 Acc 96.273%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.126 Acc 96.320%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.127 Acc 96.267%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.127 Acc 96.259%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.153 Acc 96.875%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.214 Acc 95.282%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.210 Acc 95.293%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.181 Acc 93.750%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.131 Acc 95.931%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.130 Acc 96.024%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.132 Acc 96.018%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.134 Acc 96.006%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.136 Acc 95.946%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.188 Acc 92.969%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.213 Acc 95.552%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.209 Acc 95.616%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.053 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.126 Acc 96.303%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.128 Acc 96.102%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.128 Acc 96.195%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.130 Acc 96.137%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.129 Acc 96.091%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.170 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.223 Acc 95.297%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.212 Acc 95.445%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.168 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.126 Acc 96.156%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.129 Acc 96.067%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.130 Acc 96.063%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.132 Acc 96.024%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.131 Acc 96.070%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.193 Acc 96.094%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.218 Acc 95.351%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.215 Acc 95.414%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.168 Acc 92.188%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.140 Acc 95.761%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.131 Acc 96.024%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.130 Acc 96.050%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.129 Acc 96.068%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.132 Acc 95.991%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.112 Acc 94.531%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.201 Acc 95.575%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.193 Acc 95.651%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.067 Acc 95.312%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.121 Acc 96.419%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.125 Acc 96.276%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.129 Acc 96.115%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.130 Acc 95.990%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.132 Acc 95.977%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.223 Acc 94.531%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.224 Acc 95.351%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.218 Acc 95.414%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad4f8d2f1d7456492633adccc45219f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.305 Acc 13.281%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.249 Acc 18.758%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.246 Acc 18.598%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.242 Acc 18.805%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.241 Acc 18.805%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.240 Acc 18.854%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.228 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.228 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.253 Acc 22.656%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.239 Acc 18.897%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.235 Acc 19.022%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.236 Acc 18.890%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 2.236 Acc 18.940%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 2.220 Acc 17.969%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 2.240 Acc 18.580%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 2.238 Acc 18.738%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 2.235 Acc 18.934%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 2.236 Acc 18.896%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 2.236 Acc 18.903%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 2.218 Acc 21.875%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 2.236 Acc 18.906%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 2.237 Acc 18.916%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 2.236 Acc 18.973%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 2.247 Acc 20.312%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 2.239 Acc 18.502%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 2.238 Acc 18.839%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 2.238 Acc 18.882%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 2.237 Acc 19.015%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 2.180 Acc 21.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 2.240 Acc 18.912%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 2.238 Acc 19.111%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 2.237 Acc 19.064%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 2.238 Acc 18.935%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 2.217 Acc 18.750%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 2.246 Acc 18.325%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 2.240 Acc 18.734%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 2.237 Acc 19.030%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 2.236 Acc 19.132%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 2.237 Acc 18.979%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 2.219 Acc 20.312%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 2.238 Acc 19.098%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 2.239 Acc 18.793%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 2.239 Acc 18.802%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 2.239 Acc 18.840%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 2.238 Acc 18.890%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 2.235 Acc 18.959%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 2.238 Acc 18.903%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 2.239 Acc 18.764%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 2.238 Acc 18.831%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 2.266 Acc 19.531%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 2.241 Acc 18.765%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 2.238 Acc 18.731%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 2.239 Acc 18.768%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 2.237 Acc 18.957%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 2.273 Acc 11.719%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 2.234 Acc 19.168%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 2.236 Acc 19.014%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 2.236 Acc 19.051%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 2.297 Acc 14.844%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 2.237 Acc 19.199%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 2.235 Acc 19.143%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 2.238 Acc 18.900%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 2.233 Acc 20.312%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 2.236 Acc 19.214%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 2.237 Acc 19.123%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 2.237 Acc 18.991%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 2.237 Acc 18.929%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 2.256 Acc 18.750%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 2.235 Acc 18.870%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 2.235 Acc 18.888%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 2.236 Acc 18.937%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 2.246 Acc 18.750%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 2.233 Acc 19.361%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 2.234 Acc 19.080%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 2.236 Acc 18.940%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 2.256 Acc 17.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 2.240 Acc 18.704%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 2.236 Acc 19.103%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 2.236 Acc 19.058%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 2.236 Acc 19.085%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 2.234 Acc 19.407%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 2.235 Acc 19.127%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 2.234 Acc 19.150%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 2.236 Acc 18.958%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 2.246 Acc 17.188%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 2.234 Acc 19.052%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 2.234 Acc 19.069%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 2.235 Acc 19.048%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 2.267 Acc 14.062%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 2.241 Acc 18.533%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 2.240 Acc 18.738%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 2.238 Acc 18.863%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 2.211 Acc 23.438%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 2.233 Acc 19.021%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 2.238 Acc 18.746%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 2.238 Acc 18.867%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 2.237 Acc 14.844%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 2.236 Acc 19.038%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 2.236 Acc 19.019%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 2.234 Acc 16.406%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 2.238 Acc 18.456%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 2.238 Acc 18.618%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 2.238 Acc 18.628%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 2.238 Acc 18.754%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 2.238 Acc 18.862%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 2.246 Acc 15.625%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 2.238 Acc 18.750%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 2.239 Acc 18.715%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 2.239 Acc 18.859%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 2.194 Acc 21.875%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 2.238 Acc 18.619%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 2.236 Acc 19.018%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 2.236 Acc 18.991%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 2.238 Acc 18.875%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 2.278 Acc 14.062%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 2.240 Acc 18.889%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 2.238 Acc 19.045%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 2.238 Acc 18.949%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 2.238 Acc 18.959%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 2.244 Acc 17.969%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 2.240 Acc 18.572%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 2.238 Acc 18.937%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 2.195 Acc 20.312%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 2.236 Acc 19.330%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 2.236 Acc 19.174%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 2.275 Acc 15.625%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 2.234 Acc 18.881%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 2.237 Acc 18.878%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 2.237 Acc 18.773%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 2.238 Acc 18.781%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 2.258 Acc 14.844%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 2.240 Acc 18.937%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 2.238 Acc 18.960%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 2.237 Acc 18.883%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 2.294 Acc 14.062%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 2.241 Acc 18.858%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 2.239 Acc 18.902%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 2.239 Acc 18.810%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 2.239 Acc 18.816%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 2.210 Acc 21.094%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 2.237 Acc 18.805%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 2.237 Acc 18.838%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 2.237 Acc 18.865%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 2.276 Acc 13.281%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 2.240 Acc 18.982%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 2.237 Acc 18.913%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 2.239 Acc 18.740%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 2.237 Acc 18.995%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 2.236 Acc 17.188%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 2.236 Acc 19.137%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 2.236 Acc 18.855%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 2.237 Acc 18.854%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 2.237 Acc 18.855%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 2.238 Acc 18.879%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 2.184 Acc 23.438%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 2.233 Acc 19.245%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 2.236 Acc 19.022%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 2.236 Acc 18.908%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 2.242 Acc 17.188%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 2.235 Acc 18.881%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 2.234 Acc 19.007%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 2.235 Acc 18.999%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 2.236 Acc 19.032%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 2.212 Acc 19.531%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 2.230 Acc 19.423%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 2.234 Acc 19.216%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 2.236 Acc 19.001%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 2.238 Acc 18.879%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 2.264 Acc 17.969%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 2.237 Acc 18.878%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 2.230 Acc 21.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 2.237 Acc 19.076%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 2.238 Acc 18.878%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 2.239 Acc 17.188%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 2.235 Acc 19.346%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 2.239 Acc 18.785%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 2.237 Acc 19.048%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 2.235 Acc 19.157%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 2.236 Acc 19.057%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 2.257 Acc 17.188%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 2.244 Acc 18.255%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 2.241 Acc 18.567%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 2.240 Acc 18.644%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 2.238 Acc 18.918%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 2.238 Acc 18.943%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 2.260 Acc 14.844%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 2.236 Acc 19.129%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 2.237 Acc 19.135%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 2.237 Acc 19.103%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 2.213 Acc 24.219%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 2.232 Acc 19.369%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 2.236 Acc 19.116%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 2.238 Acc 18.941%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 2.225 Acc 23.438%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 2.232 Acc 19.570%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 2.235 Acc 19.263%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 2.238 Acc 19.007%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 2.237 Acc 19.068%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 2.241 Acc 18.970%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 2.187 Acc 18.750%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 2.238 Acc 19.160%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 2.239 Acc 19.003%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 2.238 Acc 18.825%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 2.227 Acc 22.656%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 2.239 Acc 18.758%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 2.237 Acc 18.898%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 2.256 Acc 16.406%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 2.243 Acc 18.611%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 2.241 Acc 18.785%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 2.239 Acc 18.984%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 2.237 Acc 19.056%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 2.251 Acc 15.625%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 2.238 Acc 18.742%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 2.235 Acc 19.088%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 2.238 Acc 18.799%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 2.238 Acc 18.889%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 2.265 Acc 17.188%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 2.236 Acc 18.898%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 2.238 Acc 18.784%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 2.238 Acc 18.873%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 2.234 Acc 17.188%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 2.237 Acc 19.013%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 2.235 Acc 19.185%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 2.237 Acc 18.999%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 2.236 Acc 19.046%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 2.214 Acc 17.188%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 2.236 Acc 18.996%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 2.238 Acc 14.844%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 2.235 Acc 19.067%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 2.233 Acc 19.170%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 2.235 Acc 19.087%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 2.236 Acc 19.021%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 2.206 Acc 19.531%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 2.237 Acc 18.595%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 2.237 Acc 18.676%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 2.237 Acc 18.810%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 2.237 Acc 18.865%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 2.237 Acc 18.870%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 2.274 Acc 14.844%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 2.237 Acc 18.796%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 2.237 Acc 19.014%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 2.236 Acc 19.186%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 2.235 Acc 19.157%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 2.202 Acc 23.438%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 2.235 Acc 19.191%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 2.236 Acc 19.045%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 2.237 Acc 19.080%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 2.236 Acc 19.132%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 2.257 Acc 10.938%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 2.237 Acc 19.129%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 2.235 Acc 19.115%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 2.234 Acc 19.212%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 2.236 Acc 19.075%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 2.253 Acc 15.625%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 2.241 Acc 18.727%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 2.236 Acc 19.030%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 2.237 Acc 19.043%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 2.236 Acc 19.058%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 2.306 Acc 14.844%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 2.240 Acc 18.765%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 2.240 Acc 18.657%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 2.239 Acc 18.667%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 2.238 Acc 18.690%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 2.237 Acc 18.872%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 2.214 Acc 20.312%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 2.241 Acc 18.394%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 2.239 Acc 18.715%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 2.240 Acc 18.755%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 2.238 Acc 18.842%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 2.238 Acc 18.945%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 2.227 Acc 17.188%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 2.240 Acc 18.502%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 2.237 Acc 19.162%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 2.238 Acc 18.901%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 2.237 Acc 19.017%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 2.227 Acc 16.406%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 2.237 Acc 19.299%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 2.238 Acc 18.766%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 2.238 Acc 18.857%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 2.238 Acc 18.942%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 2.191 Acc 25.000%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 2.232 Acc 19.508%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 2.236 Acc 19.076%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 2.236 Acc 19.038%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 2.236 Acc 18.995%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 2.278 Acc 16.406%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 2.237 Acc 18.762%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 2.238 Acc 18.776%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 2.238 Acc 18.844%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 2.237 Acc 18.945%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 2.227 Acc 21.094%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 2.237 Acc 19.137%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 2.237 Acc 18.893%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 2.333 Acc 6.250%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 2.239 Acc 18.696%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 2.236 Acc 18.839%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 2.238 Acc 18.779%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 2.238 Acc 18.816%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 2.237 Acc 18.917%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 2.229 Acc 21.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 2.234 Acc 19.191%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 2.235 Acc 19.038%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 2.234 Acc 19.017%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 2.237 Acc 18.900%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 2.191 Acc 21.875%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 2.236 Acc 19.049%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 2.237 Acc 18.869%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 2.237 Acc 18.875%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 2.185 Acc 25.781%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 2.234 Acc 19.407%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 2.233 Acc 19.411%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 2.234 Acc 19.168%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 2.235 Acc 19.130%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 2.236 Acc 18.975%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 2.313 Acc 13.281%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 2.241 Acc 19.307%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 2.242 Acc 18.874%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 2.239 Acc 18.797%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 2.237 Acc 18.890%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 2.237 Acc 18.904%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 2.264 Acc 14.844%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 2.236 Acc 19.392%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 2.236 Acc 19.178%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 2.237 Acc 19.087%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 2.237 Acc 18.943%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 2.237 Acc 18.951%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 2.313 Acc 13.281%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 2.240 Acc 18.665%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 2.238 Acc 19.003%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 2.239 Acc 18.810%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 2.279 Acc 17.188%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 2.235 Acc 19.524%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 2.239 Acc 18.856%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 2.237 Acc 18.949%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 2.255 Acc 17.188%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 2.241 Acc 18.464%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 2.239 Acc 18.653%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 2.238 Acc 18.886%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 2.235 Acc 18.920%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 2.237 Acc 18.933%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 2.238 Acc 18.849%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 2.236 Acc 18.959%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 2.206 Acc 20.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 2.234 Acc 19.384%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 2.237 Acc 19.073%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 2.238 Acc 18.934%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 2.237 Acc 18.799%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 2.264 Acc 16.406%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 2.238 Acc 18.765%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 2.235 Acc 19.049%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 2.236 Acc 18.971%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 2.238 Acc 18.902%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 2.238 Acc 18.865%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 2.236 Acc 17.969%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 2.235 Acc 19.384%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 2.236 Acc 19.088%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 2.238 Acc 18.862%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 2.239 Acc 18.857%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 2.238 Acc 18.925%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 2.263 Acc 14.062%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 2.238 Acc 18.456%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 2.237 Acc 18.633%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 2.237 Acc 18.680%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 2.237 Acc 18.851%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 2.185 Acc 25.000%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 2.235 Acc 19.259%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 2.236 Acc 19.046%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 2.236 Acc 18.945%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 2.181 Acc 27.344%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 2.239 Acc 18.754%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 2.237 Acc 18.880%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 2.238 Acc 18.847%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 2.192 Acc 17.188%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 2.231 Acc 19.322%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 2.236 Acc 18.916%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 2.236 Acc 18.980%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 2.237 Acc 18.897%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 2.244 Acc 20.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 2.240 Acc 19.152%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 2.238 Acc 18.916%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 2.238 Acc 18.840%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 2.202 Acc 23.438%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 2.190 Acc 25.000%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 2.236 Acc 18.967%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 2.236 Acc 19.205%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 2.238 Acc 18.833%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 2.237 Acc 19.017%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 2.271 Acc 17.188%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 2.234 Acc 19.206%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 2.237 Acc 19.053%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 2.238 Acc 18.911%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 2.237 Acc 18.904%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 2.238 Acc 18.898%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 2.270 Acc 15.625%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 2.233 Acc 19.462%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 2.234 Acc 19.181%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 2.236 Acc 18.882%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 2.236 Acc 18.992%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 2.204 Acc 21.094%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 2.236 Acc 18.936%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 2.239 Acc 18.664%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 2.237 Acc 18.901%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 2.238 Acc 18.933%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 2.276 Acc 15.625%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 2.237 Acc 18.510%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 2.238 Acc 18.637%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 2.239 Acc 18.786%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 2.238 Acc 18.769%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 2.232 Acc 14.844%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 2.241 Acc 18.549%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 2.238 Acc 19.018%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 2.239 Acc 18.911%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 2.261 Acc 21.094%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 2.238 Acc 18.541%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 2.236 Acc 18.727%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 2.235 Acc 18.939%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 2.235 Acc 18.939%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 2.229 Acc 14.844%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 2.240 Acc 18.974%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 2.240 Acc 18.913%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 2.240 Acc 18.841%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 2.237 Acc 19.175%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 2.236 Acc 19.119%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 2.236 Acc 19.072%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 2.237 Acc 18.920%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 2.244 Acc 15.625%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 2.238 Acc 19.059%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 2.237 Acc 19.022%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 2.239 Acc 18.869%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 2.239 Acc 18.845%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 2.237 Acc 18.956%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 2.201 Acc 21.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 2.241 Acc 19.044%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 2.239 Acc 19.076%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 2.237 Acc 18.989%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 2.238 Acc 18.927%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 2.238 Acc 18.915%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 2.210 Acc 21.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 2.233 Acc 19.299%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 2.235 Acc 19.092%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 2.236 Acc 19.080%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 2.236 Acc 18.947%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 2.237 Acc 18.903%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 2.205 Acc 21.094%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 2.238 Acc 18.665%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 2.237 Acc 18.820%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 2.236 Acc 18.892%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 2.229 Acc 17.969%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 2.239 Acc 18.672%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 2.236 Acc 18.976%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 2.236 Acc 18.992%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 2.261 Acc 16.406%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 2.240 Acc 18.510%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 2.240 Acc 18.509%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 2.239 Acc 18.618%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 2.238 Acc 18.783%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 2.238 Acc 18.837%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 2.233 Acc 17.188%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 2.235 Acc 19.152%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 2.237 Acc 18.653%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 2.236 Acc 18.750%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 2.237 Acc 18.717%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 2.236 Acc 18.878%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 2.203 Acc 20.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 2.235 Acc 19.021%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 2.234 Acc 19.185%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 2.235 Acc 19.126%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 2.236 Acc 19.050%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 2.237 Acc 18.931%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 2.208 Acc 18.750%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 2.239 Acc 18.664%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 2.238 Acc 18.802%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 2.228 Acc 18.750%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 2.237 Acc 19.052%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 2.235 Acc 19.158%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 2.236 Acc 18.939%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 2.237 Acc 18.898%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 2.233 Acc 19.245%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 2.236 Acc 18.870%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 2.238 Acc 18.846%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 2.238 Acc 18.951%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 2.237 Acc 18.985%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 2.231 Acc 20.312%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 2.237 Acc 19.106%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 2.236 Acc 19.128%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 2.192 Acc 22.656%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 2.235 Acc 18.858%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 2.237 Acc 18.941%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 2.236 Acc 18.954%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 2.247 Acc 18.750%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 2.238 Acc 19.067%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 2.238 Acc 18.894%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 2.238 Acc 18.915%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 2.238 Acc 21.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 2.236 Acc 19.183%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 2.240 Acc 18.793%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 2.238 Acc 18.945%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 2.212 Acc 23.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 2.238 Acc 18.611%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 2.237 Acc 18.905%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 2.238 Acc 18.828%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 2.237 Acc 18.918%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 2.212 Acc 21.094%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 2.237 Acc 18.897%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 2.238 Acc 18.806%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 2.227 Acc 25.000%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 2.233 Acc 19.222%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 2.233 Acc 19.213%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 2.235 Acc 19.183%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 2.236 Acc 19.050%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 2.236 Acc 19.034%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 2.200 Acc 20.312%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 2.238 Acc 18.866%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 2.239 Acc 18.781%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 2.240 Acc 18.820%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 2.238 Acc 18.923%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 2.237 Acc 18.918%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 2.267 Acc 18.750%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 2.239 Acc 18.526%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 2.239 Acc 18.633%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 2.238 Acc 18.820%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 2.238 Acc 18.783%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 2.257 Acc 21.094%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 2.238 Acc 18.843%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 2.237 Acc 18.812%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 2.237 Acc 18.864%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 2.238 Acc 18.903%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 2.143 Acc 21.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 2.241 Acc 18.696%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 2.238 Acc 19.088%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 2.237 Acc 19.028%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 2.237 Acc 18.928%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 2.231 Acc 21.094%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 2.241 Acc 18.611%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 2.238 Acc 18.785%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 2.236 Acc 18.893%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 2.237 Acc 18.849%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 2.236 Acc 18.950%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 2.215 Acc 17.188%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 2.233 Acc 19.090%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 2.238 Acc 18.789%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 2.238 Acc 18.872%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 2.219 Acc 21.875%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 2.236 Acc 19.067%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 2.234 Acc 19.267%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 2.236 Acc 19.285%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 2.236 Acc 19.147%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 2.236 Acc 19.048%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 2.212 Acc 21.875%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 2.236 Acc 19.003%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 2.236 Acc 19.106%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 2.236 Acc 19.095%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 2.237 Acc 19.009%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 2.152 Acc 26.562%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 2.233 Acc 18.912%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 2.235 Acc 19.135%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 2.234 Acc 19.007%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 2.236 Acc 18.847%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 2.237 Acc 18.886%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 2.236 Acc 21.875%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 2.232 Acc 19.446%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 2.232 Acc 19.376%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 2.234 Acc 19.129%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 2.236 Acc 19.052%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 2.237 Acc 19.034%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 2.228 Acc 17.188%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 2.240 Acc 18.750%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 2.238 Acc 18.801%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 2.236 Acc 19.031%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 2.225 Acc 21.094%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 2.236 Acc 19.137%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 2.236 Acc 19.150%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 2.236 Acc 19.217%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 2.237 Acc 19.101%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 2.228 Acc 21.094%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 2.236 Acc 19.361%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 2.238 Acc 18.916%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 2.237 Acc 18.966%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 2.238 Acc 18.861%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 2.262 Acc 14.062%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 2.242 Acc 18.642%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 2.237 Acc 18.836%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 2.237 Acc 18.976%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 2.237 Acc 18.879%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 2.237 Acc 18.953%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 2.261 Acc 17.969%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 2.238 Acc 19.098%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 2.236 Acc 19.185%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 2.237 Acc 18.926%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 2.238 Acc 18.873%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 2.280 Acc 15.625%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 2.239 Acc 18.789%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 2.238 Acc 19.038%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 2.237 Acc 18.941%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 2.254 Acc 19.531%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 2.234 Acc 19.083%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 2.238 Acc 18.898%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 2.248 Acc 19.531%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 2.235 Acc 18.827%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 2.237 Acc 18.870%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 2.237 Acc 18.955%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 2.237 Acc 18.908%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 2.237 Acc 18.861%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 2.252 Acc 20.312%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 2.240 Acc 18.433%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 2.238 Acc 18.602%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 2.238 Acc 18.836%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 2.165 Acc 25.000%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 2.235 Acc 19.485%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 2.238 Acc 18.995%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 2.238 Acc 19.004%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 2.236 Acc 19.068%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 2.227 Acc 18.750%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 2.241 Acc 18.680%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 2.238 Acc 19.069%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 2.238 Acc 19.011%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 2.238 Acc 18.920%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 2.241 Acc 25.000%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 2.233 Acc 19.670%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 2.239 Acc 18.817%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 2.238 Acc 18.849%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 2.238 Acc 18.864%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 2.214 Acc 24.219%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 2.239 Acc 18.820%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 2.237 Acc 18.944%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 2.236 Acc 19.012%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 2.236 Acc 18.921%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 2.236 Acc 19.012%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 2.248 Acc 15.625%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 2.232 Acc 19.469%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 2.234 Acc 19.329%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 2.237 Acc 19.002%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 2.237 Acc 18.873%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 2.238 Acc 18.848%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 2.228 Acc 21.875%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 2.238 Acc 18.886%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 2.237 Acc 18.906%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 2.237 Acc 18.889%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 2.252 Acc 15.625%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 2.234 Acc 19.438%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 2.236 Acc 19.209%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 2.237 Acc 18.935%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 2.237 Acc 18.934%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 2.298 Acc 13.281%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 2.236 Acc 19.059%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 2.233 Acc 19.061%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 2.236 Acc 18.856%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 2.236 Acc 18.951%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 2.236 Acc 18.982%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 2.247 Acc 18.750%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 2.240 Acc 18.619%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 2.238 Acc 18.758%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 2.238 Acc 18.752%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 2.238 Acc 18.803%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 2.252 Acc 18.750%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 2.240 Acc 18.526%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 2.236 Acc 18.978%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 2.307 Acc 14.844%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 2.235 Acc 18.987%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 2.236 Acc 19.025%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 2.237 Acc 18.947%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 2.237 Acc 18.973%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 2.199 Acc 23.438%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 2.238 Acc 18.781%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 2.238 Acc 18.805%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 2.238 Acc 18.869%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 2.238 Acc 18.872%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 2.256 Acc 14.844%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 2.236 Acc 18.881%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 2.236 Acc 18.894%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 2.236 Acc 18.906%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 2.236 Acc 18.877%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 2.237 Acc 18.909%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 2.268 Acc 17.969%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 2.236 Acc 19.245%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 2.234 Acc 19.213%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 2.235 Acc 19.129%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 2.236 Acc 19.060%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 2.236 Acc 19.020%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 2.248 Acc 18.750%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 2.236 Acc 19.065%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 2.236 Acc 18.986%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 2.236 Acc 18.972%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 2.237 Acc 18.892%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 2.224 Acc 20.312%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 2.241 Acc 18.943%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 2.238 Acc 18.940%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 2.237 Acc 18.885%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 2.237 Acc 18.921%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 2.237 Acc 18.976%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 2.251 Acc 16.406%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 2.243 Acc 18.472%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 2.240 Acc 18.777%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 2.240 Acc 18.683%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 2.238 Acc 18.727%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 2.236 Acc 18.959%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 2.201 Acc 23.438%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 2.235 Acc 19.276%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 2.237 Acc 18.847%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 2.239 Acc 18.802%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 2.237 Acc 18.881%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 2.236 Acc 18.970%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 2.214 Acc 23.438%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 2.194 Acc 22.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 2.243 Acc 18.588%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 2.239 Acc 18.937%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 2.239 Acc 18.911%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 2.238 Acc 18.949%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 2.238 Acc 18.895%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 2.277 Acc 15.625%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 2.239 Acc 18.881%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 2.239 Acc 18.645%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 2.238 Acc 18.812%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 2.237 Acc 18.875%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 2.237 Acc 18.879%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 2.200 Acc 21.875%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 2.236 Acc 18.696%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 2.236 Acc 18.999%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 2.237 Acc 18.825%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 2.236 Acc 18.962%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 2.237 Acc 18.970%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 2.267 Acc 16.406%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 2.238 Acc 18.735%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 2.237 Acc 18.688%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 2.238 Acc 18.638%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 2.238 Acc 18.810%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 2.237 Acc 18.893%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 2.243 Acc 21.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 2.237 Acc 18.889%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 2.236 Acc 19.139%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 2.237 Acc 19.001%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 2.237 Acc 19.017%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 2.246 Acc 18.750%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 2.242 Acc 18.649%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 2.239 Acc 18.719%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 2.238 Acc 18.714%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 2.237 Acc 18.808%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 2.236 Acc 18.939%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 2.268 Acc 15.625%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 2.236 Acc 18.974%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 2.235 Acc 19.139%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 2.236 Acc 19.048%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 2.237 Acc 19.052%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 2.210 Acc 23.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 2.238 Acc 18.773%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 2.237 Acc 18.929%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 2.236 Acc 18.932%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 2.237 Acc 18.882%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 2.237 Acc 18.926%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 2.261 Acc 15.625%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 2.236 Acc 18.827%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 2.236 Acc 18.933%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 2.238 Acc 18.740%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 2.238 Acc 18.845%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 2.238 Acc 18.873%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 2.273 Acc 15.625%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 2.240 Acc 18.789%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 2.239 Acc 18.849%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 2.238 Acc 18.939%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 2.237 Acc 18.946%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 2.195 Acc 18.750%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 2.236 Acc 19.299%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 2.237 Acc 19.146%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 2.237 Acc 19.007%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 2.236 Acc 19.015%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 2.236 Acc 19.024%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 2.226 Acc 19.516%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 2.227 Acc 19.574%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 2.265 Acc 16.406%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 2.241 Acc 18.564%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 2.240 Acc 18.972%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 2.239 Acc 19.033%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 2.238 Acc 18.925%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 2.237 Acc 18.939%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 2.220 Acc 20.312%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 2.239 Acc 18.874%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 2.238 Acc 18.979%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 2.237 Acc 19.036%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 2.237 Acc 18.971%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 2.179 Acc 24.219%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 2.238 Acc 18.967%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 2.240 Acc 18.824%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 2.239 Acc 18.836%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 2.238 Acc 18.990%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 2.238 Acc 18.981%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 2.212 Acc 23.438%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 2.249 Acc 17.969%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 2.245 Acc 18.239%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 2.243 Acc 18.416%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 2.240 Acc 18.540%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 2.239 Acc 18.651%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 2.238 Acc 18.803%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 2.264 Acc 18.750%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 2.237 Acc 18.580%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 2.236 Acc 18.960%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 2.236 Acc 18.994%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 2.237 Acc 18.915%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 2.189 Acc 21.875%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 2.239 Acc 19.152%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 2.240 Acc 18.804%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 2.238 Acc 18.926%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 2.236 Acc 19.073%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 2.236 Acc 19.038%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 2.239 Acc 20.312%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 2.242 Acc 18.680%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 2.239 Acc 18.882%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 2.238 Acc 18.919%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 2.237 Acc 18.914%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 2.206 Acc 22.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 2.236 Acc 18.696%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 2.239 Acc 18.766%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 2.235 Acc 19.064%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 2.237 Acc 19.038%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 2.237 Acc 18.940%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 2.287 Acc 14.062%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 2.233 Acc 19.415%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 2.235 Acc 19.132%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 2.236 Acc 19.034%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 2.237 Acc 18.912%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 2.263 Acc 14.844%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 2.239 Acc 18.533%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 2.236 Acc 18.948%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 2.237 Acc 19.046%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 2.236 Acc 18.902%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 2.236 Acc 18.929%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 2.210 Acc 18.750%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 2.241 Acc 18.796%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 2.239 Acc 18.863%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 2.237 Acc 18.817%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 2.238 Acc 18.808%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 2.238 Acc 18.881%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 2.232 Acc 21.094%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 2.239 Acc 18.936%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 2.237 Acc 18.874%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 2.238 Acc 18.877%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 2.238 Acc 18.910%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 2.238 Acc 18.907%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 2.161 Acc 22.656%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 2.235 Acc 18.936%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 2.237 Acc 18.816%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 2.236 Acc 19.028%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 2.236 Acc 18.937%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 2.237 Acc 18.961%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 2.220 Acc 20.312%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 2.238 Acc 18.990%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 2.237 Acc 19.065%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 2.237 Acc 18.984%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 2.237 Acc 19.009%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 2.236 Acc 18.957%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 2.255 Acc 17.188%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 2.239 Acc 18.665%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 2.237 Acc 18.925%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 2.237 Acc 18.901%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 2.237 Acc 18.919%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 2.238 Acc 18.830%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 2.223 Acc 14.844%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 2.237 Acc 18.673%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 2.234 Acc 19.096%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 2.235 Acc 18.981%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 2.235 Acc 19.013%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 2.237 Acc 18.954%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 2.208 Acc 20.312%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 2.236 Acc 18.990%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 2.238 Acc 18.929%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 2.239 Acc 18.773%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 2.237 Acc 18.886%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 2.239 Acc 18.792%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 2.195 Acc 23.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 2.241 Acc 18.588%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 2.236 Acc 18.828%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 2.237 Acc 18.895%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 2.237 Acc 18.888%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 2.237 Acc 18.881%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 2.236 Acc 18.750%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 2.239 Acc 18.557%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 2.237 Acc 18.754%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 2.237 Acc 18.685%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 2.237 Acc 18.844%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 2.237 Acc 18.847%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 2.203 Acc 23.438%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 2.182 Acc 25.000%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 2.231 Acc 19.090%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 2.234 Acc 18.909%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 2.237 Acc 18.784%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 2.237 Acc 18.931%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 2.237 Acc 18.989%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 2.291 Acc 12.500%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 2.240 Acc 18.758%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 2.241 Acc 18.587%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 2.240 Acc 18.792%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 2.238 Acc 18.962%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 2.238 Acc 18.909%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 2.263 Acc 17.969%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 2.237 Acc 18.804%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 2.237 Acc 18.843%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 2.239 Acc 18.737%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 2.239 Acc 18.879%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 2.238 Acc 18.929%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 2.213 Acc 17.188%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 2.237 Acc 19.075%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 2.238 Acc 18.804%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 2.236 Acc 18.924%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 2.237 Acc 18.951%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 2.237 Acc 18.936%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 2.293 Acc 11.719%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 2.237 Acc 18.998%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 2.234 Acc 19.049%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 2.234 Acc 19.090%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 2.235 Acc 19.058%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 2.237 Acc 18.932%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 2.247 Acc 17.969%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 2.232 Acc 19.369%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 2.235 Acc 19.108%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 2.235 Acc 19.137%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 2.236 Acc 19.142%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 2.237 Acc 19.054%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 2.202 Acc 22.656%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 2.240 Acc 18.557%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 2.236 Acc 19.042%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 2.238 Acc 18.981%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 2.236 Acc 18.968%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 2.236 Acc 18.992%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 2.213 Acc 23.438%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 2.188 Acc 20.312%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 2.234 Acc 19.013%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 2.238 Acc 18.832%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 2.237 Acc 18.924%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 2.237 Acc 18.927%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 2.236 Acc 18.939%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 2.225 Acc 19.516%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 2.226 Acc 19.574%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 2.207 Acc 21.094%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 2.235 Acc 18.912%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 2.238 Acc 18.707%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 2.237 Acc 18.934%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 2.237 Acc 18.958%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 2.237 Acc 18.984%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 2.209 Acc 23.438%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 2.237 Acc 20.312%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 2.238 Acc 18.649%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 2.240 Acc 18.490%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 2.240 Acc 18.594%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 2.239 Acc 18.682%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 2.238 Acc 18.738%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 2.204 Acc 23.438%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 2.270 Acc 17.969%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 2.237 Acc 18.758%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 2.235 Acc 19.111%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 2.236 Acc 18.965%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 2.237 Acc 18.937%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 2.237 Acc 18.982%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 2.305 Acc 10.938%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 2.241 Acc 18.758%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 2.240 Acc 18.847%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 2.238 Acc 18.947%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 2.239 Acc 18.822%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 2.239 Acc 18.822%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 2.243 Acc 17.969%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 2.235 Acc 19.655%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 2.234 Acc 19.380%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 2.237 Acc 19.025%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 2.238 Acc 18.896%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 2.237 Acc 18.950%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 2.202 Acc 22.656%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 2.234 Acc 19.454%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 2.236 Acc 19.092%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 2.237 Acc 19.030%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 2.237 Acc 19.070%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 2.237 Acc 18.990%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 2.184 Acc 23.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 2.240 Acc 18.139%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 2.238 Acc 18.839%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 2.239 Acc 18.727%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 2.238 Acc 18.836%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 2.238 Acc 18.911%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 2.243 Acc 18.750%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 2.238 Acc 18.912%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 2.238 Acc 18.893%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 2.237 Acc 18.812%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 2.237 Acc 18.942%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 2.220 Acc 19.531%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 2.234 Acc 19.160%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 2.235 Acc 19.003%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 2.236 Acc 19.007%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 2.237 Acc 18.968%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 2.238 Acc 18.875%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 2.251 Acc 14.844%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 2.240 Acc 18.634%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 2.240 Acc 18.754%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 2.239 Acc 18.688%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 2.238 Acc 18.927%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 2.237 Acc 18.911%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 2.208 Acc 23.438%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 2.296 Acc 15.625%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 2.238 Acc 18.595%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 2.236 Acc 18.797%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 2.237 Acc 18.729%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 2.237 Acc 18.822%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 2.237 Acc 18.850%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 2.243 Acc 17.969%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 2.234 Acc 19.183%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 2.235 Acc 19.178%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 2.237 Acc 18.973%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 2.237 Acc 18.960%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 2.237 Acc 18.873%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 2.207 Acc 23.438%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 2.264 Acc 17.188%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 2.239 Acc 18.920%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 2.235 Acc 19.205%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 2.235 Acc 19.207%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 2.235 Acc 19.124%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 2.236 Acc 19.017%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 2.189 Acc 19.531%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 2.241 Acc 18.348%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 2.238 Acc 18.692%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 2.238 Acc 18.830%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 2.239 Acc 18.816%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 2.237 Acc 18.925%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 2.210 Acc 23.438%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 2.225 Acc 19.574%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 2.197 Acc 22.656%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 2.240 Acc 18.719%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 2.240 Acc 18.513%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 2.237 Acc 18.737%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 2.238 Acc 18.822%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 2.238 Acc 18.851%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 2.206 Acc 23.438%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 2.223 Acc 19.516%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 2.251 Acc 20.312%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 2.239 Acc 18.804%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 2.240 Acc 18.602%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 2.239 Acc 18.807%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 2.238 Acc 18.851%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 2.238 Acc 18.823%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 2.205 Acc 23.438%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 2.222 Acc 19.516%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 2.223 Acc 19.574%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 2.151 Acc 26.562%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 2.237 Acc 19.531%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 2.238 Acc 19.042%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 2.238 Acc 18.823%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 2.237 Acc 18.873%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 2.237 Acc 18.890%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 2.211 Acc 23.438%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 2.224 Acc 19.516%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 2.224 Acc 19.574%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e5de7d6634418e9223fe21922c8340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.309 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 2.246 Acc 18.843%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.244 Acc 18.874%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.240 Acc 18.916%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.238 Acc 18.859%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.234 Acc 19.065%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 1.941 Acc 25.000%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 1.934 Acc 25.681%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 1.937 Acc 25.342%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 1.772 Acc 37.500%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 1.450 Acc 50.487%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 1.210 Acc 59.624%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 1.033 Acc 66.022%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 0.914 Acc 70.122%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 0.837 Acc 72.873%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.897 Acc 80.469%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.850 Acc 81.946%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.852 Acc 81.810%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.494 Acc 85.938%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.433 Acc 87.044%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.433 Acc 87.088%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.424 Acc 87.370%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.413 Acc 87.568%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.409 Acc 87.725%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.540 Acc 88.281%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.543 Acc 88.072%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.539 Acc 88.134%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.320 Acc 88.281%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.350 Acc 89.488%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.351 Acc 89.478%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.351 Acc 89.428%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.350 Acc 89.468%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.347 Acc 89.566%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.611 Acc 89.844%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.615 Acc 89.062%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.611 Acc 89.327%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.210 Acc 93.750%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.320 Acc 90.300%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.324 Acc 90.365%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.322 Acc 90.443%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.320 Acc 90.506%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.318 Acc 90.570%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.316 Acc 89.062%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.332 Acc 91.553%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.324 Acc 91.764%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.198 Acc 92.188%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.296 Acc 91.414%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.294 Acc 91.418%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.296 Acc 91.282%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.296 Acc 91.338%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.294 Acc 91.356%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.309 Acc 92.969%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.359 Acc 91.491%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.353 Acc 91.655%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.207 Acc 95.312%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.274 Acc 91.855%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.274 Acc 91.822%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.279 Acc 91.705%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.277 Acc 91.827%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.280 Acc 91.801%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.310 Acc 93.750%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.348 Acc 92.149%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.343 Acc 92.289%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.267 Acc 92.188%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.284 Acc 91.669%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.271 Acc 91.923%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.272 Acc 91.886%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.272 Acc 91.960%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.272 Acc 91.982%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.601 Acc 89.062%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.552 Acc 90.524%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.551 Acc 90.582%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.337 Acc 89.062%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.243 Acc 92.744%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.259 Acc 92.428%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.256 Acc 92.616%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.258 Acc 92.544%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.260 Acc 92.448%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.368 Acc 91.406%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.342 Acc 93.131%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.336 Acc 93.284%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.270 Acc 92.188%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.247 Acc 92.969%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.238 Acc 93.039%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.245 Acc 92.862%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.250 Acc 92.776%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.252 Acc 92.708%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.291 Acc 92.969%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.310 Acc 92.984%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.307 Acc 93.089%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.170 Acc 95.312%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.246 Acc 92.984%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.244 Acc 92.840%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.240 Acc 92.901%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.243 Acc 92.877%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.242 Acc 92.920%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.359 Acc 93.750%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.395 Acc 93.549%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.391 Acc 93.661%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.165 Acc 95.312%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.215 Acc 93.518%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.227 Acc 93.350%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.234 Acc 93.210%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.233 Acc 93.218%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.235 Acc 93.242%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.336 Acc 92.188%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.338 Acc 92.226%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.334 Acc 92.292%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.235 Acc 93.456%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.229 Acc 93.622%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.224 Acc 93.553%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.228 Acc 93.425%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.229 Acc 93.437%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.358 Acc 93.750%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.381 Acc 92.528%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.376 Acc 92.704%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.395 Acc 89.062%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.223 Acc 93.402%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.220 Acc 93.447%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.227 Acc 93.358%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.228 Acc 93.388%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.228 Acc 93.357%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.355 Acc 93.750%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.373 Acc 92.860%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.367 Acc 93.050%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.236 Acc 93.750%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.203 Acc 94.121%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.215 Acc 93.649%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.217 Acc 93.654%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.215 Acc 93.731%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.217 Acc 93.700%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.486 Acc 91.406%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.508 Acc 91.538%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.503 Acc 91.682%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.310 Acc 91.406%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.220 Acc 93.533%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.221 Acc 93.653%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.215 Acc 93.823%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.217 Acc 93.781%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.216 Acc 93.830%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.353 Acc 93.750%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.364 Acc 93.990%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.359 Acc 94.170%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.354 Acc 92.188%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.203 Acc 94.168%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.203 Acc 94.104%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.209 Acc 94.025%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.209 Acc 94.040%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.209 Acc 94.054%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.348 Acc 91.406%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.372 Acc 92.938%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.367 Acc 93.046%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.213 Acc 93.750%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.201 Acc 94.106%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.204 Acc 94.007%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.211 Acc 93.867%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.206 Acc 93.958%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.206 Acc 94.040%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.289 Acc 93.796%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.284 Acc 93.560%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.260 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.198 Acc 94.214%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.201 Acc 94.158%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.203 Acc 94.119%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.204 Acc 94.140%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.207 Acc 94.053%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.288 Acc 92.907%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.282 Acc 92.992%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.121 Acc 95.312%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.184 Acc 94.562%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.188 Acc 94.617%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.194 Acc 94.412%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.196 Acc 94.323%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.197 Acc 94.336%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.306 Acc 95.312%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.362 Acc 93.758%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.358 Acc 93.762%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.149 Acc 96.094%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.187 Acc 94.624%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.186 Acc 94.632%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.191 Acc 94.521%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.197 Acc 94.338%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.198 Acc 94.389%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.263 Acc 92.969%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.300 Acc 93.232%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.294 Acc 93.377%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.427 Acc 93.750%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.196 Acc 94.392%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.194 Acc 94.407%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.190 Acc 94.562%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.193 Acc 94.436%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.193 Acc 94.427%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.286 Acc 94.531%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.324 Acc 92.752%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.317 Acc 92.938%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.198 Acc 93.750%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.194 Acc 94.315%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.190 Acc 94.450%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.189 Acc 94.485%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.192 Acc 94.418%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.191 Acc 94.433%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.397 Acc 93.750%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.424 Acc 92.102%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.418 Acc 92.335%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.309 Acc 92.969%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.170 Acc 95.196%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.184 Acc 94.757%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.182 Acc 94.799%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.184 Acc 94.742%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.182 Acc 94.798%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.319 Acc 92.188%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.346 Acc 93.054%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.339 Acc 93.295%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.190 Acc 92.969%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.180 Acc 94.879%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.184 Acc 94.593%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.189 Acc 94.500%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.186 Acc 94.520%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.188 Acc 94.539%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.204 Acc 96.094%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.272 Acc 94.160%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.267 Acc 94.080%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.101 Acc 95.312%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.176 Acc 94.988%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.181 Acc 94.978%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.182 Acc 94.830%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.182 Acc 94.816%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.181 Acc 94.813%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.349 Acc 93.750%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.395 Acc 93.224%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.390 Acc 93.354%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.165 Acc 95.243%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.173 Acc 95.044%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.176 Acc 94.931%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.177 Acc 94.905%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.180 Acc 94.824%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.253 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.293 Acc 94.075%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.288 Acc 94.181%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.172 Acc 95.080%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.169 Acc 95.130%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.173 Acc 94.983%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.173 Acc 94.991%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.174 Acc 94.965%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.273 Acc 92.188%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.298 Acc 93.859%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.123 Acc 96.094%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.170 Acc 94.817%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.166 Acc 95.087%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.171 Acc 94.960%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.169 Acc 95.022%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.172 Acc 94.999%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.312 Acc 92.969%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.339 Acc 93.085%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.332 Acc 93.295%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.235 Acc 93.750%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.162 Acc 95.243%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.166 Acc 95.130%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.169 Acc 95.084%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.173 Acc 95.020%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.174 Acc 94.955%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.283 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.316 Acc 93.727%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.312 Acc 93.839%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.167 Acc 94.531%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.169 Acc 95.498%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.166 Acc 95.328%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.166 Acc 95.227%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.165 Acc 95.266%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.165 Acc 95.258%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.416 Acc 92.969%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.412 Acc 92.327%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.409 Acc 92.265%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.083 Acc 96.875%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.160 Acc 95.266%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.163 Acc 95.239%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.166 Acc 95.167%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.166 Acc 95.147%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.167 Acc 95.133%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.295 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.330 Acc 93.688%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.327 Acc 93.657%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.154 Acc 95.490%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.158 Acc 95.386%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.161 Acc 95.255%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.160 Acc 95.293%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.163 Acc 95.224%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.347 Acc 92.969%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.351 Acc 93.123%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.348 Acc 92.984%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.204 Acc 93.750%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.165 Acc 95.158%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.158 Acc 95.332%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.162 Acc 95.248%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.165 Acc 95.213%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.165 Acc 95.220%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.310 Acc 96.094%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.355 Acc 93.417%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.352 Acc 93.408%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.126 Acc 96.875%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.146 Acc 95.560%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.152 Acc 95.476%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.154 Acc 95.510%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.157 Acc 95.523%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.159 Acc 95.459%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.381 Acc 94.531%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.446 Acc 91.832%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.442 Acc 91.970%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.249 Acc 92.969%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.160 Acc 95.452%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.160 Acc 95.312%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.159 Acc 95.424%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.159 Acc 95.427%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.159 Acc 95.380%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.283 Acc 95.312%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.300 Acc 94.175%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.298 Acc 94.080%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.132 Acc 95.312%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.151 Acc 95.398%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.157 Acc 95.262%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.157 Acc 95.315%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.158 Acc 95.303%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.158 Acc 95.390%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.508 Acc 90.625%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.529 Acc 91.027%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.525 Acc 91.021%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.199 Acc 93.750%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.150 Acc 95.722%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.152 Acc 95.600%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.154 Acc 95.531%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.152 Acc 95.566%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.154 Acc 95.578%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.315 Acc 92.969%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.343 Acc 93.185%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.340 Acc 93.159%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.112 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.143 Acc 95.854%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.145 Acc 95.713%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.147 Acc 95.678%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.149 Acc 95.636%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.152 Acc 95.542%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.250 Acc 96.094%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.299 Acc 93.348%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.297 Acc 93.326%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.151 Acc 95.746%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.144 Acc 95.837%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.147 Acc 95.663%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.151 Acc 95.579%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.151 Acc 95.560%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.378 Acc 91.406%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.401 Acc 92.257%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.394 Acc 92.479%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.136 Acc 95.955%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.142 Acc 95.872%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.144 Acc 95.790%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.149 Acc 95.581%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.150 Acc 95.554%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.277 Acc 94.299%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.274 Acc 94.368%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.134 Acc 96.264%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.143 Acc 96.004%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.144 Acc 95.912%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.147 Acc 95.809%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.147 Acc 95.787%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.247 Acc 96.094%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.268 Acc 93.959%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.262 Acc 94.022%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.117 Acc 95.312%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.143 Acc 95.506%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.144 Acc 95.612%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.143 Acc 95.676%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.142 Acc 95.743%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.147 Acc 95.648%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.278 Acc 93.750%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.292 Acc 93.688%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.287 Acc 93.828%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.139 Acc 95.792%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.138 Acc 95.763%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.137 Acc 95.824%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.140 Acc 95.800%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.142 Acc 95.794%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.280 Acc 92.969%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.295 Acc 93.735%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.293 Acc 93.750%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.118 Acc 94.531%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.141 Acc 95.862%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.137 Acc 95.973%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.143 Acc 95.816%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.141 Acc 95.868%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.143 Acc 95.780%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.332 Acc 92.969%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.360 Acc 93.386%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.356 Acc 93.412%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.181 Acc 94.531%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.132 Acc 95.908%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.138 Acc 95.822%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.142 Acc 95.793%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.141 Acc 95.837%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.142 Acc 95.821%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.523 Acc 90.625%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.520 Acc 90.555%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.517 Acc 90.683%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.144 Acc 95.730%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.142 Acc 95.810%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.140 Acc 95.847%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.141 Acc 95.864%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.142 Acc 95.854%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.362 Acc 92.188%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.377 Acc 92.683%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.372 Acc 92.736%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.136 Acc 95.877%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.137 Acc 95.923%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.138 Acc 95.930%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.138 Acc 95.938%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.138 Acc 95.924%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.489 Acc 91.406%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.488 Acc 91.584%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.482 Acc 91.772%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.130 Acc 96.875%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.142 Acc 95.676%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.139 Acc 95.783%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.138 Acc 95.790%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.135 Acc 95.879%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.136 Acc 95.880%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.302 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.303 Acc 93.510%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.302 Acc 93.490%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.136 Acc 96.001%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.133 Acc 95.973%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.137 Acc 95.912%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.138 Acc 95.895%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.137 Acc 95.879%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.299 Acc 93.750%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.315 Acc 93.642%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.313 Acc 93.618%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.128 Acc 95.931%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.130 Acc 95.985%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.136 Acc 95.839%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.136 Acc 95.852%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.138 Acc 95.804%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.281 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.322 Acc 93.325%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.315 Acc 93.490%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.129 Acc 96.117%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.129 Acc 96.125%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.132 Acc 96.094%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.137 Acc 95.955%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.136 Acc 95.946%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.375 Acc 92.188%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.358 Acc 93.209%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.354 Acc 93.315%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.144 Acc 92.969%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.134 Acc 95.862%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.129 Acc 96.059%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.132 Acc 95.933%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.131 Acc 95.989%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.132 Acc 95.996%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.324 Acc 93.139%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.318 Acc 93.140%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.152 Acc 93.750%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.120 Acc 96.380%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.125 Acc 96.245%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.125 Acc 96.229%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.128 Acc 96.176%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.129 Acc 96.097%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.323 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.335 Acc 93.642%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.331 Acc 93.703%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.252 Acc 96.094%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.137 Acc 96.063%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.135 Acc 96.024%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.134 Acc 96.065%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.132 Acc 96.041%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.134 Acc 96.053%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.285 Acc 94.531%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.311 Acc 93.193%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.307 Acc 93.319%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.209 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.114 Acc 96.364%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.123 Acc 96.175%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.123 Acc 96.187%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.123 Acc 96.242%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.123 Acc 96.253%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.403 Acc 93.750%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.374 Acc 93.023%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.366 Acc 93.175%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.126 Acc 96.117%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.128 Acc 96.078%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.129 Acc 96.135%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.128 Acc 96.115%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.130 Acc 96.151%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.320 Acc 90.625%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.313 Acc 93.270%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.309 Acc 93.330%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.125 Acc 96.256%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.122 Acc 96.319%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.122 Acc 96.275%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.125 Acc 96.193%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.127 Acc 96.142%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.321 Acc 93.750%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.361 Acc 92.737%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.355 Acc 92.879%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.120 Acc 96.094%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.115 Acc 96.426%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.123 Acc 96.288%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.121 Acc 96.314%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.123 Acc 96.298%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.124 Acc 96.286%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.282 Acc 94.531%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.286 Acc 93.773%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.282 Acc 93.839%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.125 Acc 97.656%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.128 Acc 96.125%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.122 Acc 96.238%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.122 Acc 96.249%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.123 Acc 96.271%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.124 Acc 96.270%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.343 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.356 Acc 93.077%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.350 Acc 93.186%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.256 Acc 92.188%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.109 Acc 96.689%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.116 Acc 96.436%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.117 Acc 96.356%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.120 Acc 96.304%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.123 Acc 96.226%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.352 Acc 92.969%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.337 Acc 93.247%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.331 Acc 93.357%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.116 Acc 96.558%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.117 Acc 96.545%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.120 Acc 96.351%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.122 Acc 96.341%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.123 Acc 96.300%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.286 Acc 94.531%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.318 Acc 92.752%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.311 Acc 93.008%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.118 Acc 96.426%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.118 Acc 96.409%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.119 Acc 96.374%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.119 Acc 96.372%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.119 Acc 96.359%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.513 Acc 91.406%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.542 Acc 89.735%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.539 Acc 89.941%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.136 Acc 97.656%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.115 Acc 96.511%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.116 Acc 96.424%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.118 Acc 96.447%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.119 Acc 96.413%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.120 Acc 96.390%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.406 Acc 92.969%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.418 Acc 91.429%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.412 Acc 91.682%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.117 Acc 96.388%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.111 Acc 96.498%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.119 Acc 96.377%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.118 Acc 96.404%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.118 Acc 96.393%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.340 Acc 92.969%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.380 Acc 92.342%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.374 Acc 92.440%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.112 Acc 96.566%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.116 Acc 96.529%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.114 Acc 96.496%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.116 Acc 96.448%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.119 Acc 96.396%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.413 Acc 91.406%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.403 Acc 91.747%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.397 Acc 91.764%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.096 Acc 96.094%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.104 Acc 96.759%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.108 Acc 96.587%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.116 Acc 96.397%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.117 Acc 96.361%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.118 Acc 96.321%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.271 Acc 92.969%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.318 Acc 92.613%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.313 Acc 92.747%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.085 Acc 97.656%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.121 Acc 96.395%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.117 Acc 96.432%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.122 Acc 96.252%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.122 Acc 96.281%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.120 Acc 96.281%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.308 Acc 91.406%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.320 Acc 92.876%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.314 Acc 93.081%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.141 Acc 93.750%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.119 Acc 96.349%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.121 Acc 96.362%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.121 Acc 96.397%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.120 Acc 96.409%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.120 Acc 96.384%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.353 Acc 92.188%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.366 Acc 92.265%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.357 Acc 92.545%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.102 Acc 96.875%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.111 Acc 96.704%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.111 Acc 96.701%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.112 Acc 96.610%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.113 Acc 96.538%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.321 Acc 92.188%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.326 Acc 92.976%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.322 Acc 93.132%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.022 Acc 100.000%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.100 Acc 96.945%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.108 Acc 96.712%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.111 Acc 96.605%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.110 Acc 96.604%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.111 Acc 96.625%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.286 Acc 93.023%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.279 Acc 93.334%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.066 Acc 96.875%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.097 Acc 96.999%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.105 Acc 96.755%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.108 Acc 96.608%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.108 Acc 96.602%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.110 Acc 96.587%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.385 Acc 92.188%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.410 Acc 91.136%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.404 Acc 91.181%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.109 Acc 96.558%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.107 Acc 96.642%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.108 Acc 96.602%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.109 Acc 96.614%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.110 Acc 96.571%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.456 Acc 89.062%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.415 Acc 92.033%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.409 Acc 91.993%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.052 Acc 98.438%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.105 Acc 96.728%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.106 Acc 96.751%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.107 Acc 96.732%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.108 Acc 96.676%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.109 Acc 96.646%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.415 Acc 90.625%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.456 Acc 90.749%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.450 Acc 90.897%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.117 Acc 96.094%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.107 Acc 96.635%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.112 Acc 96.556%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.112 Acc 96.582%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.111 Acc 96.593%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.112 Acc 96.537%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.398 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.377 Acc 92.520%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.370 Acc 92.549%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.103 Acc 96.450%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.105 Acc 96.611%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.107 Acc 96.613%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.109 Acc 96.554%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.110 Acc 96.551%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.394 Acc 89.062%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.391 Acc 92.249%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.386 Acc 92.421%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.092 Acc 96.960%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.100 Acc 96.817%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.100 Acc 96.808%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.104 Acc 96.725%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.106 Acc 96.643%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.302 Acc 92.188%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.316 Acc 92.690%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.310 Acc 92.926%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.105 Acc 96.767%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.106 Acc 96.743%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.109 Acc 96.662%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.109 Acc 96.647%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.109 Acc 96.574%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.312 Acc 92.188%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.322 Acc 92.489%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.317 Acc 92.506%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.098 Acc 96.094%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.100 Acc 96.821%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.104 Acc 96.599%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.110 Acc 96.429%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.110 Acc 96.483%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.110 Acc 96.513%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.433 Acc 91.406%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.373 Acc 92.543%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.366 Acc 92.864%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.122 Acc 96.094%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.106 Acc 96.767%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.105 Acc 96.700%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.105 Acc 96.711%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.105 Acc 96.700%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.107 Acc 96.644%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.415 Acc 91.406%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.407 Acc 91.863%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.402 Acc 92.044%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.098 Acc 96.774%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.102 Acc 96.774%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.102 Acc 96.792%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.103 Acc 96.793%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.105 Acc 96.738%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.387 Acc 89.844%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.356 Acc 91.917%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.348 Acc 92.094%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.143 Acc 96.875%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.107 Acc 96.589%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.104 Acc 96.696%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.109 Acc 96.592%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.107 Acc 96.649%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.107 Acc 96.664%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.419 Acc 90.625%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.333 Acc 92.946%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.329 Acc 93.054%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.094 Acc 97.146%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.092 Acc 97.190%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.095 Acc 97.057%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.098 Acc 96.974%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.100 Acc 96.911%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.271 Acc 95.312%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.305 Acc 93.131%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.299 Acc 93.171%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.129 Acc 96.875%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.092 Acc 97.184%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.100 Acc 96.929%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.105 Acc 96.820%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.105 Acc 96.809%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.104 Acc 96.805%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.384 Acc 92.188%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.367 Acc 92.667%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.361 Acc 92.774%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.110 Acc 96.465%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.104 Acc 96.688%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.103 Acc 96.717%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.103 Acc 96.715%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.103 Acc 96.750%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.387 Acc 91.406%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.374 Acc 91.375%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.369 Acc 91.531%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.097 Acc 97.045%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.097 Acc 97.023%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.099 Acc 97.026%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.101 Acc 96.906%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.101 Acc 96.895%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.417 Acc 92.188%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.387 Acc 91.646%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.382 Acc 91.857%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.097 Acc 96.968%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.095 Acc 97.108%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.098 Acc 96.992%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.099 Acc 96.972%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.100 Acc 96.937%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.329 Acc 92.969%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.358 Acc 92.311%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.353 Acc 92.541%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.112 Acc 95.312%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.100 Acc 96.805%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.102 Acc 96.739%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.104 Acc 96.701%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.105 Acc 96.694%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.105 Acc 96.688%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.515 Acc 89.062%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.452 Acc 90.726%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.448 Acc 90.745%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.063 Acc 98.438%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.099 Acc 96.999%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.097 Acc 96.929%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.099 Acc 96.854%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.098 Acc 96.895%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.379 Acc 92.969%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.332 Acc 92.288%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.327 Acc 92.463%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.097 Acc 96.875%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.094 Acc 96.929%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.099 Acc 96.805%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.098 Acc 96.898%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.098 Acc 96.893%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.100 Acc 96.799%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.385 Acc 92.188%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.374 Acc 91.940%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.371 Acc 91.939%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.101 Acc 96.860%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.099 Acc 96.918%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.098 Acc 96.927%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.100 Acc 96.869%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.099 Acc 96.897%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.382 Acc 90.625%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.358 Acc 91.847%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.355 Acc 91.760%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.090 Acc 97.084%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.091 Acc 97.077%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.095 Acc 97.023%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.097 Acc 96.912%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.097 Acc 96.902%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.318 Acc 91.406%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.315 Acc 92.791%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.311 Acc 92.891%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.090 Acc 97.006%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.091 Acc 97.054%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.098 Acc 96.880%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.102 Acc 96.746%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.101 Acc 96.767%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.290 Acc 91.406%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.308 Acc 93.069%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.303 Acc 93.144%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.090 Acc 97.092%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.096 Acc 96.957%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.097 Acc 96.880%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.099 Acc 96.865%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.101 Acc 96.805%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.376 Acc 92.188%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.364 Acc 92.574%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.363 Acc 92.452%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.107 Acc 96.094%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.085 Acc 97.200%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.090 Acc 97.151%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.089 Acc 97.148%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.092 Acc 97.111%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.094 Acc 97.062%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.287 Acc 93.750%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.326 Acc 92.296%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.321 Acc 92.397%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.083 Acc 97.656%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.092 Acc 96.999%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.092 Acc 97.019%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.093 Acc 96.989%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.095 Acc 96.961%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.097 Acc 96.922%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.491 Acc 92.188%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.499 Acc 90.602%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.495 Acc 90.726%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.114 Acc 95.312%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.094 Acc 97.061%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.097 Acc 97.003%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.098 Acc 96.968%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.098 Acc 96.943%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.098 Acc 96.955%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.378 Acc 91.406%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.375 Acc 91.824%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.370 Acc 92.048%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.085 Acc 95.312%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.086 Acc 97.254%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.087 Acc 97.209%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.086 Acc 97.218%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.089 Acc 97.152%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.091 Acc 97.092%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.327 Acc 92.969%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.322 Acc 92.613%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.316 Acc 92.825%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.110 Acc 95.312%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.082 Acc 97.300%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.091 Acc 97.054%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.091 Acc 97.062%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.094 Acc 96.986%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.094 Acc 96.978%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.321 Acc 94.531%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.315 Acc 92.837%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.310 Acc 93.062%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.088 Acc 96.983%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.090 Acc 97.073%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.092 Acc 97.018%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.093 Acc 96.998%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.094 Acc 96.959%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.581 Acc 87.500%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.526 Acc 89.101%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.521 Acc 89.303%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.136 Acc 95.312%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.099 Acc 96.813%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.097 Acc 96.976%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.097 Acc 96.922%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.095 Acc 96.972%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.096 Acc 96.950%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.368 Acc 92.188%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.352 Acc 91.878%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.346 Acc 92.051%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.099 Acc 96.875%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.082 Acc 97.362%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.083 Acc 97.264%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.089 Acc 97.155%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.090 Acc 97.134%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.381 Acc 90.625%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.383 Acc 91.298%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.377 Acc 91.461%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.090 Acc 96.094%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.091 Acc 97.155%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.093 Acc 97.127%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.093 Acc 97.078%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.093 Acc 97.057%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.339 Acc 92.188%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.356 Acc 92.288%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.352 Acc 92.425%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.085 Acc 97.339%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.088 Acc 97.178%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.090 Acc 97.116%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.090 Acc 97.120%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.090 Acc 97.103%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.437 Acc 89.844%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.473 Acc 88.885%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.465 Acc 89.082%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.080 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.089 Acc 97.231%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.087 Acc 97.233%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.088 Acc 97.199%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.087 Acc 97.165%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.089 Acc 97.096%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.411 Acc 92.188%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.387 Acc 91.530%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.384 Acc 91.569%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.061 Acc 98.438%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.085 Acc 97.231%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.087 Acc 97.213%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.091 Acc 97.111%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.091 Acc 97.107%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.092 Acc 97.076%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.383 Acc 90.903%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.379 Acc 91.134%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.038 Acc 100.000%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.087 Acc 97.192%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.083 Acc 97.244%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.088 Acc 97.127%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.088 Acc 97.161%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.088 Acc 97.139%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.323 Acc 92.969%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.323 Acc 92.644%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.320 Acc 92.743%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.134 Acc 94.531%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.078 Acc 97.362%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.081 Acc 97.295%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.086 Acc 97.119%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.086 Acc 97.132%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.088 Acc 97.081%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.391 Acc 92.969%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.397 Acc 90.664%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.390 Acc 90.691%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.077 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.083 Acc 97.357%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.084 Acc 97.262%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.084 Acc 97.265%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.086 Acc 97.209%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.317 Acc 94.531%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.332 Acc 92.845%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.328 Acc 92.903%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.086 Acc 97.138%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.084 Acc 97.271%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.088 Acc 97.171%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.089 Acc 97.128%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.090 Acc 97.118%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.507 Acc 89.062%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.524 Acc 88.730%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.521 Acc 88.950%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.055 Acc 99.219%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.086 Acc 97.068%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.088 Acc 97.170%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.089 Acc 97.098%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.089 Acc 97.074%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.091 Acc 97.020%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.349 Acc 92.969%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.370 Acc 91.600%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.365 Acc 91.869%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.108 Acc 96.094%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.086 Acc 97.285%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.086 Acc 97.283%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.089 Acc 97.202%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.088 Acc 97.228%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.088 Acc 97.213%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.382 Acc 90.625%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.357 Acc 91.855%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.351 Acc 91.958%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.082 Acc 96.875%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.094 Acc 96.960%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.086 Acc 97.174%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.085 Acc 97.155%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.085 Acc 97.173%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.086 Acc 97.140%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.361 Acc 91.406%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.320 Acc 92.551%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.318 Acc 92.724%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.086 Acc 97.269%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.086 Acc 97.306%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.085 Acc 97.316%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.087 Acc 97.255%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.086 Acc 97.299%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.387 Acc 92.188%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.381 Acc 91.832%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.376 Acc 91.896%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.063 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.077 Acc 97.401%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.080 Acc 97.404%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.083 Acc 97.334%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.086 Acc 97.224%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.088 Acc 97.148%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.330 Acc 90.625%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.362 Acc 91.979%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.351 Acc 92.230%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.081 Acc 95.312%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.084 Acc 97.231%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.085 Acc 97.236%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.085 Acc 97.225%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.085 Acc 97.243%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.088 Acc 97.196%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.461 Acc 90.625%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.523 Acc 87.353%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.520 Acc 87.247%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.049 Acc 99.219%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.082 Acc 97.316%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.085 Acc 97.236%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.085 Acc 97.207%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.088 Acc 97.120%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.088 Acc 97.095%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.354 Acc 91.406%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.360 Acc 92.079%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.356 Acc 91.954%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.077 Acc 97.517%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.081 Acc 97.392%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.079 Acc 97.423%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.079 Acc 97.440%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.083 Acc 97.344%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.266 Acc 92.188%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.286 Acc 93.549%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.284 Acc 93.416%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.079 Acc 95.312%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.079 Acc 97.432%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.083 Acc 97.295%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.084 Acc 97.280%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.083 Acc 97.309%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.084 Acc 97.284%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.441 Acc 87.500%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.418 Acc 90.300%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.411 Acc 90.559%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.110 Acc 96.875%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.076 Acc 97.432%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.080 Acc 97.419%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.084 Acc 97.306%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.086 Acc 97.245%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.086 Acc 97.251%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.346 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.396 Acc 90.733%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.391 Acc 90.913%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.077 Acc 97.396%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.080 Acc 97.355%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.084 Acc 97.261%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.085 Acc 97.266%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.477 Acc 90.625%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.412 Acc 90.277%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.411 Acc 90.454%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.082 Acc 98.438%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.083 Acc 97.308%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.085 Acc 97.244%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.086 Acc 97.210%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.087 Acc 97.191%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.086 Acc 97.190%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.290 Acc 94.531%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.303 Acc 92.992%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.301 Acc 92.961%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.100 Acc 96.875%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.080 Acc 97.509%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.080 Acc 97.470%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.078 Acc 97.480%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.079 Acc 97.450%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.081 Acc 97.427%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.388 Acc 89.844%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.358 Acc 92.110%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.353 Acc 92.020%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.070 Acc 97.757%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.077 Acc 97.520%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.081 Acc 97.374%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.082 Acc 97.358%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.360 Acc 91.406%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.366 Acc 91.399%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.361 Acc 91.709%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.075 Acc 96.094%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.085 Acc 97.208%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.080 Acc 97.369%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.081 Acc 97.407%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.083 Acc 97.343%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.083 Acc 97.321%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.409 Acc 92.969%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.376 Acc 90.811%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.368 Acc 91.099%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.142 Acc 96.094%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.079 Acc 97.308%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.077 Acc 97.349%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.082 Acc 97.295%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.083 Acc 97.300%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.084 Acc 97.255%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.417 Acc 91.406%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.364 Acc 92.025%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.360 Acc 92.067%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.048 Acc 97.656%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.081 Acc 97.416%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.079 Acc 97.458%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.080 Acc 97.443%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.084 Acc 97.313%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.084 Acc 97.340%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.311 Acc 90.625%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.329 Acc 91.855%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.326 Acc 91.985%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.078 Acc 97.378%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.081 Acc 97.369%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.083 Acc 97.257%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.085 Acc 97.257%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.084 Acc 97.293%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.417 Acc 92.188%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.395 Acc 91.236%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.391 Acc 91.367%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.079 Acc 97.462%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.078 Acc 97.532%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.080 Acc 97.430%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.081 Acc 97.380%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.356 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.378 Acc 91.692%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.372 Acc 91.869%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.078 Acc 97.316%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.077 Acc 97.427%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.077 Acc 97.438%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.078 Acc 97.399%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.079 Acc 97.358%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.389 Acc 92.188%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.430 Acc 89.496%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.424 Acc 89.871%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.067 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.072 Acc 97.741%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.076 Acc 97.571%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.082 Acc 97.368%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.082 Acc 97.399%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.082 Acc 97.366%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.391 Acc 90.625%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.366 Acc 91.894%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.363 Acc 91.970%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.077 Acc 97.486%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.079 Acc 97.462%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.081 Acc 97.433%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.082 Acc 97.407%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.085 Acc 97.319%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.385 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.389 Acc 91.553%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.385 Acc 91.725%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.077 Acc 97.516%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.076 Acc 97.522%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.078 Acc 97.457%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.285 Acc 93.750%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.311 Acc 92.907%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.307 Acc 93.070%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.106 Acc 95.312%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.075 Acc 97.548%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.078 Acc 97.442%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.080 Acc 97.402%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.080 Acc 97.395%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.081 Acc 97.371%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.379 Acc 91.406%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.389 Acc 91.515%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.384 Acc 91.632%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.080 Acc 96.094%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.074 Acc 97.447%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.077 Acc 97.388%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.077 Acc 97.410%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.079 Acc 97.372%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.079 Acc 97.424%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.298 Acc 92.188%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.320 Acc 92.064%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.313 Acc 92.238%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.074 Acc 97.656%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.078 Acc 97.370%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.080 Acc 97.306%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.082 Acc 97.363%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.081 Acc 97.377%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.572 Acc 85.156%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.530 Acc 88.498%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.523 Acc 88.526%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.078 Acc 97.331%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.079 Acc 97.380%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.078 Acc 97.449%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.079 Acc 97.421%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.079 Acc 97.427%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.365 Acc 92.969%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.368 Acc 91.778%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.365 Acc 91.803%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.076 Acc 97.509%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.075 Acc 97.450%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.078 Acc 97.373%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.076 Acc 97.421%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.078 Acc 97.402%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.467 Acc 89.062%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.447 Acc 90.331%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.445 Acc 90.590%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.076 Acc 97.618%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.073 Acc 97.656%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.079 Acc 97.498%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.079 Acc 97.483%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.079 Acc 97.461%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.328 Acc 92.450%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.326 Acc 92.456%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.104 Acc 96.094%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.075 Acc 97.587%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.080 Acc 97.361%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.078 Acc 97.358%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.081 Acc 97.345%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.080 Acc 97.355%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.354 Acc 90.625%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.415 Acc 89.813%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.410 Acc 89.960%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.144 Acc 95.312%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.073 Acc 97.687%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.077 Acc 97.567%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.079 Acc 97.485%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.078 Acc 97.504%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.078 Acc 97.458%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.385 Acc 91.406%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.422 Acc 90.478%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.420 Acc 90.516%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.078 Acc 97.393%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.078 Acc 97.458%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.077 Acc 97.477%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.079 Acc 97.428%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.080 Acc 97.383%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.398 Acc 89.844%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.405 Acc 90.617%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.400 Acc 90.691%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.029 Acc 99.219%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.075 Acc 97.602%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.077 Acc 97.497%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.078 Acc 97.454%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.077 Acc 97.461%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.077 Acc 97.460%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.290 Acc 92.188%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.317 Acc 92.427%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.314 Acc 92.428%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.073 Acc 97.594%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.078 Acc 97.454%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.077 Acc 97.449%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.080 Acc 97.415%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.081 Acc 97.358%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.392 Acc 89.844%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.400 Acc 91.043%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.398 Acc 91.192%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.077 Acc 96.094%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.066 Acc 97.780%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.071 Acc 97.672%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.072 Acc 97.613%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.075 Acc 97.544%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.338 Acc 92.969%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.342 Acc 92.528%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.338 Acc 92.440%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.068 Acc 97.687%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.074 Acc 97.512%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.072 Acc 97.555%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.072 Acc 97.588%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.073 Acc 97.594%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.380 Acc 90.625%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.354 Acc 92.141%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.348 Acc 92.281%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.079 Acc 97.455%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.075 Acc 97.645%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.074 Acc 97.638%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.075 Acc 97.600%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.077 Acc 97.561%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.362 Acc 91.406%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.367 Acc 91.128%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.361 Acc 91.367%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.084 Acc 97.246%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.081 Acc 97.427%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.080 Acc 97.506%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.078 Acc 97.520%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.078 Acc 97.505%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.306 Acc 92.930%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.301 Acc 92.926%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.036 Acc 99.219%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.079 Acc 97.494%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.076 Acc 97.551%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.075 Acc 97.588%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.075 Acc 97.535%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.329 Acc 92.188%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.327 Acc 92.574%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.325 Acc 92.607%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.091 Acc 96.875%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.075 Acc 97.610%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.075 Acc 97.563%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.077 Acc 97.524%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.078 Acc 97.506%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.079 Acc 97.463%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.330 Acc 93.750%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.340 Acc 92.489%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.336 Acc 92.460%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.111 Acc 96.094%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.076 Acc 97.525%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.074 Acc 97.586%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.077 Acc 97.529%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.079 Acc 97.438%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.078 Acc 97.472%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.344 Acc 90.625%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.323 Acc 92.458%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.319 Acc 92.428%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.028 Acc 97.656%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.073 Acc 97.749%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.073 Acc 97.612%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.075 Acc 97.532%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.075 Acc 97.503%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.300 Acc 92.969%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.297 Acc 92.512%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.289 Acc 92.693%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.047 Acc 98.438%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.069 Acc 97.888%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.072 Acc 97.785%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.073 Acc 97.698%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.074 Acc 97.666%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.075 Acc 97.608%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.362 Acc 89.844%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.309 Acc 92.528%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.306 Acc 92.491%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.097 Acc 97.656%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.074 Acc 97.563%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.073 Acc 97.664%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.075 Acc 97.594%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.076 Acc 97.547%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.075 Acc 97.570%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.343 Acc 90.625%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.379 Acc 91.004%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.373 Acc 91.181%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.070 Acc 97.633%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.070 Acc 97.695%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.071 Acc 97.668%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.072 Acc 97.661%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.380 Acc 89.844%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.389 Acc 90.911%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.382 Acc 91.025%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.031 Acc 98.438%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.080 Acc 97.347%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.083 Acc 97.271%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.079 Acc 97.415%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.078 Acc 97.426%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.077 Acc 97.446%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.420 Acc 91.406%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.416 Acc 90.950%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.413 Acc 90.874%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.042 Acc 98.438%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.063 Acc 97.989%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.062 Acc 97.944%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.067 Acc 97.835%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.070 Acc 97.736%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.073 Acc 97.634%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.438 Acc 90.625%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.402 Acc 90.563%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.397 Acc 90.676%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.069 Acc 98.438%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.072 Acc 97.679%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.075 Acc 97.582%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.073 Acc 97.620%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.073 Acc 97.639%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.073 Acc 97.631%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.341 Acc 92.969%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.314 Acc 92.868%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.312 Acc 92.755%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.072 Acc 97.587%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.067 Acc 97.691%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.070 Acc 97.612%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.071 Acc 97.586%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.072 Acc 97.603%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.494 Acc 89.062%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.479 Acc 88.181%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.476 Acc 88.305%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.069 Acc 97.788%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.070 Acc 97.656%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.075 Acc 97.516%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.077 Acc 97.450%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.076 Acc 97.471%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.297 Acc 94.531%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.299 Acc 92.412%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.298 Acc 92.514%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.076 Acc 97.409%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.074 Acc 97.547%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.075 Acc 97.552%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.076 Acc 97.535%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.076 Acc 97.513%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.358 Acc 92.969%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.358 Acc 91.453%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.356 Acc 91.558%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.027 Acc 98.438%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.070 Acc 97.772%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.070 Acc 97.668%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.072 Acc 97.597%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.073 Acc 97.555%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.073 Acc 97.567%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.370 Acc 89.062%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.398 Acc 90.517%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.395 Acc 90.555%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.074 Acc 97.455%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.070 Acc 97.660%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.074 Acc 97.547%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.076 Acc 97.489%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.075 Acc 97.483%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.477 Acc 89.062%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.478 Acc 88.722%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.469 Acc 88.981%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.059 Acc 97.888%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.065 Acc 97.905%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.065 Acc 97.903%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.069 Acc 97.703%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.071 Acc 97.673%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.433 Acc 88.281%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.410 Acc 90.439%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.404 Acc 90.470%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.119 Acc 97.656%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.071 Acc 97.734%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.069 Acc 97.755%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.070 Acc 97.738%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.070 Acc 97.728%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.335 Acc 92.969%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.343 Acc 91.855%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.338 Acc 91.935%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.057 Acc 96.875%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.070 Acc 97.556%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.068 Acc 97.648%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.070 Acc 97.643%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.071 Acc 97.606%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.072 Acc 97.597%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.424 Acc 91.406%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.427 Acc 90.316%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.422 Acc 90.435%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [166/200]Batch [100/573] Loss: 0.065 Acc 97.834%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [200/573] Loss: 0.066 Acc 97.800%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.068 Acc 97.690%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.071 Acc 97.584%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.072 Acc 97.580%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.345 Acc 93.750%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.403 Acc 90.710%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.400 Acc 90.777%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.082 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.070 Acc 97.757%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.067 Acc 97.718%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.069 Acc 97.633%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.069 Acc 97.647%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.069 Acc 97.661%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.249 Acc 94.531%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.291 Acc 92.984%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.288 Acc 93.050%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.079 Acc 96.094%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.064 Acc 97.757%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.066 Acc 97.742%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.069 Acc 97.625%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.071 Acc 97.563%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.073 Acc 97.539%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.355 Acc 90.625%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.368 Acc 91.174%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.365 Acc 91.492%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.068 Acc 97.656%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.079 Acc 97.355%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.076 Acc 97.516%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.073 Acc 97.565%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.073 Acc 97.578%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.073 Acc 97.600%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.386 Acc 91.406%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.359 Acc 91.917%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.353 Acc 91.915%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.116 Acc 96.875%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.069 Acc 97.834%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.073 Acc 97.641%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.072 Acc 97.646%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.069 Acc 97.730%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.070 Acc 97.658%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.518 Acc 87.500%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.492 Acc 89.279%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.491 Acc 89.144%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.044 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.074 Acc 97.664%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.072 Acc 97.660%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.073 Acc 97.633%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.073 Acc 97.596%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.073 Acc 97.645%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.373 Acc 92.969%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.320 Acc 92.721%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.314 Acc 92.786%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.013 Acc 100.000%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.072 Acc 97.710%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.070 Acc 97.800%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.069 Acc 97.825%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.072 Acc 97.700%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.321 Acc 92.969%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.298 Acc 93.363%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.291 Acc 93.342%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.050 Acc 98.438%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.061 Acc 97.904%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.061 Acc 97.967%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.063 Acc 97.898%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.065 Acc 97.851%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.065 Acc 97.843%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.460 Acc 89.844%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.431 Acc 90.989%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.427 Acc 91.080%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.072 Acc 99.219%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.066 Acc 97.842%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.068 Acc 97.808%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.068 Acc 97.830%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.067 Acc 97.818%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.069 Acc 97.723%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.439 Acc 89.062%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.392 Acc 91.321%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.389 Acc 91.383%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.103 Acc 95.312%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.076 Acc 97.424%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.073 Acc 97.637%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.075 Acc 97.617%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.073 Acc 97.639%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.073 Acc 97.617%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.422 Acc 91.406%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.391 Acc 91.190%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.388 Acc 91.165%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.035 Acc 99.219%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.064 Acc 97.795%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.066 Acc 97.726%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.068 Acc 97.659%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.068 Acc 97.687%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.069 Acc 97.658%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.419 Acc 90.625%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.392 Acc 91.197%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.390 Acc 91.185%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.087 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.065 Acc 97.803%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.065 Acc 97.870%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.068 Acc 97.778%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.068 Acc 97.756%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.068 Acc 97.781%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.336 Acc 91.406%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.353 Acc 92.087%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.346 Acc 92.215%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.069 Acc 97.780%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.068 Acc 97.726%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.069 Acc 97.737%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.070 Acc 97.680%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.070 Acc 97.681%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.363 Acc 90.625%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.377 Acc 91.174%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.373 Acc 91.274%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.059 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.061 Acc 97.942%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.062 Acc 97.983%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.064 Acc 97.913%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.067 Acc 97.845%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.337 Acc 92.188%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.348 Acc 92.041%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.346 Acc 91.985%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.063 Acc 98.113%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.069 Acc 97.831%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.069 Acc 97.787%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.070 Acc 97.736%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.355 Acc 93.750%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.396 Acc 91.499%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.390 Acc 91.597%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [181/200]Batch [200/573] Loss: 0.070 Acc 97.668%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [300/573] Loss: 0.070 Acc 97.682%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.070 Acc 97.691%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.070 Acc 97.697%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.365 Acc 89.062%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.387 Acc 91.298%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.382 Acc 91.519%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.025 Acc 100.000%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.068 Acc 97.788%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.070 Acc 97.648%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.070 Acc 97.620%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.070 Acc 97.662%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.070 Acc 97.672%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.335 Acc 89.844%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.351 Acc 91.932%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.342 Acc 91.888%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.062 Acc 98.058%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.065 Acc 97.847%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.068 Acc 97.750%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.070 Acc 97.680%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.071 Acc 97.662%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.475 Acc 87.500%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.482 Acc 89.101%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.481 Acc 89.257%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.088 Acc 97.656%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.061 Acc 97.896%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.065 Acc 97.843%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.067 Acc 97.781%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.067 Acc 97.798%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.066 Acc 97.806%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.356 Acc 91.538%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.350 Acc 91.651%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.125 Acc 96.094%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.063 Acc 98.012%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.066 Acc 97.843%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.065 Acc 97.843%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.065 Acc 97.845%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.066 Acc 97.831%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.419 Acc 89.062%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.421 Acc 90.138%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.414 Acc 90.431%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.006 Acc 100.000%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.059 Acc 98.028%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.058 Acc 98.099%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.061 Acc 97.988%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.064 Acc 97.933%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.064 Acc 97.907%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.343 Acc 92.188%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.353 Acc 92.273%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.349 Acc 92.230%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.039 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.064 Acc 98.035%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.065 Acc 97.936%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.066 Acc 97.877%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.067 Acc 97.867%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.068 Acc 97.801%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.371 Acc 90.625%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.405 Acc 90.463%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.400 Acc 90.714%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.202 Acc 94.531%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.061 Acc 97.850%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.060 Acc 97.952%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.062 Acc 97.937%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.061 Acc 97.978%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.064 Acc 97.923%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.424 Acc 90.625%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.363 Acc 91.592%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.359 Acc 91.807%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.213 Acc 94.531%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.066 Acc 97.927%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.068 Acc 97.812%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.066 Acc 97.848%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.068 Acc 97.763%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.068 Acc 97.769%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.424 Acc 90.625%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.349 Acc 91.832%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.346 Acc 91.877%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.066 Acc 97.950%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.068 Acc 97.886%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.067 Acc 97.841%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.068 Acc 97.808%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.067 Acc 97.820%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.403 Acc 90.625%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.420 Acc 89.921%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.415 Acc 89.964%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.063 Acc 97.912%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.068 Acc 97.816%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.067 Acc 97.830%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.066 Acc 97.839%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.067 Acc 97.787%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.393 Acc 88.281%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.391 Acc 90.068%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.383 Acc 90.427%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.069 Acc 97.703%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.066 Acc 97.819%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.064 Acc 97.892%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.066 Acc 97.878%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.065 Acc 97.882%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.430 Acc 89.062%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.340 Acc 91.754%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.334 Acc 91.904%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.159 Acc 96.094%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.067 Acc 97.718%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.064 Acc 97.874%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.065 Acc 97.864%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.065 Acc 97.830%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.064 Acc 97.900%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.427 Acc 91.406%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.395 Acc 90.718%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.390 Acc 90.808%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.066 Acc 97.772%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.069 Acc 97.827%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.067 Acc 97.916%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.068 Acc 97.834%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.070 Acc 97.770%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.349 Acc 90.625%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.362 Acc 91.615%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.352 Acc 91.795%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.060 Acc 98.051%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.059 Acc 98.060%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.064 Acc 97.884%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.066 Acc 97.825%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.419 Acc 92.188%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.358 Acc 92.002%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.350 Acc 91.954%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.064 Acc 97.834%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.061 Acc 97.975%\n",
      "Train Epoch [196/200]Batch [300/573] Loss: 0.064 Acc 97.952%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [400/573] Loss: 0.065 Acc 97.917%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.064 Acc 97.921%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.343 Acc 93.750%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.330 Acc 92.536%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.324 Acc 92.720%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.061 Acc 98.051%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.062 Acc 97.936%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.063 Acc 97.916%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.062 Acc 97.906%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.063 Acc 97.885%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.298 Acc 92.969%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.372 Acc 90.981%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.366 Acc 91.220%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.037 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.065 Acc 97.935%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.063 Acc 97.998%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.063 Acc 97.963%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.064 Acc 97.941%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.065 Acc 97.893%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.468 Acc 87.500%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.459 Acc 90.207%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.448 Acc 90.345%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.057 Acc 99.219%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.065 Acc 97.857%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.062 Acc 97.901%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.062 Acc 97.942%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.062 Acc 97.929%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.064 Acc 97.879%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.328 Acc 92.188%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.327 Acc 92.613%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.321 Acc 92.553%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7182ba086a1347cb8025eb0c928105cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [  0/200]Batch [  0/573] Loss: 2.305 Acc 7.031%\n",
      "Train Epoch [  0/200]Batch [100/573] Loss: 3.068 Acc 15.934%\n",
      "Train Epoch [  0/200]Batch [200/573] Loss: 2.657 Acc 17.211%\n",
      "Train Epoch [  0/200]Batch [300/573] Loss: 2.516 Acc 17.943%\n",
      "Train Epoch [  0/200]Batch [400/573] Loss: 2.446 Acc 18.191%\n",
      "Train Epoch [  0/200]Batch [500/573] Loss: 2.404 Acc 18.335%\n",
      "Test Epoch [  0/200]Batch [  0/204] Loss: 2.196 Acc 23.438%\n",
      "Test Epoch [  0/200]Batch [100/204] Loss: 2.213 Acc 19.516%\n",
      "Test Epoch [  0/200]Batch [200/204] Loss: 2.214 Acc 19.574%\n",
      "Train Epoch [  1/200]Batch [  0/573] Loss: 2.292 Acc 14.844%\n",
      "Train Epoch [  1/200]Batch [100/573] Loss: 2.229 Acc 18.943%\n",
      "Train Epoch [  1/200]Batch [200/573] Loss: 2.221 Acc 18.972%\n",
      "Train Epoch [  1/200]Batch [300/573] Loss: 2.146 Acc 22.314%\n",
      "Train Epoch [  1/200]Batch [400/573] Loss: 1.971 Acc 29.489%\n",
      "Train Epoch [  1/200]Batch [500/573] Loss: 1.781 Acc 36.940%\n",
      "Test Epoch [  1/200]Batch [  0/204] Loss: 0.928 Acc 73.438%\n",
      "Test Epoch [  1/200]Batch [100/204] Loss: 0.863 Acc 72.223%\n",
      "Test Epoch [  1/200]Batch [200/204] Loss: 0.857 Acc 72.252%\n",
      "Train Epoch [  2/200]Batch [  0/573] Loss: 0.735 Acc 76.562%\n",
      "Train Epoch [  2/200]Batch [100/573] Loss: 0.647 Acc 79.780%\n",
      "Train Epoch [  2/200]Batch [200/573] Loss: 0.589 Acc 81.685%\n",
      "Train Epoch [  2/200]Batch [300/573] Loss: 0.550 Acc 82.903%\n",
      "Train Epoch [  2/200]Batch [400/573] Loss: 0.524 Acc 83.765%\n",
      "Train Epoch [  2/200]Batch [500/573] Loss: 0.504 Acc 84.398%\n",
      "Test Epoch [  2/200]Batch [  0/204] Loss: 0.570 Acc 83.594%\n",
      "Test Epoch [  2/200]Batch [100/204] Loss: 0.486 Acc 84.901%\n",
      "Test Epoch [  2/200]Batch [200/204] Loss: 0.477 Acc 85.102%\n",
      "Train Epoch [  3/200]Batch [  0/573] Loss: 0.228 Acc 92.969%\n",
      "Train Epoch [  3/200]Batch [100/573] Loss: 0.398 Acc 87.740%\n",
      "Train Epoch [  3/200]Batch [200/573] Loss: 0.380 Acc 88.371%\n",
      "Train Epoch [  3/200]Batch [300/573] Loss: 0.375 Acc 88.637%\n",
      "Train Epoch [  3/200]Batch [400/573] Loss: 0.373 Acc 88.681%\n",
      "Train Epoch [  3/200]Batch [500/573] Loss: 0.374 Acc 88.680%\n",
      "Test Epoch [  3/200]Batch [  0/204] Loss: 0.426 Acc 86.719%\n",
      "Test Epoch [  3/200]Batch [100/204] Loss: 0.351 Acc 89.349%\n",
      "Test Epoch [  3/200]Batch [200/204] Loss: 0.344 Acc 89.626%\n",
      "Train Epoch [  4/200]Batch [  0/573] Loss: 0.411 Acc 83.594%\n",
      "Train Epoch [  4/200]Batch [100/573] Loss: 0.328 Acc 89.728%\n",
      "Train Epoch [  4/200]Batch [200/573] Loss: 0.333 Acc 89.883%\n",
      "Train Epoch [  4/200]Batch [300/573] Loss: 0.333 Acc 89.839%\n",
      "Train Epoch [  4/200]Batch [400/573] Loss: 0.334 Acc 89.891%\n",
      "Train Epoch [  4/200]Batch [500/573] Loss: 0.333 Acc 90.004%\n",
      "Test Epoch [  4/200]Batch [  0/204] Loss: 0.441 Acc 89.844%\n",
      "Test Epoch [  4/200]Batch [100/204] Loss: 0.366 Acc 90.942%\n",
      "Test Epoch [  4/200]Batch [200/204] Loss: 0.363 Acc 91.072%\n",
      "Train Epoch [  5/200]Batch [  0/573] Loss: 0.200 Acc 96.875%\n",
      "Train Epoch [  5/200]Batch [100/573] Loss: 0.310 Acc 90.610%\n",
      "Train Epoch [  5/200]Batch [200/573] Loss: 0.306 Acc 90.668%\n",
      "Train Epoch [  5/200]Batch [300/573] Loss: 0.309 Acc 90.558%\n",
      "Train Epoch [  5/200]Batch [400/573] Loss: 0.309 Acc 90.641%\n",
      "Train Epoch [  5/200]Batch [500/573] Loss: 0.308 Acc 90.706%\n",
      "Test Epoch [  5/200]Batch [  0/204] Loss: 0.546 Acc 82.031%\n",
      "Test Epoch [  5/200]Batch [100/204] Loss: 0.467 Acc 85.218%\n",
      "Test Epoch [  5/200]Batch [200/204] Loss: 0.459 Acc 85.483%\n",
      "Train Epoch [  6/200]Batch [  0/573] Loss: 0.466 Acc 90.625%\n",
      "Train Epoch [  6/200]Batch [100/573] Loss: 0.290 Acc 91.515%\n",
      "Train Epoch [  6/200]Batch [200/573] Loss: 0.287 Acc 91.527%\n",
      "Train Epoch [  6/200]Batch [300/573] Loss: 0.295 Acc 91.331%\n",
      "Train Epoch [  6/200]Batch [400/573] Loss: 0.300 Acc 91.149%\n",
      "Train Epoch [  6/200]Batch [500/573] Loss: 0.298 Acc 91.199%\n",
      "Test Epoch [  6/200]Batch [  0/204] Loss: 0.330 Acc 92.969%\n",
      "Test Epoch [  6/200]Batch [100/204] Loss: 0.312 Acc 92.837%\n",
      "Test Epoch [  6/200]Batch [200/204] Loss: 0.307 Acc 93.101%\n",
      "Train Epoch [  7/200]Batch [  0/573] Loss: 0.321 Acc 92.188%\n",
      "Train Epoch [  7/200]Batch [100/573] Loss: 0.290 Acc 91.437%\n",
      "Train Epoch [  7/200]Batch [200/573] Loss: 0.286 Acc 91.500%\n",
      "Train Epoch [  7/200]Batch [300/573] Loss: 0.282 Acc 91.604%\n",
      "Train Epoch [  7/200]Batch [400/573] Loss: 0.279 Acc 91.683%\n",
      "Train Epoch [  7/200]Batch [500/573] Loss: 0.281 Acc 91.653%\n",
      "Test Epoch [  7/200]Batch [  0/204] Loss: 0.271 Acc 89.844%\n",
      "Test Epoch [  7/200]Batch [100/204] Loss: 0.281 Acc 92.489%\n",
      "Test Epoch [  7/200]Batch [200/204] Loss: 0.279 Acc 92.576%\n",
      "Train Epoch [  8/200]Batch [  0/573] Loss: 0.284 Acc 92.188%\n",
      "Train Epoch [  8/200]Batch [100/573] Loss: 0.269 Acc 91.971%\n",
      "Train Epoch [  8/200]Batch [200/573] Loss: 0.265 Acc 92.153%\n",
      "Train Epoch [  8/200]Batch [300/573] Loss: 0.273 Acc 91.928%\n",
      "Train Epoch [  8/200]Batch [400/573] Loss: 0.270 Acc 92.045%\n",
      "Train Epoch [  8/200]Batch [500/573] Loss: 0.272 Acc 92.033%\n",
      "Test Epoch [  8/200]Batch [  0/204] Loss: 0.331 Acc 87.500%\n",
      "Test Epoch [  8/200]Batch [100/204] Loss: 0.308 Acc 92.126%\n",
      "Test Epoch [  8/200]Batch [200/204] Loss: 0.303 Acc 92.312%\n",
      "Train Epoch [  9/200]Batch [  0/573] Loss: 0.209 Acc 92.969%\n",
      "Train Epoch [  9/200]Batch [100/573] Loss: 0.264 Acc 92.025%\n",
      "Train Epoch [  9/200]Batch [200/573] Loss: 0.259 Acc 92.324%\n",
      "Train Epoch [  9/200]Batch [300/573] Loss: 0.259 Acc 92.322%\n",
      "Train Epoch [  9/200]Batch [400/573] Loss: 0.260 Acc 92.357%\n",
      "Train Epoch [  9/200]Batch [500/573] Loss: 0.263 Acc 92.300%\n",
      "Test Epoch [  9/200]Batch [  0/204] Loss: 0.365 Acc 92.188%\n",
      "Test Epoch [  9/200]Batch [100/204] Loss: 0.310 Acc 91.979%\n",
      "Test Epoch [  9/200]Batch [200/204] Loss: 0.305 Acc 92.277%\n",
      "Train Epoch [ 10/200]Batch [  0/573] Loss: 0.272 Acc 92.188%\n",
      "Train Epoch [ 10/200]Batch [100/573] Loss: 0.253 Acc 92.698%\n",
      "Train Epoch [ 10/200]Batch [200/573] Loss: 0.256 Acc 92.572%\n",
      "Train Epoch [ 10/200]Batch [300/573] Loss: 0.257 Acc 92.457%\n",
      "Train Epoch [ 10/200]Batch [400/573] Loss: 0.260 Acc 92.412%\n",
      "Train Epoch [ 10/200]Batch [500/573] Loss: 0.262 Acc 92.361%\n",
      "Test Epoch [ 10/200]Batch [  0/204] Loss: 0.227 Acc 92.969%\n",
      "Test Epoch [ 10/200]Batch [100/204] Loss: 0.266 Acc 92.667%\n",
      "Test Epoch [ 10/200]Batch [200/204] Loss: 0.258 Acc 92.938%\n",
      "Train Epoch [ 11/200]Batch [  0/573] Loss: 0.290 Acc 93.750%\n",
      "Train Epoch [ 11/200]Batch [100/573] Loss: 0.260 Acc 92.853%\n",
      "Train Epoch [ 11/200]Batch [200/573] Loss: 0.261 Acc 92.413%\n",
      "Train Epoch [ 11/200]Batch [300/573] Loss: 0.257 Acc 92.447%\n",
      "Train Epoch [ 11/200]Batch [400/573] Loss: 0.255 Acc 92.538%\n",
      "Train Epoch [ 11/200]Batch [500/573] Loss: 0.255 Acc 92.546%\n",
      "Test Epoch [ 11/200]Batch [  0/204] Loss: 0.341 Acc 91.406%\n",
      "Test Epoch [ 11/200]Batch [100/204] Loss: 0.313 Acc 92.404%\n",
      "Test Epoch [ 11/200]Batch [200/204] Loss: 0.307 Acc 92.631%\n",
      "Train Epoch [ 12/200]Batch [  0/573] Loss: 0.137 Acc 95.312%\n",
      "Train Epoch [ 12/200]Batch [100/573] Loss: 0.236 Acc 93.054%\n",
      "Train Epoch [ 12/200]Batch [200/573] Loss: 0.242 Acc 92.980%\n",
      "Train Epoch [ 12/200]Batch [300/573] Loss: 0.246 Acc 92.813%\n",
      "Train Epoch [ 12/200]Batch [400/573] Loss: 0.251 Acc 92.700%\n",
      "Train Epoch [ 12/200]Batch [500/573] Loss: 0.252 Acc 92.679%\n",
      "Test Epoch [ 12/200]Batch [  0/204] Loss: 0.414 Acc 88.281%\n",
      "Test Epoch [ 12/200]Batch [100/204] Loss: 0.364 Acc 89.148%\n",
      "Test Epoch [ 12/200]Batch [200/204] Loss: 0.356 Acc 89.269%\n",
      "Train Epoch [ 13/200]Batch [  0/573] Loss: 0.384 Acc 91.406%\n",
      "Train Epoch [ 13/200]Batch [100/573] Loss: 0.252 Acc 92.737%\n",
      "Train Epoch [ 13/200]Batch [200/573] Loss: 0.242 Acc 93.070%\n",
      "Train Epoch [ 13/200]Batch [300/573] Loss: 0.241 Acc 93.156%\n",
      "Train Epoch [ 13/200]Batch [400/573] Loss: 0.241 Acc 93.142%\n",
      "Train Epoch [ 13/200]Batch [500/573] Loss: 0.241 Acc 93.058%\n",
      "Test Epoch [ 13/200]Batch [  0/204] Loss: 0.323 Acc 91.406%\n",
      "Test Epoch [ 13/200]Batch [100/204] Loss: 0.307 Acc 91.437%\n",
      "Test Epoch [ 13/200]Batch [200/204] Loss: 0.302 Acc 91.639%\n",
      "Train Epoch [ 14/200]Batch [  0/573] Loss: 0.179 Acc 94.531%\n",
      "Train Epoch [ 14/200]Batch [100/573] Loss: 0.232 Acc 93.317%\n",
      "Train Epoch [ 14/200]Batch [200/573] Loss: 0.233 Acc 93.272%\n",
      "Train Epoch [ 14/200]Batch [300/573] Loss: 0.235 Acc 93.187%\n",
      "Train Epoch [ 14/200]Batch [400/573] Loss: 0.235 Acc 93.187%\n",
      "Train Epoch [ 14/200]Batch [500/573] Loss: 0.235 Acc 93.207%\n",
      "Test Epoch [ 14/200]Batch [  0/204] Loss: 0.396 Acc 90.625%\n",
      "Test Epoch [ 14/200]Batch [100/204] Loss: 0.349 Acc 92.311%\n",
      "Test Epoch [ 14/200]Batch [200/204] Loss: 0.342 Acc 92.627%\n",
      "Train Epoch [ 15/200]Batch [  0/573] Loss: 0.233 Acc 93.750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 15/200]Batch [100/573] Loss: 0.228 Acc 93.680%\n",
      "Train Epoch [ 15/200]Batch [200/573] Loss: 0.237 Acc 93.210%\n",
      "Train Epoch [ 15/200]Batch [300/573] Loss: 0.236 Acc 93.278%\n",
      "Train Epoch [ 15/200]Batch [400/573] Loss: 0.236 Acc 93.280%\n",
      "Train Epoch [ 15/200]Batch [500/573] Loss: 0.233 Acc 93.309%\n",
      "Test Epoch [ 15/200]Batch [  0/204] Loss: 0.353 Acc 92.969%\n",
      "Test Epoch [ 15/200]Batch [100/204] Loss: 0.375 Acc 91.955%\n",
      "Test Epoch [ 15/200]Batch [200/204] Loss: 0.369 Acc 92.226%\n",
      "Train Epoch [ 16/200]Batch [  0/573] Loss: 0.315 Acc 86.719%\n",
      "Train Epoch [ 16/200]Batch [100/573] Loss: 0.208 Acc 93.912%\n",
      "Train Epoch [ 16/200]Batch [200/573] Loss: 0.215 Acc 93.762%\n",
      "Train Epoch [ 16/200]Batch [300/573] Loss: 0.219 Acc 93.607%\n",
      "Train Epoch [ 16/200]Batch [400/573] Loss: 0.226 Acc 93.577%\n",
      "Train Epoch [ 16/200]Batch [500/573] Loss: 0.226 Acc 93.555%\n",
      "Test Epoch [ 16/200]Batch [  0/204] Loss: 0.521 Acc 90.625%\n",
      "Test Epoch [ 16/200]Batch [100/204] Loss: 0.486 Acc 91.708%\n",
      "Test Epoch [ 16/200]Batch [200/204] Loss: 0.483 Acc 91.842%\n",
      "Train Epoch [ 17/200]Batch [  0/573] Loss: 0.216 Acc 93.750%\n",
      "Train Epoch [ 17/200]Batch [100/573] Loss: 0.212 Acc 93.990%\n",
      "Train Epoch [ 17/200]Batch [200/573] Loss: 0.207 Acc 93.995%\n",
      "Train Epoch [ 17/200]Batch [300/573] Loss: 0.215 Acc 93.825%\n",
      "Train Epoch [ 17/200]Batch [400/573] Loss: 0.216 Acc 93.777%\n",
      "Train Epoch [ 17/200]Batch [500/573] Loss: 0.216 Acc 93.811%\n",
      "Test Epoch [ 17/200]Batch [  0/204] Loss: 0.377 Acc 85.938%\n",
      "Test Epoch [ 17/200]Batch [100/204] Loss: 0.348 Acc 90.989%\n",
      "Test Epoch [ 17/200]Batch [200/204] Loss: 0.343 Acc 91.146%\n",
      "Train Epoch [ 18/200]Batch [  0/573] Loss: 0.135 Acc 92.969%\n",
      "Train Epoch [ 18/200]Batch [100/573] Loss: 0.216 Acc 94.028%\n",
      "Train Epoch [ 18/200]Batch [200/573] Loss: 0.212 Acc 94.100%\n",
      "Train Epoch [ 18/200]Batch [300/573] Loss: 0.213 Acc 94.033%\n",
      "Train Epoch [ 18/200]Batch [400/573] Loss: 0.213 Acc 93.988%\n",
      "Train Epoch [ 18/200]Batch [500/573] Loss: 0.214 Acc 93.943%\n",
      "Test Epoch [ 18/200]Batch [  0/204] Loss: 0.278 Acc 93.750%\n",
      "Test Epoch [ 18/200]Batch [100/204] Loss: 0.260 Acc 94.152%\n",
      "Test Epoch [ 18/200]Batch [200/204] Loss: 0.256 Acc 94.286%\n",
      "Train Epoch [ 19/200]Batch [  0/573] Loss: 0.165 Acc 94.531%\n",
      "Train Epoch [ 19/200]Batch [100/573] Loss: 0.210 Acc 94.005%\n",
      "Train Epoch [ 19/200]Batch [200/573] Loss: 0.211 Acc 94.065%\n",
      "Train Epoch [ 19/200]Batch [300/573] Loss: 0.212 Acc 93.978%\n",
      "Train Epoch [ 19/200]Batch [400/573] Loss: 0.212 Acc 93.955%\n",
      "Train Epoch [ 19/200]Batch [500/573] Loss: 0.213 Acc 93.931%\n",
      "Test Epoch [ 19/200]Batch [  0/204] Loss: 0.307 Acc 89.062%\n",
      "Test Epoch [ 19/200]Batch [100/204] Loss: 0.275 Acc 93.317%\n",
      "Test Epoch [ 19/200]Batch [200/204] Loss: 0.273 Acc 93.155%\n",
      "Train Epoch [ 20/200]Batch [  0/573] Loss: 0.220 Acc 91.406%\n",
      "Train Epoch [ 20/200]Batch [100/573] Loss: 0.195 Acc 94.477%\n",
      "Train Epoch [ 20/200]Batch [200/573] Loss: 0.198 Acc 94.185%\n",
      "Train Epoch [ 20/200]Batch [300/573] Loss: 0.199 Acc 94.145%\n",
      "Train Epoch [ 20/200]Batch [400/573] Loss: 0.205 Acc 94.071%\n",
      "Train Epoch [ 20/200]Batch [500/573] Loss: 0.205 Acc 94.109%\n",
      "Test Epoch [ 20/200]Batch [  0/204] Loss: 0.197 Acc 95.312%\n",
      "Test Epoch [ 20/200]Batch [100/204] Loss: 0.253 Acc 93.889%\n",
      "Test Epoch [ 20/200]Batch [200/204] Loss: 0.247 Acc 94.018%\n",
      "Train Epoch [ 21/200]Batch [  0/573] Loss: 0.112 Acc 94.531%\n",
      "Train Epoch [ 21/200]Batch [100/573] Loss: 0.192 Acc 94.353%\n",
      "Train Epoch [ 21/200]Batch [200/573] Loss: 0.197 Acc 94.224%\n",
      "Train Epoch [ 21/200]Batch [300/573] Loss: 0.201 Acc 94.186%\n",
      "Train Epoch [ 21/200]Batch [400/573] Loss: 0.202 Acc 94.202%\n",
      "Train Epoch [ 21/200]Batch [500/573] Loss: 0.201 Acc 94.221%\n",
      "Test Epoch [ 21/200]Batch [  0/204] Loss: 0.326 Acc 92.188%\n",
      "Test Epoch [ 21/200]Batch [100/204] Loss: 0.280 Acc 92.830%\n",
      "Test Epoch [ 21/200]Batch [200/204] Loss: 0.272 Acc 93.183%\n",
      "Train Epoch [ 22/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 22/200]Batch [100/573] Loss: 0.179 Acc 94.632%\n",
      "Train Epoch [ 22/200]Batch [200/573] Loss: 0.183 Acc 94.764%\n",
      "Train Epoch [ 22/200]Batch [300/573] Loss: 0.191 Acc 94.583%\n",
      "Train Epoch [ 22/200]Batch [400/573] Loss: 0.194 Acc 94.562%\n",
      "Train Epoch [ 22/200]Batch [500/573] Loss: 0.198 Acc 94.491%\n",
      "Test Epoch [ 22/200]Batch [  0/204] Loss: 0.236 Acc 94.531%\n",
      "Test Epoch [ 22/200]Batch [100/204] Loss: 0.247 Acc 93.727%\n",
      "Test Epoch [ 22/200]Batch [200/204] Loss: 0.244 Acc 93.913%\n",
      "Train Epoch [ 23/200]Batch [  0/573] Loss: 0.176 Acc 94.531%\n",
      "Train Epoch [ 23/200]Batch [100/573] Loss: 0.199 Acc 94.253%\n",
      "Train Epoch [ 23/200]Batch [200/573] Loss: 0.192 Acc 94.582%\n",
      "Train Epoch [ 23/200]Batch [300/573] Loss: 0.192 Acc 94.573%\n",
      "Train Epoch [ 23/200]Batch [400/573] Loss: 0.194 Acc 94.465%\n",
      "Train Epoch [ 23/200]Batch [500/573] Loss: 0.194 Acc 94.497%\n",
      "Test Epoch [ 23/200]Batch [  0/204] Loss: 0.360 Acc 93.750%\n",
      "Test Epoch [ 23/200]Batch [100/204] Loss: 0.359 Acc 93.015%\n",
      "Test Epoch [ 23/200]Batch [200/204] Loss: 0.354 Acc 93.155%\n",
      "Train Epoch [ 24/200]Batch [  0/573] Loss: 0.167 Acc 95.312%\n",
      "Train Epoch [ 24/200]Batch [100/573] Loss: 0.181 Acc 95.057%\n",
      "Train Epoch [ 24/200]Batch [200/573] Loss: 0.178 Acc 95.005%\n",
      "Train Epoch [ 24/200]Batch [300/573] Loss: 0.185 Acc 94.788%\n",
      "Train Epoch [ 24/200]Batch [400/573] Loss: 0.189 Acc 94.714%\n",
      "Train Epoch [ 24/200]Batch [500/573] Loss: 0.189 Acc 94.711%\n",
      "Test Epoch [ 24/200]Batch [  0/204] Loss: 0.300 Acc 92.969%\n",
      "Test Epoch [ 24/200]Batch [100/204] Loss: 0.278 Acc 94.021%\n",
      "Test Epoch [ 24/200]Batch [200/204] Loss: 0.273 Acc 93.987%\n",
      "Train Epoch [ 25/200]Batch [  0/573] Loss: 0.215 Acc 92.969%\n",
      "Train Epoch [ 25/200]Batch [100/573] Loss: 0.171 Acc 94.910%\n",
      "Train Epoch [ 25/200]Batch [200/573] Loss: 0.175 Acc 94.932%\n",
      "Train Epoch [ 25/200]Batch [300/573] Loss: 0.181 Acc 94.817%\n",
      "Train Epoch [ 25/200]Batch [400/573] Loss: 0.184 Acc 94.714%\n",
      "Train Epoch [ 25/200]Batch [500/573] Loss: 0.186 Acc 94.633%\n",
      "Test Epoch [ 25/200]Batch [  0/204] Loss: 0.194 Acc 94.531%\n",
      "Test Epoch [ 25/200]Batch [100/204] Loss: 0.245 Acc 94.052%\n",
      "Test Epoch [ 25/200]Batch [200/204] Loss: 0.239 Acc 94.228%\n",
      "Train Epoch [ 26/200]Batch [  0/573] Loss: 0.109 Acc 96.875%\n",
      "Train Epoch [ 26/200]Batch [100/573] Loss: 0.174 Acc 95.019%\n",
      "Train Epoch [ 26/200]Batch [200/573] Loss: 0.178 Acc 94.963%\n",
      "Train Epoch [ 26/200]Batch [300/573] Loss: 0.181 Acc 94.845%\n",
      "Train Epoch [ 26/200]Batch [400/573] Loss: 0.183 Acc 94.839%\n",
      "Train Epoch [ 26/200]Batch [500/573] Loss: 0.187 Acc 94.729%\n",
      "Test Epoch [ 26/200]Batch [  0/204] Loss: 0.270 Acc 93.750%\n",
      "Test Epoch [ 26/200]Batch [100/204] Loss: 0.247 Acc 94.508%\n",
      "Test Epoch [ 26/200]Batch [200/204] Loss: 0.240 Acc 94.792%\n",
      "Train Epoch [ 27/200]Batch [  0/573] Loss: 0.226 Acc 92.188%\n",
      "Train Epoch [ 27/200]Batch [100/573] Loss: 0.183 Acc 94.980%\n",
      "Train Epoch [ 27/200]Batch [200/573] Loss: 0.178 Acc 95.044%\n",
      "Train Epoch [ 27/200]Batch [300/573] Loss: 0.180 Acc 94.957%\n",
      "Train Epoch [ 27/200]Batch [400/573] Loss: 0.181 Acc 94.903%\n",
      "Train Epoch [ 27/200]Batch [500/573] Loss: 0.179 Acc 94.966%\n",
      "Test Epoch [ 27/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [ 27/200]Batch [100/204] Loss: 0.237 Acc 93.804%\n",
      "Test Epoch [ 27/200]Batch [200/204] Loss: 0.232 Acc 93.905%\n",
      "Train Epoch [ 28/200]Batch [  0/573] Loss: 0.172 Acc 93.750%\n",
      "Train Epoch [ 28/200]Batch [100/573] Loss: 0.174 Acc 95.150%\n",
      "Train Epoch [ 28/200]Batch [200/573] Loss: 0.172 Acc 95.064%\n",
      "Train Epoch [ 28/200]Batch [300/573] Loss: 0.174 Acc 95.092%\n",
      "Train Epoch [ 28/200]Batch [400/573] Loss: 0.174 Acc 95.079%\n",
      "Train Epoch [ 28/200]Batch [500/573] Loss: 0.174 Acc 95.079%\n",
      "Test Epoch [ 28/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [ 28/200]Batch [100/204] Loss: 0.226 Acc 94.833%\n",
      "Test Epoch [ 28/200]Batch [200/204] Loss: 0.223 Acc 94.683%\n",
      "Train Epoch [ 29/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [ 29/200]Batch [100/573] Loss: 0.162 Acc 95.351%\n",
      "Train Epoch [ 29/200]Batch [200/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 29/200]Batch [300/573] Loss: 0.170 Acc 95.209%\n",
      "Train Epoch [ 29/200]Batch [400/573] Loss: 0.169 Acc 95.221%\n",
      "Train Epoch [ 29/200]Batch [500/573] Loss: 0.171 Acc 95.183%\n",
      "Test Epoch [ 29/200]Batch [  0/204] Loss: 0.290 Acc 91.406%\n",
      "Test Epoch [ 29/200]Batch [100/204] Loss: 0.282 Acc 92.969%\n",
      "Test Epoch [ 29/200]Batch [200/204] Loss: 0.278 Acc 93.116%\n",
      "Train Epoch [ 30/200]Batch [  0/573] Loss: 0.209 Acc 93.750%\n",
      "Train Epoch [ 30/200]Batch [100/573] Loss: 0.169 Acc 95.343%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 30/200]Batch [200/573] Loss: 0.164 Acc 95.359%\n",
      "Train Epoch [ 30/200]Batch [300/573] Loss: 0.169 Acc 95.203%\n",
      "Train Epoch [ 30/200]Batch [400/573] Loss: 0.168 Acc 95.192%\n",
      "Train Epoch [ 30/200]Batch [500/573] Loss: 0.168 Acc 95.188%\n",
      "Test Epoch [ 30/200]Batch [  0/204] Loss: 0.205 Acc 93.750%\n",
      "Test Epoch [ 30/200]Batch [100/204] Loss: 0.203 Acc 94.477%\n",
      "Test Epoch [ 30/200]Batch [200/204] Loss: 0.197 Acc 94.741%\n",
      "Train Epoch [ 31/200]Batch [  0/573] Loss: 0.133 Acc 95.312%\n",
      "Train Epoch [ 31/200]Batch [100/573] Loss: 0.169 Acc 95.398%\n",
      "Train Epoch [ 31/200]Batch [200/573] Loss: 0.162 Acc 95.476%\n",
      "Train Epoch [ 31/200]Batch [300/573] Loss: 0.160 Acc 95.546%\n",
      "Train Epoch [ 31/200]Batch [400/573] Loss: 0.163 Acc 95.416%\n",
      "Train Epoch [ 31/200]Batch [500/573] Loss: 0.166 Acc 95.305%\n",
      "Test Epoch [ 31/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [ 31/200]Batch [100/204] Loss: 0.232 Acc 94.415%\n",
      "Test Epoch [ 31/200]Batch [200/204] Loss: 0.227 Acc 94.457%\n",
      "Train Epoch [ 32/200]Batch [  0/573] Loss: 0.142 Acc 97.656%\n",
      "Train Epoch [ 32/200]Batch [100/573] Loss: 0.152 Acc 95.730%\n",
      "Train Epoch [ 32/200]Batch [200/573] Loss: 0.154 Acc 95.674%\n",
      "Train Epoch [ 32/200]Batch [300/573] Loss: 0.155 Acc 95.629%\n",
      "Train Epoch [ 32/200]Batch [400/573] Loss: 0.157 Acc 95.556%\n",
      "Train Epoch [ 32/200]Batch [500/573] Loss: 0.160 Acc 95.448%\n",
      "Test Epoch [ 32/200]Batch [  0/204] Loss: 0.249 Acc 96.094%\n",
      "Test Epoch [ 32/200]Batch [100/204] Loss: 0.265 Acc 93.858%\n",
      "Test Epoch [ 32/200]Batch [200/204] Loss: 0.261 Acc 93.952%\n",
      "Train Epoch [ 33/200]Batch [  0/573] Loss: 0.059 Acc 97.656%\n",
      "Train Epoch [ 33/200]Batch [100/573] Loss: 0.150 Acc 95.761%\n",
      "Train Epoch [ 33/200]Batch [200/573] Loss: 0.158 Acc 95.588%\n",
      "Train Epoch [ 33/200]Batch [300/573] Loss: 0.161 Acc 95.512%\n",
      "Train Epoch [ 33/200]Batch [400/573] Loss: 0.158 Acc 95.583%\n",
      "Train Epoch [ 33/200]Batch [500/573] Loss: 0.159 Acc 95.464%\n",
      "Test Epoch [ 33/200]Batch [  0/204] Loss: 0.220 Acc 92.969%\n",
      "Test Epoch [ 33/200]Batch [100/204] Loss: 0.223 Acc 95.135%\n",
      "Test Epoch [ 33/200]Batch [200/204] Loss: 0.217 Acc 95.332%\n",
      "Train Epoch [ 34/200]Batch [  0/573] Loss: 0.116 Acc 94.531%\n",
      "Train Epoch [ 34/200]Batch [100/573] Loss: 0.157 Acc 95.498%\n",
      "Train Epoch [ 34/200]Batch [200/573] Loss: 0.158 Acc 95.456%\n",
      "Train Epoch [ 34/200]Batch [300/573] Loss: 0.156 Acc 95.567%\n",
      "Train Epoch [ 34/200]Batch [400/573] Loss: 0.155 Acc 95.607%\n",
      "Train Epoch [ 34/200]Batch [500/573] Loss: 0.157 Acc 95.501%\n",
      "Test Epoch [ 34/200]Batch [  0/204] Loss: 0.263 Acc 93.750%\n",
      "Test Epoch [ 34/200]Batch [100/204] Loss: 0.272 Acc 94.206%\n",
      "Test Epoch [ 34/200]Batch [200/204] Loss: 0.268 Acc 94.259%\n",
      "Train Epoch [ 35/200]Batch [  0/573] Loss: 0.052 Acc 99.219%\n",
      "Train Epoch [ 35/200]Batch [100/573] Loss: 0.154 Acc 95.668%\n",
      "Train Epoch [ 35/200]Batch [200/573] Loss: 0.153 Acc 95.565%\n",
      "Train Epoch [ 35/200]Batch [300/573] Loss: 0.154 Acc 95.551%\n",
      "Train Epoch [ 35/200]Batch [400/573] Loss: 0.157 Acc 95.463%\n",
      "Train Epoch [ 35/200]Batch [500/573] Loss: 0.160 Acc 95.412%\n",
      "Test Epoch [ 35/200]Batch [  0/204] Loss: 0.221 Acc 92.969%\n",
      "Test Epoch [ 35/200]Batch [100/204] Loss: 0.203 Acc 95.111%\n",
      "Test Epoch [ 35/200]Batch [200/204] Loss: 0.197 Acc 95.316%\n",
      "Train Epoch [ 36/200]Batch [  0/573] Loss: 0.128 Acc 96.875%\n",
      "Train Epoch [ 36/200]Batch [100/573] Loss: 0.149 Acc 95.862%\n",
      "Train Epoch [ 36/200]Batch [200/573] Loss: 0.152 Acc 95.763%\n",
      "Train Epoch [ 36/200]Batch [300/573] Loss: 0.151 Acc 95.764%\n",
      "Train Epoch [ 36/200]Batch [400/573] Loss: 0.153 Acc 95.720%\n",
      "Train Epoch [ 36/200]Batch [500/573] Loss: 0.155 Acc 95.642%\n",
      "Test Epoch [ 36/200]Batch [  0/204] Loss: 0.204 Acc 95.312%\n",
      "Test Epoch [ 36/200]Batch [100/204] Loss: 0.249 Acc 94.438%\n",
      "Test Epoch [ 36/200]Batch [200/204] Loss: 0.247 Acc 94.512%\n",
      "Train Epoch [ 37/200]Batch [  0/573] Loss: 0.199 Acc 96.094%\n",
      "Train Epoch [ 37/200]Batch [100/573] Loss: 0.151 Acc 95.838%\n",
      "Train Epoch [ 37/200]Batch [200/573] Loss: 0.147 Acc 95.771%\n",
      "Train Epoch [ 37/200]Batch [300/573] Loss: 0.145 Acc 95.795%\n",
      "Train Epoch [ 37/200]Batch [400/573] Loss: 0.144 Acc 95.819%\n",
      "Train Epoch [ 37/200]Batch [500/573] Loss: 0.145 Acc 95.777%\n",
      "Test Epoch [ 37/200]Batch [  0/204] Loss: 0.276 Acc 92.188%\n",
      "Test Epoch [ 37/200]Batch [100/204] Loss: 0.236 Acc 93.781%\n",
      "Test Epoch [ 37/200]Batch [200/204] Loss: 0.233 Acc 93.781%\n",
      "Train Epoch [ 38/200]Batch [  0/573] Loss: 0.110 Acc 96.094%\n",
      "Train Epoch [ 38/200]Batch [100/573] Loss: 0.141 Acc 95.668%\n",
      "Train Epoch [ 38/200]Batch [200/573] Loss: 0.142 Acc 95.752%\n",
      "Train Epoch [ 38/200]Batch [300/573] Loss: 0.147 Acc 95.710%\n",
      "Train Epoch [ 38/200]Batch [400/573] Loss: 0.147 Acc 95.720%\n",
      "Train Epoch [ 38/200]Batch [500/573] Loss: 0.146 Acc 95.723%\n",
      "Test Epoch [ 38/200]Batch [  0/204] Loss: 0.205 Acc 94.531%\n",
      "Test Epoch [ 38/200]Batch [100/204] Loss: 0.223 Acc 94.578%\n",
      "Test Epoch [ 38/200]Batch [200/204] Loss: 0.219 Acc 94.776%\n",
      "Train Epoch [ 39/200]Batch [  0/573] Loss: 0.057 Acc 98.438%\n",
      "Train Epoch [ 39/200]Batch [100/573] Loss: 0.130 Acc 96.310%\n",
      "Train Epoch [ 39/200]Batch [200/573] Loss: 0.135 Acc 96.152%\n",
      "Train Epoch [ 39/200]Batch [300/573] Loss: 0.141 Acc 95.956%\n",
      "Train Epoch [ 39/200]Batch [400/573] Loss: 0.145 Acc 95.877%\n",
      "Train Epoch [ 39/200]Batch [500/573] Loss: 0.145 Acc 95.872%\n",
      "Test Epoch [ 39/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 39/200]Batch [100/204] Loss: 0.240 Acc 94.539%\n",
      "Test Epoch [ 39/200]Batch [200/204] Loss: 0.236 Acc 94.446%\n",
      "Train Epoch [ 40/200]Batch [  0/573] Loss: 0.115 Acc 97.656%\n",
      "Train Epoch [ 40/200]Batch [100/573] Loss: 0.151 Acc 95.668%\n",
      "Train Epoch [ 40/200]Batch [200/573] Loss: 0.146 Acc 95.787%\n",
      "Train Epoch [ 40/200]Batch [300/573] Loss: 0.139 Acc 95.961%\n",
      "Train Epoch [ 40/200]Batch [400/573] Loss: 0.142 Acc 95.866%\n",
      "Train Epoch [ 40/200]Batch [500/573] Loss: 0.142 Acc 95.843%\n",
      "Test Epoch [ 40/200]Batch [  0/204] Loss: 0.171 Acc 93.750%\n",
      "Test Epoch [ 40/200]Batch [100/204] Loss: 0.217 Acc 94.578%\n",
      "Test Epoch [ 40/200]Batch [200/204] Loss: 0.214 Acc 94.593%\n",
      "Train Epoch [ 41/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 41/200]Batch [100/573] Loss: 0.136 Acc 95.877%\n",
      "Train Epoch [ 41/200]Batch [200/573] Loss: 0.137 Acc 95.946%\n",
      "Train Epoch [ 41/200]Batch [300/573] Loss: 0.140 Acc 95.829%\n",
      "Train Epoch [ 41/200]Batch [400/573] Loss: 0.143 Acc 95.821%\n",
      "Train Epoch [ 41/200]Batch [500/573] Loss: 0.142 Acc 95.874%\n",
      "Test Epoch [ 41/200]Batch [  0/204] Loss: 0.182 Acc 96.875%\n",
      "Test Epoch [ 41/200]Batch [100/204] Loss: 0.225 Acc 94.624%\n",
      "Test Epoch [ 41/200]Batch [200/204] Loss: 0.219 Acc 94.834%\n",
      "Train Epoch [ 42/200]Batch [  0/573] Loss: 0.165 Acc 92.969%\n",
      "Train Epoch [ 42/200]Batch [100/573] Loss: 0.125 Acc 96.357%\n",
      "Train Epoch [ 42/200]Batch [200/573] Loss: 0.138 Acc 95.857%\n",
      "Train Epoch [ 42/200]Batch [300/573] Loss: 0.140 Acc 95.860%\n",
      "Train Epoch [ 42/200]Batch [400/573] Loss: 0.141 Acc 95.846%\n",
      "Train Epoch [ 42/200]Batch [500/573] Loss: 0.140 Acc 95.858%\n",
      "Test Epoch [ 42/200]Batch [  0/204] Loss: 0.171 Acc 96.094%\n",
      "Test Epoch [ 42/200]Batch [100/204] Loss: 0.215 Acc 95.444%\n",
      "Test Epoch [ 42/200]Batch [200/204] Loss: 0.208 Acc 95.538%\n",
      "Train Epoch [ 43/200]Batch [  0/573] Loss: 0.138 Acc 95.312%\n",
      "Train Epoch [ 43/200]Batch [100/573] Loss: 0.138 Acc 95.955%\n",
      "Train Epoch [ 43/200]Batch [200/573] Loss: 0.139 Acc 95.923%\n",
      "Train Epoch [ 43/200]Batch [300/573] Loss: 0.142 Acc 95.878%\n",
      "Train Epoch [ 43/200]Batch [400/573] Loss: 0.141 Acc 95.967%\n",
      "Train Epoch [ 43/200]Batch [500/573] Loss: 0.142 Acc 95.911%\n",
      "Test Epoch [ 43/200]Batch [  0/204] Loss: 0.153 Acc 95.312%\n",
      "Test Epoch [ 43/200]Batch [100/204] Loss: 0.206 Acc 94.872%\n",
      "Test Epoch [ 43/200]Batch [200/204] Loss: 0.200 Acc 94.967%\n",
      "Train Epoch [ 44/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 44/200]Batch [100/573] Loss: 0.129 Acc 96.426%\n",
      "Train Epoch [ 44/200]Batch [200/573] Loss: 0.137 Acc 96.082%\n",
      "Train Epoch [ 44/200]Batch [300/573] Loss: 0.139 Acc 95.956%\n",
      "Train Epoch [ 44/200]Batch [400/573] Loss: 0.139 Acc 95.975%\n",
      "Train Epoch [ 44/200]Batch [500/573] Loss: 0.139 Acc 96.010%\n",
      "Test Epoch [ 44/200]Batch [  0/204] Loss: 0.211 Acc 94.531%\n",
      "Test Epoch [ 44/200]Batch [100/204] Loss: 0.213 Acc 94.825%\n",
      "Test Epoch [ 44/200]Batch [200/204] Loss: 0.209 Acc 94.846%\n",
      "Train Epoch [ 45/200]Batch [  0/573] Loss: 0.092 Acc 96.875%\n",
      "Train Epoch [ 45/200]Batch [100/573] Loss: 0.126 Acc 96.233%\n",
      "Train Epoch [ 45/200]Batch [200/573] Loss: 0.128 Acc 96.199%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 45/200]Batch [300/573] Loss: 0.130 Acc 96.187%\n",
      "Train Epoch [ 45/200]Batch [400/573] Loss: 0.134 Acc 96.107%\n",
      "Train Epoch [ 45/200]Batch [500/573] Loss: 0.134 Acc 96.123%\n",
      "Test Epoch [ 45/200]Batch [  0/204] Loss: 0.188 Acc 96.094%\n",
      "Test Epoch [ 45/200]Batch [100/204] Loss: 0.238 Acc 94.547%\n",
      "Test Epoch [ 45/200]Batch [200/204] Loss: 0.230 Acc 94.562%\n",
      "Train Epoch [ 46/200]Batch [  0/573] Loss: 0.163 Acc 96.094%\n",
      "Train Epoch [ 46/200]Batch [100/573] Loss: 0.127 Acc 96.210%\n",
      "Train Epoch [ 46/200]Batch [200/573] Loss: 0.130 Acc 96.214%\n",
      "Train Epoch [ 46/200]Batch [300/573] Loss: 0.130 Acc 96.231%\n",
      "Train Epoch [ 46/200]Batch [400/573] Loss: 0.132 Acc 96.183%\n",
      "Train Epoch [ 46/200]Batch [500/573] Loss: 0.132 Acc 96.169%\n",
      "Test Epoch [ 46/200]Batch [  0/204] Loss: 0.141 Acc 96.094%\n",
      "Test Epoch [ 46/200]Batch [100/204] Loss: 0.193 Acc 95.050%\n",
      "Test Epoch [ 46/200]Batch [200/204] Loss: 0.188 Acc 95.153%\n",
      "Train Epoch [ 47/200]Batch [  0/573] Loss: 0.099 Acc 98.438%\n",
      "Train Epoch [ 47/200]Batch [100/573] Loss: 0.131 Acc 96.310%\n",
      "Train Epoch [ 47/200]Batch [200/573] Loss: 0.132 Acc 96.179%\n",
      "Train Epoch [ 47/200]Batch [300/573] Loss: 0.135 Acc 96.031%\n",
      "Train Epoch [ 47/200]Batch [400/573] Loss: 0.134 Acc 96.102%\n",
      "Train Epoch [ 47/200]Batch [500/573] Loss: 0.134 Acc 96.108%\n",
      "Test Epoch [ 47/200]Batch [  0/204] Loss: 0.168 Acc 96.094%\n",
      "Test Epoch [ 47/200]Batch [100/204] Loss: 0.211 Acc 94.446%\n",
      "Test Epoch [ 47/200]Batch [200/204] Loss: 0.205 Acc 94.578%\n",
      "Train Epoch [ 48/200]Batch [  0/573] Loss: 0.094 Acc 96.094%\n",
      "Train Epoch [ 48/200]Batch [100/573] Loss: 0.123 Acc 96.241%\n",
      "Train Epoch [ 48/200]Batch [200/573] Loss: 0.122 Acc 96.339%\n",
      "Train Epoch [ 48/200]Batch [300/573] Loss: 0.124 Acc 96.364%\n",
      "Train Epoch [ 48/200]Batch [400/573] Loss: 0.124 Acc 96.345%\n",
      "Train Epoch [ 48/200]Batch [500/573] Loss: 0.127 Acc 96.279%\n",
      "Test Epoch [ 48/200]Batch [  0/204] Loss: 0.213 Acc 93.750%\n",
      "Test Epoch [ 48/200]Batch [100/204] Loss: 0.208 Acc 95.104%\n",
      "Test Epoch [ 48/200]Batch [200/204] Loss: 0.199 Acc 95.211%\n",
      "Train Epoch [ 49/200]Batch [  0/573] Loss: 0.152 Acc 96.094%\n",
      "Train Epoch [ 49/200]Batch [100/573] Loss: 0.121 Acc 96.426%\n",
      "Train Epoch [ 49/200]Batch [200/573] Loss: 0.124 Acc 96.304%\n",
      "Train Epoch [ 49/200]Batch [300/573] Loss: 0.124 Acc 96.317%\n",
      "Train Epoch [ 49/200]Batch [400/573] Loss: 0.124 Acc 96.312%\n",
      "Train Epoch [ 49/200]Batch [500/573] Loss: 0.124 Acc 96.343%\n",
      "Test Epoch [ 49/200]Batch [  0/204] Loss: 0.207 Acc 96.094%\n",
      "Test Epoch [ 49/200]Batch [100/204] Loss: 0.262 Acc 94.384%\n",
      "Test Epoch [ 49/200]Batch [200/204] Loss: 0.255 Acc 94.481%\n",
      "Train Epoch [ 50/200]Batch [  0/573] Loss: 0.168 Acc 93.750%\n",
      "Train Epoch [ 50/200]Batch [100/573] Loss: 0.115 Acc 96.597%\n",
      "Train Epoch [ 50/200]Batch [200/573] Loss: 0.122 Acc 96.288%\n",
      "Train Epoch [ 50/200]Batch [300/573] Loss: 0.123 Acc 96.325%\n",
      "Train Epoch [ 50/200]Batch [400/573] Loss: 0.122 Acc 96.357%\n",
      "Train Epoch [ 50/200]Batch [500/573] Loss: 0.124 Acc 96.318%\n",
      "Test Epoch [ 50/200]Batch [  0/204] Loss: 0.219 Acc 93.750%\n",
      "Test Epoch [ 50/200]Batch [100/204] Loss: 0.215 Acc 95.034%\n",
      "Test Epoch [ 50/200]Batch [200/204] Loss: 0.211 Acc 94.982%\n",
      "Train Epoch [ 51/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [ 51/200]Batch [100/573] Loss: 0.113 Acc 96.589%\n",
      "Train Epoch [ 51/200]Batch [200/573] Loss: 0.116 Acc 96.537%\n",
      "Train Epoch [ 51/200]Batch [300/573] Loss: 0.121 Acc 96.418%\n",
      "Train Epoch [ 51/200]Batch [400/573] Loss: 0.124 Acc 96.308%\n",
      "Train Epoch [ 51/200]Batch [500/573] Loss: 0.124 Acc 96.290%\n",
      "Test Epoch [ 51/200]Batch [  0/204] Loss: 0.267 Acc 90.625%\n",
      "Test Epoch [ 51/200]Batch [100/204] Loss: 0.244 Acc 94.779%\n",
      "Test Epoch [ 51/200]Batch [200/204] Loss: 0.239 Acc 94.854%\n",
      "Train Epoch [ 52/200]Batch [  0/573] Loss: 0.060 Acc 96.094%\n",
      "Train Epoch [ 52/200]Batch [100/573] Loss: 0.112 Acc 96.627%\n",
      "Train Epoch [ 52/200]Batch [200/573] Loss: 0.116 Acc 96.607%\n",
      "Train Epoch [ 52/200]Batch [300/573] Loss: 0.115 Acc 96.519%\n",
      "Train Epoch [ 52/200]Batch [400/573] Loss: 0.117 Acc 96.442%\n",
      "Train Epoch [ 52/200]Batch [500/573] Loss: 0.120 Acc 96.392%\n",
      "Test Epoch [ 52/200]Batch [  0/204] Loss: 0.277 Acc 96.094%\n",
      "Test Epoch [ 52/200]Batch [100/204] Loss: 0.303 Acc 93.982%\n",
      "Test Epoch [ 52/200]Batch [200/204] Loss: 0.295 Acc 94.154%\n",
      "Train Epoch [ 53/200]Batch [  0/573] Loss: 0.140 Acc 95.312%\n",
      "Train Epoch [ 53/200]Batch [100/573] Loss: 0.106 Acc 96.604%\n",
      "Train Epoch [ 53/200]Batch [200/573] Loss: 0.111 Acc 96.716%\n",
      "Train Epoch [ 53/200]Batch [300/573] Loss: 0.113 Acc 96.688%\n",
      "Train Epoch [ 53/200]Batch [400/573] Loss: 0.116 Acc 96.567%\n",
      "Train Epoch [ 53/200]Batch [500/573] Loss: 0.115 Acc 96.602%\n",
      "Test Epoch [ 53/200]Batch [  0/204] Loss: 0.298 Acc 93.750%\n",
      "Test Epoch [ 53/200]Batch [100/204] Loss: 0.279 Acc 94.469%\n",
      "Test Epoch [ 53/200]Batch [200/204] Loss: 0.274 Acc 94.496%\n",
      "Train Epoch [ 54/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [ 54/200]Batch [100/573] Loss: 0.120 Acc 96.473%\n",
      "Train Epoch [ 54/200]Batch [200/573] Loss: 0.121 Acc 96.397%\n",
      "Train Epoch [ 54/200]Batch [300/573] Loss: 0.118 Acc 96.499%\n",
      "Train Epoch [ 54/200]Batch [400/573] Loss: 0.117 Acc 96.493%\n",
      "Train Epoch [ 54/200]Batch [500/573] Loss: 0.118 Acc 96.512%\n",
      "Test Epoch [ 54/200]Batch [  0/204] Loss: 0.185 Acc 93.750%\n",
      "Test Epoch [ 54/200]Batch [100/204] Loss: 0.218 Acc 95.150%\n",
      "Test Epoch [ 54/200]Batch [200/204] Loss: 0.212 Acc 95.204%\n",
      "Train Epoch [ 55/200]Batch [  0/573] Loss: 0.221 Acc 96.094%\n",
      "Train Epoch [ 55/200]Batch [100/573] Loss: 0.109 Acc 96.666%\n",
      "Train Epoch [ 55/200]Batch [200/573] Loss: 0.117 Acc 96.401%\n",
      "Train Epoch [ 55/200]Batch [300/573] Loss: 0.117 Acc 96.413%\n",
      "Train Epoch [ 55/200]Batch [400/573] Loss: 0.120 Acc 96.347%\n",
      "Train Epoch [ 55/200]Batch [500/573] Loss: 0.122 Acc 96.300%\n",
      "Test Epoch [ 55/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [ 55/200]Batch [100/204] Loss: 0.233 Acc 94.570%\n",
      "Test Epoch [ 55/200]Batch [200/204] Loss: 0.230 Acc 94.625%\n",
      "Train Epoch [ 56/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [ 56/200]Batch [100/573] Loss: 0.109 Acc 96.736%\n",
      "Train Epoch [ 56/200]Batch [200/573] Loss: 0.110 Acc 96.739%\n",
      "Train Epoch [ 56/200]Batch [300/573] Loss: 0.111 Acc 96.714%\n",
      "Train Epoch [ 56/200]Batch [400/573] Loss: 0.113 Acc 96.649%\n",
      "Train Epoch [ 56/200]Batch [500/573] Loss: 0.115 Acc 96.583%\n",
      "Test Epoch [ 56/200]Batch [  0/204] Loss: 0.199 Acc 96.875%\n",
      "Test Epoch [ 56/200]Batch [100/204] Loss: 0.218 Acc 94.640%\n",
      "Test Epoch [ 56/200]Batch [200/204] Loss: 0.213 Acc 94.694%\n",
      "Train Epoch [ 57/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [ 57/200]Batch [100/573] Loss: 0.100 Acc 96.937%\n",
      "Train Epoch [ 57/200]Batch [200/573] Loss: 0.105 Acc 96.832%\n",
      "Train Epoch [ 57/200]Batch [300/573] Loss: 0.111 Acc 96.724%\n",
      "Train Epoch [ 57/200]Batch [400/573] Loss: 0.114 Acc 96.630%\n",
      "Train Epoch [ 57/200]Batch [500/573] Loss: 0.116 Acc 96.572%\n",
      "Test Epoch [ 57/200]Batch [  0/204] Loss: 0.278 Acc 92.969%\n",
      "Test Epoch [ 57/200]Batch [100/204] Loss: 0.268 Acc 93.851%\n",
      "Test Epoch [ 57/200]Batch [200/204] Loss: 0.265 Acc 93.937%\n",
      "Train Epoch [ 58/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [ 58/200]Batch [100/573] Loss: 0.111 Acc 96.620%\n",
      "Train Epoch [ 58/200]Batch [200/573] Loss: 0.111 Acc 96.607%\n",
      "Train Epoch [ 58/200]Batch [300/573] Loss: 0.115 Acc 96.548%\n",
      "Train Epoch [ 58/200]Batch [400/573] Loss: 0.112 Acc 96.604%\n",
      "Train Epoch [ 58/200]Batch [500/573] Loss: 0.112 Acc 96.590%\n",
      "Test Epoch [ 58/200]Batch [  0/204] Loss: 0.210 Acc 93.750%\n",
      "Test Epoch [ 58/200]Batch [100/204] Loss: 0.242 Acc 94.152%\n",
      "Test Epoch [ 58/200]Batch [200/204] Loss: 0.233 Acc 94.251%\n",
      "Train Epoch [ 59/200]Batch [  0/573] Loss: 0.058 Acc 96.875%\n",
      "Train Epoch [ 59/200]Batch [100/573] Loss: 0.101 Acc 97.014%\n",
      "Train Epoch [ 59/200]Batch [200/573] Loss: 0.102 Acc 96.894%\n",
      "Train Epoch [ 59/200]Batch [300/573] Loss: 0.104 Acc 96.805%\n",
      "Train Epoch [ 59/200]Batch [400/573] Loss: 0.107 Acc 96.768%\n",
      "Train Epoch [ 59/200]Batch [500/573] Loss: 0.109 Acc 96.749%\n",
      "Test Epoch [ 59/200]Batch [  0/204] Loss: 0.253 Acc 94.531%\n",
      "Test Epoch [ 59/200]Batch [100/204] Loss: 0.290 Acc 93.673%\n",
      "Test Epoch [ 59/200]Batch [200/204] Loss: 0.284 Acc 93.793%\n",
      "Train Epoch [ 60/200]Batch [  0/573] Loss: 0.044 Acc 98.438%\n",
      "Train Epoch [ 60/200]Batch [100/573] Loss: 0.106 Acc 96.728%\n",
      "Train Epoch [ 60/200]Batch [200/573] Loss: 0.102 Acc 96.836%\n",
      "Train Epoch [ 60/200]Batch [300/573] Loss: 0.103 Acc 96.849%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 60/200]Batch [400/573] Loss: 0.105 Acc 96.830%\n",
      "Train Epoch [ 60/200]Batch [500/573] Loss: 0.107 Acc 96.724%\n",
      "Test Epoch [ 60/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [ 60/200]Batch [100/204] Loss: 0.220 Acc 94.957%\n",
      "Test Epoch [ 60/200]Batch [200/204] Loss: 0.214 Acc 95.060%\n",
      "Train Epoch [ 61/200]Batch [  0/573] Loss: 0.116 Acc 94.531%\n",
      "Train Epoch [ 61/200]Batch [100/573] Loss: 0.099 Acc 97.045%\n",
      "Train Epoch [ 61/200]Batch [200/573] Loss: 0.103 Acc 96.933%\n",
      "Train Epoch [ 61/200]Batch [300/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 61/200]Batch [400/573] Loss: 0.108 Acc 96.807%\n",
      "Train Epoch [ 61/200]Batch [500/573] Loss: 0.108 Acc 96.785%\n",
      "Test Epoch [ 61/200]Batch [  0/204] Loss: 0.174 Acc 93.750%\n",
      "Test Epoch [ 61/200]Batch [100/204] Loss: 0.220 Acc 94.446%\n",
      "Test Epoch [ 61/200]Batch [200/204] Loss: 0.213 Acc 94.737%\n",
      "Train Epoch [ 62/200]Batch [  0/573] Loss: 0.093 Acc 95.312%\n",
      "Train Epoch [ 62/200]Batch [100/573] Loss: 0.105 Acc 96.813%\n",
      "Train Epoch [ 62/200]Batch [200/573] Loss: 0.105 Acc 96.852%\n",
      "Train Epoch [ 62/200]Batch [300/573] Loss: 0.106 Acc 96.875%\n",
      "Train Epoch [ 62/200]Batch [400/573] Loss: 0.107 Acc 96.852%\n",
      "Train Epoch [ 62/200]Batch [500/573] Loss: 0.107 Acc 96.869%\n",
      "Test Epoch [ 62/200]Batch [  0/204] Loss: 0.280 Acc 89.844%\n",
      "Test Epoch [ 62/200]Batch [100/204] Loss: 0.281 Acc 93.912%\n",
      "Test Epoch [ 62/200]Batch [200/204] Loss: 0.276 Acc 94.127%\n",
      "Train Epoch [ 63/200]Batch [  0/573] Loss: 0.175 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [100/573] Loss: 0.102 Acc 97.030%\n",
      "Train Epoch [ 63/200]Batch [200/573] Loss: 0.105 Acc 96.875%\n",
      "Train Epoch [ 63/200]Batch [300/573] Loss: 0.103 Acc 96.935%\n",
      "Train Epoch [ 63/200]Batch [400/573] Loss: 0.106 Acc 96.857%\n",
      "Train Epoch [ 63/200]Batch [500/573] Loss: 0.109 Acc 96.725%\n",
      "Test Epoch [ 63/200]Batch [  0/204] Loss: 0.287 Acc 92.188%\n",
      "Test Epoch [ 63/200]Batch [100/204] Loss: 0.256 Acc 94.245%\n",
      "Test Epoch [ 63/200]Batch [200/204] Loss: 0.249 Acc 94.259%\n",
      "Train Epoch [ 64/200]Batch [  0/573] Loss: 0.108 Acc 95.312%\n",
      "Train Epoch [ 64/200]Batch [100/573] Loss: 0.101 Acc 96.689%\n",
      "Train Epoch [ 64/200]Batch [200/573] Loss: 0.108 Acc 96.537%\n",
      "Train Epoch [ 64/200]Batch [300/573] Loss: 0.108 Acc 96.631%\n",
      "Train Epoch [ 64/200]Batch [400/573] Loss: 0.110 Acc 96.633%\n",
      "Train Epoch [ 64/200]Batch [500/573] Loss: 0.107 Acc 96.688%\n",
      "Test Epoch [ 64/200]Batch [  0/204] Loss: 0.371 Acc 90.625%\n",
      "Test Epoch [ 64/200]Batch [100/204] Loss: 0.287 Acc 93.843%\n",
      "Test Epoch [ 64/200]Batch [200/204] Loss: 0.284 Acc 93.929%\n",
      "Train Epoch [ 65/200]Batch [  0/573] Loss: 0.057 Acc 97.656%\n",
      "Train Epoch [ 65/200]Batch [100/573] Loss: 0.094 Acc 97.092%\n",
      "Train Epoch [ 65/200]Batch [200/573] Loss: 0.102 Acc 96.918%\n",
      "Train Epoch [ 65/200]Batch [300/573] Loss: 0.103 Acc 96.896%\n",
      "Train Epoch [ 65/200]Batch [400/573] Loss: 0.105 Acc 96.754%\n",
      "Train Epoch [ 65/200]Batch [500/573] Loss: 0.105 Acc 96.775%\n",
      "Test Epoch [ 65/200]Batch [  0/204] Loss: 0.239 Acc 91.406%\n",
      "Test Epoch [ 65/200]Batch [100/204] Loss: 0.227 Acc 94.663%\n",
      "Test Epoch [ 65/200]Batch [200/204] Loss: 0.221 Acc 94.807%\n",
      "Train Epoch [ 66/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [ 66/200]Batch [100/573] Loss: 0.092 Acc 97.169%\n",
      "Train Epoch [ 66/200]Batch [200/573] Loss: 0.100 Acc 96.887%\n",
      "Train Epoch [ 66/200]Batch [300/573] Loss: 0.102 Acc 96.865%\n",
      "Train Epoch [ 66/200]Batch [400/573] Loss: 0.104 Acc 96.817%\n",
      "Train Epoch [ 66/200]Batch [500/573] Loss: 0.104 Acc 96.791%\n",
      "Test Epoch [ 66/200]Batch [  0/204] Loss: 0.243 Acc 93.750%\n",
      "Test Epoch [ 66/200]Batch [100/204] Loss: 0.225 Acc 94.547%\n",
      "Test Epoch [ 66/200]Batch [200/204] Loss: 0.220 Acc 94.597%\n",
      "Train Epoch [ 67/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 67/200]Batch [100/573] Loss: 0.096 Acc 97.053%\n",
      "Train Epoch [ 67/200]Batch [200/573] Loss: 0.100 Acc 96.906%\n",
      "Train Epoch [ 67/200]Batch [300/573] Loss: 0.103 Acc 96.878%\n",
      "Train Epoch [ 67/200]Batch [400/573] Loss: 0.105 Acc 96.824%\n",
      "Train Epoch [ 67/200]Batch [500/573] Loss: 0.107 Acc 96.780%\n",
      "Test Epoch [ 67/200]Batch [  0/204] Loss: 0.254 Acc 92.969%\n",
      "Test Epoch [ 67/200]Batch [100/204] Loss: 0.259 Acc 94.090%\n",
      "Test Epoch [ 67/200]Batch [200/204] Loss: 0.252 Acc 94.232%\n",
      "Train Epoch [ 68/200]Batch [  0/573] Loss: 0.077 Acc 96.875%\n",
      "Train Epoch [ 68/200]Batch [100/573] Loss: 0.094 Acc 97.153%\n",
      "Train Epoch [ 68/200]Batch [200/573] Loss: 0.097 Acc 97.034%\n",
      "Train Epoch [ 68/200]Batch [300/573] Loss: 0.095 Acc 97.101%\n",
      "Train Epoch [ 68/200]Batch [400/573] Loss: 0.100 Acc 96.953%\n",
      "Train Epoch [ 68/200]Batch [500/573] Loss: 0.099 Acc 96.964%\n",
      "Test Epoch [ 68/200]Batch [  0/204] Loss: 0.190 Acc 93.750%\n",
      "Test Epoch [ 68/200]Batch [100/204] Loss: 0.221 Acc 94.686%\n",
      "Test Epoch [ 68/200]Batch [200/204] Loss: 0.212 Acc 94.873%\n",
      "Train Epoch [ 69/200]Batch [  0/573] Loss: 0.085 Acc 98.438%\n",
      "Train Epoch [ 69/200]Batch [100/573] Loss: 0.093 Acc 97.076%\n",
      "Train Epoch [ 69/200]Batch [200/573] Loss: 0.091 Acc 97.174%\n",
      "Train Epoch [ 69/200]Batch [300/573] Loss: 0.097 Acc 97.015%\n",
      "Train Epoch [ 69/200]Batch [400/573] Loss: 0.101 Acc 96.933%\n",
      "Train Epoch [ 69/200]Batch [500/573] Loss: 0.101 Acc 96.906%\n",
      "Test Epoch [ 69/200]Batch [  0/204] Loss: 0.240 Acc 94.531%\n",
      "Test Epoch [ 69/200]Batch [100/204] Loss: 0.239 Acc 94.052%\n",
      "Test Epoch [ 69/200]Batch [200/204] Loss: 0.232 Acc 94.224%\n",
      "Train Epoch [ 70/200]Batch [  0/573] Loss: 0.123 Acc 98.438%\n",
      "Train Epoch [ 70/200]Batch [100/573] Loss: 0.103 Acc 96.829%\n",
      "Train Epoch [ 70/200]Batch [200/573] Loss: 0.101 Acc 96.848%\n",
      "Train Epoch [ 70/200]Batch [300/573] Loss: 0.103 Acc 96.805%\n",
      "Train Epoch [ 70/200]Batch [400/573] Loss: 0.103 Acc 96.830%\n",
      "Train Epoch [ 70/200]Batch [500/573] Loss: 0.102 Acc 96.870%\n",
      "Test Epoch [ 70/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [ 70/200]Batch [100/204] Loss: 0.254 Acc 94.075%\n",
      "Test Epoch [ 70/200]Batch [200/204] Loss: 0.250 Acc 94.189%\n",
      "Train Epoch [ 71/200]Batch [  0/573] Loss: 0.015 Acc 100.000%\n",
      "Train Epoch [ 71/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [ 71/200]Batch [200/573] Loss: 0.091 Acc 97.248%\n",
      "Train Epoch [ 71/200]Batch [300/573] Loss: 0.093 Acc 97.137%\n",
      "Train Epoch [ 71/200]Batch [400/573] Loss: 0.095 Acc 97.093%\n",
      "Train Epoch [ 71/200]Batch [500/573] Loss: 0.097 Acc 97.043%\n",
      "Test Epoch [ 71/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [ 71/200]Batch [100/204] Loss: 0.266 Acc 94.160%\n",
      "Test Epoch [ 71/200]Batch [200/204] Loss: 0.263 Acc 94.240%\n",
      "Train Epoch [ 72/200]Batch [  0/573] Loss: 0.068 Acc 98.438%\n",
      "Train Epoch [ 72/200]Batch [100/573] Loss: 0.096 Acc 97.061%\n",
      "Train Epoch [ 72/200]Batch [200/573] Loss: 0.097 Acc 97.058%\n",
      "Train Epoch [ 72/200]Batch [300/573] Loss: 0.096 Acc 97.129%\n",
      "Train Epoch [ 72/200]Batch [400/573] Loss: 0.096 Acc 97.113%\n",
      "Train Epoch [ 72/200]Batch [500/573] Loss: 0.099 Acc 96.990%\n",
      "Test Epoch [ 72/200]Batch [  0/204] Loss: 0.222 Acc 96.875%\n",
      "Test Epoch [ 72/200]Batch [100/204] Loss: 0.256 Acc 93.781%\n",
      "Test Epoch [ 72/200]Batch [200/204] Loss: 0.245 Acc 93.975%\n",
      "Train Epoch [ 73/200]Batch [  0/573] Loss: 0.115 Acc 95.312%\n",
      "Train Epoch [ 73/200]Batch [100/573] Loss: 0.089 Acc 97.308%\n",
      "Train Epoch [ 73/200]Batch [200/573] Loss: 0.095 Acc 96.992%\n",
      "Train Epoch [ 73/200]Batch [300/573] Loss: 0.098 Acc 96.932%\n",
      "Train Epoch [ 73/200]Batch [400/573] Loss: 0.097 Acc 96.969%\n",
      "Train Epoch [ 73/200]Batch [500/573] Loss: 0.097 Acc 97.012%\n",
      "Test Epoch [ 73/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [ 73/200]Batch [100/204] Loss: 0.208 Acc 95.204%\n",
      "Test Epoch [ 73/200]Batch [200/204] Loss: 0.200 Acc 95.340%\n",
      "Train Epoch [ 74/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 74/200]Batch [100/573] Loss: 0.092 Acc 97.192%\n",
      "Train Epoch [ 74/200]Batch [200/573] Loss: 0.090 Acc 97.240%\n",
      "Train Epoch [ 74/200]Batch [300/573] Loss: 0.093 Acc 97.202%\n",
      "Train Epoch [ 74/200]Batch [400/573] Loss: 0.095 Acc 97.136%\n",
      "Train Epoch [ 74/200]Batch [500/573] Loss: 0.095 Acc 97.112%\n",
      "Test Epoch [ 74/200]Batch [  0/204] Loss: 0.228 Acc 93.750%\n",
      "Test Epoch [ 74/200]Batch [100/204] Loss: 0.253 Acc 93.502%\n",
      "Test Epoch [ 74/200]Batch [200/204] Loss: 0.248 Acc 93.641%\n",
      "Train Epoch [ 75/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [ 75/200]Batch [100/573] Loss: 0.089 Acc 97.184%\n",
      "Train Epoch [ 75/200]Batch [200/573] Loss: 0.094 Acc 96.972%\n",
      "Train Epoch [ 75/200]Batch [300/573] Loss: 0.098 Acc 96.885%\n",
      "Train Epoch [ 75/200]Batch [400/573] Loss: 0.100 Acc 96.826%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [ 75/200]Batch [500/573] Loss: 0.099 Acc 96.859%\n",
      "Test Epoch [ 75/200]Batch [  0/204] Loss: 0.234 Acc 92.969%\n",
      "Test Epoch [ 75/200]Batch [100/204] Loss: 0.252 Acc 94.701%\n",
      "Test Epoch [ 75/200]Batch [200/204] Loss: 0.246 Acc 94.803%\n",
      "Train Epoch [ 76/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [ 76/200]Batch [100/573] Loss: 0.092 Acc 97.030%\n",
      "Train Epoch [ 76/200]Batch [200/573] Loss: 0.089 Acc 97.155%\n",
      "Train Epoch [ 76/200]Batch [300/573] Loss: 0.089 Acc 97.161%\n",
      "Train Epoch [ 76/200]Batch [400/573] Loss: 0.092 Acc 97.082%\n",
      "Train Epoch [ 76/200]Batch [500/573] Loss: 0.093 Acc 97.023%\n",
      "Test Epoch [ 76/200]Batch [  0/204] Loss: 0.310 Acc 92.969%\n",
      "Test Epoch [ 76/200]Batch [100/204] Loss: 0.328 Acc 92.822%\n",
      "Test Epoch [ 76/200]Batch [200/204] Loss: 0.322 Acc 92.907%\n",
      "Train Epoch [ 77/200]Batch [  0/573] Loss: 0.078 Acc 98.438%\n",
      "Train Epoch [ 77/200]Batch [100/573] Loss: 0.087 Acc 97.269%\n",
      "Train Epoch [ 77/200]Batch [200/573] Loss: 0.091 Acc 97.155%\n",
      "Train Epoch [ 77/200]Batch [300/573] Loss: 0.093 Acc 97.093%\n",
      "Train Epoch [ 77/200]Batch [400/573] Loss: 0.095 Acc 97.076%\n",
      "Train Epoch [ 77/200]Batch [500/573] Loss: 0.098 Acc 96.947%\n",
      "Test Epoch [ 77/200]Batch [  0/204] Loss: 0.227 Acc 91.406%\n",
      "Test Epoch [ 77/200]Batch [100/204] Loss: 0.247 Acc 94.114%\n",
      "Test Epoch [ 77/200]Batch [200/204] Loss: 0.239 Acc 94.201%\n",
      "Train Epoch [ 78/200]Batch [  0/573] Loss: 0.050 Acc 99.219%\n",
      "Train Epoch [ 78/200]Batch [100/573] Loss: 0.083 Acc 97.246%\n",
      "Train Epoch [ 78/200]Batch [200/573] Loss: 0.083 Acc 97.279%\n",
      "Train Epoch [ 78/200]Batch [300/573] Loss: 0.087 Acc 97.173%\n",
      "Train Epoch [ 78/200]Batch [400/573] Loss: 0.088 Acc 97.150%\n",
      "Train Epoch [ 78/200]Batch [500/573] Loss: 0.091 Acc 97.064%\n",
      "Test Epoch [ 78/200]Batch [  0/204] Loss: 0.213 Acc 92.969%\n",
      "Test Epoch [ 78/200]Batch [100/204] Loss: 0.236 Acc 94.655%\n",
      "Test Epoch [ 78/200]Batch [200/204] Loss: 0.230 Acc 94.636%\n",
      "Train Epoch [ 79/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [ 79/200]Batch [100/573] Loss: 0.085 Acc 97.525%\n",
      "Train Epoch [ 79/200]Batch [200/573] Loss: 0.087 Acc 97.345%\n",
      "Train Epoch [ 79/200]Batch [300/573] Loss: 0.088 Acc 97.306%\n",
      "Train Epoch [ 79/200]Batch [400/573] Loss: 0.092 Acc 97.191%\n",
      "Train Epoch [ 79/200]Batch [500/573] Loss: 0.092 Acc 97.185%\n",
      "Test Epoch [ 79/200]Batch [  0/204] Loss: 0.203 Acc 90.625%\n",
      "Test Epoch [ 79/200]Batch [100/204] Loss: 0.234 Acc 94.299%\n",
      "Test Epoch [ 79/200]Batch [200/204] Loss: 0.225 Acc 94.512%\n",
      "Train Epoch [ 80/200]Batch [  0/573] Loss: 0.173 Acc 95.312%\n",
      "Train Epoch [ 80/200]Batch [100/573] Loss: 0.089 Acc 97.269%\n",
      "Train Epoch [ 80/200]Batch [200/573] Loss: 0.088 Acc 97.287%\n",
      "Train Epoch [ 80/200]Batch [300/573] Loss: 0.090 Acc 97.262%\n",
      "Train Epoch [ 80/200]Batch [400/573] Loss: 0.089 Acc 97.282%\n",
      "Train Epoch [ 80/200]Batch [500/573] Loss: 0.092 Acc 97.173%\n",
      "Test Epoch [ 80/200]Batch [  0/204] Loss: 0.268 Acc 92.969%\n",
      "Test Epoch [ 80/200]Batch [100/204] Loss: 0.245 Acc 94.400%\n",
      "Test Epoch [ 80/200]Batch [200/204] Loss: 0.237 Acc 94.535%\n",
      "Train Epoch [ 81/200]Batch [  0/573] Loss: 0.155 Acc 94.531%\n",
      "Train Epoch [ 81/200]Batch [100/573] Loss: 0.094 Acc 97.115%\n",
      "Train Epoch [ 81/200]Batch [200/573] Loss: 0.094 Acc 97.073%\n",
      "Train Epoch [ 81/200]Batch [300/573] Loss: 0.093 Acc 97.103%\n",
      "Train Epoch [ 81/200]Batch [400/573] Loss: 0.094 Acc 97.126%\n",
      "Train Epoch [ 81/200]Batch [500/573] Loss: 0.094 Acc 97.084%\n",
      "Test Epoch [ 81/200]Batch [  0/204] Loss: 0.228 Acc 92.969%\n",
      "Test Epoch [ 81/200]Batch [100/204] Loss: 0.228 Acc 94.740%\n",
      "Test Epoch [ 81/200]Batch [200/204] Loss: 0.223 Acc 94.796%\n",
      "Train Epoch [ 82/200]Batch [  0/573] Loss: 0.037 Acc 99.219%\n",
      "Train Epoch [ 82/200]Batch [100/573] Loss: 0.084 Acc 97.440%\n",
      "Train Epoch [ 82/200]Batch [200/573] Loss: 0.086 Acc 97.415%\n",
      "Train Epoch [ 82/200]Batch [300/573] Loss: 0.089 Acc 97.303%\n",
      "Train Epoch [ 82/200]Batch [400/573] Loss: 0.089 Acc 97.294%\n",
      "Train Epoch [ 82/200]Batch [500/573] Loss: 0.091 Acc 97.226%\n",
      "Test Epoch [ 82/200]Batch [  0/204] Loss: 0.200 Acc 94.531%\n",
      "Test Epoch [ 82/200]Batch [100/204] Loss: 0.262 Acc 94.168%\n",
      "Test Epoch [ 82/200]Batch [200/204] Loss: 0.254 Acc 94.251%\n",
      "Train Epoch [ 83/200]Batch [  0/573] Loss: 0.101 Acc 97.656%\n",
      "Train Epoch [ 83/200]Batch [100/573] Loss: 0.086 Acc 97.115%\n",
      "Train Epoch [ 83/200]Batch [200/573] Loss: 0.088 Acc 97.100%\n",
      "Train Epoch [ 83/200]Batch [300/573] Loss: 0.089 Acc 97.129%\n",
      "Train Epoch [ 83/200]Batch [400/573] Loss: 0.089 Acc 97.152%\n",
      "Train Epoch [ 83/200]Batch [500/573] Loss: 0.090 Acc 97.156%\n",
      "Test Epoch [ 83/200]Batch [  0/204] Loss: 0.349 Acc 90.625%\n",
      "Test Epoch [ 83/200]Batch [100/204] Loss: 0.312 Acc 93.007%\n",
      "Test Epoch [ 83/200]Batch [200/204] Loss: 0.307 Acc 93.151%\n",
      "Train Epoch [ 84/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [ 84/200]Batch [100/573] Loss: 0.075 Acc 97.687%\n",
      "Train Epoch [ 84/200]Batch [200/573] Loss: 0.082 Acc 97.431%\n",
      "Train Epoch [ 84/200]Batch [300/573] Loss: 0.083 Acc 97.381%\n",
      "Train Epoch [ 84/200]Batch [400/573] Loss: 0.087 Acc 97.278%\n",
      "Train Epoch [ 84/200]Batch [500/573] Loss: 0.090 Acc 97.199%\n",
      "Test Epoch [ 84/200]Batch [  0/204] Loss: 0.230 Acc 94.531%\n",
      "Test Epoch [ 84/200]Batch [100/204] Loss: 0.266 Acc 94.067%\n",
      "Test Epoch [ 84/200]Batch [200/204] Loss: 0.260 Acc 94.216%\n",
      "Train Epoch [ 85/200]Batch [  0/573] Loss: 0.054 Acc 97.656%\n",
      "Train Epoch [ 85/200]Batch [100/573] Loss: 0.087 Acc 97.300%\n",
      "Train Epoch [ 85/200]Batch [200/573] Loss: 0.085 Acc 97.341%\n",
      "Train Epoch [ 85/200]Batch [300/573] Loss: 0.087 Acc 97.249%\n",
      "Train Epoch [ 85/200]Batch [400/573] Loss: 0.088 Acc 97.233%\n",
      "Train Epoch [ 85/200]Batch [500/573] Loss: 0.088 Acc 97.245%\n",
      "Test Epoch [ 85/200]Batch [  0/204] Loss: 0.220 Acc 93.750%\n",
      "Test Epoch [ 85/200]Batch [100/204] Loss: 0.259 Acc 94.261%\n",
      "Test Epoch [ 85/200]Batch [200/204] Loss: 0.254 Acc 94.298%\n",
      "Train Epoch [ 86/200]Batch [  0/573] Loss: 0.045 Acc 98.438%\n",
      "Train Epoch [ 86/200]Batch [100/573] Loss: 0.082 Acc 97.339%\n",
      "Train Epoch [ 86/200]Batch [200/573] Loss: 0.083 Acc 97.361%\n",
      "Train Epoch [ 86/200]Batch [300/573] Loss: 0.086 Acc 97.257%\n",
      "Train Epoch [ 86/200]Batch [400/573] Loss: 0.086 Acc 97.263%\n",
      "Train Epoch [ 86/200]Batch [500/573] Loss: 0.086 Acc 97.262%\n",
      "Test Epoch [ 86/200]Batch [  0/204] Loss: 0.259 Acc 92.188%\n",
      "Test Epoch [ 86/200]Batch [100/204] Loss: 0.274 Acc 94.121%\n",
      "Test Epoch [ 86/200]Batch [200/204] Loss: 0.267 Acc 94.178%\n",
      "Train Epoch [ 87/200]Batch [  0/573] Loss: 0.104 Acc 96.875%\n",
      "Train Epoch [ 87/200]Batch [100/573] Loss: 0.078 Acc 97.455%\n",
      "Train Epoch [ 87/200]Batch [200/573] Loss: 0.083 Acc 97.392%\n",
      "Train Epoch [ 87/200]Batch [300/573] Loss: 0.085 Acc 97.334%\n",
      "Train Epoch [ 87/200]Batch [400/573] Loss: 0.088 Acc 97.259%\n",
      "Train Epoch [ 87/200]Batch [500/573] Loss: 0.088 Acc 97.240%\n",
      "Test Epoch [ 87/200]Batch [  0/204] Loss: 0.192 Acc 93.750%\n",
      "Test Epoch [ 87/200]Batch [100/204] Loss: 0.242 Acc 94.291%\n",
      "Test Epoch [ 87/200]Batch [200/204] Loss: 0.236 Acc 94.368%\n",
      "Train Epoch [ 88/200]Batch [  0/573] Loss: 0.076 Acc 96.094%\n",
      "Train Epoch [ 88/200]Batch [100/573] Loss: 0.085 Acc 97.215%\n",
      "Train Epoch [ 88/200]Batch [200/573] Loss: 0.086 Acc 97.287%\n",
      "Train Epoch [ 88/200]Batch [300/573] Loss: 0.089 Acc 97.194%\n",
      "Train Epoch [ 88/200]Batch [400/573] Loss: 0.091 Acc 97.185%\n",
      "Train Epoch [ 88/200]Batch [500/573] Loss: 0.092 Acc 97.165%\n",
      "Test Epoch [ 88/200]Batch [  0/204] Loss: 0.229 Acc 94.531%\n",
      "Test Epoch [ 88/200]Batch [100/204] Loss: 0.243 Acc 94.175%\n",
      "Test Epoch [ 88/200]Batch [200/204] Loss: 0.234 Acc 94.333%\n",
      "Train Epoch [ 89/200]Batch [  0/573] Loss: 0.060 Acc 97.656%\n",
      "Train Epoch [ 89/200]Batch [100/573] Loss: 0.091 Acc 97.208%\n",
      "Train Epoch [ 89/200]Batch [200/573] Loss: 0.086 Acc 97.209%\n",
      "Train Epoch [ 89/200]Batch [300/573] Loss: 0.089 Acc 97.194%\n",
      "Train Epoch [ 89/200]Batch [400/573] Loss: 0.087 Acc 97.237%\n",
      "Train Epoch [ 89/200]Batch [500/573] Loss: 0.088 Acc 97.248%\n",
      "Test Epoch [ 89/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [ 89/200]Batch [100/204] Loss: 0.275 Acc 94.052%\n",
      "Test Epoch [ 89/200]Batch [200/204] Loss: 0.268 Acc 94.205%\n",
      "Train Epoch [ 90/200]Batch [  0/573] Loss: 0.055 Acc 97.656%\n",
      "Train Epoch [ 90/200]Batch [100/573] Loss: 0.071 Acc 97.625%\n",
      "Train Epoch [ 90/200]Batch [200/573] Loss: 0.073 Acc 97.610%\n",
      "Train Epoch [ 90/200]Batch [300/573] Loss: 0.080 Acc 97.446%\n",
      "Train Epoch [ 90/200]Batch [400/573] Loss: 0.081 Acc 97.385%\n",
      "Train Epoch [ 90/200]Batch [500/573] Loss: 0.082 Acc 97.391%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [ 90/200]Batch [  0/204] Loss: 0.184 Acc 95.312%\n",
      "Test Epoch [ 90/200]Batch [100/204] Loss: 0.251 Acc 93.967%\n",
      "Test Epoch [ 90/200]Batch [200/204] Loss: 0.242 Acc 94.325%\n",
      "Train Epoch [ 91/200]Batch [  0/573] Loss: 0.019 Acc 100.000%\n",
      "Train Epoch [ 91/200]Batch [100/573] Loss: 0.083 Acc 97.556%\n",
      "Train Epoch [ 91/200]Batch [200/573] Loss: 0.078 Acc 97.660%\n",
      "Train Epoch [ 91/200]Batch [300/573] Loss: 0.081 Acc 97.539%\n",
      "Train Epoch [ 91/200]Batch [400/573] Loss: 0.082 Acc 97.477%\n",
      "Train Epoch [ 91/200]Batch [500/573] Loss: 0.084 Acc 97.376%\n",
      "Test Epoch [ 91/200]Batch [  0/204] Loss: 0.247 Acc 95.312%\n",
      "Test Epoch [ 91/200]Batch [100/204] Loss: 0.282 Acc 93.680%\n",
      "Test Epoch [ 91/200]Batch [200/204] Loss: 0.272 Acc 93.828%\n",
      "Train Epoch [ 92/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [ 92/200]Batch [100/573] Loss: 0.083 Acc 97.262%\n",
      "Train Epoch [ 92/200]Batch [200/573] Loss: 0.086 Acc 97.271%\n",
      "Train Epoch [ 92/200]Batch [300/573] Loss: 0.086 Acc 97.262%\n",
      "Train Epoch [ 92/200]Batch [400/573] Loss: 0.087 Acc 97.274%\n",
      "Train Epoch [ 92/200]Batch [500/573] Loss: 0.086 Acc 97.271%\n",
      "Test Epoch [ 92/200]Batch [  0/204] Loss: 0.164 Acc 95.312%\n",
      "Test Epoch [ 92/200]Batch [100/204] Loss: 0.227 Acc 94.694%\n",
      "Test Epoch [ 92/200]Batch [200/204] Loss: 0.215 Acc 94.854%\n",
      "Train Epoch [ 93/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [ 93/200]Batch [100/573] Loss: 0.087 Acc 97.161%\n",
      "Train Epoch [ 93/200]Batch [200/573] Loss: 0.084 Acc 97.330%\n",
      "Train Epoch [ 93/200]Batch [300/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [ 93/200]Batch [400/573] Loss: 0.086 Acc 97.292%\n",
      "Train Epoch [ 93/200]Batch [500/573] Loss: 0.086 Acc 97.280%\n",
      "Test Epoch [ 93/200]Batch [  0/204] Loss: 0.222 Acc 92.969%\n",
      "Test Epoch [ 93/200]Batch [100/204] Loss: 0.265 Acc 94.253%\n",
      "Test Epoch [ 93/200]Batch [200/204] Loss: 0.259 Acc 94.271%\n",
      "Train Epoch [ 94/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [ 94/200]Batch [100/573] Loss: 0.081 Acc 97.409%\n",
      "Train Epoch [ 94/200]Batch [200/573] Loss: 0.079 Acc 97.407%\n",
      "Train Epoch [ 94/200]Batch [300/573] Loss: 0.082 Acc 97.334%\n",
      "Train Epoch [ 94/200]Batch [400/573] Loss: 0.082 Acc 97.352%\n",
      "Train Epoch [ 94/200]Batch [500/573] Loss: 0.082 Acc 97.380%\n",
      "Test Epoch [ 94/200]Batch [  0/204] Loss: 0.319 Acc 92.188%\n",
      "Test Epoch [ 94/200]Batch [100/204] Loss: 0.306 Acc 93.170%\n",
      "Test Epoch [ 94/200]Batch [200/204] Loss: 0.299 Acc 93.264%\n",
      "Train Epoch [ 95/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [ 95/200]Batch [100/573] Loss: 0.079 Acc 97.509%\n",
      "Train Epoch [ 95/200]Batch [200/573] Loss: 0.079 Acc 97.415%\n",
      "Train Epoch [ 95/200]Batch [300/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [ 95/200]Batch [400/573] Loss: 0.080 Acc 97.495%\n",
      "Train Epoch [ 95/200]Batch [500/573] Loss: 0.083 Acc 97.450%\n",
      "Test Epoch [ 95/200]Batch [  0/204] Loss: 0.233 Acc 96.094%\n",
      "Test Epoch [ 95/200]Batch [100/204] Loss: 0.304 Acc 93.085%\n",
      "Test Epoch [ 95/200]Batch [200/204] Loss: 0.294 Acc 93.221%\n",
      "Train Epoch [ 96/200]Batch [  0/573] Loss: 0.099 Acc 96.094%\n",
      "Train Epoch [ 96/200]Batch [100/573] Loss: 0.075 Acc 97.424%\n",
      "Train Epoch [ 96/200]Batch [200/573] Loss: 0.078 Acc 97.516%\n",
      "Train Epoch [ 96/200]Batch [300/573] Loss: 0.079 Acc 97.498%\n",
      "Train Epoch [ 96/200]Batch [400/573] Loss: 0.083 Acc 97.372%\n",
      "Train Epoch [ 96/200]Batch [500/573] Loss: 0.082 Acc 97.405%\n",
      "Test Epoch [ 96/200]Batch [  0/204] Loss: 0.230 Acc 91.406%\n",
      "Test Epoch [ 96/200]Batch [100/204] Loss: 0.279 Acc 93.386%\n",
      "Test Epoch [ 96/200]Batch [200/204] Loss: 0.267 Acc 93.560%\n",
      "Train Epoch [ 97/200]Batch [  0/573] Loss: 0.069 Acc 96.875%\n",
      "Train Epoch [ 97/200]Batch [100/573] Loss: 0.087 Acc 97.192%\n",
      "Train Epoch [ 97/200]Batch [200/573] Loss: 0.085 Acc 97.306%\n",
      "Train Epoch [ 97/200]Batch [300/573] Loss: 0.084 Acc 97.355%\n",
      "Train Epoch [ 97/200]Batch [400/573] Loss: 0.084 Acc 97.323%\n",
      "Train Epoch [ 97/200]Batch [500/573] Loss: 0.084 Acc 97.338%\n",
      "Test Epoch [ 97/200]Batch [  0/204] Loss: 0.244 Acc 92.188%\n",
      "Test Epoch [ 97/200]Batch [100/204] Loss: 0.279 Acc 94.044%\n",
      "Test Epoch [ 97/200]Batch [200/204] Loss: 0.271 Acc 94.096%\n",
      "Train Epoch [ 98/200]Batch [  0/573] Loss: 0.079 Acc 97.656%\n",
      "Train Epoch [ 98/200]Batch [100/573] Loss: 0.072 Acc 97.703%\n",
      "Train Epoch [ 98/200]Batch [200/573] Loss: 0.073 Acc 97.711%\n",
      "Train Epoch [ 98/200]Batch [300/573] Loss: 0.074 Acc 97.641%\n",
      "Train Epoch [ 98/200]Batch [400/573] Loss: 0.077 Acc 97.569%\n",
      "Train Epoch [ 98/200]Batch [500/573] Loss: 0.080 Acc 97.489%\n",
      "Test Epoch [ 98/200]Batch [  0/204] Loss: 0.169 Acc 95.312%\n",
      "Test Epoch [ 98/200]Batch [100/204] Loss: 0.234 Acc 94.392%\n",
      "Test Epoch [ 98/200]Batch [200/204] Loss: 0.228 Acc 94.477%\n",
      "Train Epoch [ 99/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [ 99/200]Batch [100/573] Loss: 0.071 Acc 97.718%\n",
      "Train Epoch [ 99/200]Batch [200/573] Loss: 0.074 Acc 97.730%\n",
      "Train Epoch [ 99/200]Batch [300/573] Loss: 0.076 Acc 97.659%\n",
      "Train Epoch [ 99/200]Batch [400/573] Loss: 0.080 Acc 97.520%\n",
      "Train Epoch [ 99/200]Batch [500/573] Loss: 0.080 Acc 97.499%\n",
      "Test Epoch [ 99/200]Batch [  0/204] Loss: 0.262 Acc 88.281%\n",
      "Test Epoch [ 99/200]Batch [100/204] Loss: 0.262 Acc 93.595%\n",
      "Test Epoch [ 99/200]Batch [200/204] Loss: 0.252 Acc 93.851%\n",
      "Train Epoch [100/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [100/200]Batch [100/573] Loss: 0.074 Acc 97.579%\n",
      "Train Epoch [100/200]Batch [200/573] Loss: 0.078 Acc 97.520%\n",
      "Train Epoch [100/200]Batch [300/573] Loss: 0.079 Acc 97.443%\n",
      "Train Epoch [100/200]Batch [400/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [100/200]Batch [500/573] Loss: 0.081 Acc 97.449%\n",
      "Test Epoch [100/200]Batch [  0/204] Loss: 0.197 Acc 94.531%\n",
      "Test Epoch [100/200]Batch [100/204] Loss: 0.261 Acc 93.928%\n",
      "Test Epoch [100/200]Batch [200/204] Loss: 0.251 Acc 94.135%\n",
      "Train Epoch [101/200]Batch [  0/573] Loss: 0.072 Acc 97.656%\n",
      "Train Epoch [101/200]Batch [100/573] Loss: 0.072 Acc 97.649%\n",
      "Train Epoch [101/200]Batch [200/573] Loss: 0.076 Acc 97.555%\n",
      "Train Epoch [101/200]Batch [300/573] Loss: 0.078 Acc 97.493%\n",
      "Train Epoch [101/200]Batch [400/573] Loss: 0.080 Acc 97.463%\n",
      "Train Epoch [101/200]Batch [500/573] Loss: 0.081 Acc 97.439%\n",
      "Test Epoch [101/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [101/200]Batch [100/204] Loss: 0.275 Acc 93.170%\n",
      "Test Epoch [101/200]Batch [200/204] Loss: 0.267 Acc 93.458%\n",
      "Train Epoch [102/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [102/200]Batch [100/573] Loss: 0.075 Acc 97.641%\n",
      "Train Epoch [102/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [102/200]Batch [300/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [102/200]Batch [400/573] Loss: 0.075 Acc 97.576%\n",
      "Train Epoch [102/200]Batch [500/573] Loss: 0.076 Acc 97.558%\n",
      "Test Epoch [102/200]Batch [  0/204] Loss: 0.252 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [100/204] Loss: 0.235 Acc 94.531%\n",
      "Test Epoch [102/200]Batch [200/204] Loss: 0.227 Acc 94.628%\n",
      "Train Epoch [103/200]Batch [  0/573] Loss: 0.017 Acc 100.000%\n",
      "Train Epoch [103/200]Batch [100/573] Loss: 0.069 Acc 97.819%\n",
      "Train Epoch [103/200]Batch [200/573] Loss: 0.070 Acc 97.812%\n",
      "Train Epoch [103/200]Batch [300/573] Loss: 0.071 Acc 97.794%\n",
      "Train Epoch [103/200]Batch [400/573] Loss: 0.073 Acc 97.719%\n",
      "Train Epoch [103/200]Batch [500/573] Loss: 0.075 Acc 97.627%\n",
      "Test Epoch [103/200]Batch [  0/204] Loss: 0.203 Acc 92.969%\n",
      "Test Epoch [103/200]Batch [100/204] Loss: 0.249 Acc 93.851%\n",
      "Test Epoch [103/200]Batch [200/204] Loss: 0.240 Acc 94.158%\n",
      "Train Epoch [104/200]Batch [  0/573] Loss: 0.111 Acc 96.875%\n",
      "Train Epoch [104/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [104/200]Batch [200/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [104/200]Batch [300/573] Loss: 0.075 Acc 97.638%\n",
      "Train Epoch [104/200]Batch [400/573] Loss: 0.076 Acc 97.611%\n",
      "Train Epoch [104/200]Batch [500/573] Loss: 0.077 Acc 97.555%\n",
      "Test Epoch [104/200]Batch [  0/204] Loss: 0.149 Acc 96.875%\n",
      "Test Epoch [104/200]Batch [100/204] Loss: 0.239 Acc 94.291%\n",
      "Test Epoch [104/200]Batch [200/204] Loss: 0.230 Acc 94.523%\n",
      "Train Epoch [105/200]Batch [  0/573] Loss: 0.089 Acc 96.875%\n",
      "Train Epoch [105/200]Batch [100/573] Loss: 0.079 Acc 97.440%\n",
      "Train Epoch [105/200]Batch [200/573] Loss: 0.081 Acc 97.450%\n",
      "Train Epoch [105/200]Batch [300/573] Loss: 0.079 Acc 97.493%\n",
      "Train Epoch [105/200]Batch [400/573] Loss: 0.079 Acc 97.489%\n",
      "Train Epoch [105/200]Batch [500/573] Loss: 0.079 Acc 97.493%\n",
      "Test Epoch [105/200]Batch [  0/204] Loss: 0.217 Acc 95.312%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [105/200]Batch [100/204] Loss: 0.239 Acc 94.423%\n",
      "Test Epoch [105/200]Batch [200/204] Loss: 0.229 Acc 94.430%\n",
      "Train Epoch [106/200]Batch [  0/573] Loss: 0.063 Acc 99.219%\n",
      "Train Epoch [106/200]Batch [100/573] Loss: 0.071 Acc 97.803%\n",
      "Train Epoch [106/200]Batch [200/573] Loss: 0.075 Acc 97.563%\n",
      "Train Epoch [106/200]Batch [300/573] Loss: 0.075 Acc 97.552%\n",
      "Train Epoch [106/200]Batch [400/573] Loss: 0.075 Acc 97.582%\n",
      "Train Epoch [106/200]Batch [500/573] Loss: 0.077 Acc 97.485%\n",
      "Test Epoch [106/200]Batch [  0/204] Loss: 0.207 Acc 95.312%\n",
      "Test Epoch [106/200]Batch [100/204] Loss: 0.240 Acc 93.943%\n",
      "Test Epoch [106/200]Batch [200/204] Loss: 0.233 Acc 94.119%\n",
      "Train Epoch [107/200]Batch [  0/573] Loss: 0.049 Acc 97.656%\n",
      "Train Epoch [107/200]Batch [100/573] Loss: 0.068 Acc 97.842%\n",
      "Train Epoch [107/200]Batch [200/573] Loss: 0.070 Acc 97.785%\n",
      "Train Epoch [107/200]Batch [300/573] Loss: 0.073 Acc 97.721%\n",
      "Train Epoch [107/200]Batch [400/573] Loss: 0.075 Acc 97.691%\n",
      "Train Epoch [107/200]Batch [500/573] Loss: 0.076 Acc 97.684%\n",
      "Test Epoch [107/200]Batch [  0/204] Loss: 0.270 Acc 94.531%\n",
      "Test Epoch [107/200]Batch [100/204] Loss: 0.280 Acc 93.472%\n",
      "Test Epoch [107/200]Batch [200/204] Loss: 0.274 Acc 93.672%\n",
      "Train Epoch [108/200]Batch [  0/573] Loss: 0.092 Acc 97.656%\n",
      "Train Epoch [108/200]Batch [100/573] Loss: 0.067 Acc 97.850%\n",
      "Train Epoch [108/200]Batch [200/573] Loss: 0.071 Acc 97.715%\n",
      "Train Epoch [108/200]Batch [300/573] Loss: 0.073 Acc 97.589%\n",
      "Train Epoch [108/200]Batch [400/573] Loss: 0.075 Acc 97.553%\n",
      "Train Epoch [108/200]Batch [500/573] Loss: 0.077 Acc 97.536%\n",
      "Test Epoch [108/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [108/200]Batch [100/204] Loss: 0.252 Acc 94.191%\n",
      "Test Epoch [108/200]Batch [200/204] Loss: 0.243 Acc 94.395%\n",
      "Train Epoch [109/200]Batch [  0/573] Loss: 0.065 Acc 98.438%\n",
      "Train Epoch [109/200]Batch [100/573] Loss: 0.094 Acc 97.022%\n",
      "Train Epoch [109/200]Batch [200/573] Loss: 0.085 Acc 97.299%\n",
      "Train Epoch [109/200]Batch [300/573] Loss: 0.081 Acc 97.433%\n",
      "Train Epoch [109/200]Batch [400/573] Loss: 0.080 Acc 97.477%\n",
      "Train Epoch [109/200]Batch [500/573] Loss: 0.080 Acc 97.475%\n",
      "Test Epoch [109/200]Batch [  0/204] Loss: 0.219 Acc 91.406%\n",
      "Test Epoch [109/200]Batch [100/204] Loss: 0.247 Acc 93.758%\n",
      "Test Epoch [109/200]Batch [200/204] Loss: 0.238 Acc 94.053%\n",
      "Train Epoch [110/200]Batch [  0/573] Loss: 0.071 Acc 96.875%\n",
      "Train Epoch [110/200]Batch [100/573] Loss: 0.071 Acc 97.532%\n",
      "Train Epoch [110/200]Batch [200/573] Loss: 0.072 Acc 97.590%\n",
      "Train Epoch [110/200]Batch [300/573] Loss: 0.072 Acc 97.599%\n",
      "Train Epoch [110/200]Batch [400/573] Loss: 0.075 Acc 97.535%\n",
      "Train Epoch [110/200]Batch [500/573] Loss: 0.075 Acc 97.544%\n",
      "Test Epoch [110/200]Batch [  0/204] Loss: 0.220 Acc 94.531%\n",
      "Test Epoch [110/200]Batch [100/204] Loss: 0.254 Acc 93.696%\n",
      "Test Epoch [110/200]Batch [200/204] Loss: 0.249 Acc 93.921%\n",
      "Train Epoch [111/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [111/200]Batch [100/573] Loss: 0.071 Acc 97.695%\n",
      "Train Epoch [111/200]Batch [200/573] Loss: 0.073 Acc 97.691%\n",
      "Train Epoch [111/200]Batch [300/573] Loss: 0.073 Acc 97.677%\n",
      "Train Epoch [111/200]Batch [400/573] Loss: 0.072 Acc 97.662%\n",
      "Train Epoch [111/200]Batch [500/573] Loss: 0.072 Acc 97.659%\n",
      "Test Epoch [111/200]Batch [  0/204] Loss: 0.268 Acc 94.531%\n",
      "Test Epoch [111/200]Batch [100/204] Loss: 0.263 Acc 93.959%\n",
      "Test Epoch [111/200]Batch [200/204] Loss: 0.252 Acc 94.135%\n",
      "Train Epoch [112/200]Batch [  0/573] Loss: 0.041 Acc 98.438%\n",
      "Train Epoch [112/200]Batch [100/573] Loss: 0.075 Acc 97.842%\n",
      "Train Epoch [112/200]Batch [200/573] Loss: 0.077 Acc 97.672%\n",
      "Train Epoch [112/200]Batch [300/573] Loss: 0.074 Acc 97.726%\n",
      "Train Epoch [112/200]Batch [400/573] Loss: 0.073 Acc 97.713%\n",
      "Train Epoch [112/200]Batch [500/573] Loss: 0.075 Acc 97.672%\n",
      "Test Epoch [112/200]Batch [  0/204] Loss: 0.289 Acc 92.188%\n",
      "Test Epoch [112/200]Batch [100/204] Loss: 0.283 Acc 93.626%\n",
      "Test Epoch [112/200]Batch [200/204] Loss: 0.272 Acc 93.797%\n",
      "Train Epoch [113/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [113/200]Batch [100/573] Loss: 0.072 Acc 97.772%\n",
      "Train Epoch [113/200]Batch [200/573] Loss: 0.076 Acc 97.590%\n",
      "Train Epoch [113/200]Batch [300/573] Loss: 0.076 Acc 97.565%\n",
      "Train Epoch [113/200]Batch [400/573] Loss: 0.076 Acc 97.547%\n",
      "Train Epoch [113/200]Batch [500/573] Loss: 0.076 Acc 97.578%\n",
      "Test Epoch [113/200]Batch [  0/204] Loss: 0.270 Acc 91.406%\n",
      "Test Epoch [113/200]Batch [100/204] Loss: 0.286 Acc 93.394%\n",
      "Test Epoch [113/200]Batch [200/204] Loss: 0.280 Acc 93.544%\n",
      "Train Epoch [114/200]Batch [  0/573] Loss: 0.076 Acc 97.656%\n",
      "Train Epoch [114/200]Batch [100/573] Loss: 0.071 Acc 97.587%\n",
      "Train Epoch [114/200]Batch [200/573] Loss: 0.069 Acc 97.750%\n",
      "Train Epoch [114/200]Batch [300/573] Loss: 0.070 Acc 97.742%\n",
      "Train Epoch [114/200]Batch [400/573] Loss: 0.071 Acc 97.748%\n",
      "Train Epoch [114/200]Batch [500/573] Loss: 0.071 Acc 97.717%\n",
      "Test Epoch [114/200]Batch [  0/204] Loss: 0.228 Acc 92.188%\n",
      "Test Epoch [114/200]Batch [100/204] Loss: 0.222 Acc 94.554%\n",
      "Test Epoch [114/200]Batch [200/204] Loss: 0.214 Acc 94.764%\n",
      "Train Epoch [115/200]Batch [  0/573] Loss: 0.058 Acc 98.438%\n",
      "Train Epoch [115/200]Batch [100/573] Loss: 0.064 Acc 97.873%\n",
      "Train Epoch [115/200]Batch [200/573] Loss: 0.071 Acc 97.699%\n",
      "Train Epoch [115/200]Batch [300/573] Loss: 0.074 Acc 97.597%\n",
      "Train Epoch [115/200]Batch [400/573] Loss: 0.077 Acc 97.541%\n",
      "Train Epoch [115/200]Batch [500/573] Loss: 0.077 Acc 97.531%\n",
      "Test Epoch [115/200]Batch [  0/204] Loss: 0.244 Acc 92.969%\n",
      "Test Epoch [115/200]Batch [100/204] Loss: 0.237 Acc 94.028%\n",
      "Test Epoch [115/200]Batch [200/204] Loss: 0.232 Acc 94.216%\n",
      "Train Epoch [116/200]Batch [  0/573] Loss: 0.090 Acc 97.656%\n",
      "Train Epoch [116/200]Batch [100/573] Loss: 0.067 Acc 97.826%\n",
      "Train Epoch [116/200]Batch [200/573] Loss: 0.073 Acc 97.602%\n",
      "Train Epoch [116/200]Batch [300/573] Loss: 0.072 Acc 97.669%\n",
      "Train Epoch [116/200]Batch [400/573] Loss: 0.070 Acc 97.732%\n",
      "Train Epoch [116/200]Batch [500/573] Loss: 0.070 Acc 97.745%\n",
      "Test Epoch [116/200]Batch [  0/204] Loss: 0.291 Acc 92.188%\n",
      "Test Epoch [116/200]Batch [100/204] Loss: 0.279 Acc 93.518%\n",
      "Test Epoch [116/200]Batch [200/204] Loss: 0.273 Acc 93.723%\n",
      "Train Epoch [117/200]Batch [  0/573] Loss: 0.075 Acc 98.438%\n",
      "Train Epoch [117/200]Batch [100/573] Loss: 0.072 Acc 97.734%\n",
      "Train Epoch [117/200]Batch [200/573] Loss: 0.073 Acc 97.683%\n",
      "Train Epoch [117/200]Batch [300/573] Loss: 0.071 Acc 97.755%\n",
      "Train Epoch [117/200]Batch [400/573] Loss: 0.071 Acc 97.730%\n",
      "Train Epoch [117/200]Batch [500/573] Loss: 0.071 Acc 97.723%\n",
      "Test Epoch [117/200]Batch [  0/204] Loss: 0.261 Acc 93.750%\n",
      "Test Epoch [117/200]Batch [100/204] Loss: 0.269 Acc 93.634%\n",
      "Test Epoch [117/200]Batch [200/204] Loss: 0.261 Acc 93.874%\n",
      "Train Epoch [118/200]Batch [  0/573] Loss: 0.030 Acc 98.438%\n",
      "Train Epoch [118/200]Batch [100/573] Loss: 0.072 Acc 97.679%\n",
      "Train Epoch [118/200]Batch [200/573] Loss: 0.075 Acc 97.536%\n",
      "Train Epoch [118/200]Batch [300/573] Loss: 0.074 Acc 97.560%\n",
      "Train Epoch [118/200]Batch [400/573] Loss: 0.073 Acc 97.582%\n",
      "Train Epoch [118/200]Batch [500/573] Loss: 0.074 Acc 97.549%\n",
      "Test Epoch [118/200]Batch [  0/204] Loss: 0.202 Acc 94.531%\n",
      "Test Epoch [118/200]Batch [100/204] Loss: 0.233 Acc 94.570%\n",
      "Test Epoch [118/200]Batch [200/204] Loss: 0.226 Acc 94.726%\n",
      "Train Epoch [119/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [119/200]Batch [100/573] Loss: 0.067 Acc 97.695%\n",
      "Train Epoch [119/200]Batch [200/573] Loss: 0.071 Acc 97.648%\n",
      "Train Epoch [119/200]Batch [300/573] Loss: 0.072 Acc 97.620%\n",
      "Train Epoch [119/200]Batch [400/573] Loss: 0.074 Acc 97.600%\n",
      "Train Epoch [119/200]Batch [500/573] Loss: 0.075 Acc 97.600%\n",
      "Test Epoch [119/200]Batch [  0/204] Loss: 0.238 Acc 94.531%\n",
      "Test Epoch [119/200]Batch [100/204] Loss: 0.270 Acc 93.495%\n",
      "Test Epoch [119/200]Batch [200/204] Loss: 0.265 Acc 93.571%\n",
      "Train Epoch [120/200]Batch [  0/573] Loss: 0.146 Acc 95.312%\n",
      "Train Epoch [120/200]Batch [100/573] Loss: 0.078 Acc 97.618%\n",
      "Train Epoch [120/200]Batch [200/573] Loss: 0.075 Acc 97.746%\n",
      "Train Epoch [120/200]Batch [300/573] Loss: 0.074 Acc 97.750%\n",
      "Train Epoch [120/200]Batch [400/573] Loss: 0.073 Acc 97.722%\n",
      "Train Epoch [120/200]Batch [500/573] Loss: 0.073 Acc 97.714%\n",
      "Test Epoch [120/200]Batch [  0/204] Loss: 0.223 Acc 93.750%\n",
      "Test Epoch [120/200]Batch [100/204] Loss: 0.260 Acc 93.827%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Epoch [120/200]Batch [200/204] Loss: 0.254 Acc 93.952%\n",
      "Train Epoch [121/200]Batch [  0/573] Loss: 0.036 Acc 97.656%\n",
      "Train Epoch [121/200]Batch [100/573] Loss: 0.068 Acc 97.780%\n",
      "Train Epoch [121/200]Batch [200/573] Loss: 0.070 Acc 97.730%\n",
      "Train Epoch [121/200]Batch [300/573] Loss: 0.069 Acc 97.765%\n",
      "Train Epoch [121/200]Batch [400/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [121/200]Batch [500/573] Loss: 0.071 Acc 97.720%\n",
      "Test Epoch [121/200]Batch [  0/204] Loss: 0.256 Acc 92.188%\n",
      "Test Epoch [121/200]Batch [100/204] Loss: 0.282 Acc 93.255%\n",
      "Test Epoch [121/200]Batch [200/204] Loss: 0.275 Acc 93.381%\n",
      "Train Epoch [122/200]Batch [  0/573] Loss: 0.040 Acc 99.219%\n",
      "Train Epoch [122/200]Batch [100/573] Loss: 0.086 Acc 97.370%\n",
      "Train Epoch [122/200]Batch [200/573] Loss: 0.077 Acc 97.582%\n",
      "Train Epoch [122/200]Batch [300/573] Loss: 0.074 Acc 97.659%\n",
      "Train Epoch [122/200]Batch [400/573] Loss: 0.074 Acc 97.703%\n",
      "Train Epoch [122/200]Batch [500/573] Loss: 0.074 Acc 97.672%\n",
      "Test Epoch [122/200]Batch [  0/204] Loss: 0.279 Acc 94.531%\n",
      "Test Epoch [122/200]Batch [100/204] Loss: 0.285 Acc 93.495%\n",
      "Test Epoch [122/200]Batch [200/204] Loss: 0.278 Acc 93.742%\n",
      "Train Epoch [123/200]Batch [  0/573] Loss: 0.117 Acc 96.875%\n",
      "Train Epoch [123/200]Batch [100/573] Loss: 0.064 Acc 98.089%\n",
      "Train Epoch [123/200]Batch [200/573] Loss: 0.067 Acc 97.878%\n",
      "Train Epoch [123/200]Batch [300/573] Loss: 0.065 Acc 97.921%\n",
      "Train Epoch [123/200]Batch [400/573] Loss: 0.067 Acc 97.855%\n",
      "Train Epoch [123/200]Batch [500/573] Loss: 0.067 Acc 97.857%\n",
      "Test Epoch [123/200]Batch [  0/204] Loss: 0.213 Acc 94.531%\n",
      "Test Epoch [123/200]Batch [100/204] Loss: 0.238 Acc 94.361%\n",
      "Test Epoch [123/200]Batch [200/204] Loss: 0.231 Acc 94.500%\n",
      "Train Epoch [124/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [124/200]Batch [100/573] Loss: 0.061 Acc 97.973%\n",
      "Train Epoch [124/200]Batch [200/573] Loss: 0.063 Acc 98.057%\n",
      "Train Epoch [124/200]Batch [300/573] Loss: 0.066 Acc 97.918%\n",
      "Train Epoch [124/200]Batch [400/573] Loss: 0.068 Acc 97.857%\n",
      "Train Epoch [124/200]Batch [500/573] Loss: 0.068 Acc 97.832%\n",
      "Test Epoch [124/200]Batch [  0/204] Loss: 0.217 Acc 96.094%\n",
      "Test Epoch [124/200]Batch [100/204] Loss: 0.274 Acc 93.023%\n",
      "Test Epoch [124/200]Batch [200/204] Loss: 0.267 Acc 93.167%\n",
      "Train Epoch [125/200]Batch [  0/573] Loss: 0.118 Acc 96.875%\n",
      "Train Epoch [125/200]Batch [100/573] Loss: 0.074 Acc 97.672%\n",
      "Train Epoch [125/200]Batch [200/573] Loss: 0.068 Acc 97.870%\n",
      "Train Epoch [125/200]Batch [300/573] Loss: 0.069 Acc 97.856%\n",
      "Train Epoch [125/200]Batch [400/573] Loss: 0.070 Acc 97.793%\n",
      "Train Epoch [125/200]Batch [500/573] Loss: 0.071 Acc 97.804%\n",
      "Test Epoch [125/200]Batch [  0/204] Loss: 0.266 Acc 91.406%\n",
      "Test Epoch [125/200]Batch [100/204] Loss: 0.249 Acc 93.905%\n",
      "Test Epoch [125/200]Batch [200/204] Loss: 0.245 Acc 93.937%\n",
      "Train Epoch [126/200]Batch [  0/573] Loss: 0.046 Acc 98.438%\n",
      "Train Epoch [126/200]Batch [100/573] Loss: 0.063 Acc 97.935%\n",
      "Train Epoch [126/200]Batch [200/573] Loss: 0.062 Acc 98.006%\n",
      "Train Epoch [126/200]Batch [300/573] Loss: 0.060 Acc 98.085%\n",
      "Train Epoch [126/200]Batch [400/573] Loss: 0.059 Acc 98.104%\n",
      "Train Epoch [126/200]Batch [500/573] Loss: 0.062 Acc 98.029%\n",
      "Test Epoch [126/200]Batch [  0/204] Loss: 0.221 Acc 94.531%\n",
      "Test Epoch [126/200]Batch [100/204] Loss: 0.278 Acc 93.572%\n",
      "Test Epoch [126/200]Batch [200/204] Loss: 0.272 Acc 93.719%\n",
      "Train Epoch [127/200]Batch [  0/573] Loss: 0.086 Acc 96.094%\n",
      "Train Epoch [127/200]Batch [100/573] Loss: 0.070 Acc 97.919%\n",
      "Train Epoch [127/200]Batch [200/573] Loss: 0.071 Acc 97.761%\n",
      "Train Epoch [127/200]Batch [300/573] Loss: 0.072 Acc 97.750%\n",
      "Train Epoch [127/200]Batch [400/573] Loss: 0.074 Acc 97.717%\n",
      "Train Epoch [127/200]Batch [500/573] Loss: 0.074 Acc 97.695%\n",
      "Test Epoch [127/200]Batch [  0/204] Loss: 0.245 Acc 94.531%\n",
      "Test Epoch [127/200]Batch [100/204] Loss: 0.224 Acc 94.593%\n",
      "Test Epoch [127/200]Batch [200/204] Loss: 0.218 Acc 94.702%\n",
      "Train Epoch [128/200]Batch [  0/573] Loss: 0.002 Acc 100.000%\n",
      "Train Epoch [128/200]Batch [100/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [128/200]Batch [200/573] Loss: 0.065 Acc 97.878%\n",
      "Train Epoch [128/200]Batch [300/573] Loss: 0.067 Acc 97.877%\n",
      "Train Epoch [128/200]Batch [400/573] Loss: 0.068 Acc 97.851%\n",
      "Train Epoch [128/200]Batch [500/573] Loss: 0.070 Acc 97.801%\n",
      "Test Epoch [128/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [128/200]Batch [100/204] Loss: 0.271 Acc 93.425%\n",
      "Test Epoch [128/200]Batch [200/204] Loss: 0.264 Acc 93.493%\n",
      "Train Epoch [129/200]Batch [  0/573] Loss: 0.043 Acc 98.438%\n",
      "Train Epoch [129/200]Batch [100/573] Loss: 0.071 Acc 97.765%\n",
      "Train Epoch [129/200]Batch [200/573] Loss: 0.069 Acc 97.781%\n",
      "Train Epoch [129/200]Batch [300/573] Loss: 0.068 Acc 97.846%\n",
      "Train Epoch [129/200]Batch [400/573] Loss: 0.070 Acc 97.719%\n",
      "Train Epoch [129/200]Batch [500/573] Loss: 0.074 Acc 97.650%\n",
      "Test Epoch [129/200]Batch [  0/204] Loss: 0.237 Acc 95.312%\n",
      "Test Epoch [129/200]Batch [100/204] Loss: 0.258 Acc 93.912%\n",
      "Test Epoch [129/200]Batch [200/204] Loss: 0.246 Acc 94.123%\n",
      "Train Epoch [130/200]Batch [  0/573] Loss: 0.121 Acc 96.094%\n",
      "Train Epoch [130/200]Batch [100/573] Loss: 0.065 Acc 97.950%\n",
      "Train Epoch [130/200]Batch [200/573] Loss: 0.063 Acc 98.018%\n",
      "Train Epoch [130/200]Batch [300/573] Loss: 0.067 Acc 97.882%\n",
      "Train Epoch [130/200]Batch [400/573] Loss: 0.071 Acc 97.756%\n",
      "Train Epoch [130/200]Batch [500/573] Loss: 0.069 Acc 97.803%\n",
      "Test Epoch [130/200]Batch [  0/204] Loss: 0.225 Acc 94.531%\n",
      "Test Epoch [130/200]Batch [100/204] Loss: 0.241 Acc 94.338%\n",
      "Test Epoch [130/200]Batch [200/204] Loss: 0.233 Acc 94.419%\n",
      "Train Epoch [131/200]Batch [  0/573] Loss: 0.081 Acc 97.656%\n",
      "Train Epoch [131/200]Batch [100/573] Loss: 0.067 Acc 97.726%\n",
      "Train Epoch [131/200]Batch [200/573] Loss: 0.069 Acc 97.707%\n",
      "Train Epoch [131/200]Batch [300/573] Loss: 0.070 Acc 97.726%\n",
      "Train Epoch [131/200]Batch [400/573] Loss: 0.069 Acc 97.785%\n",
      "Train Epoch [131/200]Batch [500/573] Loss: 0.068 Acc 97.806%\n",
      "Test Epoch [131/200]Batch [  0/204] Loss: 0.207 Acc 93.750%\n",
      "Test Epoch [131/200]Batch [100/204] Loss: 0.250 Acc 94.199%\n",
      "Test Epoch [131/200]Batch [200/204] Loss: 0.240 Acc 94.407%\n",
      "Train Epoch [132/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [132/200]Batch [100/573] Loss: 0.057 Acc 98.182%\n",
      "Train Epoch [132/200]Batch [200/573] Loss: 0.064 Acc 97.948%\n",
      "Train Epoch [132/200]Batch [300/573] Loss: 0.069 Acc 97.776%\n",
      "Train Epoch [132/200]Batch [400/573] Loss: 0.068 Acc 97.802%\n",
      "Train Epoch [132/200]Batch [500/573] Loss: 0.069 Acc 97.772%\n",
      "Test Epoch [132/200]Batch [  0/204] Loss: 0.200 Acc 96.094%\n",
      "Test Epoch [132/200]Batch [100/204] Loss: 0.241 Acc 94.245%\n",
      "Test Epoch [132/200]Batch [200/204] Loss: 0.236 Acc 94.298%\n",
      "Train Epoch [133/200]Batch [  0/573] Loss: 0.126 Acc 96.094%\n",
      "Train Epoch [133/200]Batch [100/573] Loss: 0.060 Acc 98.159%\n",
      "Train Epoch [133/200]Batch [200/573] Loss: 0.068 Acc 97.901%\n",
      "Train Epoch [133/200]Batch [300/573] Loss: 0.068 Acc 97.856%\n",
      "Train Epoch [133/200]Batch [400/573] Loss: 0.069 Acc 97.832%\n",
      "Train Epoch [133/200]Batch [500/573] Loss: 0.069 Acc 97.809%\n",
      "Test Epoch [133/200]Batch [  0/204] Loss: 0.212 Acc 94.531%\n",
      "Test Epoch [133/200]Batch [100/204] Loss: 0.268 Acc 93.858%\n",
      "Test Epoch [133/200]Batch [200/204] Loss: 0.263 Acc 94.003%\n",
      "Train Epoch [134/200]Batch [  0/573] Loss: 0.086 Acc 96.875%\n",
      "Train Epoch [134/200]Batch [100/573] Loss: 0.071 Acc 97.664%\n",
      "Train Epoch [134/200]Batch [200/573] Loss: 0.069 Acc 97.792%\n",
      "Train Epoch [134/200]Batch [300/573] Loss: 0.069 Acc 97.820%\n",
      "Train Epoch [134/200]Batch [400/573] Loss: 0.067 Acc 97.876%\n",
      "Train Epoch [134/200]Batch [500/573] Loss: 0.066 Acc 97.895%\n",
      "Test Epoch [134/200]Batch [  0/204] Loss: 0.210 Acc 94.531%\n",
      "Test Epoch [134/200]Batch [100/204] Loss: 0.267 Acc 93.472%\n",
      "Test Epoch [134/200]Batch [200/204] Loss: 0.257 Acc 93.707%\n",
      "Train Epoch [135/200]Batch [  0/573] Loss: 0.114 Acc 98.438%\n",
      "Train Epoch [135/200]Batch [100/573] Loss: 0.073 Acc 97.672%\n",
      "Train Epoch [135/200]Batch [200/573] Loss: 0.073 Acc 97.625%\n",
      "Train Epoch [135/200]Batch [300/573] Loss: 0.070 Acc 97.716%\n",
      "Train Epoch [135/200]Batch [400/573] Loss: 0.068 Acc 97.785%\n",
      "Train Epoch [135/200]Batch [500/573] Loss: 0.071 Acc 97.759%\n",
      "Test Epoch [135/200]Batch [  0/204] Loss: 0.194 Acc 95.312%\n",
      "Test Epoch [135/200]Batch [100/204] Loss: 0.261 Acc 93.472%\n",
      "Test Epoch [135/200]Batch [200/204] Loss: 0.255 Acc 93.711%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [136/200]Batch [  0/573] Loss: 0.062 Acc 98.438%\n",
      "Train Epoch [136/200]Batch [100/573] Loss: 0.067 Acc 97.896%\n",
      "Train Epoch [136/200]Batch [200/573] Loss: 0.069 Acc 97.893%\n",
      "Train Epoch [136/200]Batch [300/573] Loss: 0.068 Acc 97.916%\n",
      "Train Epoch [136/200]Batch [400/573] Loss: 0.067 Acc 97.931%\n",
      "Train Epoch [136/200]Batch [500/573] Loss: 0.068 Acc 97.903%\n",
      "Test Epoch [136/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [136/200]Batch [100/204] Loss: 0.239 Acc 94.175%\n",
      "Test Epoch [136/200]Batch [200/204] Loss: 0.232 Acc 94.360%\n",
      "Train Epoch [137/200]Batch [  0/573] Loss: 0.094 Acc 97.656%\n",
      "Train Epoch [137/200]Batch [100/573] Loss: 0.065 Acc 97.850%\n",
      "Train Epoch [137/200]Batch [200/573] Loss: 0.067 Acc 97.796%\n",
      "Train Epoch [137/200]Batch [300/573] Loss: 0.067 Acc 97.804%\n",
      "Train Epoch [137/200]Batch [400/573] Loss: 0.067 Acc 97.832%\n",
      "Train Epoch [137/200]Batch [500/573] Loss: 0.066 Acc 97.850%\n",
      "Test Epoch [137/200]Batch [  0/204] Loss: 0.149 Acc 96.094%\n",
      "Test Epoch [137/200]Batch [100/204] Loss: 0.238 Acc 94.199%\n",
      "Test Epoch [137/200]Batch [200/204] Loss: 0.231 Acc 94.352%\n",
      "Train Epoch [138/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [138/200]Batch [100/573] Loss: 0.058 Acc 98.136%\n",
      "Train Epoch [138/200]Batch [200/573] Loss: 0.064 Acc 97.967%\n",
      "Train Epoch [138/200]Batch [300/573] Loss: 0.064 Acc 97.916%\n",
      "Train Epoch [138/200]Batch [400/573] Loss: 0.066 Acc 97.843%\n",
      "Train Epoch [138/200]Batch [500/573] Loss: 0.066 Acc 97.868%\n",
      "Test Epoch [138/200]Batch [  0/204] Loss: 0.342 Acc 90.625%\n",
      "Test Epoch [138/200]Batch [100/204] Loss: 0.299 Acc 93.193%\n",
      "Test Epoch [138/200]Batch [200/204] Loss: 0.292 Acc 93.357%\n",
      "Train Epoch [139/200]Batch [  0/573] Loss: 0.047 Acc 97.656%\n",
      "Train Epoch [139/200]Batch [100/573] Loss: 0.063 Acc 97.865%\n",
      "Train Epoch [139/200]Batch [200/573] Loss: 0.064 Acc 97.847%\n",
      "Train Epoch [139/200]Batch [300/573] Loss: 0.067 Acc 97.729%\n",
      "Train Epoch [139/200]Batch [400/573] Loss: 0.067 Acc 97.728%\n",
      "Train Epoch [139/200]Batch [500/573] Loss: 0.068 Acc 97.730%\n",
      "Test Epoch [139/200]Batch [  0/204] Loss: 0.187 Acc 92.188%\n",
      "Test Epoch [139/200]Batch [100/204] Loss: 0.238 Acc 94.431%\n",
      "Test Epoch [139/200]Batch [200/204] Loss: 0.233 Acc 94.508%\n",
      "Train Epoch [140/200]Batch [  0/573] Loss: 0.046 Acc 97.656%\n",
      "Train Epoch [140/200]Batch [100/573] Loss: 0.064 Acc 97.811%\n",
      "Train Epoch [140/200]Batch [200/573] Loss: 0.063 Acc 97.866%\n",
      "Train Epoch [140/200]Batch [300/573] Loss: 0.063 Acc 97.921%\n",
      "Train Epoch [140/200]Batch [400/573] Loss: 0.063 Acc 97.898%\n",
      "Train Epoch [140/200]Batch [500/573] Loss: 0.064 Acc 97.929%\n",
      "Test Epoch [140/200]Batch [  0/204] Loss: 0.247 Acc 92.969%\n",
      "Test Epoch [140/200]Batch [100/204] Loss: 0.274 Acc 93.394%\n",
      "Test Epoch [140/200]Batch [200/204] Loss: 0.268 Acc 93.431%\n",
      "Train Epoch [141/200]Batch [  0/573] Loss: 0.139 Acc 97.656%\n",
      "Train Epoch [141/200]Batch [100/573] Loss: 0.068 Acc 97.850%\n",
      "Train Epoch [141/200]Batch [200/573] Loss: 0.068 Acc 97.831%\n",
      "Train Epoch [141/200]Batch [300/573] Loss: 0.067 Acc 97.877%\n",
      "Train Epoch [141/200]Batch [400/573] Loss: 0.068 Acc 97.869%\n",
      "Train Epoch [141/200]Batch [500/573] Loss: 0.068 Acc 97.879%\n",
      "Test Epoch [141/200]Batch [  0/204] Loss: 0.143 Acc 96.875%\n",
      "Test Epoch [141/200]Batch [100/204] Loss: 0.227 Acc 94.670%\n",
      "Test Epoch [141/200]Batch [200/204] Loss: 0.225 Acc 94.683%\n",
      "Train Epoch [142/200]Batch [  0/573] Loss: 0.071 Acc 97.656%\n",
      "Train Epoch [142/200]Batch [100/573] Loss: 0.070 Acc 97.649%\n",
      "Train Epoch [142/200]Batch [200/573] Loss: 0.069 Acc 97.769%\n",
      "Train Epoch [142/200]Batch [300/573] Loss: 0.068 Acc 97.791%\n",
      "Train Epoch [142/200]Batch [400/573] Loss: 0.067 Acc 97.828%\n",
      "Train Epoch [142/200]Batch [500/573] Loss: 0.066 Acc 97.845%\n",
      "Test Epoch [142/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [142/200]Batch [100/204] Loss: 0.264 Acc 93.974%\n",
      "Test Epoch [142/200]Batch [200/204] Loss: 0.258 Acc 93.995%\n",
      "Train Epoch [143/200]Batch [  0/573] Loss: 0.083 Acc 96.094%\n",
      "Train Epoch [143/200]Batch [100/573] Loss: 0.055 Acc 98.058%\n",
      "Train Epoch [143/200]Batch [200/573] Loss: 0.065 Acc 97.913%\n",
      "Train Epoch [143/200]Batch [300/573] Loss: 0.064 Acc 97.892%\n",
      "Train Epoch [143/200]Batch [400/573] Loss: 0.064 Acc 97.896%\n",
      "Train Epoch [143/200]Batch [500/573] Loss: 0.067 Acc 97.823%\n",
      "Test Epoch [143/200]Batch [  0/204] Loss: 0.199 Acc 94.531%\n",
      "Test Epoch [143/200]Batch [100/204] Loss: 0.269 Acc 93.735%\n",
      "Test Epoch [143/200]Batch [200/204] Loss: 0.263 Acc 93.719%\n",
      "Train Epoch [144/200]Batch [  0/573] Loss: 0.093 Acc 96.875%\n",
      "Train Epoch [144/200]Batch [100/573] Loss: 0.062 Acc 98.043%\n",
      "Train Epoch [144/200]Batch [200/573] Loss: 0.065 Acc 97.994%\n",
      "Train Epoch [144/200]Batch [300/573] Loss: 0.065 Acc 97.937%\n",
      "Train Epoch [144/200]Batch [400/573] Loss: 0.066 Acc 97.931%\n",
      "Train Epoch [144/200]Batch [500/573] Loss: 0.068 Acc 97.867%\n",
      "Test Epoch [144/200]Batch [  0/204] Loss: 0.197 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [100/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [144/200]Batch [200/204] Loss: 0.270 Acc 93.703%\n",
      "Train Epoch [145/200]Batch [  0/573] Loss: 0.073 Acc 96.094%\n",
      "Train Epoch [145/200]Batch [100/573] Loss: 0.059 Acc 98.105%\n",
      "Train Epoch [145/200]Batch [200/573] Loss: 0.061 Acc 98.068%\n",
      "Train Epoch [145/200]Batch [300/573] Loss: 0.063 Acc 98.038%\n",
      "Train Epoch [145/200]Batch [400/573] Loss: 0.061 Acc 98.044%\n",
      "Train Epoch [145/200]Batch [500/573] Loss: 0.063 Acc 98.026%\n",
      "Test Epoch [145/200]Batch [  0/204] Loss: 0.224 Acc 95.312%\n",
      "Test Epoch [145/200]Batch [100/204] Loss: 0.269 Acc 93.502%\n",
      "Test Epoch [145/200]Batch [200/204] Loss: 0.262 Acc 93.552%\n",
      "Train Epoch [146/200]Batch [  0/573] Loss: 0.020 Acc 100.000%\n",
      "Train Epoch [146/200]Batch [100/573] Loss: 0.056 Acc 98.089%\n",
      "Train Epoch [146/200]Batch [200/573] Loss: 0.062 Acc 97.983%\n",
      "Train Epoch [146/200]Batch [300/573] Loss: 0.064 Acc 97.916%\n",
      "Train Epoch [146/200]Batch [400/573] Loss: 0.068 Acc 97.857%\n",
      "Train Epoch [146/200]Batch [500/573] Loss: 0.068 Acc 97.826%\n",
      "Test Epoch [146/200]Batch [  0/204] Loss: 0.262 Acc 93.750%\n",
      "Test Epoch [146/200]Batch [100/204] Loss: 0.272 Acc 93.943%\n",
      "Test Epoch [146/200]Batch [200/204] Loss: 0.264 Acc 93.944%\n",
      "Train Epoch [147/200]Batch [  0/573] Loss: 0.041 Acc 97.656%\n",
      "Train Epoch [147/200]Batch [100/573] Loss: 0.063 Acc 98.051%\n",
      "Train Epoch [147/200]Batch [200/573] Loss: 0.067 Acc 97.870%\n",
      "Train Epoch [147/200]Batch [300/573] Loss: 0.065 Acc 97.885%\n",
      "Train Epoch [147/200]Batch [400/573] Loss: 0.063 Acc 97.943%\n",
      "Train Epoch [147/200]Batch [500/573] Loss: 0.064 Acc 97.909%\n",
      "Test Epoch [147/200]Batch [  0/204] Loss: 0.333 Acc 92.188%\n",
      "Test Epoch [147/200]Batch [100/204] Loss: 0.282 Acc 93.317%\n",
      "Test Epoch [147/200]Batch [200/204] Loss: 0.279 Acc 93.458%\n",
      "Train Epoch [148/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [148/200]Batch [100/573] Loss: 0.063 Acc 97.973%\n",
      "Train Epoch [148/200]Batch [200/573] Loss: 0.064 Acc 97.991%\n",
      "Train Epoch [148/200]Batch [300/573] Loss: 0.061 Acc 98.038%\n",
      "Train Epoch [148/200]Batch [400/573] Loss: 0.064 Acc 97.964%\n",
      "Train Epoch [148/200]Batch [500/573] Loss: 0.065 Acc 97.900%\n",
      "Test Epoch [148/200]Batch [  0/204] Loss: 0.377 Acc 90.625%\n",
      "Test Epoch [148/200]Batch [100/204] Loss: 0.289 Acc 92.775%\n",
      "Test Epoch [148/200]Batch [200/204] Loss: 0.280 Acc 92.930%\n",
      "Train Epoch [149/200]Batch [  0/573] Loss: 0.042 Acc 99.219%\n",
      "Train Epoch [149/200]Batch [100/573] Loss: 0.056 Acc 98.120%\n",
      "Train Epoch [149/200]Batch [200/573] Loss: 0.057 Acc 98.111%\n",
      "Train Epoch [149/200]Batch [300/573] Loss: 0.060 Acc 97.994%\n",
      "Train Epoch [149/200]Batch [400/573] Loss: 0.063 Acc 97.882%\n",
      "Train Epoch [149/200]Batch [500/573] Loss: 0.065 Acc 97.864%\n",
      "Test Epoch [149/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [149/200]Batch [100/204] Loss: 0.253 Acc 93.851%\n",
      "Test Epoch [149/200]Batch [200/204] Loss: 0.245 Acc 94.092%\n",
      "Train Epoch [150/200]Batch [  0/573] Loss: 0.086 Acc 97.656%\n",
      "Train Epoch [150/200]Batch [100/573] Loss: 0.062 Acc 97.958%\n",
      "Train Epoch [150/200]Batch [200/573] Loss: 0.062 Acc 98.057%\n",
      "Train Epoch [150/200]Batch [300/573] Loss: 0.063 Acc 97.978%\n",
      "Train Epoch [150/200]Batch [400/573] Loss: 0.062 Acc 98.003%\n",
      "Train Epoch [150/200]Batch [500/573] Loss: 0.062 Acc 98.040%\n",
      "Test Epoch [150/200]Batch [  0/204] Loss: 0.272 Acc 93.750%\n",
      "Test Epoch [150/200]Batch [100/204] Loss: 0.270 Acc 93.448%\n",
      "Test Epoch [150/200]Batch [200/204] Loss: 0.267 Acc 93.501%\n",
      "Train Epoch [151/200]Batch [  0/573] Loss: 0.078 Acc 96.875%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [151/200]Batch [100/573] Loss: 0.059 Acc 98.151%\n",
      "Train Epoch [151/200]Batch [200/573] Loss: 0.065 Acc 97.979%\n",
      "Train Epoch [151/200]Batch [300/573] Loss: 0.065 Acc 97.921%\n",
      "Train Epoch [151/200]Batch [400/573] Loss: 0.066 Acc 97.919%\n",
      "Train Epoch [151/200]Batch [500/573] Loss: 0.067 Acc 97.892%\n",
      "Test Epoch [151/200]Batch [  0/204] Loss: 0.222 Acc 93.750%\n",
      "Test Epoch [151/200]Batch [100/204] Loss: 0.305 Acc 93.116%\n",
      "Test Epoch [151/200]Batch [200/204] Loss: 0.296 Acc 93.198%\n",
      "Train Epoch [152/200]Batch [  0/573] Loss: 0.064 Acc 97.656%\n",
      "Train Epoch [152/200]Batch [100/573] Loss: 0.064 Acc 97.857%\n",
      "Train Epoch [152/200]Batch [200/573] Loss: 0.062 Acc 97.889%\n",
      "Train Epoch [152/200]Batch [300/573] Loss: 0.063 Acc 97.900%\n",
      "Train Epoch [152/200]Batch [400/573] Loss: 0.063 Acc 97.931%\n",
      "Train Epoch [152/200]Batch [500/573] Loss: 0.064 Acc 97.896%\n",
      "Test Epoch [152/200]Batch [  0/204] Loss: 0.244 Acc 93.750%\n",
      "Test Epoch [152/200]Batch [100/204] Loss: 0.251 Acc 93.765%\n",
      "Test Epoch [152/200]Batch [200/204] Loss: 0.244 Acc 94.014%\n",
      "Train Epoch [153/200]Batch [  0/573] Loss: 0.138 Acc 92.969%\n",
      "Train Epoch [153/200]Batch [100/573] Loss: 0.054 Acc 98.352%\n",
      "Train Epoch [153/200]Batch [200/573] Loss: 0.055 Acc 98.290%\n",
      "Train Epoch [153/200]Batch [300/573] Loss: 0.057 Acc 98.183%\n",
      "Train Epoch [153/200]Batch [400/573] Loss: 0.059 Acc 98.085%\n",
      "Train Epoch [153/200]Batch [500/573] Loss: 0.060 Acc 98.046%\n",
      "Test Epoch [153/200]Batch [  0/204] Loss: 0.245 Acc 92.969%\n",
      "Test Epoch [153/200]Batch [100/204] Loss: 0.247 Acc 94.137%\n",
      "Test Epoch [153/200]Batch [200/204] Loss: 0.239 Acc 94.282%\n",
      "Train Epoch [154/200]Batch [  0/573] Loss: 0.008 Acc 100.000%\n",
      "Train Epoch [154/200]Batch [100/573] Loss: 0.056 Acc 98.198%\n",
      "Train Epoch [154/200]Batch [200/573] Loss: 0.055 Acc 98.200%\n",
      "Train Epoch [154/200]Batch [300/573] Loss: 0.059 Acc 98.069%\n",
      "Train Epoch [154/200]Batch [400/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [154/200]Batch [500/573] Loss: 0.062 Acc 97.993%\n",
      "Test Epoch [154/200]Batch [  0/204] Loss: 0.215 Acc 93.750%\n",
      "Test Epoch [154/200]Batch [100/204] Loss: 0.261 Acc 93.727%\n",
      "Test Epoch [154/200]Batch [200/204] Loss: 0.252 Acc 93.731%\n",
      "Train Epoch [155/200]Batch [  0/573] Loss: 0.098 Acc 96.875%\n",
      "Train Epoch [155/200]Batch [100/573] Loss: 0.065 Acc 97.942%\n",
      "Train Epoch [155/200]Batch [200/573] Loss: 0.068 Acc 97.835%\n",
      "Train Epoch [155/200]Batch [300/573] Loss: 0.069 Acc 97.833%\n",
      "Train Epoch [155/200]Batch [400/573] Loss: 0.067 Acc 97.892%\n",
      "Train Epoch [155/200]Batch [500/573] Loss: 0.067 Acc 97.876%\n",
      "Test Epoch [155/200]Batch [  0/204] Loss: 0.280 Acc 92.188%\n",
      "Test Epoch [155/200]Batch [100/204] Loss: 0.268 Acc 93.479%\n",
      "Test Epoch [155/200]Batch [200/204] Loss: 0.263 Acc 93.703%\n",
      "Train Epoch [156/200]Batch [  0/573] Loss: 0.010 Acc 100.000%\n",
      "Train Epoch [156/200]Batch [100/573] Loss: 0.058 Acc 98.012%\n",
      "Train Epoch [156/200]Batch [200/573] Loss: 0.062 Acc 98.029%\n",
      "Train Epoch [156/200]Batch [300/573] Loss: 0.061 Acc 98.033%\n",
      "Train Epoch [156/200]Batch [400/573] Loss: 0.063 Acc 98.005%\n",
      "Train Epoch [156/200]Batch [500/573] Loss: 0.064 Acc 97.999%\n",
      "Test Epoch [156/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [156/200]Batch [100/204] Loss: 0.244 Acc 94.152%\n",
      "Test Epoch [156/200]Batch [200/204] Loss: 0.237 Acc 94.248%\n",
      "Train Epoch [157/200]Batch [  0/573] Loss: 0.020 Acc 99.219%\n",
      "Train Epoch [157/200]Batch [100/573] Loss: 0.053 Acc 98.345%\n",
      "Train Epoch [157/200]Batch [200/573] Loss: 0.057 Acc 98.165%\n",
      "Train Epoch [157/200]Batch [300/573] Loss: 0.060 Acc 98.053%\n",
      "Train Epoch [157/200]Batch [400/573] Loss: 0.060 Acc 98.063%\n",
      "Train Epoch [157/200]Batch [500/573] Loss: 0.059 Acc 98.098%\n",
      "Test Epoch [157/200]Batch [  0/204] Loss: 0.239 Acc 95.312%\n",
      "Test Epoch [157/200]Batch [100/204] Loss: 0.263 Acc 93.557%\n",
      "Test Epoch [157/200]Batch [200/204] Loss: 0.257 Acc 93.773%\n",
      "Train Epoch [158/200]Batch [  0/573] Loss: 0.073 Acc 98.438%\n",
      "Train Epoch [158/200]Batch [100/573] Loss: 0.062 Acc 97.989%\n",
      "Train Epoch [158/200]Batch [200/573] Loss: 0.066 Acc 97.882%\n",
      "Train Epoch [158/200]Batch [300/573] Loss: 0.065 Acc 97.874%\n",
      "Train Epoch [158/200]Batch [400/573] Loss: 0.066 Acc 97.882%\n",
      "Train Epoch [158/200]Batch [500/573] Loss: 0.065 Acc 97.928%\n",
      "Test Epoch [158/200]Batch [  0/204] Loss: 0.239 Acc 93.750%\n",
      "Test Epoch [158/200]Batch [100/204] Loss: 0.260 Acc 93.433%\n",
      "Test Epoch [158/200]Batch [200/204] Loss: 0.253 Acc 93.703%\n",
      "Train Epoch [159/200]Batch [  0/573] Loss: 0.068 Acc 96.094%\n",
      "Train Epoch [159/200]Batch [100/573] Loss: 0.058 Acc 97.997%\n",
      "Train Epoch [159/200]Batch [200/573] Loss: 0.059 Acc 98.088%\n",
      "Train Epoch [159/200]Batch [300/573] Loss: 0.061 Acc 98.004%\n",
      "Train Epoch [159/200]Batch [400/573] Loss: 0.062 Acc 97.999%\n",
      "Train Epoch [159/200]Batch [500/573] Loss: 0.062 Acc 98.006%\n",
      "Test Epoch [159/200]Batch [  0/204] Loss: 0.313 Acc 92.969%\n",
      "Test Epoch [159/200]Batch [100/204] Loss: 0.262 Acc 93.680%\n",
      "Test Epoch [159/200]Batch [200/204] Loss: 0.260 Acc 93.630%\n",
      "Train Epoch [160/200]Batch [  0/573] Loss: 0.018 Acc 100.000%\n",
      "Train Epoch [160/200]Batch [100/573] Loss: 0.053 Acc 98.252%\n",
      "Train Epoch [160/200]Batch [200/573] Loss: 0.057 Acc 98.103%\n",
      "Train Epoch [160/200]Batch [300/573] Loss: 0.057 Acc 98.110%\n",
      "Train Epoch [160/200]Batch [400/573] Loss: 0.060 Acc 98.005%\n",
      "Train Epoch [160/200]Batch [500/573] Loss: 0.061 Acc 97.998%\n",
      "Test Epoch [160/200]Batch [  0/204] Loss: 0.199 Acc 95.312%\n",
      "Test Epoch [160/200]Batch [100/204] Loss: 0.228 Acc 94.531%\n",
      "Test Epoch [160/200]Batch [200/204] Loss: 0.222 Acc 94.469%\n",
      "Train Epoch [161/200]Batch [  0/573] Loss: 0.052 Acc 97.656%\n",
      "Train Epoch [161/200]Batch [100/573] Loss: 0.061 Acc 98.043%\n",
      "Train Epoch [161/200]Batch [200/573] Loss: 0.062 Acc 97.979%\n",
      "Train Epoch [161/200]Batch [300/573] Loss: 0.063 Acc 97.937%\n",
      "Train Epoch [161/200]Batch [400/573] Loss: 0.062 Acc 97.991%\n",
      "Train Epoch [161/200]Batch [500/573] Loss: 0.061 Acc 98.045%\n",
      "Test Epoch [161/200]Batch [  0/204] Loss: 0.303 Acc 94.531%\n",
      "Test Epoch [161/200]Batch [100/204] Loss: 0.251 Acc 94.075%\n",
      "Test Epoch [161/200]Batch [200/204] Loss: 0.248 Acc 94.127%\n",
      "Train Epoch [162/200]Batch [  0/573] Loss: 0.025 Acc 99.219%\n",
      "Train Epoch [162/200]Batch [100/573] Loss: 0.050 Acc 98.407%\n",
      "Train Epoch [162/200]Batch [200/573] Loss: 0.056 Acc 98.193%\n",
      "Train Epoch [162/200]Batch [300/573] Loss: 0.057 Acc 98.178%\n",
      "Train Epoch [162/200]Batch [400/573] Loss: 0.059 Acc 98.118%\n",
      "Train Epoch [162/200]Batch [500/573] Loss: 0.059 Acc 98.091%\n",
      "Test Epoch [162/200]Batch [  0/204] Loss: 0.243 Acc 95.312%\n",
      "Test Epoch [162/200]Batch [100/204] Loss: 0.269 Acc 93.673%\n",
      "Test Epoch [162/200]Batch [200/204] Loss: 0.261 Acc 93.711%\n",
      "Train Epoch [163/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [163/200]Batch [100/573] Loss: 0.059 Acc 98.144%\n",
      "Train Epoch [163/200]Batch [200/573] Loss: 0.058 Acc 98.208%\n",
      "Train Epoch [163/200]Batch [300/573] Loss: 0.059 Acc 98.129%\n",
      "Train Epoch [163/200]Batch [400/573] Loss: 0.059 Acc 98.100%\n",
      "Train Epoch [163/200]Batch [500/573] Loss: 0.061 Acc 98.048%\n",
      "Test Epoch [163/200]Batch [  0/204] Loss: 0.257 Acc 92.188%\n",
      "Test Epoch [163/200]Batch [100/204] Loss: 0.269 Acc 93.518%\n",
      "Test Epoch [163/200]Batch [200/204] Loss: 0.264 Acc 93.579%\n",
      "Train Epoch [164/200]Batch [  0/573] Loss: 0.113 Acc 94.531%\n",
      "Train Epoch [164/200]Batch [100/573] Loss: 0.064 Acc 97.865%\n",
      "Train Epoch [164/200]Batch [200/573] Loss: 0.062 Acc 97.924%\n",
      "Train Epoch [164/200]Batch [300/573] Loss: 0.064 Acc 97.908%\n",
      "Train Epoch [164/200]Batch [400/573] Loss: 0.064 Acc 97.910%\n",
      "Train Epoch [164/200]Batch [500/573] Loss: 0.063 Acc 97.937%\n",
      "Test Epoch [164/200]Batch [  0/204] Loss: 0.337 Acc 94.531%\n",
      "Test Epoch [164/200]Batch [100/204] Loss: 0.278 Acc 93.472%\n",
      "Test Epoch [164/200]Batch [200/204] Loss: 0.270 Acc 93.606%\n",
      "Train Epoch [165/200]Batch [  0/573] Loss: 0.020 Acc 98.438%\n",
      "Train Epoch [165/200]Batch [100/573] Loss: 0.054 Acc 98.260%\n",
      "Train Epoch [165/200]Batch [200/573] Loss: 0.056 Acc 98.197%\n",
      "Train Epoch [165/200]Batch [300/573] Loss: 0.057 Acc 98.188%\n",
      "Train Epoch [165/200]Batch [400/573] Loss: 0.058 Acc 98.145%\n",
      "Train Epoch [165/200]Batch [500/573] Loss: 0.059 Acc 98.094%\n",
      "Test Epoch [165/200]Batch [  0/204] Loss: 0.215 Acc 92.188%\n",
      "Test Epoch [165/200]Batch [100/204] Loss: 0.253 Acc 94.369%\n",
      "Test Epoch [165/200]Batch [200/204] Loss: 0.244 Acc 94.364%\n",
      "Train Epoch [166/200]Batch [  0/573] Loss: 0.097 Acc 96.094%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [166/200]Batch [100/573] Loss: 0.062 Acc 98.012%\n",
      "Train Epoch [166/200]Batch [200/573] Loss: 0.061 Acc 98.014%\n",
      "Train Epoch [166/200]Batch [300/573] Loss: 0.060 Acc 97.986%\n",
      "Train Epoch [166/200]Batch [400/573] Loss: 0.061 Acc 97.986%\n",
      "Train Epoch [166/200]Batch [500/573] Loss: 0.062 Acc 97.992%\n",
      "Test Epoch [166/200]Batch [  0/204] Loss: 0.249 Acc 94.531%\n",
      "Test Epoch [166/200]Batch [100/204] Loss: 0.249 Acc 94.268%\n",
      "Test Epoch [166/200]Batch [200/204] Loss: 0.238 Acc 94.446%\n",
      "Train Epoch [167/200]Batch [  0/573] Loss: 0.044 Acc 97.656%\n",
      "Train Epoch [167/200]Batch [100/573] Loss: 0.056 Acc 98.105%\n",
      "Train Epoch [167/200]Batch [200/573] Loss: 0.060 Acc 98.018%\n",
      "Train Epoch [167/200]Batch [300/573] Loss: 0.062 Acc 97.955%\n",
      "Train Epoch [167/200]Batch [400/573] Loss: 0.063 Acc 97.956%\n",
      "Train Epoch [167/200]Batch [500/573] Loss: 0.062 Acc 97.953%\n",
      "Test Epoch [167/200]Batch [  0/204] Loss: 0.252 Acc 92.188%\n",
      "Test Epoch [167/200]Batch [100/204] Loss: 0.276 Acc 93.680%\n",
      "Test Epoch [167/200]Batch [200/204] Loss: 0.269 Acc 93.707%\n",
      "Train Epoch [168/200]Batch [  0/573] Loss: 0.102 Acc 95.312%\n",
      "Train Epoch [168/200]Batch [100/573] Loss: 0.064 Acc 97.989%\n",
      "Train Epoch [168/200]Batch [200/573] Loss: 0.061 Acc 98.041%\n",
      "Train Epoch [168/200]Batch [300/573] Loss: 0.061 Acc 98.069%\n",
      "Train Epoch [168/200]Batch [400/573] Loss: 0.059 Acc 98.149%\n",
      "Train Epoch [168/200]Batch [500/573] Loss: 0.059 Acc 98.119%\n",
      "Test Epoch [168/200]Batch [  0/204] Loss: 0.267 Acc 92.188%\n",
      "Test Epoch [168/200]Batch [100/204] Loss: 0.258 Acc 93.967%\n",
      "Test Epoch [168/200]Batch [200/204] Loss: 0.253 Acc 93.921%\n",
      "Train Epoch [169/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [169/200]Batch [100/573] Loss: 0.057 Acc 98.136%\n",
      "Train Epoch [169/200]Batch [200/573] Loss: 0.055 Acc 98.173%\n",
      "Train Epoch [169/200]Batch [300/573] Loss: 0.060 Acc 98.048%\n",
      "Train Epoch [169/200]Batch [400/573] Loss: 0.061 Acc 98.030%\n",
      "Train Epoch [169/200]Batch [500/573] Loss: 0.060 Acc 98.049%\n",
      "Test Epoch [169/200]Batch [  0/204] Loss: 0.285 Acc 91.406%\n",
      "Test Epoch [169/200]Batch [100/204] Loss: 0.301 Acc 93.193%\n",
      "Test Epoch [169/200]Batch [200/204] Loss: 0.289 Acc 93.291%\n",
      "Train Epoch [170/200]Batch [  0/573] Loss: 0.058 Acc 97.656%\n",
      "Train Epoch [170/200]Batch [100/573] Loss: 0.062 Acc 98.097%\n",
      "Train Epoch [170/200]Batch [200/573] Loss: 0.059 Acc 98.146%\n",
      "Train Epoch [170/200]Batch [300/573] Loss: 0.062 Acc 98.072%\n",
      "Train Epoch [170/200]Batch [400/573] Loss: 0.061 Acc 98.102%\n",
      "Train Epoch [170/200]Batch [500/573] Loss: 0.062 Acc 98.073%\n",
      "Test Epoch [170/200]Batch [  0/204] Loss: 0.198 Acc 94.531%\n",
      "Test Epoch [170/200]Batch [100/204] Loss: 0.245 Acc 94.361%\n",
      "Test Epoch [170/200]Batch [200/204] Loss: 0.238 Acc 94.368%\n",
      "Train Epoch [171/200]Batch [  0/573] Loss: 0.053 Acc 99.219%\n",
      "Train Epoch [171/200]Batch [100/573] Loss: 0.058 Acc 98.267%\n",
      "Train Epoch [171/200]Batch [200/573] Loss: 0.057 Acc 98.165%\n",
      "Train Epoch [171/200]Batch [300/573] Loss: 0.057 Acc 98.170%\n",
      "Train Epoch [171/200]Batch [400/573] Loss: 0.057 Acc 98.190%\n",
      "Train Epoch [171/200]Batch [500/573] Loss: 0.056 Acc 98.236%\n",
      "Test Epoch [171/200]Batch [  0/204] Loss: 0.200 Acc 93.750%\n",
      "Test Epoch [171/200]Batch [100/204] Loss: 0.233 Acc 94.531%\n",
      "Test Epoch [171/200]Batch [200/204] Loss: 0.224 Acc 94.694%\n",
      "Train Epoch [172/200]Batch [  0/573] Loss: 0.068 Acc 96.875%\n",
      "Train Epoch [172/200]Batch [100/573] Loss: 0.064 Acc 97.927%\n",
      "Train Epoch [172/200]Batch [200/573] Loss: 0.061 Acc 98.010%\n",
      "Train Epoch [172/200]Batch [300/573] Loss: 0.058 Acc 98.126%\n",
      "Train Epoch [172/200]Batch [400/573] Loss: 0.060 Acc 98.100%\n",
      "Train Epoch [172/200]Batch [500/573] Loss: 0.061 Acc 98.052%\n",
      "Test Epoch [172/200]Batch [  0/204] Loss: 0.248 Acc 92.969%\n",
      "Test Epoch [172/200]Batch [100/204] Loss: 0.245 Acc 94.121%\n",
      "Test Epoch [172/200]Batch [200/204] Loss: 0.239 Acc 94.166%\n",
      "Train Epoch [173/200]Batch [  0/573] Loss: 0.031 Acc 99.219%\n",
      "Train Epoch [173/200]Batch [100/573] Loss: 0.056 Acc 98.244%\n",
      "Train Epoch [173/200]Batch [200/573] Loss: 0.057 Acc 98.158%\n",
      "Train Epoch [173/200]Batch [300/573] Loss: 0.057 Acc 98.183%\n",
      "Train Epoch [173/200]Batch [400/573] Loss: 0.058 Acc 98.128%\n",
      "Train Epoch [173/200]Batch [500/573] Loss: 0.059 Acc 98.088%\n",
      "Test Epoch [173/200]Batch [  0/204] Loss: 0.205 Acc 94.531%\n",
      "Test Epoch [173/200]Batch [100/204] Loss: 0.253 Acc 93.588%\n",
      "Test Epoch [173/200]Batch [200/204] Loss: 0.247 Acc 93.614%\n",
      "Train Epoch [174/200]Batch [  0/573] Loss: 0.074 Acc 98.438%\n",
      "Train Epoch [174/200]Batch [100/573] Loss: 0.062 Acc 98.151%\n",
      "Train Epoch [174/200]Batch [200/573] Loss: 0.060 Acc 98.103%\n",
      "Train Epoch [174/200]Batch [300/573] Loss: 0.059 Acc 98.110%\n",
      "Train Epoch [174/200]Batch [400/573] Loss: 0.060 Acc 98.087%\n",
      "Train Epoch [174/200]Batch [500/573] Loss: 0.060 Acc 98.069%\n",
      "Test Epoch [174/200]Batch [  0/204] Loss: 0.249 Acc 92.969%\n",
      "Test Epoch [174/200]Batch [100/204] Loss: 0.297 Acc 93.054%\n",
      "Test Epoch [174/200]Batch [200/204] Loss: 0.293 Acc 93.120%\n",
      "Train Epoch [175/200]Batch [  0/573] Loss: 0.019 Acc 99.219%\n",
      "Train Epoch [175/200]Batch [100/573] Loss: 0.056 Acc 98.205%\n",
      "Train Epoch [175/200]Batch [200/573] Loss: 0.060 Acc 98.057%\n",
      "Train Epoch [175/200]Batch [300/573] Loss: 0.058 Acc 98.149%\n",
      "Train Epoch [175/200]Batch [400/573] Loss: 0.059 Acc 98.188%\n",
      "Train Epoch [175/200]Batch [500/573] Loss: 0.059 Acc 98.158%\n",
      "Test Epoch [175/200]Batch [  0/204] Loss: 0.249 Acc 93.750%\n",
      "Test Epoch [175/200]Batch [100/204] Loss: 0.262 Acc 93.680%\n",
      "Test Epoch [175/200]Batch [200/204] Loss: 0.256 Acc 93.793%\n",
      "Train Epoch [176/200]Batch [  0/573] Loss: 0.056 Acc 98.438%\n",
      "Train Epoch [176/200]Batch [100/573] Loss: 0.059 Acc 98.035%\n",
      "Train Epoch [176/200]Batch [200/573] Loss: 0.060 Acc 98.025%\n",
      "Train Epoch [176/200]Batch [300/573] Loss: 0.061 Acc 97.968%\n",
      "Train Epoch [176/200]Batch [400/573] Loss: 0.061 Acc 98.011%\n",
      "Train Epoch [176/200]Batch [500/573] Loss: 0.062 Acc 97.965%\n",
      "Test Epoch [176/200]Batch [  0/204] Loss: 0.245 Acc 92.969%\n",
      "Test Epoch [176/200]Batch [100/204] Loss: 0.261 Acc 93.472%\n",
      "Test Epoch [176/200]Batch [200/204] Loss: 0.256 Acc 93.672%\n",
      "Train Epoch [177/200]Batch [  0/573] Loss: 0.101 Acc 96.875%\n",
      "Train Epoch [177/200]Batch [100/573] Loss: 0.060 Acc 98.028%\n",
      "Train Epoch [177/200]Batch [200/573] Loss: 0.058 Acc 98.130%\n",
      "Train Epoch [177/200]Batch [300/573] Loss: 0.057 Acc 98.139%\n",
      "Train Epoch [177/200]Batch [400/573] Loss: 0.057 Acc 98.147%\n",
      "Train Epoch [177/200]Batch [500/573] Loss: 0.058 Acc 98.101%\n",
      "Test Epoch [177/200]Batch [  0/204] Loss: 0.199 Acc 92.969%\n",
      "Test Epoch [177/200]Batch [100/204] Loss: 0.235 Acc 94.268%\n",
      "Test Epoch [177/200]Batch [200/204] Loss: 0.233 Acc 94.267%\n",
      "Train Epoch [178/200]Batch [  0/573] Loss: 0.003 Acc 100.000%\n",
      "Train Epoch [178/200]Batch [100/573] Loss: 0.054 Acc 98.430%\n",
      "Train Epoch [178/200]Batch [200/573] Loss: 0.056 Acc 98.301%\n",
      "Train Epoch [178/200]Batch [300/573] Loss: 0.057 Acc 98.238%\n",
      "Train Epoch [178/200]Batch [400/573] Loss: 0.056 Acc 98.241%\n",
      "Train Epoch [178/200]Batch [500/573] Loss: 0.056 Acc 98.224%\n",
      "Test Epoch [178/200]Batch [  0/204] Loss: 0.292 Acc 92.969%\n",
      "Test Epoch [178/200]Batch [100/204] Loss: 0.303 Acc 92.853%\n",
      "Test Epoch [178/200]Batch [200/204] Loss: 0.297 Acc 92.965%\n",
      "Train Epoch [179/200]Batch [  0/573] Loss: 0.034 Acc 98.438%\n",
      "Train Epoch [179/200]Batch [100/573] Loss: 0.069 Acc 97.966%\n",
      "Train Epoch [179/200]Batch [200/573] Loss: 0.067 Acc 98.033%\n",
      "Train Epoch [179/200]Batch [300/573] Loss: 0.067 Acc 97.965%\n",
      "Train Epoch [179/200]Batch [400/573] Loss: 0.065 Acc 98.032%\n",
      "Train Epoch [179/200]Batch [500/573] Loss: 0.064 Acc 98.079%\n",
      "Test Epoch [179/200]Batch [  0/204] Loss: 0.195 Acc 95.312%\n",
      "Test Epoch [179/200]Batch [100/204] Loss: 0.258 Acc 93.998%\n",
      "Test Epoch [179/200]Batch [200/204] Loss: 0.253 Acc 93.983%\n",
      "Train Epoch [180/200]Batch [  0/573] Loss: 0.034 Acc 99.219%\n",
      "Train Epoch [180/200]Batch [100/573] Loss: 0.055 Acc 98.182%\n",
      "Train Epoch [180/200]Batch [200/573] Loss: 0.056 Acc 98.173%\n",
      "Train Epoch [180/200]Batch [300/573] Loss: 0.055 Acc 98.206%\n",
      "Train Epoch [180/200]Batch [400/573] Loss: 0.057 Acc 98.159%\n",
      "Train Epoch [180/200]Batch [500/573] Loss: 0.058 Acc 98.127%\n",
      "Test Epoch [180/200]Batch [  0/204] Loss: 0.256 Acc 94.531%\n",
      "Test Epoch [180/200]Batch [100/204] Loss: 0.243 Acc 94.183%\n",
      "Test Epoch [180/200]Batch [200/204] Loss: 0.235 Acc 94.360%\n",
      "Train Epoch [181/200]Batch [  0/573] Loss: 0.026 Acc 99.219%\n",
      "Train Epoch [181/200]Batch [100/573] Loss: 0.058 Acc 98.314%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [181/200]Batch [200/573] Loss: 0.053 Acc 98.356%\n",
      "Train Epoch [181/200]Batch [300/573] Loss: 0.056 Acc 98.269%\n",
      "Train Epoch [181/200]Batch [400/573] Loss: 0.057 Acc 98.231%\n",
      "Train Epoch [181/200]Batch [500/573] Loss: 0.058 Acc 98.190%\n",
      "Test Epoch [181/200]Batch [  0/204] Loss: 0.388 Acc 92.969%\n",
      "Test Epoch [181/200]Batch [100/204] Loss: 0.358 Acc 91.468%\n",
      "Test Epoch [181/200]Batch [200/204] Loss: 0.355 Acc 91.612%\n",
      "Train Epoch [182/200]Batch [  0/573] Loss: 0.035 Acc 98.438%\n",
      "Train Epoch [182/200]Batch [100/573] Loss: 0.053 Acc 98.314%\n",
      "Train Epoch [182/200]Batch [200/573] Loss: 0.053 Acc 98.270%\n",
      "Train Epoch [182/200]Batch [300/573] Loss: 0.053 Acc 98.274%\n",
      "Train Epoch [182/200]Batch [400/573] Loss: 0.055 Acc 98.213%\n",
      "Train Epoch [182/200]Batch [500/573] Loss: 0.056 Acc 98.186%\n",
      "Test Epoch [182/200]Batch [  0/204] Loss: 0.228 Acc 90.625%\n",
      "Test Epoch [182/200]Batch [100/204] Loss: 0.263 Acc 93.959%\n",
      "Test Epoch [182/200]Batch [200/204] Loss: 0.256 Acc 94.104%\n",
      "Train Epoch [183/200]Batch [  0/573] Loss: 0.030 Acc 99.219%\n",
      "Train Epoch [183/200]Batch [100/573] Loss: 0.058 Acc 98.097%\n",
      "Train Epoch [183/200]Batch [200/573] Loss: 0.059 Acc 98.095%\n",
      "Train Epoch [183/200]Batch [300/573] Loss: 0.058 Acc 98.108%\n",
      "Train Epoch [183/200]Batch [400/573] Loss: 0.057 Acc 98.116%\n",
      "Train Epoch [183/200]Batch [500/573] Loss: 0.058 Acc 98.115%\n",
      "Test Epoch [183/200]Batch [  0/204] Loss: 0.181 Acc 94.531%\n",
      "Test Epoch [183/200]Batch [100/204] Loss: 0.245 Acc 94.446%\n",
      "Test Epoch [183/200]Batch [200/204] Loss: 0.240 Acc 94.403%\n",
      "Train Epoch [184/200]Batch [  0/573] Loss: 0.071 Acc 98.438%\n",
      "Train Epoch [184/200]Batch [100/573] Loss: 0.061 Acc 98.128%\n",
      "Train Epoch [184/200]Batch [200/573] Loss: 0.060 Acc 98.134%\n",
      "Train Epoch [184/200]Batch [300/573] Loss: 0.060 Acc 98.123%\n",
      "Train Epoch [184/200]Batch [400/573] Loss: 0.060 Acc 98.110%\n",
      "Train Epoch [184/200]Batch [500/573] Loss: 0.060 Acc 98.093%\n",
      "Test Epoch [184/200]Batch [  0/204] Loss: 0.193 Acc 95.312%\n",
      "Test Epoch [184/200]Batch [100/204] Loss: 0.244 Acc 94.237%\n",
      "Test Epoch [184/200]Batch [200/204] Loss: 0.237 Acc 94.317%\n",
      "Train Epoch [185/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [185/200]Batch [100/573] Loss: 0.067 Acc 97.989%\n",
      "Train Epoch [185/200]Batch [200/573] Loss: 0.058 Acc 98.127%\n",
      "Train Epoch [185/200]Batch [300/573] Loss: 0.059 Acc 98.116%\n",
      "Train Epoch [185/200]Batch [400/573] Loss: 0.059 Acc 98.118%\n",
      "Train Epoch [185/200]Batch [500/573] Loss: 0.060 Acc 98.090%\n",
      "Test Epoch [185/200]Batch [  0/204] Loss: 0.195 Acc 93.750%\n",
      "Test Epoch [185/200]Batch [100/204] Loss: 0.252 Acc 93.835%\n",
      "Test Epoch [185/200]Batch [200/204] Loss: 0.244 Acc 93.964%\n",
      "Train Epoch [186/200]Batch [  0/573] Loss: 0.070 Acc 96.875%\n",
      "Train Epoch [186/200]Batch [100/573] Loss: 0.062 Acc 98.051%\n",
      "Train Epoch [186/200]Batch [200/573] Loss: 0.062 Acc 98.025%\n",
      "Train Epoch [186/200]Batch [300/573] Loss: 0.059 Acc 98.136%\n",
      "Train Epoch [186/200]Batch [400/573] Loss: 0.060 Acc 98.104%\n",
      "Train Epoch [186/200]Batch [500/573] Loss: 0.061 Acc 98.071%\n",
      "Test Epoch [186/200]Batch [  0/204] Loss: 0.294 Acc 93.750%\n",
      "Test Epoch [186/200]Batch [100/204] Loss: 0.275 Acc 93.533%\n",
      "Test Epoch [186/200]Batch [200/204] Loss: 0.270 Acc 93.707%\n",
      "Train Epoch [187/200]Batch [  0/573] Loss: 0.040 Acc 98.438%\n",
      "Train Epoch [187/200]Batch [100/573] Loss: 0.057 Acc 98.082%\n",
      "Train Epoch [187/200]Batch [200/573] Loss: 0.059 Acc 98.084%\n",
      "Train Epoch [187/200]Batch [300/573] Loss: 0.057 Acc 98.110%\n",
      "Train Epoch [187/200]Batch [400/573] Loss: 0.060 Acc 98.071%\n",
      "Train Epoch [187/200]Batch [500/573] Loss: 0.058 Acc 98.129%\n",
      "Test Epoch [187/200]Batch [  0/204] Loss: 0.253 Acc 96.094%\n",
      "Test Epoch [187/200]Batch [100/204] Loss: 0.253 Acc 94.230%\n",
      "Test Epoch [187/200]Batch [200/204] Loss: 0.244 Acc 94.279%\n",
      "Train Epoch [188/200]Batch [  0/573] Loss: 0.161 Acc 95.312%\n",
      "Train Epoch [188/200]Batch [100/573] Loss: 0.058 Acc 98.205%\n",
      "Train Epoch [188/200]Batch [200/573] Loss: 0.056 Acc 98.212%\n",
      "Train Epoch [188/200]Batch [300/573] Loss: 0.061 Acc 98.131%\n",
      "Train Epoch [188/200]Batch [400/573] Loss: 0.060 Acc 98.106%\n",
      "Train Epoch [188/200]Batch [500/573] Loss: 0.060 Acc 98.098%\n",
      "Test Epoch [188/200]Batch [  0/204] Loss: 0.306 Acc 91.406%\n",
      "Test Epoch [188/200]Batch [100/204] Loss: 0.269 Acc 93.920%\n",
      "Test Epoch [188/200]Batch [200/204] Loss: 0.260 Acc 94.088%\n",
      "Train Epoch [189/200]Batch [  0/573] Loss: 0.103 Acc 98.438%\n",
      "Train Epoch [189/200]Batch [100/573] Loss: 0.049 Acc 98.468%\n",
      "Train Epoch [189/200]Batch [200/573] Loss: 0.054 Acc 98.344%\n",
      "Train Epoch [189/200]Batch [300/573] Loss: 0.054 Acc 98.323%\n",
      "Train Epoch [189/200]Batch [400/573] Loss: 0.054 Acc 98.323%\n",
      "Train Epoch [189/200]Batch [500/573] Loss: 0.056 Acc 98.246%\n",
      "Test Epoch [189/200]Batch [  0/204] Loss: 0.249 Acc 92.969%\n",
      "Test Epoch [189/200]Batch [100/204] Loss: 0.244 Acc 94.044%\n",
      "Test Epoch [189/200]Batch [200/204] Loss: 0.237 Acc 94.158%\n",
      "Train Epoch [190/200]Batch [  0/573] Loss: 0.040 Acc 97.656%\n",
      "Train Epoch [190/200]Batch [100/573] Loss: 0.048 Acc 98.345%\n",
      "Train Epoch [190/200]Batch [200/573] Loss: 0.056 Acc 98.193%\n",
      "Train Epoch [190/200]Batch [300/573] Loss: 0.056 Acc 98.178%\n",
      "Train Epoch [190/200]Batch [400/573] Loss: 0.057 Acc 98.143%\n",
      "Train Epoch [190/200]Batch [500/573] Loss: 0.055 Acc 98.230%\n",
      "Test Epoch [190/200]Batch [  0/204] Loss: 0.232 Acc 95.312%\n",
      "Test Epoch [190/200]Batch [100/204] Loss: 0.272 Acc 93.588%\n",
      "Test Epoch [190/200]Batch [200/204] Loss: 0.266 Acc 93.505%\n",
      "Train Epoch [191/200]Batch [  0/573] Loss: 0.078 Acc 96.094%\n",
      "Train Epoch [191/200]Batch [100/573] Loss: 0.052 Acc 98.182%\n",
      "Train Epoch [191/200]Batch [200/573] Loss: 0.055 Acc 98.158%\n",
      "Train Epoch [191/200]Batch [300/573] Loss: 0.056 Acc 98.121%\n",
      "Train Epoch [191/200]Batch [400/573] Loss: 0.057 Acc 98.089%\n",
      "Train Epoch [191/200]Batch [500/573] Loss: 0.060 Acc 98.054%\n",
      "Test Epoch [191/200]Batch [  0/204] Loss: 0.275 Acc 89.844%\n",
      "Test Epoch [191/200]Batch [100/204] Loss: 0.295 Acc 93.046%\n",
      "Test Epoch [191/200]Batch [200/204] Loss: 0.284 Acc 93.249%\n",
      "Train Epoch [192/200]Batch [  0/573] Loss: 0.023 Acc 99.219%\n",
      "Train Epoch [192/200]Batch [100/573] Loss: 0.044 Acc 98.646%\n",
      "Train Epoch [192/200]Batch [200/573] Loss: 0.049 Acc 98.504%\n",
      "Train Epoch [192/200]Batch [300/573] Loss: 0.049 Acc 98.463%\n",
      "Train Epoch [192/200]Batch [400/573] Loss: 0.051 Acc 98.422%\n",
      "Train Epoch [192/200]Batch [500/573] Loss: 0.053 Acc 98.339%\n",
      "Test Epoch [192/200]Batch [  0/204] Loss: 0.246 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [100/204] Loss: 0.257 Acc 93.750%\n",
      "Test Epoch [192/200]Batch [200/204] Loss: 0.246 Acc 93.995%\n",
      "Train Epoch [193/200]Batch [  0/573] Loss: 0.054 Acc 98.438%\n",
      "Train Epoch [193/200]Batch [100/573] Loss: 0.058 Acc 98.113%\n",
      "Train Epoch [193/200]Batch [200/573] Loss: 0.057 Acc 98.181%\n",
      "Train Epoch [193/200]Batch [300/573] Loss: 0.054 Acc 98.292%\n",
      "Train Epoch [193/200]Batch [400/573] Loss: 0.055 Acc 98.287%\n",
      "Train Epoch [193/200]Batch [500/573] Loss: 0.056 Acc 98.229%\n",
      "Test Epoch [193/200]Batch [  0/204] Loss: 0.198 Acc 93.750%\n",
      "Test Epoch [193/200]Batch [100/204] Loss: 0.252 Acc 94.392%\n",
      "Test Epoch [193/200]Batch [200/204] Loss: 0.244 Acc 94.465%\n",
      "Train Epoch [194/200]Batch [  0/573] Loss: 0.091 Acc 97.656%\n",
      "Train Epoch [194/200]Batch [100/573] Loss: 0.051 Acc 98.391%\n",
      "Train Epoch [194/200]Batch [200/573] Loss: 0.050 Acc 98.418%\n",
      "Train Epoch [194/200]Batch [300/573] Loss: 0.051 Acc 98.373%\n",
      "Train Epoch [194/200]Batch [400/573] Loss: 0.052 Acc 98.350%\n",
      "Train Epoch [194/200]Batch [500/573] Loss: 0.054 Acc 98.275%\n",
      "Test Epoch [194/200]Batch [  0/204] Loss: 0.223 Acc 95.312%\n",
      "Test Epoch [194/200]Batch [100/204] Loss: 0.257 Acc 93.820%\n",
      "Test Epoch [194/200]Batch [200/204] Loss: 0.251 Acc 94.049%\n",
      "Train Epoch [195/200]Batch [  0/573] Loss: 0.164 Acc 96.094%\n",
      "Train Epoch [195/200]Batch [100/573] Loss: 0.059 Acc 98.291%\n",
      "Train Epoch [195/200]Batch [200/573] Loss: 0.059 Acc 98.208%\n",
      "Train Epoch [195/200]Batch [300/573] Loss: 0.060 Acc 98.165%\n",
      "Train Epoch [195/200]Batch [400/573] Loss: 0.059 Acc 98.171%\n",
      "Train Epoch [195/200]Batch [500/573] Loss: 0.060 Acc 98.146%\n",
      "Test Epoch [195/200]Batch [  0/204] Loss: 0.273 Acc 90.625%\n",
      "Test Epoch [195/200]Batch [100/204] Loss: 0.254 Acc 94.175%\n",
      "Test Epoch [195/200]Batch [200/204] Loss: 0.244 Acc 94.349%\n",
      "Train Epoch [196/200]Batch [  0/573] Loss: 0.092 Acc 95.312%\n",
      "Train Epoch [196/200]Batch [100/573] Loss: 0.054 Acc 98.236%\n",
      "Train Epoch [196/200]Batch [200/573] Loss: 0.055 Acc 98.212%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch [196/200]Batch [300/573] Loss: 0.058 Acc 98.142%\n",
      "Train Epoch [196/200]Batch [400/573] Loss: 0.059 Acc 98.102%\n",
      "Train Epoch [196/200]Batch [500/573] Loss: 0.058 Acc 98.129%\n",
      "Test Epoch [196/200]Batch [  0/204] Loss: 0.363 Acc 92.188%\n",
      "Test Epoch [196/200]Batch [100/204] Loss: 0.367 Acc 91.136%\n",
      "Test Epoch [196/200]Batch [200/204] Loss: 0.357 Acc 91.585%\n",
      "Train Epoch [197/200]Batch [  0/573] Loss: 0.101 Acc 96.094%\n",
      "Train Epoch [197/200]Batch [100/573] Loss: 0.052 Acc 98.321%\n",
      "Train Epoch [197/200]Batch [200/573] Loss: 0.051 Acc 98.356%\n",
      "Train Epoch [197/200]Batch [300/573] Loss: 0.052 Acc 98.295%\n",
      "Train Epoch [197/200]Batch [400/573] Loss: 0.051 Acc 98.336%\n",
      "Train Epoch [197/200]Batch [500/573] Loss: 0.052 Acc 98.319%\n",
      "Test Epoch [197/200]Batch [  0/204] Loss: 0.289 Acc 94.531%\n",
      "Test Epoch [197/200]Batch [100/204] Loss: 0.260 Acc 94.013%\n",
      "Test Epoch [197/200]Batch [200/204] Loss: 0.252 Acc 94.181%\n",
      "Train Epoch [198/200]Batch [  0/573] Loss: 0.079 Acc 98.438%\n",
      "Train Epoch [198/200]Batch [100/573] Loss: 0.051 Acc 98.391%\n",
      "Train Epoch [198/200]Batch [200/573] Loss: 0.053 Acc 98.329%\n",
      "Train Epoch [198/200]Batch [300/573] Loss: 0.053 Acc 98.308%\n",
      "Train Epoch [198/200]Batch [400/573] Loss: 0.053 Acc 98.297%\n",
      "Train Epoch [198/200]Batch [500/573] Loss: 0.053 Acc 98.325%\n",
      "Test Epoch [198/200]Batch [  0/204] Loss: 0.276 Acc 92.969%\n",
      "Test Epoch [198/200]Batch [100/204] Loss: 0.246 Acc 94.593%\n",
      "Test Epoch [198/200]Batch [200/204] Loss: 0.238 Acc 94.613%\n",
      "Train Epoch [199/200]Batch [  0/573] Loss: 0.084 Acc 96.875%\n",
      "Train Epoch [199/200]Batch [100/573] Loss: 0.049 Acc 98.422%\n",
      "Train Epoch [199/200]Batch [200/573] Loss: 0.049 Acc 98.476%\n",
      "Train Epoch [199/200]Batch [300/573] Loss: 0.052 Acc 98.365%\n",
      "Train Epoch [199/200]Batch [400/573] Loss: 0.053 Acc 98.344%\n",
      "Train Epoch [199/200]Batch [500/573] Loss: 0.054 Acc 98.294%\n",
      "Test Epoch [199/200]Batch [  0/204] Loss: 0.227 Acc 95.312%\n",
      "Test Epoch [199/200]Batch [100/204] Loss: 0.262 Acc 93.773%\n",
      "Test Epoch [199/200]Batch [200/204] Loss: 0.257 Acc 93.898%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0 \n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "for lr in tqdm_notebook(LRS):\n",
    "    for norm in tqdm_notebook(NORMS):\n",
    "        net =  WideResNet(depth=16, num_classes=10, widen_factor=2,dropout_rate=0.3,norm=norm).cuda()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "        train_loss_log =[]\n",
    "        train_acc_log = []\n",
    "        test_loss_log =[]\n",
    "        test_acc_log =[]\n",
    "\n",
    "        for epoch in tqdm_notebook(range(NUM_EPOCH)):\n",
    "            train(epoch)\n",
    "            test(epoch)\n",
    "\n",
    "        np.save(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr), train_loss_log)  \n",
    "        np.save(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr), test_loss_log)    \n",
    "        np.save(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr), train_acc_log)    \n",
    "        np.save(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr), test_acc_log)   \n",
    "        del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5347194af230473ab5047a320eae2c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582b9f273a3f4b619577340fcc547b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8218f280d914aef97efa22e6844f64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "LRS = [0.0001, 0.001]\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook([None,'BN', 'SN', 'MSN'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "        \n",
    "        ax = plt.subplot(2,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "                \n",
    "        ax = plt.subplot(2,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Act_Norm_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200c5d0e97cb4d4eb9874664e2843dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676c3ccd71dc492e9ecc4af6ad0699a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866d600a39fc421baefc29dbbe4bcf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook(['WN', 'SN', 'MSN'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "        \n",
    "        ax = plt.subplot(2,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "                \n",
    "        ax = plt.subplot(2,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Weight_reparam_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373b6bc7ca9c41bf94978167e16ce496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057e3deafc894efda224216f92774883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49264db767eb4f5c829ded2ec3613762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 0\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, lr in enumerate(tqdm_notebook(LRS)):    \n",
    "    for j, norm in enumerate(tqdm_notebook(['MSNTReLU', 'WNTReLU'])):\n",
    "        print(k)\n",
    "        train_loss_log = np.load(SAVE_PATH+\"WideResNet_Train_loss_{}_{}.npy\".format(norm,lr) )  \n",
    "        test_loss_log = np.load(SAVE_PATH+\"WideResNet_Test_loss_{}_{}.npy\".format(norm,lr))    \n",
    "        train_acc_log = np.load(SAVE_PATH+\"WideResNet_Train_Acc_{}_{}.npy\".format(norm,lr))    \n",
    "        test_acc_log= np.load(SAVE_PATH+\"WideResNet_Test_Acc_{}_{}.npy\".format(norm,lr))   \n",
    "\n",
    "        ax = plt.subplot(2,4,k+1)\n",
    "        plt.plot(train_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Loss', fontsize=18)     \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+2)\n",
    "        plt.plot(test_loss_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Loss', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+3)\n",
    "        plt.plot(train_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Train Accuracy', fontsize=18) \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "\n",
    "        ax = plt.subplot(2,4,k+4)\n",
    "        plt.plot(test_acc_log, lw=2.5, label=str(norm))\n",
    "        plt.xlabel('Iterations', fontsize=18)\n",
    "        plt.ylabel('Test Accuracy', fontsize=18)        \n",
    "        plt.legend(fontsize=18)\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Learning Rate ={}\".format(lr), fontsize=20);\n",
    "    k+= 4\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_PATH+'Weight_reparam_act_Results.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Weight_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fa01599f2701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWideResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiden_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'WN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Anand/NeuralBlocks/models/wresnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, depth, num_classes, widen_factor, dropout_rate, norm)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wideLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_stages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/models/wresnet.py\u001b[0m in \u001b[0;36m_wideLayer\u001b[0;34m(self, out_planes, num_blocks, dropout_rate, stride)\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         \u001b[0mout_planes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                         \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                         stride=stride, padding=1, norm=self.norm, conv_last=True))\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_planes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_planes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/resblock.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, norm, kernel_size, stride, padding, reflection_pad, dropout_rate, conv_last)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodules\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         modules.append(ConvNormRelu(in_channels, out_channels, norm=norm, kernel_size=kernel_size,\n\u001b[0;32m---> 13\u001b[0;31m                              stride=1, padding=padding, conv_last=conv_last))\n\u001b[0m\u001b[1;32m     14\u001b[0m         modules.append(ConvNorm(out_channels, out_channels, norm=norm, kernel_size=kernel_size,\n\u001b[1;32m     15\u001b[0m                              stride=stride, padding=padding, conv_last= conv_last))\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/convnormrelu.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, norm, groups_size, conv_last, act)\u001b[0m\n\u001b[1;32m     46\u001b[0m             conv2d = WeightNormConv2d(in_channels, out_channels, kernel_size,\n\u001b[1;32m     47\u001b[0m                                           \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                                           bias, padding_mode)\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MWN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anand/NeuralBlocks/blocks/weightnorm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeightNormConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         self.conv = Weight_norm(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n\u001b[0m\u001b[1;32m     11\u001b[0m                               \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                               bias=bias, padding_mode=padding_mode))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Weight_norm' is not defined"
     ]
    }
   ],
   "source": [
    "WideResNet(depth=16, num_classes=10, widen_factor=2,dropout_rate=0.3,norm='WN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
